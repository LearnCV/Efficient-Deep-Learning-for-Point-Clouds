
**************************

[print_freq_iter]: 20

[evaluate]: 1

[base_lr]: 0.001

[batch_size]: 32

[val_freq_epoch]: 0.5

[num_classes]: 40

[weight_decay]: 0

[epochs]: 400

[checkpoint]: 

[workers]: 1

[decay_step]: 21

[save_path]: cls

[num_points]: 1024

[bn_momentum]: 0.9

[bn_decay]: 0.5

[bnm_clip]: 0.01

[input_channels]: 0

[lr_clip]: 1e-05

[lr_decay]: 0.7

[data_root]: ModelNet40

**************************

[epoch   1:   0/307] 	 train loss: 3.800659 	 lr: 0.00100
[epoch   1:  20/307] 	 train loss: 2.806335 	 lr: 0.00100
[epoch   1:  40/307] 	 train loss: 1.994241 	 lr: 0.00100
[epoch   1:  60/307] 	 train loss: 1.594051 	 lr: 0.00100
[epoch   1:  80/307] 	 train loss: 1.780689 	 lr: 0.00100
[epoch   1: 100/307] 	 train loss: 1.401145 	 lr: 0.00100
[epoch   1: 120/307] 	 train loss: 1.860615 	 lr: 0.00100
[epoch   1: 140/307] 	 train loss: 1.253624 	 lr: 0.00100

val loss: 2.303944 	 acc: 0.447326

[epoch   1: 160/307] 	 train loss: 1.073683 	 lr: 0.00100
[epoch   1: 180/307] 	 train loss: 1.290529 	 lr: 0.00100
[epoch   1: 200/307] 	 train loss: 1.441937 	 lr: 0.00100
[epoch   1: 220/307] 	 train loss: 1.055202 	 lr: 0.00100
[epoch   1: 240/307] 	 train loss: 1.124953 	 lr: 0.00100
[epoch   1: 260/307] 	 train loss: 1.314914 	 lr: 0.00100
[epoch   1: 280/307] 	 train loss: 1.418743 	 lr: 0.00100
[epoch   1: 300/307] 	 train loss: 1.601346 	 lr: 0.00100

val loss: 1.181049 	 acc: 0.655592

[epoch   2:   0/307] 	 train loss: 1.084379 	 lr: 0.00100
[epoch   2:  20/307] 	 train loss: 1.313236 	 lr: 0.00100
[epoch   2:  40/307] 	 train loss: 0.652000 	 lr: 0.00100
[epoch   2:  60/307] 	 train loss: 0.865636 	 lr: 0.00100
[epoch   2:  80/307] 	 train loss: 1.076753 	 lr: 0.00100
[epoch   2: 100/307] 	 train loss: 0.849297 	 lr: 0.00100
[epoch   2: 120/307] 	 train loss: 1.108629 	 lr: 0.00100
[epoch   2: 140/307] 	 train loss: 1.125260 	 lr: 0.00100

val loss: 0.776612 	 acc: 0.778768

[epoch   2: 160/307] 	 train loss: 0.772541 	 lr: 0.00100
[epoch   2: 180/307] 	 train loss: 1.032444 	 lr: 0.00100
[epoch   2: 200/307] 	 train loss: 0.892176 	 lr: 0.00100
[epoch   2: 220/307] 	 train loss: 1.082683 	 lr: 0.00100
[epoch   2: 240/307] 	 train loss: 0.996573 	 lr: 0.00100
[epoch   2: 260/307] 	 train loss: 0.962469 	 lr: 0.00100
[epoch   2: 280/307] 	 train loss: 0.860400 	 lr: 0.00100
[epoch   2: 300/307] 	 train loss: 0.741806 	 lr: 0.00100

val loss: 0.652065 	 acc: 0.808347

[epoch   3:   0/307] 	 train loss: 0.817903 	 lr: 0.00100
[epoch   3:  20/307] 	 train loss: 0.683478 	 lr: 0.00100
[epoch   3:  40/307] 	 train loss: 0.775316 	 lr: 0.00100
[epoch   3:  60/307] 	 train loss: 0.806294 	 lr: 0.00100
[epoch   3:  80/307] 	 train loss: 0.884936 	 lr: 0.00100
[epoch   3: 100/307] 	 train loss: 0.727706 	 lr: 0.00100
[epoch   3: 120/307] 	 train loss: 0.953972 	 lr: 0.00100
[epoch   3: 140/307] 	 train loss: 1.054282 	 lr: 0.00100

val loss: 0.645551 	 acc: 0.804295

[epoch   3: 160/307] 	 train loss: 0.700414 	 lr: 0.00100
[epoch   3: 180/307] 	 train loss: 0.937262 	 lr: 0.00100
[epoch   3: 200/307] 	 train loss: 0.610128 	 lr: 0.00100
[epoch   3: 220/307] 	 train loss: 0.508701 	 lr: 0.00100
[epoch   3: 240/307] 	 train loss: 0.922151 	 lr: 0.00100
[epoch   3: 260/307] 	 train loss: 0.517889 	 lr: 0.00100
[epoch   3: 280/307] 	 train loss: 0.882529 	 lr: 0.00100
[epoch   3: 300/307] 	 train loss: 0.560008 	 lr: 0.00100

val loss: 0.620904 	 acc: 0.801459

[epoch   4:   0/307] 	 train loss: 0.663301 	 lr: 0.00100
[epoch   4:  20/307] 	 train loss: 0.658695 	 lr: 0.00100
[epoch   4:  40/307] 	 train loss: 0.584234 	 lr: 0.00100
[epoch   4:  60/307] 	 train loss: 0.697977 	 lr: 0.00100
[epoch   4:  80/307] 	 train loss: 0.699061 	 lr: 0.00100
[epoch   4: 100/307] 	 train loss: 0.795630 	 lr: 0.00100
[epoch   4: 120/307] 	 train loss: 0.577346 	 lr: 0.00100
[epoch   4: 140/307] 	 train loss: 1.102728 	 lr: 0.00100

val loss: 0.570475 	 acc: 0.827391

[epoch   4: 160/307] 	 train loss: 0.457984 	 lr: 0.00100
[epoch   4: 180/307] 	 train loss: 0.532028 	 lr: 0.00100
[epoch   4: 200/307] 	 train loss: 0.915990 	 lr: 0.00100
[epoch   4: 220/307] 	 train loss: 0.419279 	 lr: 0.00100
[epoch   4: 240/307] 	 train loss: 0.538381 	 lr: 0.00100
[epoch   4: 260/307] 	 train loss: 0.751434 	 lr: 0.00100
[epoch   4: 280/307] 	 train loss: 0.398290 	 lr: 0.00100

val loss: 0.496775 	 acc: 0.845219

[epoch   4: 300/307] 	 train loss: 0.910654 	 lr: 0.00100
[epoch   5:   0/307] 	 train loss: 0.410556 	 lr: 0.00100
[epoch   5:  20/307] 	 train loss: 0.700032 	 lr: 0.00100
[epoch   5:  40/307] 	 train loss: 0.538123 	 lr: 0.00100
[epoch   5:  60/307] 	 train loss: 0.475722 	 lr: 0.00100
[epoch   5:  80/307] 	 train loss: 0.869616 	 lr: 0.00100
[epoch   5: 100/307] 	 train loss: 0.509270 	 lr: 0.00100
[epoch   5: 120/307] 	 train loss: 0.752591 	 lr: 0.00100
[epoch   5: 140/307] 	 train loss: 0.683699 	 lr: 0.00100

val loss: 0.499587 	 acc: 0.850081

[epoch   5: 160/307] 	 train loss: 0.506530 	 lr: 0.00100
[epoch   5: 180/307] 	 train loss: 0.721813 	 lr: 0.00100
[epoch   5: 200/307] 	 train loss: 0.338924 	 lr: 0.00100
[epoch   5: 220/307] 	 train loss: 0.697376 	 lr: 0.00100
[epoch   5: 240/307] 	 train loss: 0.824224 	 lr: 0.00100
[epoch   5: 260/307] 	 train loss: 0.446459 	 lr: 0.00100
[epoch   5: 280/307] 	 train loss: 0.429292 	 lr: 0.00100

val loss: 0.492365 	 acc: 0.848460

[epoch   5: 300/307] 	 train loss: 0.523165 	 lr: 0.00100
[epoch   6:   0/307] 	 train loss: 0.443622 	 lr: 0.00100
[epoch   6:  20/307] 	 train loss: 0.621730 	 lr: 0.00100
[epoch   6:  40/307] 	 train loss: 0.248946 	 lr: 0.00100
[epoch   6:  60/307] 	 train loss: 0.425553 	 lr: 0.00100
[epoch   6:  80/307] 	 train loss: 0.764562 	 lr: 0.00100
[epoch   6: 100/307] 	 train loss: 0.478820 	 lr: 0.00100
[epoch   6: 120/307] 	 train loss: 0.739975 	 lr: 0.00100
[epoch   6: 140/307] 	 train loss: 0.518799 	 lr: 0.00100

val loss: 0.484244 	 acc: 0.850486

[epoch   6: 160/307] 	 train loss: 0.499704 	 lr: 0.00100
[epoch   6: 180/307] 	 train loss: 0.718058 	 lr: 0.00100
[epoch   6: 200/307] 	 train loss: 0.667392 	 lr: 0.00100
[epoch   6: 220/307] 	 train loss: 0.431100 	 lr: 0.00100
[epoch   6: 240/307] 	 train loss: 0.546621 	 lr: 0.00100
[epoch   6: 260/307] 	 train loss: 0.507800 	 lr: 0.00100
[epoch   6: 280/307] 	 train loss: 0.528191 	 lr: 0.00100

val loss: 0.450388 	 acc: 0.851297

[epoch   6: 300/307] 	 train loss: 0.497749 	 lr: 0.00100
[epoch   7:   0/307] 	 train loss: 0.372732 	 lr: 0.00100
[epoch   7:  20/307] 	 train loss: 0.395820 	 lr: 0.00100
[epoch   7:  40/307] 	 train loss: 0.777835 	 lr: 0.00100
[epoch   7:  60/307] 	 train loss: 0.618719 	 lr: 0.00100
[epoch   7:  80/307] 	 train loss: 0.587671 	 lr: 0.00100
[epoch   7: 100/307] 	 train loss: 0.367825 	 lr: 0.00100
[epoch   7: 120/307] 	 train loss: 0.345315 	 lr: 0.00100
[epoch   7: 140/307] 	 train loss: 0.828281 	 lr: 0.00100

val loss: 0.461886 	 acc: 0.870340

[epoch   7: 160/307] 	 train loss: 0.679007 	 lr: 0.00100
[epoch   7: 180/307] 	 train loss: 0.521786 	 lr: 0.00100
[epoch   7: 200/307] 	 train loss: 0.317018 	 lr: 0.00100
[epoch   7: 220/307] 	 train loss: 0.346172 	 lr: 0.00100
[epoch   7: 240/307] 	 train loss: 0.247028 	 lr: 0.00100
[epoch   7: 260/307] 	 train loss: 1.084000 	 lr: 0.00100
[epoch   7: 280/307] 	 train loss: 0.288880 	 lr: 0.00100

val loss: 0.406154 	 acc: 0.879660

[epoch   7: 300/307] 	 train loss: 0.478186 	 lr: 0.00100
[epoch   8:   0/307] 	 train loss: 0.287039 	 lr: 0.00100
[epoch   8:  20/307] 	 train loss: 0.497516 	 lr: 0.00100
[epoch   8:  40/307] 	 train loss: 0.606812 	 lr: 0.00100
[epoch   8:  60/307] 	 train loss: 0.751331 	 lr: 0.00100
[epoch   8:  80/307] 	 train loss: 1.020804 	 lr: 0.00100
[epoch   8: 100/307] 	 train loss: 0.715241 	 lr: 0.00100
[epoch   8: 120/307] 	 train loss: 0.358106 	 lr: 0.00100

val loss: 0.408131 	 acc: 0.868314

[epoch   8: 140/307] 	 train loss: 0.724987 	 lr: 0.00100
[epoch   8: 160/307] 	 train loss: 0.465253 	 lr: 0.00100
[epoch   8: 180/307] 	 train loss: 0.510971 	 lr: 0.00100
[epoch   8: 200/307] 	 train loss: 0.613418 	 lr: 0.00100
[epoch   8: 220/307] 	 train loss: 0.543514 	 lr: 0.00100
[epoch   8: 240/307] 	 train loss: 0.621629 	 lr: 0.00100
[epoch   8: 260/307] 	 train loss: 0.394988 	 lr: 0.00100
[epoch   8: 280/307] 	 train loss: 0.780476 	 lr: 0.00100

val loss: 0.435966 	 acc: 0.870746

[epoch   8: 300/307] 	 train loss: 0.426884 	 lr: 0.00100
[epoch   9:   0/307] 	 train loss: 0.293266 	 lr: 0.00100
[epoch   9:  20/307] 	 train loss: 1.079477 	 lr: 0.00100
[epoch   9:  40/307] 	 train loss: 0.238102 	 lr: 0.00100
[epoch   9:  60/307] 	 train loss: 0.383026 	 lr: 0.00100
[epoch   9:  80/307] 	 train loss: 0.537888 	 lr: 0.00100
[epoch   9: 100/307] 	 train loss: 0.602773 	 lr: 0.00100
[epoch   9: 120/307] 	 train loss: 0.743826 	 lr: 0.00100

val loss: 0.377987 	 acc: 0.889384

[epoch   9: 140/307] 	 train loss: 0.254606 	 lr: 0.00100
[epoch   9: 160/307] 	 train loss: 0.415151 	 lr: 0.00100
[epoch   9: 180/307] 	 train loss: 0.465309 	 lr: 0.00100
[epoch   9: 200/307] 	 train loss: 1.003366 	 lr: 0.00100
[epoch   9: 220/307] 	 train loss: 0.374254 	 lr: 0.00100
[epoch   9: 240/307] 	 train loss: 0.462176 	 lr: 0.00100
[epoch   9: 260/307] 	 train loss: 0.610577 	 lr: 0.00100
[epoch   9: 280/307] 	 train loss: 0.368039 	 lr: 0.00100

val loss: 0.420351 	 acc: 0.865883

[epoch   9: 300/307] 	 train loss: 0.475284 	 lr: 0.00100
[epoch  10:   0/307] 	 train loss: 0.521706 	 lr: 0.00100
[epoch  10:  20/307] 	 train loss: 0.239299 	 lr: 0.00100
[epoch  10:  40/307] 	 train loss: 0.227222 	 lr: 0.00100
[epoch  10:  60/307] 	 train loss: 0.525300 	 lr: 0.00100
[epoch  10:  80/307] 	 train loss: 0.634917 	 lr: 0.00100
[epoch  10: 100/307] 	 train loss: 0.288705 	 lr: 0.00100
[epoch  10: 120/307] 	 train loss: 0.455235 	 lr: 0.00100

val loss: 0.427580 	 acc: 0.866694

[epoch  10: 140/307] 	 train loss: 0.544730 	 lr: 0.00100
[epoch  10: 160/307] 	 train loss: 0.409994 	 lr: 0.00100
[epoch  10: 180/307] 	 train loss: 0.261868 	 lr: 0.00100
[epoch  10: 200/307] 	 train loss: 0.891795 	 lr: 0.00100
[epoch  10: 220/307] 	 train loss: 0.418270 	 lr: 0.00100
[epoch  10: 240/307] 	 train loss: 0.701546 	 lr: 0.00100
[epoch  10: 260/307] 	 train loss: 0.928983 	 lr: 0.00100
[epoch  10: 280/307] 	 train loss: 0.610811 	 lr: 0.00100

val loss: 0.435738 	 acc: 0.865883

[epoch  10: 300/307] 	 train loss: 0.868591 	 lr: 0.00100
[epoch  11:   0/307] 	 train loss: 0.412786 	 lr: 0.00100
[epoch  11:  20/307] 	 train loss: 0.493495 	 lr: 0.00100
[epoch  11:  40/307] 	 train loss: 0.367629 	 lr: 0.00100
[epoch  11:  60/307] 	 train loss: 0.306949 	 lr: 0.00100
[epoch  11:  80/307] 	 train loss: 0.386620 	 lr: 0.00100
[epoch  11: 100/307] 	 train loss: 0.268008 	 lr: 0.00100
[epoch  11: 120/307] 	 train loss: 0.359366 	 lr: 0.00100

val loss: 0.373821 	 acc: 0.882496

[epoch  11: 140/307] 	 train loss: 0.240327 	 lr: 0.00100
[epoch  11: 160/307] 	 train loss: 0.265384 	 lr: 0.00100
[epoch  11: 180/307] 	 train loss: 0.436468 	 lr: 0.00100
[epoch  11: 200/307] 	 train loss: 0.284792 	 lr: 0.00100
[epoch  11: 220/307] 	 train loss: 0.262871 	 lr: 0.00100
[epoch  11: 240/307] 	 train loss: 0.645693 	 lr: 0.00100
[epoch  11: 260/307] 	 train loss: 0.440717 	 lr: 0.00100
[epoch  11: 280/307] 	 train loss: 0.406661 	 lr: 0.00100

val loss: 0.406298 	 acc: 0.875608

[epoch  11: 300/307] 	 train loss: 0.426740 	 lr: 0.00100
[epoch  12:   0/307] 	 train loss: 0.755258 	 lr: 0.00100
[epoch  12:  20/307] 	 train loss: 0.149170 	 lr: 0.00100
[epoch  12:  40/307] 	 train loss: 0.545205 	 lr: 0.00100
[epoch  12:  60/307] 	 train loss: 0.518408 	 lr: 0.00100
[epoch  12:  80/307] 	 train loss: 0.442457 	 lr: 0.00100
[epoch  12: 100/307] 	 train loss: 0.414905 	 lr: 0.00100
[epoch  12: 120/307] 	 train loss: 0.434867 	 lr: 0.00100

val loss: 0.411297 	 acc: 0.879254

[epoch  12: 140/307] 	 train loss: 0.306204 	 lr: 0.00100
[epoch  12: 160/307] 	 train loss: 0.671085 	 lr: 0.00100
[epoch  12: 180/307] 	 train loss: 0.657286 	 lr: 0.00100
[epoch  12: 200/307] 	 train loss: 0.679841 	 lr: 0.00100
[epoch  12: 220/307] 	 train loss: 0.597257 	 lr: 0.00100
[epoch  12: 240/307] 	 train loss: 0.606027 	 lr: 0.00100
[epoch  12: 260/307] 	 train loss: 0.444829 	 lr: 0.00100
[epoch  12: 280/307] 	 train loss: 0.471706 	 lr: 0.00100

val loss: 0.403186 	 acc: 0.880065

[epoch  12: 300/307] 	 train loss: 1.293814 	 lr: 0.00100
[epoch  13:   0/307] 	 train loss: 0.262551 	 lr: 0.00100
[epoch  13:  20/307] 	 train loss: 0.391860 	 lr: 0.00100
[epoch  13:  40/307] 	 train loss: 0.352993 	 lr: 0.00100
[epoch  13:  60/307] 	 train loss: 0.444486 	 lr: 0.00100
[epoch  13:  80/307] 	 train loss: 0.384242 	 lr: 0.00100
[epoch  13: 100/307] 	 train loss: 0.821591 	 lr: 0.00100
[epoch  13: 120/307] 	 train loss: 0.458928 	 lr: 0.00100

val loss: 0.390651 	 acc: 0.879660

[epoch  13: 140/307] 	 train loss: 0.489457 	 lr: 0.00100
[epoch  13: 160/307] 	 train loss: 0.661309 	 lr: 0.00100
[epoch  13: 180/307] 	 train loss: 0.348652 	 lr: 0.00100
[epoch  13: 200/307] 	 train loss: 0.537561 	 lr: 0.00100
[epoch  13: 220/307] 	 train loss: 0.557164 	 lr: 0.00100
[epoch  13: 240/307] 	 train loss: 0.575368 	 lr: 0.00100
[epoch  13: 260/307] 	 train loss: 0.481373 	 lr: 0.00100
[epoch  13: 280/307] 	 train loss: 0.493698 	 lr: 0.00100

val loss: 0.379229 	 acc: 0.883712

[epoch  13: 300/307] 	 train loss: 0.391065 	 lr: 0.00100
[epoch  14:   0/307] 	 train loss: 0.903371 	 lr: 0.00100
[epoch  14:  20/307] 	 train loss: 0.282636 	 lr: 0.00100
[epoch  14:  40/307] 	 train loss: 0.351880 	 lr: 0.00100
[epoch  14:  60/307] 	 train loss: 0.559648 	 lr: 0.00100
[epoch  14:  80/307] 	 train loss: 0.336355 	 lr: 0.00100
[epoch  14: 100/307] 	 train loss: 0.518614 	 lr: 0.00100
[epoch  14: 120/307] 	 train loss: 0.116164 	 lr: 0.00100

val loss: 0.367166 	 acc: 0.891815

[epoch  14: 140/307] 	 train loss: 0.309558 	 lr: 0.00100
[epoch  14: 160/307] 	 train loss: 0.607417 	 lr: 0.00100
[epoch  14: 180/307] 	 train loss: 0.514028 	 lr: 0.00100
[epoch  14: 200/307] 	 train loss: 0.313952 	 lr: 0.00100
[epoch  14: 220/307] 	 train loss: 0.213720 	 lr: 0.00100
[epoch  14: 240/307] 	 train loss: 0.536726 	 lr: 0.00100
[epoch  14: 260/307] 	 train loss: 0.600803 	 lr: 0.00100

val loss: 0.401571 	 acc: 0.876013

[epoch  14: 280/307] 	 train loss: 0.406728 	 lr: 0.00100
[epoch  14: 300/307] 	 train loss: 0.488160 	 lr: 0.00100
[epoch  15:   0/307] 	 train loss: 0.355427 	 lr: 0.00100
[epoch  15:  20/307] 	 train loss: 0.243552 	 lr: 0.00100
[epoch  15:  40/307] 	 train loss: 0.372296 	 lr: 0.00100
[epoch  15:  60/307] 	 train loss: 0.484430 	 lr: 0.00100
[epoch  15:  80/307] 	 train loss: 0.337276 	 lr: 0.00100
[epoch  15: 100/307] 	 train loss: 0.330414 	 lr: 0.00100
[epoch  15: 120/307] 	 train loss: 0.258930 	 lr: 0.00100

val loss: 0.359403 	 acc: 0.891005

[epoch  15: 140/307] 	 train loss: 0.554914 	 lr: 0.00100
[epoch  15: 160/307] 	 train loss: 0.350748 	 lr: 0.00100
[epoch  15: 180/307] 	 train loss: 0.547599 	 lr: 0.00100
[epoch  15: 200/307] 	 train loss: 0.792398 	 lr: 0.00100
[epoch  15: 220/307] 	 train loss: 0.555197 	 lr: 0.00100
[epoch  15: 240/307] 	 train loss: 0.451956 	 lr: 0.00100
[epoch  15: 260/307] 	 train loss: 0.442413 	 lr: 0.00100

val loss: 0.373957 	 acc: 0.889789

[epoch  15: 280/307] 	 train loss: 0.478111 	 lr: 0.00100
[epoch  15: 300/307] 	 train loss: 0.338243 	 lr: 0.00100
[epoch  16:   0/307] 	 train loss: 0.316336 	 lr: 0.00100
[epoch  16:  20/307] 	 train loss: 0.435824 	 lr: 0.00100
[epoch  16:  40/307] 	 train loss: 0.272063 	 lr: 0.00100
[epoch  16:  60/307] 	 train loss: 0.464241 	 lr: 0.00100
[epoch  16:  80/307] 	 train loss: 0.874212 	 lr: 0.00100
[epoch  16: 100/307] 	 train loss: 0.460353 	 lr: 0.00100
[epoch  16: 120/307] 	 train loss: 0.233396 	 lr: 0.00100

val loss: 0.351072 	 acc: 0.893436

[epoch  16: 140/307] 	 train loss: 0.556759 	 lr: 0.00100
[epoch  16: 160/307] 	 train loss: 0.681781 	 lr: 0.00100
[epoch  16: 180/307] 	 train loss: 0.669305 	 lr: 0.00100
[epoch  16: 200/307] 	 train loss: 0.246438 	 lr: 0.00100
[epoch  16: 220/307] 	 train loss: 0.361890 	 lr: 0.00100
[epoch  16: 240/307] 	 train loss: 0.350082 	 lr: 0.00100
[epoch  16: 260/307] 	 train loss: 0.446923 	 lr: 0.00100

val loss: 0.378931 	 acc: 0.883306

[epoch  16: 280/307] 	 train loss: 0.500425 	 lr: 0.00100
[epoch  16: 300/307] 	 train loss: 0.295861 	 lr: 0.00100
[epoch  17:   0/307] 	 train loss: 0.315062 	 lr: 0.00100
[epoch  17:  20/307] 	 train loss: 0.273219 	 lr: 0.00100
[epoch  17:  40/307] 	 train loss: 0.174358 	 lr: 0.00100
[epoch  17:  60/307] 	 train loss: 0.273577 	 lr: 0.00100
[epoch  17:  80/307] 	 train loss: 0.563901 	 lr: 0.00100
[epoch  17: 100/307] 	 train loss: 0.608748 	 lr: 0.00100
[epoch  17: 120/307] 	 train loss: 0.571480 	 lr: 0.00100

val loss: 0.383647 	 acc: 0.886548

[epoch  17: 140/307] 	 train loss: 0.370804 	 lr: 0.00100
[epoch  17: 160/307] 	 train loss: 0.622147 	 lr: 0.00100
[epoch  17: 180/307] 	 train loss: 0.274108 	 lr: 0.00100
[epoch  17: 200/307] 	 train loss: 0.366461 	 lr: 0.00100
[epoch  17: 220/307] 	 train loss: 0.349959 	 lr: 0.00100
[epoch  17: 240/307] 	 train loss: 0.387643 	 lr: 0.00100
[epoch  17: 260/307] 	 train loss: 0.613726 	 lr: 0.00100

val loss: 0.351926 	 acc: 0.891815

[epoch  17: 280/307] 	 train loss: 0.557441 	 lr: 0.00100
[epoch  17: 300/307] 	 train loss: 0.382540 	 lr: 0.00100
[epoch  18:   0/307] 	 train loss: 0.318338 	 lr: 0.00100
[epoch  18:  20/307] 	 train loss: 0.483824 	 lr: 0.00100
[epoch  18:  40/307] 	 train loss: 0.661332 	 lr: 0.00100
[epoch  18:  60/307] 	 train loss: 0.392095 	 lr: 0.00100
[epoch  18:  80/307] 	 train loss: 0.372154 	 lr: 0.00100
[epoch  18: 100/307] 	 train loss: 0.228375 	 lr: 0.00100

val loss: 0.372566 	 acc: 0.891815

[epoch  18: 120/307] 	 train loss: 0.278179 	 lr: 0.00100
[epoch  18: 140/307] 	 train loss: 0.089467 	 lr: 0.00100
[epoch  18: 160/307] 	 train loss: 0.308066 	 lr: 0.00100
[epoch  18: 180/307] 	 train loss: 0.261176 	 lr: 0.00100
[epoch  18: 200/307] 	 train loss: 0.249124 	 lr: 0.00100
[epoch  18: 220/307] 	 train loss: 0.391241 	 lr: 0.00100
[epoch  18: 240/307] 	 train loss: 0.194558 	 lr: 0.00100
[epoch  18: 260/307] 	 train loss: 0.594946 	 lr: 0.00100

val loss: 0.376836 	 acc: 0.875608

[epoch  18: 280/307] 	 train loss: 0.421447 	 lr: 0.00100
[epoch  18: 300/307] 	 train loss: 0.634236 	 lr: 0.00100
[epoch  19:   0/307] 	 train loss: 0.221136 	 lr: 0.00100
[epoch  19:  20/307] 	 train loss: 0.593442 	 lr: 0.00100
[epoch  19:  40/307] 	 train loss: 0.277703 	 lr: 0.00100
[epoch  19:  60/307] 	 train loss: 0.661604 	 lr: 0.00100
[epoch  19:  80/307] 	 train loss: 0.238696 	 lr: 0.00100
[epoch  19: 100/307] 	 train loss: 0.567510 	 lr: 0.00100

val loss: 0.371632 	 acc: 0.888169

[epoch  19: 120/307] 	 train loss: 0.259424 	 lr: 0.00100
[epoch  19: 140/307] 	 train loss: 0.319524 	 lr: 0.00100
[epoch  19: 160/307] 	 train loss: 0.231051 	 lr: 0.00100
[epoch  19: 180/307] 	 train loss: 0.244215 	 lr: 0.00100
[epoch  19: 200/307] 	 train loss: 0.652152 	 lr: 0.00100
[epoch  19: 220/307] 	 train loss: 0.393473 	 lr: 0.00100
[epoch  19: 240/307] 	 train loss: 0.332568 	 lr: 0.00100
[epoch  19: 260/307] 	 train loss: 0.575211 	 lr: 0.00100

val loss: 0.384412 	 acc: 0.884117

[epoch  19: 280/307] 	 train loss: 0.197596 	 lr: 0.00100
[epoch  19: 300/307] 	 train loss: 0.324470 	 lr: 0.00100
[epoch  20:   0/307] 	 train loss: 0.097034 	 lr: 0.00100
[epoch  20:  20/307] 	 train loss: 0.362327 	 lr: 0.00100
[epoch  20:  40/307] 	 train loss: 0.184712 	 lr: 0.00100
[epoch  20:  60/307] 	 train loss: 0.375151 	 lr: 0.00100
[epoch  20:  80/307] 	 train loss: 0.601379 	 lr: 0.00100
[epoch  20: 100/307] 	 train loss: 0.185153 	 lr: 0.00100

val loss: 0.402388 	 acc: 0.881280

[epoch  20: 120/307] 	 train loss: 0.312821 	 lr: 0.00100
[epoch  20: 140/307] 	 train loss: 0.229434 	 lr: 0.00100
[epoch  20: 160/307] 	 train loss: 0.365518 	 lr: 0.00100
[epoch  20: 180/307] 	 train loss: 0.257006 	 lr: 0.00100
[epoch  20: 200/307] 	 train loss: 0.218657 	 lr: 0.00100
[epoch  20: 220/307] 	 train loss: 0.227567 	 lr: 0.00100
[epoch  20: 240/307] 	 train loss: 0.378592 	 lr: 0.00100
[epoch  20: 260/307] 	 train loss: 0.478223 	 lr: 0.00100

val loss: 0.369177 	 acc: 0.893436

[epoch  20: 280/307] 	 train loss: 0.390683 	 lr: 0.00100
[epoch  20: 300/307] 	 train loss: 0.470971 	 lr: 0.00100
[epoch  21:   0/307] 	 train loss: 0.139326 	 lr: 0.00100
[epoch  21:  20/307] 	 train loss: 0.464379 	 lr: 0.00100
[epoch  21:  40/307] 	 train loss: 0.244447 	 lr: 0.00100
[epoch  21:  60/307] 	 train loss: 0.316103 	 lr: 0.00100
[epoch  21:  80/307] 	 train loss: 0.415919 	 lr: 0.00100
[epoch  21: 100/307] 	 train loss: 0.213896 	 lr: 0.00100

val loss: 0.360771 	 acc: 0.891815

[epoch  21: 120/307] 	 train loss: 0.154311 	 lr: 0.00100
[epoch  21: 140/307] 	 train loss: 0.191959 	 lr: 0.00100
[epoch  21: 160/307] 	 train loss: 0.408610 	 lr: 0.00100
[epoch  21: 180/307] 	 train loss: 0.354991 	 lr: 0.00100
[epoch  21: 200/307] 	 train loss: 0.488231 	 lr: 0.00100
[epoch  21: 220/307] 	 train loss: 0.723566 	 lr: 0.00100
[epoch  21: 240/307] 	 train loss: 0.392137 	 lr: 0.00100
[epoch  21: 260/307] 	 train loss: 0.192429 	 lr: 0.00100

val loss: 0.395949 	 acc: 0.887763

[epoch  21: 280/307] 	 train loss: 0.299485 	 lr: 0.00100
[epoch  21: 300/307] 	 train loss: 0.383297 	 lr: 0.00100
[epoch  22:   0/307] 	 train loss: 0.340373 	 lr: 0.00070
[epoch  22:  20/307] 	 train loss: 0.199424 	 lr: 0.00070
[epoch  22:  40/307] 	 train loss: 0.440703 	 lr: 0.00070
[epoch  22:  60/307] 	 train loss: 1.011118 	 lr: 0.00070
[epoch  22:  80/307] 	 train loss: 0.461697 	 lr: 0.00070
[epoch  22: 100/307] 	 train loss: 0.824969 	 lr: 0.00070

val loss: 0.346280 	 acc: 0.896272

[epoch  22: 120/307] 	 train loss: 0.504130 	 lr: 0.00070
[epoch  22: 140/307] 	 train loss: 0.589086 	 lr: 0.00070
[epoch  22: 160/307] 	 train loss: 0.204302 	 lr: 0.00070
[epoch  22: 180/307] 	 train loss: 0.393537 	 lr: 0.00070
[epoch  22: 200/307] 	 train loss: 0.353284 	 lr: 0.00070
[epoch  22: 220/307] 	 train loss: 0.464592 	 lr: 0.00070
[epoch  22: 240/307] 	 train loss: 0.656213 	 lr: 0.00070
[epoch  22: 260/307] 	 train loss: 0.181221 	 lr: 0.00070

val loss: 0.369607 	 acc: 0.891410

[epoch  22: 280/307] 	 train loss: 0.270548 	 lr: 0.00070
[epoch  22: 300/307] 	 train loss: 0.352829 	 lr: 0.00070
[epoch  23:   0/307] 	 train loss: 0.176245 	 lr: 0.00070
[epoch  23:  20/307] 	 train loss: 0.446068 	 lr: 0.00070
[epoch  23:  40/307] 	 train loss: 0.304439 	 lr: 0.00070
[epoch  23:  60/307] 	 train loss: 0.384051 	 lr: 0.00070
[epoch  23:  80/307] 	 train loss: 0.532724 	 lr: 0.00070
[epoch  23: 100/307] 	 train loss: 0.237675 	 lr: 0.00070

val loss: 0.318696 	 acc: 0.901540

[epoch  23: 120/307] 	 train loss: 0.366168 	 lr: 0.00070
[epoch  23: 140/307] 	 train loss: 0.225758 	 lr: 0.00070
[epoch  23: 160/307] 	 train loss: 0.149726 	 lr: 0.00070
[epoch  23: 180/307] 	 train loss: 0.309446 	 lr: 0.00070
[epoch  23: 200/307] 	 train loss: 0.336401 	 lr: 0.00070
[epoch  23: 220/307] 	 train loss: 0.505773 	 lr: 0.00070
[epoch  23: 240/307] 	 train loss: 0.405995 	 lr: 0.00070
[epoch  23: 260/307] 	 train loss: 0.118800 	 lr: 0.00070

val loss: 0.326556 	 acc: 0.905997

[epoch  23: 280/307] 	 train loss: 0.212359 	 lr: 0.00070
[epoch  23: 300/307] 	 train loss: 0.483623 	 lr: 0.00070
[epoch  24:   0/307] 	 train loss: 0.283187 	 lr: 0.00070
[epoch  24:  20/307] 	 train loss: 0.376348 	 lr: 0.00070
[epoch  24:  40/307] 	 train loss: 0.300671 	 lr: 0.00070
[epoch  24:  60/307] 	 train loss: 0.189337 	 lr: 0.00070
[epoch  24:  80/307] 	 train loss: 0.653359 	 lr: 0.00070
[epoch  24: 100/307] 	 train loss: 0.121251 	 lr: 0.00070

val loss: 0.326559 	 acc: 0.899919

[epoch  24: 120/307] 	 train loss: 0.299707 	 lr: 0.00070
[epoch  24: 140/307] 	 train loss: 0.409152 	 lr: 0.00070
[epoch  24: 160/307] 	 train loss: 0.203594 	 lr: 0.00070
[epoch  24: 180/307] 	 train loss: 0.245633 	 lr: 0.00070
[epoch  24: 200/307] 	 train loss: 0.188651 	 lr: 0.00070
[epoch  24: 220/307] 	 train loss: 0.203415 	 lr: 0.00070
[epoch  24: 240/307] 	 train loss: 0.429011 	 lr: 0.00070

val loss: 0.368107 	 acc: 0.886548

[epoch  24: 260/307] 	 train loss: 0.604356 	 lr: 0.00070
[epoch  24: 280/307] 	 train loss: 0.313380 	 lr: 0.00070
[epoch  24: 300/307] 	 train loss: 0.196511 	 lr: 0.00070
[epoch  25:   0/307] 	 train loss: 0.612531 	 lr: 0.00070
[epoch  25:  20/307] 	 train loss: 0.134049 	 lr: 0.00070
[epoch  25:  40/307] 	 train loss: 0.436839 	 lr: 0.00070
[epoch  25:  60/307] 	 train loss: 0.259260 	 lr: 0.00070
[epoch  25:  80/307] 	 train loss: 0.256230 	 lr: 0.00070
[epoch  25: 100/307] 	 train loss: 0.182815 	 lr: 0.00070

val loss: 0.359840 	 acc: 0.890194

[epoch  25: 120/307] 	 train loss: 0.207912 	 lr: 0.00070
[epoch  25: 140/307] 	 train loss: 0.263405 	 lr: 0.00070
[epoch  25: 160/307] 	 train loss: 0.175930 	 lr: 0.00070
[epoch  25: 180/307] 	 train loss: 0.313436 	 lr: 0.00070
[epoch  25: 200/307] 	 train loss: 0.295818 	 lr: 0.00070
[epoch  25: 220/307] 	 train loss: 0.124417 	 lr: 0.00070
[epoch  25: 240/307] 	 train loss: 0.375513 	 lr: 0.00070

val loss: 0.312107 	 acc: 0.903566

[epoch  25: 260/307] 	 train loss: 0.279165 	 lr: 0.00070
[epoch  25: 280/307] 	 train loss: 0.275695 	 lr: 0.00070
[epoch  25: 300/307] 	 train loss: 0.161852 	 lr: 0.00070
[epoch  26:   0/307] 	 train loss: 0.207284 	 lr: 0.00070
[epoch  26:  20/307] 	 train loss: 0.188279 	 lr: 0.00070
[epoch  26:  40/307] 	 train loss: 0.146414 	 lr: 0.00070
[epoch  26:  60/307] 	 train loss: 0.311539 	 lr: 0.00070
[epoch  26:  80/307] 	 train loss: 0.332246 	 lr: 0.00070
[epoch  26: 100/307] 	 train loss: 0.311731 	 lr: 0.00070

val loss: 0.346018 	 acc: 0.903160

[epoch  26: 120/307] 	 train loss: 0.458049 	 lr: 0.00070
[epoch  26: 140/307] 	 train loss: 0.165106 	 lr: 0.00070
[epoch  26: 160/307] 	 train loss: 0.267711 	 lr: 0.00070
[epoch  26: 180/307] 	 train loss: 0.525340 	 lr: 0.00070
[epoch  26: 200/307] 	 train loss: 0.456508 	 lr: 0.00070
[epoch  26: 220/307] 	 train loss: 0.209465 	 lr: 0.00070
[epoch  26: 240/307] 	 train loss: 0.580740 	 lr: 0.00070

val loss: 0.348604 	 acc: 0.887763

[epoch  26: 260/307] 	 train loss: 0.239412 	 lr: 0.00070
[epoch  26: 280/307] 	 train loss: 0.373607 	 lr: 0.00070
[epoch  26: 300/307] 	 train loss: 0.424981 	 lr: 0.00070
[epoch  27:   0/307] 	 train loss: 0.210548 	 lr: 0.00070
[epoch  27:  20/307] 	 train loss: 0.338730 	 lr: 0.00070
[epoch  27:  40/307] 	 train loss: 0.143668 	 lr: 0.00070
[epoch  27:  60/307] 	 train loss: 0.223315 	 lr: 0.00070
[epoch  27:  80/307] 	 train loss: 0.114475 	 lr: 0.00070
[epoch  27: 100/307] 	 train loss: 0.273456 	 lr: 0.00070

val loss: 0.323632 	 acc: 0.901945

[epoch  27: 120/307] 	 train loss: 0.343828 	 lr: 0.00070
[epoch  27: 140/307] 	 train loss: 0.405734 	 lr: 0.00070
[epoch  27: 160/307] 	 train loss: 0.128574 	 lr: 0.00070
[epoch  27: 180/307] 	 train loss: 0.316848 	 lr: 0.00070
[epoch  27: 200/307] 	 train loss: 0.336971 	 lr: 0.00070
[epoch  27: 220/307] 	 train loss: 0.136958 	 lr: 0.00070
[epoch  27: 240/307] 	 train loss: 0.297769 	 lr: 0.00070

val loss: 0.319264 	 acc: 0.905997

[epoch  27: 260/307] 	 train loss: 0.065738 	 lr: 0.00070
[epoch  27: 280/307] 	 train loss: 0.495302 	 lr: 0.00070
[epoch  27: 300/307] 	 train loss: 0.516764 	 lr: 0.00070
[epoch  28:   0/307] 	 train loss: 0.323955 	 lr: 0.00070
[epoch  28:  20/307] 	 train loss: 0.223753 	 lr: 0.00070
[epoch  28:  40/307] 	 train loss: 0.145782 	 lr: 0.00070
[epoch  28:  60/307] 	 train loss: 0.074242 	 lr: 0.00070
[epoch  28:  80/307] 	 train loss: 0.439671 	 lr: 0.00070

val loss: 0.317555 	 acc: 0.905592

[epoch  28: 100/307] 	 train loss: 0.220582 	 lr: 0.00070
[epoch  28: 120/307] 	 train loss: 0.188989 	 lr: 0.00070
[epoch  28: 140/307] 	 train loss: 0.254365 	 lr: 0.00070
[epoch  28: 160/307] 	 train loss: 0.622932 	 lr: 0.00070
[epoch  28: 180/307] 	 train loss: 0.186726 	 lr: 0.00070
[epoch  28: 200/307] 	 train loss: 0.705605 	 lr: 0.00070
[epoch  28: 220/307] 	 train loss: 0.696771 	 lr: 0.00070
[epoch  28: 240/307] 	 train loss: 0.135090 	 lr: 0.00070

val loss: 0.344077 	 acc: 0.888169

[epoch  28: 260/307] 	 train loss: 0.302107 	 lr: 0.00070
[epoch  28: 280/307] 	 train loss: 0.154760 	 lr: 0.00070
[epoch  28: 300/307] 	 train loss: 0.134656 	 lr: 0.00070
[epoch  29:   0/307] 	 train loss: 0.157869 	 lr: 0.00070
[epoch  29:  20/307] 	 train loss: 0.287542 	 lr: 0.00070
[epoch  29:  40/307] 	 train loss: 0.144302 	 lr: 0.00070
[epoch  29:  60/307] 	 train loss: 0.482022 	 lr: 0.00070
[epoch  29:  80/307] 	 train loss: 0.272116 	 lr: 0.00070

val loss: 0.317235 	 acc: 0.905997

[epoch  29: 100/307] 	 train loss: 0.284401 	 lr: 0.00070
[epoch  29: 120/307] 	 train loss: 0.157464 	 lr: 0.00070
[epoch  29: 140/307] 	 train loss: 0.215879 	 lr: 0.00070
[epoch  29: 160/307] 	 train loss: 0.225917 	 lr: 0.00070
[epoch  29: 180/307] 	 train loss: 0.406805 	 lr: 0.00070
[epoch  29: 200/307] 	 train loss: 0.208041 	 lr: 0.00070
[epoch  29: 220/307] 	 train loss: 0.336886 	 lr: 0.00070
[epoch  29: 240/307] 	 train loss: 0.359193 	 lr: 0.00070

val loss: 0.321929 	 acc: 0.910859

saved model with accuracy %0.6f:  0.9108589951377634
[epoch  29: 260/307] 	 train loss: 0.214305 	 lr: 0.00070
[epoch  29: 280/307] 	 train loss: 0.383743 	 lr: 0.00070
[epoch  29: 300/307] 	 train loss: 0.468158 	 lr: 0.00070
[epoch  30:   0/307] 	 train loss: 0.241660 	 lr: 0.00070
[epoch  30:  20/307] 	 train loss: 0.346484 	 lr: 0.00070
[epoch  30:  40/307] 	 train loss: 0.372600 	 lr: 0.00070
[epoch  30:  60/307] 	 train loss: 0.082421 	 lr: 0.00070
[epoch  30:  80/307] 	 train loss: 0.258754 	 lr: 0.00070

val loss: 0.334633 	 acc: 0.905186

[epoch  30: 100/307] 	 train loss: 0.225213 	 lr: 0.00070
[epoch  30: 120/307] 	 train loss: 0.537105 	 lr: 0.00070
[epoch  30: 140/307] 	 train loss: 0.365204 	 lr: 0.00070
[epoch  30: 160/307] 	 train loss: 0.124451 	 lr: 0.00070
[epoch  30: 180/307] 	 train loss: 0.365803 	 lr: 0.00070
[epoch  30: 200/307] 	 train loss: 0.396139 	 lr: 0.00070
[epoch  30: 220/307] 	 train loss: 0.348472 	 lr: 0.00070
[epoch  30: 240/307] 	 train loss: 0.219642 	 lr: 0.00070

val loss: 0.354117 	 acc: 0.887763

[epoch  30: 260/307] 	 train loss: 0.336024 	 lr: 0.00070
[epoch  30: 280/307] 	 train loss: 0.202098 	 lr: 0.00070
[epoch  30: 300/307] 	 train loss: 0.406014 	 lr: 0.00070
[epoch  31:   0/307] 	 train loss: 0.566590 	 lr: 0.00070
[epoch  31:  20/307] 	 train loss: 0.234638 	 lr: 0.00070
[epoch  31:  40/307] 	 train loss: 0.262171 	 lr: 0.00070
[epoch  31:  60/307] 	 train loss: 0.163370 	 lr: 0.00070
[epoch  31:  80/307] 	 train loss: 0.159684 	 lr: 0.00070

val loss: 0.337885 	 acc: 0.900729

[epoch  31: 100/307] 	 train loss: 0.126297 	 lr: 0.00070
[epoch  31: 120/307] 	 train loss: 0.200815 	 lr: 0.00070
[epoch  31: 140/307] 	 train loss: 0.408208 	 lr: 0.00070
[epoch  31: 160/307] 	 train loss: 0.555017 	 lr: 0.00070
[epoch  31: 180/307] 	 train loss: 0.110212 	 lr: 0.00070
[epoch  31: 200/307] 	 train loss: 0.094780 	 lr: 0.00070
[epoch  31: 220/307] 	 train loss: 0.298813 	 lr: 0.00070
[epoch  31: 240/307] 	 train loss: 0.266752 	 lr: 0.00070

val loss: 0.316691 	 acc: 0.905186

[epoch  31: 260/307] 	 train loss: 0.177599 	 lr: 0.00070
[epoch  31: 280/307] 	 train loss: 0.268760 	 lr: 0.00070
[epoch  31: 300/307] 	 train loss: 0.101682 	 lr: 0.00070
[epoch  32:   0/307] 	 train loss: 0.362276 	 lr: 0.00070
[epoch  32:  20/307] 	 train loss: 0.421308 	 lr: 0.00070
[epoch  32:  40/307] 	 train loss: 0.492775 	 lr: 0.00070
[epoch  32:  60/307] 	 train loss: 0.177673 	 lr: 0.00070
[epoch  32:  80/307] 	 train loss: 0.273285 	 lr: 0.00070

val loss: 0.325588 	 acc: 0.908023

[epoch  32: 100/307] 	 train loss: 0.158282 	 lr: 0.00070
[epoch  32: 120/307] 	 train loss: 0.366624 	 lr: 0.00070
[epoch  32: 140/307] 	 train loss: 0.311031 	 lr: 0.00070
[epoch  32: 160/307] 	 train loss: 0.175810 	 lr: 0.00070
[epoch  32: 180/307] 	 train loss: 0.202493 	 lr: 0.00070
[epoch  32: 200/307] 	 train loss: 0.253187 	 lr: 0.00070
[epoch  32: 220/307] 	 train loss: 0.460651 	 lr: 0.00070
[epoch  32: 240/307] 	 train loss: 0.301473 	 lr: 0.00070

val loss: 0.329569 	 acc: 0.901135

[epoch  32: 260/307] 	 train loss: 0.280966 	 lr: 0.00070
[epoch  32: 280/307] 	 train loss: 0.156539 	 lr: 0.00070
[epoch  32: 300/307] 	 train loss: 0.422324 	 lr: 0.00070
[epoch  33:   0/307] 	 train loss: 0.727531 	 lr: 0.00070
[epoch  33:  20/307] 	 train loss: 0.206916 	 lr: 0.00070
[epoch  33:  40/307] 	 train loss: 0.293810 	 lr: 0.00070
[epoch  33:  60/307] 	 train loss: 0.131069 	 lr: 0.00070
[epoch  33:  80/307] 	 train loss: 0.184803 	 lr: 0.00070

val loss: 0.341924 	 acc: 0.898703

[epoch  33: 100/307] 	 train loss: 0.159739 	 lr: 0.00070
[epoch  33: 120/307] 	 train loss: 0.469212 	 lr: 0.00070
[epoch  33: 140/307] 	 train loss: 0.607180 	 lr: 0.00070
[epoch  33: 160/307] 	 train loss: 0.453684 	 lr: 0.00070
[epoch  33: 180/307] 	 train loss: 0.409763 	 lr: 0.00070
[epoch  33: 200/307] 	 train loss: 0.151397 	 lr: 0.00070
[epoch  33: 220/307] 	 train loss: 0.189526 	 lr: 0.00070
[epoch  33: 240/307] 	 train loss: 0.352364 	 lr: 0.00070

val loss: 0.330474 	 acc: 0.905186

[epoch  33: 260/307] 	 train loss: 0.321079 	 lr: 0.00070
[epoch  33: 280/307] 	 train loss: 0.152304 	 lr: 0.00070
[epoch  33: 300/307] 	 train loss: 0.112012 	 lr: 0.00070
[epoch  34:   0/307] 	 train loss: 0.425832 	 lr: 0.00070
[epoch  34:  20/307] 	 train loss: 0.320499 	 lr: 0.00070
[epoch  34:  40/307] 	 train loss: 0.204266 	 lr: 0.00070
[epoch  34:  60/307] 	 train loss: 0.484450 	 lr: 0.00070
[epoch  34:  80/307] 	 train loss: 0.288510 	 lr: 0.00070

val loss: 0.341816 	 acc: 0.901945

[epoch  34: 100/307] 	 train loss: 0.413650 	 lr: 0.00070
[epoch  34: 120/307] 	 train loss: 0.158422 	 lr: 0.00070
[epoch  34: 140/307] 	 train loss: 0.103254 	 lr: 0.00070
[epoch  34: 160/307] 	 train loss: 0.249886 	 lr: 0.00070
[epoch  34: 180/307] 	 train loss: 0.446009 	 lr: 0.00070
[epoch  34: 200/307] 	 train loss: 0.038390 	 lr: 0.00070
[epoch  34: 220/307] 	 train loss: 0.209862 	 lr: 0.00070

val loss: 0.329409 	 acc: 0.911264

saved model with accuracy %0.6f:  0.9112641815235009
[epoch  34: 240/307] 	 train loss: 0.506072 	 lr: 0.00070
[epoch  34: 260/307] 	 train loss: 0.240598 	 lr: 0.00070
[epoch  34: 280/307] 	 train loss: 0.366296 	 lr: 0.00070
[epoch  34: 300/307] 	 train loss: 0.293829 	 lr: 0.00070
[epoch  35:   0/307] 	 train loss: 0.323575 	 lr: 0.00070
[epoch  35:  20/307] 	 train loss: 0.158165 	 lr: 0.00070
[epoch  35:  40/307] 	 train loss: 0.334650 	 lr: 0.00070
[epoch  35:  60/307] 	 train loss: 0.149895 	 lr: 0.00070
[epoch  35:  80/307] 	 train loss: 0.233557 	 lr: 0.00070

val loss: 0.352295 	 acc: 0.901945

[epoch  35: 100/307] 	 train loss: 0.390283 	 lr: 0.00070
[epoch  35: 120/307] 	 train loss: 0.207529 	 lr: 0.00070
[epoch  35: 140/307] 	 train loss: 0.143523 	 lr: 0.00070
[epoch  35: 160/307] 	 train loss: 0.200251 	 lr: 0.00070
[epoch  35: 180/307] 	 train loss: 0.322769 	 lr: 0.00070
[epoch  35: 200/307] 	 train loss: 0.263438 	 lr: 0.00070
[epoch  35: 220/307] 	 train loss: 0.097267 	 lr: 0.00070

val loss: 0.331494 	 acc: 0.907618

[epoch  35: 240/307] 	 train loss: 0.112131 	 lr: 0.00070
[epoch  35: 260/307] 	 train loss: 0.211108 	 lr: 0.00070
[epoch  35: 280/307] 	 train loss: 0.602440 	 lr: 0.00070
[epoch  35: 300/307] 	 train loss: 0.197406 	 lr: 0.00070
[epoch  36:   0/307] 	 train loss: 0.270352 	 lr: 0.00070
[epoch  36:  20/307] 	 train loss: 0.500148 	 lr: 0.00070
[epoch  36:  40/307] 	 train loss: 0.276752 	 lr: 0.00070
[epoch  36:  60/307] 	 train loss: 0.351593 	 lr: 0.00070
[epoch  36:  80/307] 	 train loss: 0.314717 	 lr: 0.00070

val loss: 0.333863 	 acc: 0.912885

saved model with accuracy %0.6f:  0.9128849270664505
[epoch  36: 100/307] 	 train loss: 0.166532 	 lr: 0.00070
[epoch  36: 120/307] 	 train loss: 0.190325 	 lr: 0.00070
[epoch  36: 140/307] 	 train loss: 0.212234 	 lr: 0.00070
[epoch  36: 160/307] 	 train loss: 0.341229 	 lr: 0.00070
[epoch  36: 180/307] 	 train loss: 0.242453 	 lr: 0.00070
[epoch  36: 200/307] 	 train loss: 0.354181 	 lr: 0.00070
[epoch  36: 220/307] 	 train loss: 0.161901 	 lr: 0.00070

val loss: 0.337543 	 acc: 0.904781

[epoch  36: 240/307] 	 train loss: 0.277434 	 lr: 0.00070
[epoch  36: 260/307] 	 train loss: 0.458503 	 lr: 0.00070
[epoch  36: 280/307] 	 train loss: 0.451379 	 lr: 0.00070
[epoch  36: 300/307] 	 train loss: 0.301363 	 lr: 0.00070
[epoch  37:   0/307] 	 train loss: 0.232319 	 lr: 0.00070
[epoch  37:  20/307] 	 train loss: 0.272196 	 lr: 0.00070
[epoch  37:  40/307] 	 train loss: 0.281528 	 lr: 0.00070
[epoch  37:  60/307] 	 train loss: 0.519743 	 lr: 0.00070
[epoch  37:  80/307] 	 train loss: 0.482718 	 lr: 0.00070

val loss: 0.338879 	 acc: 0.905997

[epoch  37: 100/307] 	 train loss: 0.437227 	 lr: 0.00070
[epoch  37: 120/307] 	 train loss: 0.117743 	 lr: 0.00070
[epoch  37: 140/307] 	 train loss: 0.239894 	 lr: 0.00070
[epoch  37: 160/307] 	 train loss: 0.378871 	 lr: 0.00070
[epoch  37: 180/307] 	 train loss: 0.195381 	 lr: 0.00070
[epoch  37: 200/307] 	 train loss: 0.401696 	 lr: 0.00070
[epoch  37: 220/307] 	 train loss: 0.174649 	 lr: 0.00070

val loss: 0.345846 	 acc: 0.900729

[epoch  37: 240/307] 	 train loss: 0.136904 	 lr: 0.00070
[epoch  37: 260/307] 	 train loss: 0.137740 	 lr: 0.00070
[epoch  37: 280/307] 	 train loss: 0.287251 	 lr: 0.00070
[epoch  37: 300/307] 	 train loss: 0.288524 	 lr: 0.00070
[epoch  38:   0/307] 	 train loss: 0.287387 	 lr: 0.00070
[epoch  38:  20/307] 	 train loss: 0.271755 	 lr: 0.00070
[epoch  38:  40/307] 	 train loss: 0.143541 	 lr: 0.00070
[epoch  38:  60/307] 	 train loss: 0.409324 	 lr: 0.00070

val loss: 0.350039 	 acc: 0.901135

[epoch  38:  80/307] 	 train loss: 0.380470 	 lr: 0.00070
[epoch  38: 100/307] 	 train loss: 0.089646 	 lr: 0.00070
[epoch  38: 120/307] 	 train loss: 0.191468 	 lr: 0.00070
[epoch  38: 140/307] 	 train loss: 0.445108 	 lr: 0.00070
[epoch  38: 160/307] 	 train loss: 0.188558 	 lr: 0.00070
[epoch  38: 180/307] 	 train loss: 0.485438 	 lr: 0.00070
[epoch  38: 200/307] 	 train loss: 0.035910 	 lr: 0.00070
[epoch  38: 220/307] 	 train loss: 0.241312 	 lr: 0.00070

val loss: 0.344677 	 acc: 0.903566

[epoch  38: 240/307] 	 train loss: 0.470330 	 lr: 0.00070
[epoch  38: 260/307] 	 train loss: 0.270858 	 lr: 0.00070
[epoch  38: 280/307] 	 train loss: 0.106255 	 lr: 0.00070
[epoch  38: 300/307] 	 train loss: 0.175458 	 lr: 0.00070
[epoch  39:   0/307] 	 train loss: 0.216015 	 lr: 0.00070
[epoch  39:  20/307] 	 train loss: 0.122905 	 lr: 0.00070
[epoch  39:  40/307] 	 train loss: 0.392660 	 lr: 0.00070
[epoch  39:  60/307] 	 train loss: 0.300626 	 lr: 0.00070

val loss: 0.352060 	 acc: 0.901945

[epoch  39:  80/307] 	 train loss: 0.144780 	 lr: 0.00070
[epoch  39: 100/307] 	 train loss: 0.376520 	 lr: 0.00070
[epoch  39: 120/307] 	 train loss: 0.264810 	 lr: 0.00070
[epoch  39: 140/307] 	 train loss: 0.222243 	 lr: 0.00070
[epoch  39: 160/307] 	 train loss: 0.324249 	 lr: 0.00070
[epoch  39: 180/307] 	 train loss: 0.278617 	 lr: 0.00070
[epoch  39: 200/307] 	 train loss: 0.141858 	 lr: 0.00070
[epoch  39: 220/307] 	 train loss: 0.181731 	 lr: 0.00070

val loss: 0.338059 	 acc: 0.908428

[epoch  39: 240/307] 	 train loss: 0.571437 	 lr: 0.00070
[epoch  39: 260/307] 	 train loss: 0.323987 	 lr: 0.00070
[epoch  39: 280/307] 	 train loss: 0.230120 	 lr: 0.00070
[epoch  39: 300/307] 	 train loss: 0.323446 	 lr: 0.00070
[epoch  40:   0/307] 	 train loss: 0.132412 	 lr: 0.00070
[epoch  40:  20/307] 	 train loss: 0.168818 	 lr: 0.00070
[epoch  40:  40/307] 	 train loss: 0.409565 	 lr: 0.00070
[epoch  40:  60/307] 	 train loss: 0.206651 	 lr: 0.00070

val loss: 0.340366 	 acc: 0.906402

[epoch  40:  80/307] 	 train loss: 0.448622 	 lr: 0.00070
[epoch  40: 100/307] 	 train loss: 0.278404 	 lr: 0.00070
[epoch  40: 120/307] 	 train loss: 0.361275 	 lr: 0.00070
[epoch  40: 140/307] 	 train loss: 0.164574 	 lr: 0.00070
[epoch  40: 160/307] 	 train loss: 0.252217 	 lr: 0.00070
[epoch  40: 180/307] 	 train loss: 0.272769 	 lr: 0.00070
[epoch  40: 200/307] 	 train loss: 0.158443 	 lr: 0.00070
[epoch  40: 220/307] 	 train loss: 0.187367 	 lr: 0.00070

val loss: 0.342417 	 acc: 0.910454

[epoch  40: 240/307] 	 train loss: 0.124483 	 lr: 0.00070
[epoch  40: 260/307] 	 train loss: 0.282063 	 lr: 0.00070
[epoch  40: 280/307] 	 train loss: 0.291954 	 lr: 0.00070
[epoch  40: 300/307] 	 train loss: 0.269234 	 lr: 0.00070
[epoch  41:   0/307] 	 train loss: 0.252236 	 lr: 0.00070
[epoch  41:  20/307] 	 train loss: 0.465982 	 lr: 0.00070
[epoch  41:  40/307] 	 train loss: 0.129047 	 lr: 0.00070
[epoch  41:  60/307] 	 train loss: 0.284997 	 lr: 0.00070

val loss: 0.346359 	 acc: 0.903160

[epoch  41:  80/307] 	 train loss: 0.121002 	 lr: 0.00070
[epoch  41: 100/307] 	 train loss: 0.151402 	 lr: 0.00070
[epoch  41: 120/307] 	 train loss: 0.172568 	 lr: 0.00070
[epoch  41: 140/307] 	 train loss: 0.355363 	 lr: 0.00070
[epoch  41: 160/307] 	 train loss: 0.216468 	 lr: 0.00070
[epoch  41: 180/307] 	 train loss: 0.171546 	 lr: 0.00070
[epoch  41: 200/307] 	 train loss: 0.569769 	 lr: 0.00070
[epoch  41: 220/307] 	 train loss: 0.292500 	 lr: 0.00070

val loss: 0.362566 	 acc: 0.895867

[epoch  41: 240/307] 	 train loss: 0.294988 	 lr: 0.00070
[epoch  41: 260/307] 	 train loss: 0.342225 	 lr: 0.00070
[epoch  41: 280/307] 	 train loss: 0.080951 	 lr: 0.00070
[epoch  41: 300/307] 	 train loss: 0.529482 	 lr: 0.00070
[epoch  42:   0/307] 	 train loss: 0.318413 	 lr: 0.00070
[epoch  42:  20/307] 	 train loss: 0.180125 	 lr: 0.00070
[epoch  42:  40/307] 	 train loss: 0.189208 	 lr: 0.00070
[epoch  42:  60/307] 	 train loss: 0.237479 	 lr: 0.00070

val loss: 0.347699 	 acc: 0.906807

[epoch  42:  80/307] 	 train loss: 0.273099 	 lr: 0.00070
[epoch  42: 100/307] 	 train loss: 0.484054 	 lr: 0.00070
[epoch  42: 120/307] 	 train loss: 0.184807 	 lr: 0.00070
[epoch  42: 140/307] 	 train loss: 0.108123 	 lr: 0.00070
[epoch  42: 160/307] 	 train loss: 0.080998 	 lr: 0.00070
[epoch  42: 180/307] 	 train loss: 0.175275 	 lr: 0.00070
[epoch  42: 200/307] 	 train loss: 0.288738 	 lr: 0.00070
[epoch  42: 220/307] 	 train loss: 0.197626 	 lr: 0.00070

val loss: 0.351832 	 acc: 0.903160

[epoch  42: 240/307] 	 train loss: 0.192209 	 lr: 0.00070
[epoch  42: 260/307] 	 train loss: 0.221390 	 lr: 0.00070
[epoch  42: 280/307] 	 train loss: 0.420343 	 lr: 0.00070
[epoch  42: 300/307] 	 train loss: 0.357377 	 lr: 0.00070
[epoch  43:   0/307] 	 train loss: 0.134402 	 lr: 0.00049
[epoch  43:  20/307] 	 train loss: 0.053791 	 lr: 0.00049
[epoch  43:  40/307] 	 train loss: 0.249450 	 lr: 0.00049
[epoch  43:  60/307] 	 train loss: 0.192094 	 lr: 0.00049

val loss: 0.351578 	 acc: 0.906807

[epoch  43:  80/307] 	 train loss: 0.241935 	 lr: 0.00049
[epoch  43: 100/307] 	 train loss: 0.373810 	 lr: 0.00049
[epoch  43: 120/307] 	 train loss: 0.327476 	 lr: 0.00049
[epoch  43: 140/307] 	 train loss: 0.234728 	 lr: 0.00049
[epoch  43: 160/307] 	 train loss: 0.273456 	 lr: 0.00049
[epoch  43: 180/307] 	 train loss: 0.287132 	 lr: 0.00049
[epoch  43: 200/307] 	 train loss: 0.139265 	 lr: 0.00049
[epoch  43: 220/307] 	 train loss: 0.363741 	 lr: 0.00049

val loss: 0.363688 	 acc: 0.904781

[epoch  43: 240/307] 	 train loss: 0.704850 	 lr: 0.00049
[epoch  43: 260/307] 	 train loss: 0.318757 	 lr: 0.00049
[epoch  43: 280/307] 	 train loss: 0.272520 	 lr: 0.00049
[epoch  43: 300/307] 	 train loss: 0.365962 	 lr: 0.00049
[epoch  44:   0/307] 	 train loss: 0.538695 	 lr: 0.00049
[epoch  44:  20/307] 	 train loss: 0.461376 	 lr: 0.00049
[epoch  44:  40/307] 	 train loss: 0.267159 	 lr: 0.00049
[epoch  44:  60/307] 	 train loss: 0.122717 	 lr: 0.00049

val loss: 0.359107 	 acc: 0.908428

[epoch  44:  80/307] 	 train loss: 0.301924 	 lr: 0.00049
[epoch  44: 100/307] 	 train loss: 0.351166 	 lr: 0.00049
[epoch  44: 120/307] 	 train loss: 0.312796 	 lr: 0.00049
[epoch  44: 140/307] 	 train loss: 0.240825 	 lr: 0.00049
[epoch  44: 160/307] 	 train loss: 0.181749 	 lr: 0.00049
[epoch  44: 180/307] 	 train loss: 0.278338 	 lr: 0.00049
[epoch  44: 200/307] 	 train loss: 0.255084 	 lr: 0.00049

val loss: 0.340738 	 acc: 0.908023

[epoch  44: 220/307] 	 train loss: 0.161281 	 lr: 0.00049
[epoch  44: 240/307] 	 train loss: 0.356929 	 lr: 0.00049
[epoch  44: 260/307] 	 train loss: 0.267829 	 lr: 0.00049
[epoch  44: 280/307] 	 train loss: 0.126739 	 lr: 0.00049
[epoch  44: 300/307] 	 train loss: 0.152059 	 lr: 0.00049
[epoch  45:   0/307] 	 train loss: 0.185456 	 lr: 0.00049
[epoch  45:  20/307] 	 train loss: 0.333885 	 lr: 0.00049
[epoch  45:  40/307] 	 train loss: 0.216477 	 lr: 0.00049
[epoch  45:  60/307] 	 train loss: 0.238382 	 lr: 0.00049

val loss: 0.361450 	 acc: 0.905592

[epoch  45:  80/307] 	 train loss: 0.405834 	 lr: 0.00049
[epoch  45: 100/307] 	 train loss: 0.117570 	 lr: 0.00049
[epoch  45: 120/307] 	 train loss: 0.106240 	 lr: 0.00049
[epoch  45: 140/307] 	 train loss: 0.390559 	 lr: 0.00049
[epoch  45: 160/307] 	 train loss: 0.246806 	 lr: 0.00049
[epoch  45: 180/307] 	 train loss: 0.093297 	 lr: 0.00049
[epoch  45: 200/307] 	 train loss: 0.333347 	 lr: 0.00049

val loss: 0.354403 	 acc: 0.904376

[epoch  45: 220/307] 	 train loss: 0.378773 	 lr: 0.00049
[epoch  45: 240/307] 	 train loss: 0.233960 	 lr: 0.00049
[epoch  45: 260/307] 	 train loss: 0.157086 	 lr: 0.00049
[epoch  45: 280/307] 	 train loss: 0.198241 	 lr: 0.00049
[epoch  45: 300/307] 	 train loss: 0.177165 	 lr: 0.00049
[epoch  46:   0/307] 	 train loss: 0.197880 	 lr: 0.00049
[epoch  46:  20/307] 	 train loss: 0.326891 	 lr: 0.00049
[epoch  46:  40/307] 	 train loss: 0.208380 	 lr: 0.00049
[epoch  46:  60/307] 	 train loss: 0.279902 	 lr: 0.00049

val loss: 0.348558 	 acc: 0.909238

[epoch  46:  80/307] 	 train loss: 0.237693 	 lr: 0.00049
[epoch  46: 100/307] 	 train loss: 0.252457 	 lr: 0.00049
[epoch  46: 120/307] 	 train loss: 0.232149 	 lr: 0.00049
[epoch  46: 140/307] 	 train loss: 0.055891 	 lr: 0.00049
[epoch  46: 160/307] 	 train loss: 0.400293 	 lr: 0.00049
[epoch  46: 180/307] 	 train loss: 0.196137 	 lr: 0.00049
[epoch  46: 200/307] 	 train loss: 0.337668 	 lr: 0.00049

val loss: 0.347881 	 acc: 0.908428

[epoch  46: 220/307] 	 train loss: 0.386870 	 lr: 0.00049
[epoch  46: 240/307] 	 train loss: 0.171767 	 lr: 0.00049
[epoch  46: 260/307] 	 train loss: 0.064737 	 lr: 0.00049
[epoch  46: 280/307] 	 train loss: 0.238225 	 lr: 0.00049
[epoch  46: 300/307] 	 train loss: 0.195801 	 lr: 0.00049
[epoch  47:   0/307] 	 train loss: 0.339163 	 lr: 0.00049
[epoch  47:  20/307] 	 train loss: 0.188570 	 lr: 0.00049
[epoch  47:  40/307] 	 train loss: 0.211089 	 lr: 0.00049
[epoch  47:  60/307] 	 train loss: 0.136059 	 lr: 0.00049

val loss: 0.331568 	 acc: 0.904781

[epoch  47:  80/307] 	 train loss: 0.209693 	 lr: 0.00049
[epoch  47: 100/307] 	 train loss: 0.325315 	 lr: 0.00049
[epoch  47: 120/307] 	 train loss: 0.097074 	 lr: 0.00049
[epoch  47: 140/307] 	 train loss: 0.518493 	 lr: 0.00049
[epoch  47: 160/307] 	 train loss: 0.142936 	 lr: 0.00049
[epoch  47: 180/307] 	 train loss: 0.319291 	 lr: 0.00049
[epoch  47: 200/307] 	 train loss: 0.169893 	 lr: 0.00049

val loss: 0.338328 	 acc: 0.911264

[epoch  47: 220/307] 	 train loss: 0.414639 	 lr: 0.00049
[epoch  47: 240/307] 	 train loss: 0.046714 	 lr: 0.00049
[epoch  47: 260/307] 	 train loss: 0.088734 	 lr: 0.00049
[epoch  47: 280/307] 	 train loss: 0.491244 	 lr: 0.00049
[epoch  47: 300/307] 	 train loss: 0.327965 	 lr: 0.00049
[epoch  48:   0/307] 	 train loss: 0.207109 	 lr: 0.00049
[epoch  48:  20/307] 	 train loss: 0.128168 	 lr: 0.00049
[epoch  48:  40/307] 	 train loss: 0.267927 	 lr: 0.00049

val loss: 0.328845 	 acc: 0.912075

[epoch  48:  60/307] 	 train loss: 0.192521 	 lr: 0.00049
[epoch  48:  80/307] 	 train loss: 0.399003 	 lr: 0.00049
[epoch  48: 100/307] 	 train loss: 0.158784 	 lr: 0.00049
[epoch  48: 120/307] 	 train loss: 0.113990 	 lr: 0.00049
[epoch  48: 140/307] 	 train loss: 0.286546 	 lr: 0.00049
[epoch  48: 160/307] 	 train loss: 0.428077 	 lr: 0.00049
[epoch  48: 180/307] 	 train loss: 0.401688 	 lr: 0.00049
[epoch  48: 200/307] 	 train loss: 0.311956 	 lr: 0.00049

val loss: 0.344137 	 acc: 0.904376

[epoch  48: 220/307] 	 train loss: 0.405285 	 lr: 0.00049
[epoch  48: 240/307] 	 train loss: 0.442622 	 lr: 0.00049
[epoch  48: 260/307] 	 train loss: 0.392088 	 lr: 0.00049
[epoch  48: 280/307] 	 train loss: 0.114188 	 lr: 0.00049
[epoch  48: 300/307] 	 train loss: 0.214701 	 lr: 0.00049
[epoch  49:   0/307] 	 train loss: 0.200086 	 lr: 0.00049
[epoch  49:  20/307] 	 train loss: 0.364874 	 lr: 0.00049
[epoch  49:  40/307] 	 train loss: 0.347077 	 lr: 0.00049

val loss: 0.310544 	 acc: 0.914506

saved model with accuracy %0.6f:  0.9145056726094003
[epoch  49:  60/307] 	 train loss: 0.337470 	 lr: 0.00049
[epoch  49:  80/307] 	 train loss: 0.096328 	 lr: 0.00049
[epoch  49: 100/307] 	 train loss: 0.233385 	 lr: 0.00049
[epoch  49: 120/307] 	 train loss: 0.177446 	 lr: 0.00049
[epoch  49: 140/307] 	 train loss: 0.310028 	 lr: 0.00049
[epoch  49: 160/307] 	 train loss: 0.126745 	 lr: 0.00049
[epoch  49: 180/307] 	 train loss: 0.150874 	 lr: 0.00049
[epoch  49: 200/307] 	 train loss: 0.139202 	 lr: 0.00049

val loss: 0.309952 	 acc: 0.913290

[epoch  49: 220/307] 	 train loss: 0.145444 	 lr: 0.00049
[epoch  49: 240/307] 	 train loss: 0.314010 	 lr: 0.00049
[epoch  49: 260/307] 	 train loss: 0.143446 	 lr: 0.00049
[epoch  49: 280/307] 	 train loss: 0.189489 	 lr: 0.00049
[epoch  49: 300/307] 	 train loss: 0.111862 	 lr: 0.00049
[epoch  50:   0/307] 	 train loss: 0.192900 	 lr: 0.00049
[epoch  50:  20/307] 	 train loss: 0.218520 	 lr: 0.00049
[epoch  50:  40/307] 	 train loss: 0.189150 	 lr: 0.00049

val loss: 0.308853 	 acc: 0.910454

[epoch  50:  60/307] 	 train loss: 0.410190 	 lr: 0.00049
[epoch  50:  80/307] 	 train loss: 0.203590 	 lr: 0.00049
[epoch  50: 100/307] 	 train loss: 0.103229 	 lr: 0.00049
[epoch  50: 120/307] 	 train loss: 0.319002 	 lr: 0.00049
[epoch  50: 140/307] 	 train loss: 0.183614 	 lr: 0.00049
[epoch  50: 160/307] 	 train loss: 0.135369 	 lr: 0.00049
[epoch  50: 180/307] 	 train loss: 0.245033 	 lr: 0.00049
[epoch  50: 200/307] 	 train loss: 0.237647 	 lr: 0.00049

val loss: 0.335754 	 acc: 0.900324

[epoch  50: 220/307] 	 train loss: 0.337900 	 lr: 0.00049
[epoch  50: 240/307] 	 train loss: 0.437894 	 lr: 0.00049
[epoch  50: 260/307] 	 train loss: 0.309374 	 lr: 0.00049
[epoch  50: 280/307] 	 train loss: 0.102000 	 lr: 0.00049
[epoch  50: 300/307] 	 train loss: 0.175457 	 lr: 0.00049
[epoch  51:   0/307] 	 train loss: 0.202651 	 lr: 0.00049
[epoch  51:  20/307] 	 train loss: 0.200689 	 lr: 0.00049
[epoch  51:  40/307] 	 train loss: 0.188346 	 lr: 0.00049

val loss: 0.338308 	 acc: 0.908023

[epoch  51:  60/307] 	 train loss: 0.185469 	 lr: 0.00049
[epoch  51:  80/307] 	 train loss: 0.247370 	 lr: 0.00049
[epoch  51: 100/307] 	 train loss: 0.323313 	 lr: 0.00049
[epoch  51: 120/307] 	 train loss: 0.205106 	 lr: 0.00049
[epoch  51: 140/307] 	 train loss: 0.326270 	 lr: 0.00049
[epoch  51: 160/307] 	 train loss: 0.074090 	 lr: 0.00049
[epoch  51: 180/307] 	 train loss: 0.092415 	 lr: 0.00049
[epoch  51: 200/307] 	 train loss: 0.156991 	 lr: 0.00049

val loss: 0.319938 	 acc: 0.907618

[epoch  51: 220/307] 	 train loss: 0.260311 	 lr: 0.00049
[epoch  51: 240/307] 	 train loss: 0.181675 	 lr: 0.00049
[epoch  51: 260/307] 	 train loss: 0.232702 	 lr: 0.00049
[epoch  51: 280/307] 	 train loss: 0.117621 	 lr: 0.00049
[epoch  51: 300/307] 	 train loss: 0.172291 	 lr: 0.00049
[epoch  52:   0/307] 	 train loss: 0.095352 	 lr: 0.00049
[epoch  52:  20/307] 	 train loss: 0.242130 	 lr: 0.00049
[epoch  52:  40/307] 	 train loss: 0.073523 	 lr: 0.00049

val loss: 0.317756 	 acc: 0.917747

saved model with accuracy %0.6f:  0.9177471636952999
[epoch  52:  60/307] 	 train loss: 0.496170 	 lr: 0.00049
[epoch  52:  80/307] 	 train loss: 0.730877 	 lr: 0.00049
[epoch  52: 100/307] 	 train loss: 0.074495 	 lr: 0.00049
[epoch  52: 120/307] 	 train loss: 0.103853 	 lr: 0.00049
[epoch  52: 140/307] 	 train loss: 0.073011 	 lr: 0.00049
[epoch  52: 160/307] 	 train loss: 0.077532 	 lr: 0.00049
[epoch  52: 180/307] 	 train loss: 0.202915 	 lr: 0.00049
[epoch  52: 200/307] 	 train loss: 0.148185 	 lr: 0.00049

val loss: 0.311000 	 acc: 0.912885

[epoch  52: 220/307] 	 train loss: 0.230023 	 lr: 0.00049
[epoch  52: 240/307] 	 train loss: 0.257242 	 lr: 0.00049
[epoch  52: 260/307] 	 train loss: 0.153228 	 lr: 0.00049
[epoch  52: 280/307] 	 train loss: 0.118104 	 lr: 0.00049
[epoch  52: 300/307] 	 train loss: 0.119458 	 lr: 0.00049
[epoch  53:   0/307] 	 train loss: 0.400575 	 lr: 0.00049
[epoch  53:  20/307] 	 train loss: 0.159427 	 lr: 0.00049
[epoch  53:  40/307] 	 train loss: 0.193735 	 lr: 0.00049

val loss: 0.329645 	 acc: 0.903566

[epoch  53:  60/307] 	 train loss: 0.112906 	 lr: 0.00049
[epoch  53:  80/307] 	 train loss: 0.295808 	 lr: 0.00049
[epoch  53: 100/307] 	 train loss: 0.176233 	 lr: 0.00049
[epoch  53: 120/307] 	 train loss: 0.271603 	 lr: 0.00049
[epoch  53: 140/307] 	 train loss: 0.101011 	 lr: 0.00049
[epoch  53: 160/307] 	 train loss: 0.405121 	 lr: 0.00049
[epoch  53: 180/307] 	 train loss: 0.077187 	 lr: 0.00049
[epoch  53: 200/307] 	 train loss: 0.226437 	 lr: 0.00049

val loss: 0.328121 	 acc: 0.908833

[epoch  53: 220/307] 	 train loss: 0.169486 	 lr: 0.00049
[epoch  53: 240/307] 	 train loss: 0.132895 	 lr: 0.00049
[epoch  53: 260/307] 	 train loss: 0.080875 	 lr: 0.00049
[epoch  53: 280/307] 	 train loss: 0.159029 	 lr: 0.00049
[epoch  53: 300/307] 	 train loss: 0.021692 	 lr: 0.00049
[epoch  54:   0/307] 	 train loss: 0.309181 	 lr: 0.00049
[epoch  54:  20/307] 	 train loss: 0.066362 	 lr: 0.00049
[epoch  54:  40/307] 	 train loss: 0.124161 	 lr: 0.00049

val loss: 0.327497 	 acc: 0.910049

[epoch  54:  60/307] 	 train loss: 0.355743 	 lr: 0.00049
[epoch  54:  80/307] 	 train loss: 0.084689 	 lr: 0.00049
[epoch  54: 100/307] 	 train loss: 0.073115 	 lr: 0.00049
[epoch  54: 120/307] 	 train loss: 0.162410 	 lr: 0.00049
[epoch  54: 140/307] 	 train loss: 0.330492 	 lr: 0.00049
[epoch  54: 160/307] 	 train loss: 0.303121 	 lr: 0.00049
[epoch  54: 180/307] 	 train loss: 0.113719 	 lr: 0.00049

val loss: 0.325736 	 acc: 0.910454

[epoch  54: 200/307] 	 train loss: 0.109242 	 lr: 0.00049
[epoch  54: 220/307] 	 train loss: 0.126230 	 lr: 0.00049
[epoch  54: 240/307] 	 train loss: 0.049363 	 lr: 0.00049
[epoch  54: 260/307] 	 train loss: 0.160610 	 lr: 0.00049
[epoch  54: 280/307] 	 train loss: 0.157942 	 lr: 0.00049
[epoch  54: 300/307] 	 train loss: 0.204964 	 lr: 0.00049
[epoch  55:   0/307] 	 train loss: 0.237465 	 lr: 0.00049
[epoch  55:  20/307] 	 train loss: 0.193915 	 lr: 0.00049
[epoch  55:  40/307] 	 train loss: 0.183177 	 lr: 0.00049

val loss: 0.324789 	 acc: 0.909238

[epoch  55:  60/307] 	 train loss: 0.405133 	 lr: 0.00049
[epoch  55:  80/307] 	 train loss: 0.352404 	 lr: 0.00049
[epoch  55: 100/307] 	 train loss: 0.139615 	 lr: 0.00049
[epoch  55: 120/307] 	 train loss: 0.123277 	 lr: 0.00049
[epoch  55: 140/307] 	 train loss: 0.212357 	 lr: 0.00049
[epoch  55: 160/307] 	 train loss: 0.110397 	 lr: 0.00049
[epoch  55: 180/307] 	 train loss: 0.046062 	 lr: 0.00049

val loss: 0.325870 	 acc: 0.910454

[epoch  55: 200/307] 	 train loss: 0.187752 	 lr: 0.00049
[epoch  55: 220/307] 	 train loss: 0.271530 	 lr: 0.00049
[epoch  55: 240/307] 	 train loss: 0.095264 	 lr: 0.00049
[epoch  55: 260/307] 	 train loss: 0.310390 	 lr: 0.00049
[epoch  55: 280/307] 	 train loss: 0.172319 	 lr: 0.00049
[epoch  55: 300/307] 	 train loss: 0.254348 	 lr: 0.00049
[epoch  56:   0/307] 	 train loss: 0.187053 	 lr: 0.00049
[epoch  56:  20/307] 	 train loss: 0.051977 	 lr: 0.00049
[epoch  56:  40/307] 	 train loss: 0.069095 	 lr: 0.00049

val loss: 0.321938 	 acc: 0.906402

[epoch  56:  60/307] 	 train loss: 0.085300 	 lr: 0.00049
[epoch  56:  80/307] 	 train loss: 0.354635 	 lr: 0.00049
[epoch  56: 100/307] 	 train loss: 0.123948 	 lr: 0.00049
[epoch  56: 120/307] 	 train loss: 0.278978 	 lr: 0.00049
[epoch  56: 140/307] 	 train loss: 0.514025 	 lr: 0.00049
[epoch  56: 160/307] 	 train loss: 0.150062 	 lr: 0.00049
[epoch  56: 180/307] 	 train loss: 0.398601 	 lr: 0.00049

val loss: 0.327720 	 acc: 0.905592

[epoch  56: 200/307] 	 train loss: 0.105139 	 lr: 0.00049
[epoch  56: 220/307] 	 train loss: 0.045259 	 lr: 0.00049
[epoch  56: 240/307] 	 train loss: 0.324686 	 lr: 0.00049
[epoch  56: 260/307] 	 train loss: 0.144956 	 lr: 0.00049
[epoch  56: 280/307] 	 train loss: 0.163246 	 lr: 0.00049
[epoch  56: 300/307] 	 train loss: 0.240138 	 lr: 0.00049
[epoch  57:   0/307] 	 train loss: 0.256284 	 lr: 0.00049
[epoch  57:  20/307] 	 train loss: 0.088984 	 lr: 0.00049
[epoch  57:  40/307] 	 train loss: 0.200132 	 lr: 0.00049

val loss: 0.327095 	 acc: 0.908833

[epoch  57:  60/307] 	 train loss: 0.197518 	 lr: 0.00049
[epoch  57:  80/307] 	 train loss: 0.206693 	 lr: 0.00049
[epoch  57: 100/307] 	 train loss: 0.151113 	 lr: 0.00049
[epoch  57: 120/307] 	 train loss: 0.245517 	 lr: 0.00049
[epoch  57: 140/307] 	 train loss: 0.199963 	 lr: 0.00049
[epoch  57: 160/307] 	 train loss: 0.043268 	 lr: 0.00049
[epoch  57: 180/307] 	 train loss: 0.322291 	 lr: 0.00049

val loss: 0.323161 	 acc: 0.914100

[epoch  57: 200/307] 	 train loss: 0.176341 	 lr: 0.00049
[epoch  57: 220/307] 	 train loss: 0.176560 	 lr: 0.00049
[epoch  57: 240/307] 	 train loss: 0.463511 	 lr: 0.00049
[epoch  57: 260/307] 	 train loss: 0.320578 	 lr: 0.00049
[epoch  57: 280/307] 	 train loss: 0.688849 	 lr: 0.00049
[epoch  57: 300/307] 	 train loss: 0.132008 	 lr: 0.00049
[epoch  58:   0/307] 	 train loss: 0.215162 	 lr: 0.00049
[epoch  58:  20/307] 	 train loss: 0.445982 	 lr: 0.00049

val loss: 0.310207 	 acc: 0.918152

saved model with accuracy %0.6f:  0.9181523500810372
[epoch  58:  40/307] 	 train loss: 0.080474 	 lr: 0.00049
[epoch  58:  60/307] 	 train loss: 0.210854 	 lr: 0.00049
[epoch  58:  80/307] 	 train loss: 0.168718 	 lr: 0.00049
[epoch  58: 100/307] 	 train loss: 0.236292 	 lr: 0.00049
[epoch  58: 120/307] 	 train loss: 0.276727 	 lr: 0.00049
[epoch  58: 140/307] 	 train loss: 0.212213 	 lr: 0.00049
[epoch  58: 160/307] 	 train loss: 0.261532 	 lr: 0.00049
[epoch  58: 180/307] 	 train loss: 0.073616 	 lr: 0.00049

val loss: 0.315979 	 acc: 0.912075

[epoch  58: 200/307] 	 train loss: 0.163065 	 lr: 0.00049
[epoch  58: 220/307] 	 train loss: 0.047945 	 lr: 0.00049
[epoch  58: 240/307] 	 train loss: 0.132077 	 lr: 0.00049
[epoch  58: 260/307] 	 train loss: 0.186595 	 lr: 0.00049
[epoch  58: 280/307] 	 train loss: 0.195622 	 lr: 0.00049
[epoch  58: 300/307] 	 train loss: 0.227388 	 lr: 0.00049
[epoch  59:   0/307] 	 train loss: 0.184722 	 lr: 0.00049
[epoch  59:  20/307] 	 train loss: 0.299003 	 lr: 0.00049

val loss: 0.322502 	 acc: 0.917342

[epoch  59:  40/307] 	 train loss: 0.040257 	 lr: 0.00049
[epoch  59:  60/307] 	 train loss: 0.136111 	 lr: 0.00049
[epoch  59:  80/307] 	 train loss: 0.081187 	 lr: 0.00049
[epoch  59: 100/307] 	 train loss: 0.513628 	 lr: 0.00049
[epoch  59: 120/307] 	 train loss: 0.578778 	 lr: 0.00049
[epoch  59: 140/307] 	 train loss: 0.224820 	 lr: 0.00049
[epoch  59: 160/307] 	 train loss: 0.225972 	 lr: 0.00049
[epoch  59: 180/307] 	 train loss: 0.285679 	 lr: 0.00049

val loss: 0.313176 	 acc: 0.912885

[epoch  59: 200/307] 	 train loss: 0.044985 	 lr: 0.00049
[epoch  59: 220/307] 	 train loss: 0.153617 	 lr: 0.00049
[epoch  59: 240/307] 	 train loss: 0.422936 	 lr: 0.00049
[epoch  59: 260/307] 	 train loss: 0.146999 	 lr: 0.00049
[epoch  59: 280/307] 	 train loss: 0.047146 	 lr: 0.00049
[epoch  59: 300/307] 	 train loss: 0.252951 	 lr: 0.00049
[epoch  60:   0/307] 	 train loss: 0.076188 	 lr: 0.00049
[epoch  60:  20/307] 	 train loss: 0.438335 	 lr: 0.00049

val loss: 0.322495 	 acc: 0.912480

[epoch  60:  40/307] 	 train loss: 0.207051 	 lr: 0.00049
[epoch  60:  60/307] 	 train loss: 0.202861 	 lr: 0.00049
[epoch  60:  80/307] 	 train loss: 0.151732 	 lr: 0.00049
[epoch  60: 100/307] 	 train loss: 0.011610 	 lr: 0.00049
[epoch  60: 120/307] 	 train loss: 0.334200 	 lr: 0.00049
[epoch  60: 140/307] 	 train loss: 0.195747 	 lr: 0.00049
[epoch  60: 160/307] 	 train loss: 0.108631 	 lr: 0.00049
[epoch  60: 180/307] 	 train loss: 0.232133 	 lr: 0.00049

val loss: 0.311995 	 acc: 0.911264

[epoch  60: 200/307] 	 train loss: 0.240984 	 lr: 0.00049
[epoch  60: 220/307] 	 train loss: 0.233901 	 lr: 0.00049
[epoch  60: 240/307] 	 train loss: 0.269425 	 lr: 0.00049
[epoch  60: 260/307] 	 train loss: 0.186243 	 lr: 0.00049
[epoch  60: 280/307] 	 train loss: 0.254187 	 lr: 0.00049
[epoch  60: 300/307] 	 train loss: 0.062890 	 lr: 0.00049
[epoch  61:   0/307] 	 train loss: 0.260895 	 lr: 0.00049
[epoch  61:  20/307] 	 train loss: 0.147700 	 lr: 0.00049

val loss: 0.344354 	 acc: 0.909643

[epoch  61:  40/307] 	 train loss: 0.057558 	 lr: 0.00049
[epoch  61:  60/307] 	 train loss: 0.337572 	 lr: 0.00049
[epoch  61:  80/307] 	 train loss: 0.135502 	 lr: 0.00049
[epoch  61: 100/307] 	 train loss: 0.164940 	 lr: 0.00049
[epoch  61: 120/307] 	 train loss: 0.206340 	 lr: 0.00049
[epoch  61: 140/307] 	 train loss: 0.593554 	 lr: 0.00049
[epoch  61: 160/307] 	 train loss: 0.322438 	 lr: 0.00049
[epoch  61: 180/307] 	 train loss: 0.202188 	 lr: 0.00049

val loss: 0.334692 	 acc: 0.910049

[epoch  61: 200/307] 	 train loss: 0.340642 	 lr: 0.00049
[epoch  61: 220/307] 	 train loss: 0.159346 	 lr: 0.00049
[epoch  61: 240/307] 	 train loss: 0.221246 	 lr: 0.00049
[epoch  61: 260/307] 	 train loss: 0.218174 	 lr: 0.00049
[epoch  61: 280/307] 	 train loss: 0.225460 	 lr: 0.00049
[epoch  61: 300/307] 	 train loss: 0.363594 	 lr: 0.00049
[epoch  62:   0/307] 	 train loss: 0.162706 	 lr: 0.00049
[epoch  62:  20/307] 	 train loss: 0.450873 	 lr: 0.00049

val loss: 0.329745 	 acc: 0.910859

[epoch  62:  40/307] 	 train loss: 0.159247 	 lr: 0.00049
[epoch  62:  60/307] 	 train loss: 0.178257 	 lr: 0.00049
[epoch  62:  80/307] 	 train loss: 0.126690 	 lr: 0.00049
[epoch  62: 100/307] 	 train loss: 0.084280 	 lr: 0.00049
[epoch  62: 120/307] 	 train loss: 0.334703 	 lr: 0.00049
[epoch  62: 140/307] 	 train loss: 0.138414 	 lr: 0.00049
[epoch  62: 160/307] 	 train loss: 0.098195 	 lr: 0.00049
[epoch  62: 180/307] 	 train loss: 0.217477 	 lr: 0.00049

val loss: 0.319606 	 acc: 0.912885

[epoch  62: 200/307] 	 train loss: 0.143293 	 lr: 0.00049
[epoch  62: 220/307] 	 train loss: 0.108949 	 lr: 0.00049
[epoch  62: 240/307] 	 train loss: 0.175020 	 lr: 0.00049
[epoch  62: 260/307] 	 train loss: 0.143074 	 lr: 0.00049
[epoch  62: 280/307] 	 train loss: 0.310498 	 lr: 0.00049
[epoch  62: 300/307] 	 train loss: 0.365427 	 lr: 0.00049
[epoch  63:   0/307] 	 train loss: 0.094879 	 lr: 0.00049
[epoch  63:  20/307] 	 train loss: 0.388159 	 lr: 0.00049

val loss: 0.314258 	 acc: 0.908428

[epoch  63:  40/307] 	 train loss: 0.126643 	 lr: 0.00049
[epoch  63:  60/307] 	 train loss: 0.242728 	 lr: 0.00049
[epoch  63:  80/307] 	 train loss: 0.246760 	 lr: 0.00049
[epoch  63: 100/307] 	 train loss: 0.143288 	 lr: 0.00049
[epoch  63: 120/307] 	 train loss: 0.064239 	 lr: 0.00049
[epoch  63: 140/307] 	 train loss: 0.442345 	 lr: 0.00049
[epoch  63: 160/307] 	 train loss: 0.070212 	 lr: 0.00049
[epoch  63: 180/307] 	 train loss: 0.282908 	 lr: 0.00049

val loss: 0.333910 	 acc: 0.907618

[epoch  63: 200/307] 	 train loss: 0.192617 	 lr: 0.00049
[epoch  63: 220/307] 	 train loss: 0.278042 	 lr: 0.00049
[epoch  63: 240/307] 	 train loss: 0.166373 	 lr: 0.00049
[epoch  63: 260/307] 	 train loss: 0.310212 	 lr: 0.00049
[epoch  63: 280/307] 	 train loss: 0.179541 	 lr: 0.00049
[epoch  63: 300/307] 	 train loss: 0.155678 	 lr: 0.00049
[epoch  64:   0/307] 	 train loss: 0.290827 	 lr: 0.00034
[epoch  64:  20/307] 	 train loss: 0.374703 	 lr: 0.00034

val loss: 0.321925 	 acc: 0.912480

[epoch  64:  40/307] 	 train loss: 0.109227 	 lr: 0.00034
[epoch  64:  60/307] 	 train loss: 0.233399 	 lr: 0.00034
[epoch  64:  80/307] 	 train loss: 0.232964 	 lr: 0.00034
[epoch  64: 100/307] 	 train loss: 0.473691 	 lr: 0.00034
[epoch  64: 120/307] 	 train loss: 0.115870 	 lr: 0.00034
[epoch  64: 140/307] 	 train loss: 0.224524 	 lr: 0.00034
[epoch  64: 160/307] 	 train loss: 0.211249 	 lr: 0.00034

val loss: 0.339080 	 acc: 0.904376

[epoch  64: 180/307] 	 train loss: 0.498069 	 lr: 0.00034
[epoch  64: 200/307] 	 train loss: 0.123364 	 lr: 0.00034
[epoch  64: 220/307] 	 train loss: 0.283014 	 lr: 0.00034
[epoch  64: 240/307] 	 train loss: 0.222820 	 lr: 0.00034
[epoch  64: 260/307] 	 train loss: 0.336808 	 lr: 0.00034
[epoch  64: 280/307] 	 train loss: 0.400006 	 lr: 0.00034
[epoch  64: 300/307] 	 train loss: 0.148141 	 lr: 0.00034
[epoch  65:   0/307] 	 train loss: 0.167490 	 lr: 0.00034
[epoch  65:  20/307] 	 train loss: 0.158887 	 lr: 0.00034

val loss: 0.313763 	 acc: 0.914506

[epoch  65:  40/307] 	 train loss: 0.149422 	 lr: 0.00034
[epoch  65:  60/307] 	 train loss: 0.170388 	 lr: 0.00034
[epoch  65:  80/307] 	 train loss: 0.276440 	 lr: 0.00034
[epoch  65: 100/307] 	 train loss: 0.262033 	 lr: 0.00034
[epoch  65: 120/307] 	 train loss: 0.254164 	 lr: 0.00034
[epoch  65: 140/307] 	 train loss: 0.047602 	 lr: 0.00034
[epoch  65: 160/307] 	 train loss: 0.181999 	 lr: 0.00034

val loss: 0.323442 	 acc: 0.912885

[epoch  65: 180/307] 	 train loss: 0.201422 	 lr: 0.00034
[epoch  65: 200/307] 	 train loss: 0.315209 	 lr: 0.00034
[epoch  65: 220/307] 	 train loss: 0.423358 	 lr: 0.00034
[epoch  65: 240/307] 	 train loss: 0.161831 	 lr: 0.00034
[epoch  65: 260/307] 	 train loss: 0.198846 	 lr: 0.00034
[epoch  65: 280/307] 	 train loss: 0.383917 	 lr: 0.00034
[epoch  65: 300/307] 	 train loss: 0.040810 	 lr: 0.00034
[epoch  66:   0/307] 	 train loss: 0.212156 	 lr: 0.00034
[epoch  66:  20/307] 	 train loss: 0.204792 	 lr: 0.00034

val loss: 0.320389 	 acc: 0.907618

[epoch  66:  40/307] 	 train loss: 0.232577 	 lr: 0.00034
[epoch  66:  60/307] 	 train loss: 0.066072 	 lr: 0.00034
[epoch  66:  80/307] 	 train loss: 0.147292 	 lr: 0.00034
[epoch  66: 100/307] 	 train loss: 0.081649 	 lr: 0.00034
[epoch  66: 120/307] 	 train loss: 0.115994 	 lr: 0.00034
[epoch  66: 140/307] 	 train loss: 0.137097 	 lr: 0.00034
[epoch  66: 160/307] 	 train loss: 0.160782 	 lr: 0.00034

val loss: 0.310747 	 acc: 0.914100

[epoch  66: 180/307] 	 train loss: 0.017086 	 lr: 0.00034
[epoch  66: 200/307] 	 train loss: 0.089518 	 lr: 0.00034
[epoch  66: 220/307] 	 train loss: 0.089134 	 lr: 0.00034
[epoch  66: 240/307] 	 train loss: 0.118171 	 lr: 0.00034
[epoch  66: 260/307] 	 train loss: 0.097729 	 lr: 0.00034
[epoch  66: 280/307] 	 train loss: 0.300471 	 lr: 0.00034
[epoch  66: 300/307] 	 train loss: 0.290653 	 lr: 0.00034
[epoch  67:   0/307] 	 train loss: 0.160307 	 lr: 0.00034
[epoch  67:  20/307] 	 train loss: 0.149679 	 lr: 0.00034

val loss: 0.325938 	 acc: 0.909643

[epoch  67:  40/307] 	 train loss: 0.044782 	 lr: 0.00034
[epoch  67:  60/307] 	 train loss: 0.087925 	 lr: 0.00034
[epoch  67:  80/307] 	 train loss: 0.193513 	 lr: 0.00034
[epoch  67: 100/307] 	 train loss: 0.120786 	 lr: 0.00034
[epoch  67: 120/307] 	 train loss: 0.180302 	 lr: 0.00034
[epoch  67: 140/307] 	 train loss: 0.290752 	 lr: 0.00034
[epoch  67: 160/307] 	 train loss: 0.098291 	 lr: 0.00034

val loss: 0.309389 	 acc: 0.915316

[epoch  67: 180/307] 	 train loss: 0.096574 	 lr: 0.00034
[epoch  67: 200/307] 	 train loss: 0.317855 	 lr: 0.00034
[epoch  67: 220/307] 	 train loss: 0.159731 	 lr: 0.00034
[epoch  67: 240/307] 	 train loss: 0.325896 	 lr: 0.00034
[epoch  67: 260/307] 	 train loss: 0.211917 	 lr: 0.00034
[epoch  67: 280/307] 	 train loss: 0.378211 	 lr: 0.00034
[epoch  67: 300/307] 	 train loss: 0.077612 	 lr: 0.00034
[epoch  68:   0/307] 	 train loss: 0.179466 	 lr: 0.00034

val loss: 0.334680 	 acc: 0.907618

[epoch  68:  20/307] 	 train loss: 0.250894 	 lr: 0.00034
[epoch  68:  40/307] 	 train loss: 0.326158 	 lr: 0.00034
[epoch  68:  60/307] 	 train loss: 0.174027 	 lr: 0.00034
[epoch  68:  80/307] 	 train loss: 0.106121 	 lr: 0.00034
[epoch  68: 100/307] 	 train loss: 0.143874 	 lr: 0.00034
[epoch  68: 120/307] 	 train loss: 0.073565 	 lr: 0.00034
[epoch  68: 140/307] 	 train loss: 0.079450 	 lr: 0.00034
[epoch  68: 160/307] 	 train loss: 0.124122 	 lr: 0.00034

val loss: 0.318778 	 acc: 0.917342

[epoch  68: 180/307] 	 train loss: 0.388179 	 lr: 0.00034
[epoch  68: 200/307] 	 train loss: 0.124108 	 lr: 0.00034
[epoch  68: 220/307] 	 train loss: 0.216092 	 lr: 0.00034
[epoch  68: 240/307] 	 train loss: 0.247163 	 lr: 0.00034
[epoch  68: 260/307] 	 train loss: 0.096351 	 lr: 0.00034
[epoch  68: 280/307] 	 train loss: 0.229818 	 lr: 0.00034
[epoch  68: 300/307] 	 train loss: 0.069328 	 lr: 0.00034
[epoch  69:   0/307] 	 train loss: 0.107703 	 lr: 0.00034

val loss: 0.330589 	 acc: 0.908833

[epoch  69:  20/307] 	 train loss: 0.146062 	 lr: 0.00034
[epoch  69:  40/307] 	 train loss: 0.182241 	 lr: 0.00034
[epoch  69:  60/307] 	 train loss: 0.189995 	 lr: 0.00034
[epoch  69:  80/307] 	 train loss: 0.083066 	 lr: 0.00034
[epoch  69: 100/307] 	 train loss: 0.262186 	 lr: 0.00034
[epoch  69: 120/307] 	 train loss: 0.066453 	 lr: 0.00034
[epoch  69: 140/307] 	 train loss: 0.047975 	 lr: 0.00034
[epoch  69: 160/307] 	 train loss: 0.101333 	 lr: 0.00034

val loss: 0.338692 	 acc: 0.909238

[epoch  69: 180/307] 	 train loss: 0.219894 	 lr: 0.00034
[epoch  69: 200/307] 	 train loss: 0.410999 	 lr: 0.00034
[epoch  69: 220/307] 	 train loss: 0.196995 	 lr: 0.00034
[epoch  69: 240/307] 	 train loss: 0.306411 	 lr: 0.00034
[epoch  69: 260/307] 	 train loss: 0.134131 	 lr: 0.00034
[epoch  69: 280/307] 	 train loss: 0.250616 	 lr: 0.00034
[epoch  69: 300/307] 	 train loss: 0.237349 	 lr: 0.00034
[epoch  70:   0/307] 	 train loss: 0.268644 	 lr: 0.00034

val loss: 0.322424 	 acc: 0.908428

[epoch  70:  20/307] 	 train loss: 0.098233 	 lr: 0.00034
[epoch  70:  40/307] 	 train loss: 0.033546 	 lr: 0.00034
[epoch  70:  60/307] 	 train loss: 0.307416 	 lr: 0.00034
[epoch  70:  80/307] 	 train loss: 0.254551 	 lr: 0.00034
[epoch  70: 100/307] 	 train loss: 0.135122 	 lr: 0.00034
[epoch  70: 120/307] 	 train loss: 0.172304 	 lr: 0.00034
[epoch  70: 140/307] 	 train loss: 0.115482 	 lr: 0.00034
[epoch  70: 160/307] 	 train loss: 0.130924 	 lr: 0.00034

val loss: 0.310925 	 acc: 0.916126

[epoch  70: 180/307] 	 train loss: 0.335762 	 lr: 0.00034
[epoch  70: 200/307] 	 train loss: 0.380440 	 lr: 0.00034
[epoch  70: 220/307] 	 train loss: 0.054916 	 lr: 0.00034
[epoch  70: 240/307] 	 train loss: 0.414640 	 lr: 0.00034
[epoch  70: 260/307] 	 train loss: 0.389686 	 lr: 0.00034
[epoch  70: 280/307] 	 train loss: 0.156836 	 lr: 0.00034
[epoch  70: 300/307] 	 train loss: 0.204412 	 lr: 0.00034
[epoch  71:   0/307] 	 train loss: 0.318694 	 lr: 0.00034

val loss: 0.311237 	 acc: 0.916126

[epoch  71:  20/307] 	 train loss: 0.150736 	 lr: 0.00034
[epoch  71:  40/307] 	 train loss: 0.267900 	 lr: 0.00034
[epoch  71:  60/307] 	 train loss: 0.131550 	 lr: 0.00034
[epoch  71:  80/307] 	 train loss: 0.252727 	 lr: 0.00034
[epoch  71: 100/307] 	 train loss: 0.310144 	 lr: 0.00034
[epoch  71: 120/307] 	 train loss: 0.085099 	 lr: 0.00034
[epoch  71: 140/307] 	 train loss: 0.066741 	 lr: 0.00034
[epoch  71: 160/307] 	 train loss: 0.112913 	 lr: 0.00034

val loss: 0.314954 	 acc: 0.912480

[epoch  71: 180/307] 	 train loss: 0.056477 	 lr: 0.00034
[epoch  71: 200/307] 	 train loss: 0.222026 	 lr: 0.00034
[epoch  71: 220/307] 	 train loss: 0.026656 	 lr: 0.00034
[epoch  71: 240/307] 	 train loss: 0.179251 	 lr: 0.00034
[epoch  71: 260/307] 	 train loss: 0.119848 	 lr: 0.00034
[epoch  71: 280/307] 	 train loss: 0.176638 	 lr: 0.00034
[epoch  71: 300/307] 	 train loss: 0.177706 	 lr: 0.00034
[epoch  72:   0/307] 	 train loss: 0.072931 	 lr: 0.00034

val loss: 0.326666 	 acc: 0.913695

[epoch  72:  20/307] 	 train loss: 0.079787 	 lr: 0.00034
[epoch  72:  40/307] 	 train loss: 0.078162 	 lr: 0.00034
[epoch  72:  60/307] 	 train loss: 0.289276 	 lr: 0.00034
[epoch  72:  80/307] 	 train loss: 0.086523 	 lr: 0.00034
[epoch  72: 100/307] 	 train loss: 0.392052 	 lr: 0.00034
[epoch  72: 120/307] 	 train loss: 0.306302 	 lr: 0.00034
[epoch  72: 140/307] 	 train loss: 0.131084 	 lr: 0.00034
[epoch  72: 160/307] 	 train loss: 0.096174 	 lr: 0.00034

val loss: 0.325480 	 acc: 0.908428

[epoch  72: 180/307] 	 train loss: 0.035989 	 lr: 0.00034
[epoch  72: 200/307] 	 train loss: 0.253801 	 lr: 0.00034
[epoch  72: 220/307] 	 train loss: 0.178249 	 lr: 0.00034
[epoch  72: 240/307] 	 train loss: 0.162262 	 lr: 0.00034
[epoch  72: 260/307] 	 train loss: 0.231314 	 lr: 0.00034
[epoch  72: 280/307] 	 train loss: 0.045344 	 lr: 0.00034
[epoch  72: 300/307] 	 train loss: 0.113814 	 lr: 0.00034
[epoch  73:   0/307] 	 train loss: 0.293289 	 lr: 0.00034

val loss: 0.327437 	 acc: 0.908833

[epoch  73:  20/307] 	 train loss: 0.186142 	 lr: 0.00034
[epoch  73:  40/307] 	 train loss: 0.105552 	 lr: 0.00034
[epoch  73:  60/307] 	 train loss: 0.226453 	 lr: 0.00034
[epoch  73:  80/307] 	 train loss: 0.083262 	 lr: 0.00034
[epoch  73: 100/307] 	 train loss: 0.056853 	 lr: 0.00034
[epoch  73: 120/307] 	 train loss: 0.365401 	 lr: 0.00034
[epoch  73: 140/307] 	 train loss: 0.075837 	 lr: 0.00034
[epoch  73: 160/307] 	 train loss: 0.173310 	 lr: 0.00034

val loss: 0.316273 	 acc: 0.911264

[epoch  73: 180/307] 	 train loss: 0.077457 	 lr: 0.00034
[epoch  73: 200/307] 	 train loss: 0.160684 	 lr: 0.00034
[epoch  73: 220/307] 	 train loss: 0.281102 	 lr: 0.00034
[epoch  73: 240/307] 	 train loss: 0.204942 	 lr: 0.00034
[epoch  73: 260/307] 	 train loss: 0.106375 	 lr: 0.00034
[epoch  73: 280/307] 	 train loss: 0.141500 	 lr: 0.00034
[epoch  73: 300/307] 	 train loss: 0.174962 	 lr: 0.00034
[epoch  74:   0/307] 	 train loss: 0.192607 	 lr: 0.00034

val loss: 0.324929 	 acc: 0.913290

[epoch  74:  20/307] 	 train loss: 0.117778 	 lr: 0.00034
[epoch  74:  40/307] 	 train loss: 0.093916 	 lr: 0.00034
[epoch  74:  60/307] 	 train loss: 0.404440 	 lr: 0.00034
[epoch  74:  80/307] 	 train loss: 0.421428 	 lr: 0.00034
[epoch  74: 100/307] 	 train loss: 0.140287 	 lr: 0.00034
[epoch  74: 120/307] 	 train loss: 0.244132 	 lr: 0.00034
[epoch  74: 140/307] 	 train loss: 0.178380 	 lr: 0.00034

val loss: 0.345612 	 acc: 0.901945

[epoch  74: 160/307] 	 train loss: 0.319946 	 lr: 0.00034
[epoch  74: 180/307] 	 train loss: 0.107712 	 lr: 0.00034
[epoch  74: 200/307] 	 train loss: 0.213731 	 lr: 0.00034
[epoch  74: 220/307] 	 train loss: 0.035640 	 lr: 0.00034
[epoch  74: 240/307] 	 train loss: 0.123966 	 lr: 0.00034
[epoch  74: 260/307] 	 train loss: 0.284148 	 lr: 0.00034
[epoch  74: 280/307] 	 train loss: 0.091791 	 lr: 0.00034
[epoch  74: 300/307] 	 train loss: 0.165500 	 lr: 0.00034
[epoch  75:   0/307] 	 train loss: 0.149955 	 lr: 0.00034

val loss: 0.342923 	 acc: 0.910049

[epoch  75:  20/307] 	 train loss: 0.133774 	 lr: 0.00034
[epoch  75:  40/307] 	 train loss: 0.283031 	 lr: 0.00034
[epoch  75:  60/307] 	 train loss: 0.108879 	 lr: 0.00034
[epoch  75:  80/307] 	 train loss: 0.087207 	 lr: 0.00034
[epoch  75: 100/307] 	 train loss: 0.059350 	 lr: 0.00034
[epoch  75: 120/307] 	 train loss: 0.062473 	 lr: 0.00034
[epoch  75: 140/307] 	 train loss: 0.159540 	 lr: 0.00034

val loss: 0.328222 	 acc: 0.909643

[epoch  75: 160/307] 	 train loss: 0.247255 	 lr: 0.00034
[epoch  75: 180/307] 	 train loss: 0.317381 	 lr: 0.00034
[epoch  75: 200/307] 	 train loss: 0.209329 	 lr: 0.00034
[epoch  75: 220/307] 	 train loss: 0.321120 	 lr: 0.00034
[epoch  75: 240/307] 	 train loss: 0.234360 	 lr: 0.00034
[epoch  75: 260/307] 	 train loss: 0.223397 	 lr: 0.00034
[epoch  75: 280/307] 	 train loss: 0.121741 	 lr: 0.00034
[epoch  75: 300/307] 	 train loss: 0.167873 	 lr: 0.00034
[epoch  76:   0/307] 	 train loss: 0.075936 	 lr: 0.00034

val loss: 0.319871 	 acc: 0.912480

[epoch  76:  20/307] 	 train loss: 0.247215 	 lr: 0.00034
[epoch  76:  40/307] 	 train loss: 0.065740 	 lr: 0.00034
[epoch  76:  60/307] 	 train loss: 0.041088 	 lr: 0.00034
[epoch  76:  80/307] 	 train loss: 0.373797 	 lr: 0.00034
[epoch  76: 100/307] 	 train loss: 0.029370 	 lr: 0.00034
[epoch  76: 120/307] 	 train loss: 0.117985 	 lr: 0.00034
[epoch  76: 140/307] 	 train loss: 0.065941 	 lr: 0.00034

val loss: 0.334103 	 acc: 0.908833

[epoch  76: 160/307] 	 train loss: 0.249065 	 lr: 0.00034
[epoch  76: 180/307] 	 train loss: 0.241442 	 lr: 0.00034
[epoch  76: 200/307] 	 train loss: 0.316986 	 lr: 0.00034
[epoch  76: 220/307] 	 train loss: 0.115378 	 lr: 0.00034
[epoch  76: 240/307] 	 train loss: 0.055380 	 lr: 0.00034
[epoch  76: 260/307] 	 train loss: 0.195136 	 lr: 0.00034
[epoch  76: 280/307] 	 train loss: 0.251260 	 lr: 0.00034
[epoch  76: 300/307] 	 train loss: 0.022505 	 lr: 0.00034
[epoch  77:   0/307] 	 train loss: 0.136635 	 lr: 0.00034

val loss: 0.330085 	 acc: 0.910454

[epoch  77:  20/307] 	 train loss: 0.139243 	 lr: 0.00034
[epoch  77:  40/307] 	 train loss: 0.522734 	 lr: 0.00034
[epoch  77:  60/307] 	 train loss: 0.165041 	 lr: 0.00034
[epoch  77:  80/307] 	 train loss: 0.155424 	 lr: 0.00034
[epoch  77: 100/307] 	 train loss: 0.108222 	 lr: 0.00034
[epoch  77: 120/307] 	 train loss: 0.320847 	 lr: 0.00034
[epoch  77: 140/307] 	 train loss: 0.061700 	 lr: 0.00034

val loss: 0.339241 	 acc: 0.909643

[epoch  77: 160/307] 	 train loss: 0.043883 	 lr: 0.00034
[epoch  77: 180/307] 	 train loss: 0.084059 	 lr: 0.00034
[epoch  77: 200/307] 	 train loss: 0.175491 	 lr: 0.00034
[epoch  77: 220/307] 	 train loss: 0.200992 	 lr: 0.00034
[epoch  77: 240/307] 	 train loss: 0.141247 	 lr: 0.00034
[epoch  77: 260/307] 	 train loss: 0.445867 	 lr: 0.00034
[epoch  77: 280/307] 	 train loss: 0.485143 	 lr: 0.00034
[epoch  77: 300/307] 	 train loss: 0.084665 	 lr: 0.00034

val loss: 0.327873 	 acc: 0.910454

[epoch  78:   0/307] 	 train loss: 0.453730 	 lr: 0.00034
[epoch  78:  20/307] 	 train loss: 0.130148 	 lr: 0.00034
[epoch  78:  40/307] 	 train loss: 0.324214 	 lr: 0.00034
[epoch  78:  60/307] 	 train loss: 0.119268 	 lr: 0.00034
[epoch  78:  80/307] 	 train loss: 0.066067 	 lr: 0.00034
[epoch  78: 100/307] 	 train loss: 0.322804 	 lr: 0.00034
[epoch  78: 120/307] 	 train loss: 0.051565 	 lr: 0.00034
[epoch  78: 140/307] 	 train loss: 0.078949 	 lr: 0.00034

val loss: 0.336495 	 acc: 0.911669

[epoch  78: 160/307] 	 train loss: 0.248353 	 lr: 0.00034
[epoch  78: 180/307] 	 train loss: 0.229927 	 lr: 0.00034
[epoch  78: 200/307] 	 train loss: 0.114691 	 lr: 0.00034
[epoch  78: 220/307] 	 train loss: 0.150371 	 lr: 0.00034
[epoch  78: 240/307] 	 train loss: 0.087318 	 lr: 0.00034
[epoch  78: 260/307] 	 train loss: 0.252097 	 lr: 0.00034
[epoch  78: 280/307] 	 train loss: 0.170770 	 lr: 0.00034
[epoch  78: 300/307] 	 train loss: 0.072618 	 lr: 0.00034

val loss: 0.339369 	 acc: 0.907618

[epoch  79:   0/307] 	 train loss: 0.128390 	 lr: 0.00034
[epoch  79:  20/307] 	 train loss: 0.031774 	 lr: 0.00034
[epoch  79:  40/307] 	 train loss: 0.102896 	 lr: 0.00034
[epoch  79:  60/307] 	 train loss: 0.129545 	 lr: 0.00034
[epoch  79:  80/307] 	 train loss: 0.233322 	 lr: 0.00034
[epoch  79: 100/307] 	 train loss: 0.446961 	 lr: 0.00034
[epoch  79: 120/307] 	 train loss: 0.164565 	 lr: 0.00034
[epoch  79: 140/307] 	 train loss: 0.125799 	 lr: 0.00034

val loss: 0.319549 	 acc: 0.910454

[epoch  79: 160/307] 	 train loss: 0.079096 	 lr: 0.00034
[epoch  79: 180/307] 	 train loss: 0.226547 	 lr: 0.00034
[epoch  79: 200/307] 	 train loss: 0.311956 	 lr: 0.00034
[epoch  79: 220/307] 	 train loss: 0.090874 	 lr: 0.00034
[epoch  79: 240/307] 	 train loss: 0.228392 	 lr: 0.00034
[epoch  79: 260/307] 	 train loss: 0.179606 	 lr: 0.00034
[epoch  79: 280/307] 	 train loss: 0.033931 	 lr: 0.00034
[epoch  79: 300/307] 	 train loss: 0.051645 	 lr: 0.00034

val loss: 0.323751 	 acc: 0.912075

[epoch  80:   0/307] 	 train loss: 0.181509 	 lr: 0.00034
[epoch  80:  20/307] 	 train loss: 0.029164 	 lr: 0.00034
[epoch  80:  40/307] 	 train loss: 0.330160 	 lr: 0.00034
[epoch  80:  60/307] 	 train loss: 0.269863 	 lr: 0.00034
[epoch  80:  80/307] 	 train loss: 0.117463 	 lr: 0.00034
[epoch  80: 100/307] 	 train loss: 0.071884 	 lr: 0.00034
[epoch  80: 120/307] 	 train loss: 0.216544 	 lr: 0.00034
[epoch  80: 140/307] 	 train loss: 0.104682 	 lr: 0.00034

val loss: 0.330938 	 acc: 0.912075

[epoch  80: 160/307] 	 train loss: 0.222392 	 lr: 0.00034
[epoch  80: 180/307] 	 train loss: 0.080713 	 lr: 0.00034
[epoch  80: 200/307] 	 train loss: 0.157944 	 lr: 0.00034
[epoch  80: 220/307] 	 train loss: 0.200715 	 lr: 0.00034
[epoch  80: 240/307] 	 train loss: 0.024370 	 lr: 0.00034
[epoch  80: 260/307] 	 train loss: 0.104636 	 lr: 0.00034
[epoch  80: 280/307] 	 train loss: 0.258105 	 lr: 0.00034
[epoch  80: 300/307] 	 train loss: 0.207792 	 lr: 0.00034

val loss: 0.344337 	 acc: 0.911264

[epoch  81:   0/307] 	 train loss: 0.015820 	 lr: 0.00034
[epoch  81:  20/307] 	 train loss: 0.163153 	 lr: 0.00034
[epoch  81:  40/307] 	 train loss: 0.254880 	 lr: 0.00034
[epoch  81:  60/307] 	 train loss: 0.185000 	 lr: 0.00034
[epoch  81:  80/307] 	 train loss: 0.130898 	 lr: 0.00034
[epoch  81: 100/307] 	 train loss: 0.195751 	 lr: 0.00034
[epoch  81: 120/307] 	 train loss: 0.101889 	 lr: 0.00034
[epoch  81: 140/307] 	 train loss: 0.075699 	 lr: 0.00034

val loss: 0.323877 	 acc: 0.913290

[epoch  81: 160/307] 	 train loss: 0.100869 	 lr: 0.00034
[epoch  81: 180/307] 	 train loss: 0.148782 	 lr: 0.00034
[epoch  81: 200/307] 	 train loss: 0.114296 	 lr: 0.00034
[epoch  81: 220/307] 	 train loss: 0.500617 	 lr: 0.00034
[epoch  81: 240/307] 	 train loss: 0.058087 	 lr: 0.00034
[epoch  81: 260/307] 	 train loss: 0.131822 	 lr: 0.00034
[epoch  81: 280/307] 	 train loss: 0.169220 	 lr: 0.00034

val loss: 0.327917 	 acc: 0.912480

[epoch  81: 300/307] 	 train loss: 0.292142 	 lr: 0.00034
[epoch  82:   0/307] 	 train loss: 0.156681 	 lr: 0.00034
[epoch  82:  20/307] 	 train loss: 0.240402 	 lr: 0.00034
[epoch  82:  40/307] 	 train loss: 0.083456 	 lr: 0.00034
[epoch  82:  60/307] 	 train loss: 0.191271 	 lr: 0.00034
[epoch  82:  80/307] 	 train loss: 0.268182 	 lr: 0.00034
[epoch  82: 100/307] 	 train loss: 0.115216 	 lr: 0.00034
[epoch  82: 120/307] 	 train loss: 0.083476 	 lr: 0.00034
[epoch  82: 140/307] 	 train loss: 0.131334 	 lr: 0.00034

val loss: 0.339369 	 acc: 0.914100

[epoch  82: 160/307] 	 train loss: 0.195372 	 lr: 0.00034
[epoch  82: 180/307] 	 train loss: 0.101557 	 lr: 0.00034
[epoch  82: 200/307] 	 train loss: 0.243357 	 lr: 0.00034
[epoch  82: 220/307] 	 train loss: 0.202717 	 lr: 0.00034
[epoch  82: 240/307] 	 train loss: 0.189727 	 lr: 0.00034
[epoch  82: 260/307] 	 train loss: 0.124495 	 lr: 0.00034
[epoch  82: 280/307] 	 train loss: 0.210081 	 lr: 0.00034

val loss: 0.337465 	 acc: 0.913290

[epoch  82: 300/307] 	 train loss: 0.194901 	 lr: 0.00034
[epoch  83:   0/307] 	 train loss: 0.056555 	 lr: 0.00034
[epoch  83:  20/307] 	 train loss: 0.068564 	 lr: 0.00034
[epoch  83:  40/307] 	 train loss: 0.064481 	 lr: 0.00034
[epoch  83:  60/307] 	 train loss: 0.096485 	 lr: 0.00034
[epoch  83:  80/307] 	 train loss: 0.031700 	 lr: 0.00034
[epoch  83: 100/307] 	 train loss: 0.075009 	 lr: 0.00034
[epoch  83: 120/307] 	 train loss: 0.209427 	 lr: 0.00034
[epoch  83: 140/307] 	 train loss: 0.520332 	 lr: 0.00034

val loss: 0.333317 	 acc: 0.909643

[epoch  83: 160/307] 	 train loss: 0.350020 	 lr: 0.00034
[epoch  83: 180/307] 	 train loss: 0.115993 	 lr: 0.00034
[epoch  83: 200/307] 	 train loss: 0.127839 	 lr: 0.00034
[epoch  83: 220/307] 	 train loss: 0.082002 	 lr: 0.00034
[epoch  83: 240/307] 	 train loss: 0.244124 	 lr: 0.00034
[epoch  83: 260/307] 	 train loss: 0.077037 	 lr: 0.00034
[epoch  83: 280/307] 	 train loss: 0.095112 	 lr: 0.00034

val loss: 0.323781 	 acc: 0.910049

[epoch  83: 300/307] 	 train loss: 0.282010 	 lr: 0.00034
[epoch  84:   0/307] 	 train loss: 0.079733 	 lr: 0.00034
[epoch  84:  20/307] 	 train loss: 0.024121 	 lr: 0.00034
[epoch  84:  40/307] 	 train loss: 0.098111 	 lr: 0.00034
[epoch  84:  60/307] 	 train loss: 0.176072 	 lr: 0.00034
[epoch  84:  80/307] 	 train loss: 0.296527 	 lr: 0.00034
[epoch  84: 100/307] 	 train loss: 0.088526 	 lr: 0.00034
[epoch  84: 120/307] 	 train loss: 0.232573 	 lr: 0.00034

val loss: 0.305305 	 acc: 0.918558

saved model with accuracy %0.6f:  0.9185575364667747
[epoch  84: 140/307] 	 train loss: 0.363187 	 lr: 0.00034
[epoch  84: 160/307] 	 train loss: 0.115555 	 lr: 0.00034
[epoch  84: 180/307] 	 train loss: 0.051409 	 lr: 0.00034
[epoch  84: 200/307] 	 train loss: 0.070518 	 lr: 0.00034
[epoch  84: 220/307] 	 train loss: 0.259606 	 lr: 0.00034
[epoch  84: 240/307] 	 train loss: 0.164825 	 lr: 0.00034
[epoch  84: 260/307] 	 train loss: 0.161543 	 lr: 0.00034
[epoch  84: 280/307] 	 train loss: 0.047260 	 lr: 0.00034

val loss: 0.315153 	 acc: 0.914506

[epoch  84: 300/307] 	 train loss: 0.236058 	 lr: 0.00034
[epoch  85:   0/307] 	 train loss: 0.253542 	 lr: 0.00024
[epoch  85:  20/307] 	 train loss: 0.273092 	 lr: 0.00024
[epoch  85:  40/307] 	 train loss: 0.186719 	 lr: 0.00024
[epoch  85:  60/307] 	 train loss: 0.087808 	 lr: 0.00024
[epoch  85:  80/307] 	 train loss: 0.040171 	 lr: 0.00024
[epoch  85: 100/307] 	 train loss: 0.150767 	 lr: 0.00024
[epoch  85: 120/307] 	 train loss: 0.041893 	 lr: 0.00024

val loss: 0.318390 	 acc: 0.915316

[epoch  85: 140/307] 	 train loss: 0.108203 	 lr: 0.00024
[epoch  85: 160/307] 	 train loss: 0.271364 	 lr: 0.00024
[epoch  85: 180/307] 	 train loss: 0.086312 	 lr: 0.00024
[epoch  85: 200/307] 	 train loss: 0.022232 	 lr: 0.00024
[epoch  85: 220/307] 	 train loss: 0.116944 	 lr: 0.00024
[epoch  85: 240/307] 	 train loss: 0.115329 	 lr: 0.00024
[epoch  85: 260/307] 	 train loss: 0.174603 	 lr: 0.00024
[epoch  85: 280/307] 	 train loss: 0.269044 	 lr: 0.00024

val loss: 0.328451 	 acc: 0.913695

[epoch  85: 300/307] 	 train loss: 0.198727 	 lr: 0.00024
[epoch  86:   0/307] 	 train loss: 0.074254 	 lr: 0.00024
[epoch  86:  20/307] 	 train loss: 0.152109 	 lr: 0.00024
[epoch  86:  40/307] 	 train loss: 0.437206 	 lr: 0.00024
[epoch  86:  60/307] 	 train loss: 0.129751 	 lr: 0.00024
[epoch  86:  80/307] 	 train loss: 0.100854 	 lr: 0.00024
[epoch  86: 100/307] 	 train loss: 0.368818 	 lr: 0.00024
[epoch  86: 120/307] 	 train loss: 0.221924 	 lr: 0.00024

val loss: 0.327922 	 acc: 0.912885

[epoch  86: 140/307] 	 train loss: 0.123972 	 lr: 0.00024
[epoch  86: 160/307] 	 train loss: 0.108128 	 lr: 0.00024
[epoch  86: 180/307] 	 train loss: 0.107217 	 lr: 0.00024
[epoch  86: 200/307] 	 train loss: 0.294123 	 lr: 0.00024
[epoch  86: 220/307] 	 train loss: 0.303094 	 lr: 0.00024
[epoch  86: 240/307] 	 train loss: 0.190897 	 lr: 0.00024
[epoch  86: 260/307] 	 train loss: 0.264871 	 lr: 0.00024
[epoch  86: 280/307] 	 train loss: 0.017939 	 lr: 0.00024

val loss: 0.323504 	 acc: 0.912480

[epoch  86: 300/307] 	 train loss: 0.071933 	 lr: 0.00024
[epoch  87:   0/307] 	 train loss: 0.139722 	 lr: 0.00024
[epoch  87:  20/307] 	 train loss: 0.196761 	 lr: 0.00024
[epoch  87:  40/307] 	 train loss: 0.140181 	 lr: 0.00024
[epoch  87:  60/307] 	 train loss: 0.119009 	 lr: 0.00024
[epoch  87:  80/307] 	 train loss: 0.237306 	 lr: 0.00024
[epoch  87: 100/307] 	 train loss: 0.189233 	 lr: 0.00024
[epoch  87: 120/307] 	 train loss: 0.105865 	 lr: 0.00024

val loss: 0.336998 	 acc: 0.912075

[epoch  87: 140/307] 	 train loss: 0.121628 	 lr: 0.00024
[epoch  87: 160/307] 	 train loss: 0.177600 	 lr: 0.00024
[epoch  87: 180/307] 	 train loss: 0.052701 	 lr: 0.00024
[epoch  87: 200/307] 	 train loss: 0.240770 	 lr: 0.00024
[epoch  87: 220/307] 	 train loss: 0.188453 	 lr: 0.00024
[epoch  87: 240/307] 	 train loss: 0.194186 	 lr: 0.00024
[epoch  87: 260/307] 	 train loss: 0.147146 	 lr: 0.00024
[epoch  87: 280/307] 	 train loss: 0.226760 	 lr: 0.00024

val loss: 0.313335 	 acc: 0.915316

[epoch  87: 300/307] 	 train loss: 0.101483 	 lr: 0.00024
[epoch  88:   0/307] 	 train loss: 0.098233 	 lr: 0.00024
[epoch  88:  20/307] 	 train loss: 0.084628 	 lr: 0.00024
[epoch  88:  40/307] 	 train loss: 0.162295 	 lr: 0.00024
[epoch  88:  60/307] 	 train loss: 0.152511 	 lr: 0.00024
[epoch  88:  80/307] 	 train loss: 0.074890 	 lr: 0.00024
[epoch  88: 100/307] 	 train loss: 0.174625 	 lr: 0.00024
[epoch  88: 120/307] 	 train loss: 0.177443 	 lr: 0.00024

val loss: 0.327332 	 acc: 0.912885

[epoch  88: 140/307] 	 train loss: 0.814202 	 lr: 0.00024
[epoch  88: 160/307] 	 train loss: 0.188331 	 lr: 0.00024
[epoch  88: 180/307] 	 train loss: 0.066507 	 lr: 0.00024
[epoch  88: 200/307] 	 train loss: 0.092298 	 lr: 0.00024
[epoch  88: 220/307] 	 train loss: 0.147203 	 lr: 0.00024
[epoch  88: 240/307] 	 train loss: 0.026301 	 lr: 0.00024
[epoch  88: 260/307] 	 train loss: 0.037319 	 lr: 0.00024
[epoch  88: 280/307] 	 train loss: 0.396477 	 lr: 0.00024

val loss: 0.321862 	 acc: 0.914100

[epoch  88: 300/307] 	 train loss: 0.236368 	 lr: 0.00024
[epoch  89:   0/307] 	 train loss: 0.154758 	 lr: 0.00024
[epoch  89:  20/307] 	 train loss: 0.134560 	 lr: 0.00024
[epoch  89:  40/307] 	 train loss: 0.044175 	 lr: 0.00024
[epoch  89:  60/307] 	 train loss: 0.135813 	 lr: 0.00024
[epoch  89:  80/307] 	 train loss: 0.093916 	 lr: 0.00024
[epoch  89: 100/307] 	 train loss: 0.196102 	 lr: 0.00024
[epoch  89: 120/307] 	 train loss: 0.141360 	 lr: 0.00024

val loss: 0.337365 	 acc: 0.914100

[epoch  89: 140/307] 	 train loss: 0.034736 	 lr: 0.00024
[epoch  89: 160/307] 	 train loss: 0.073695 	 lr: 0.00024
[epoch  89: 180/307] 	 train loss: 0.083281 	 lr: 0.00024
[epoch  89: 200/307] 	 train loss: 0.167350 	 lr: 0.00024
[epoch  89: 220/307] 	 train loss: 0.394392 	 lr: 0.00024
[epoch  89: 240/307] 	 train loss: 0.168253 	 lr: 0.00024
[epoch  89: 260/307] 	 train loss: 0.198746 	 lr: 0.00024
[epoch  89: 280/307] 	 train loss: 0.248093 	 lr: 0.00024

val loss: 0.328288 	 acc: 0.912885

[epoch  89: 300/307] 	 train loss: 0.266643 	 lr: 0.00024
[epoch  90:   0/307] 	 train loss: 0.180942 	 lr: 0.00024
[epoch  90:  20/307] 	 train loss: 0.161907 	 lr: 0.00024
[epoch  90:  40/307] 	 train loss: 0.130094 	 lr: 0.00024
[epoch  90:  60/307] 	 train loss: 0.387489 	 lr: 0.00024
[epoch  90:  80/307] 	 train loss: 0.167444 	 lr: 0.00024
[epoch  90: 100/307] 	 train loss: 0.095833 	 lr: 0.00024
[epoch  90: 120/307] 	 train loss: 0.102202 	 lr: 0.00024

val loss: 0.327418 	 acc: 0.912480

[epoch  90: 140/307] 	 train loss: 0.312795 	 lr: 0.00024
[epoch  90: 160/307] 	 train loss: 0.186925 	 lr: 0.00024
[epoch  90: 180/307] 	 train loss: 0.126106 	 lr: 0.00024
[epoch  90: 200/307] 	 train loss: 0.263242 	 lr: 0.00024
[epoch  90: 220/307] 	 train loss: 0.103825 	 lr: 0.00024
[epoch  90: 240/307] 	 train loss: 0.199543 	 lr: 0.00024
[epoch  90: 260/307] 	 train loss: 0.065860 	 lr: 0.00024
[epoch  90: 280/307] 	 train loss: 0.112474 	 lr: 0.00024

val loss: 0.339157 	 acc: 0.907212

[epoch  90: 300/307] 	 train loss: 0.373742 	 lr: 0.00024
[epoch  91:   0/307] 	 train loss: 0.086964 	 lr: 0.00024
[epoch  91:  20/307] 	 train loss: 0.200312 	 lr: 0.00024
[epoch  91:  40/307] 	 train loss: 0.180279 	 lr: 0.00024
[epoch  91:  60/307] 	 train loss: 0.162842 	 lr: 0.00024
[epoch  91:  80/307] 	 train loss: 0.178876 	 lr: 0.00024
[epoch  91: 100/307] 	 train loss: 0.155531 	 lr: 0.00024
[epoch  91: 120/307] 	 train loss: 0.064835 	 lr: 0.00024

val loss: 0.321989 	 acc: 0.910859

[epoch  91: 140/307] 	 train loss: 0.150908 	 lr: 0.00024
[epoch  91: 160/307] 	 train loss: 0.233658 	 lr: 0.00024
[epoch  91: 180/307] 	 train loss: 0.045917 	 lr: 0.00024
[epoch  91: 200/307] 	 train loss: 0.120251 	 lr: 0.00024
[epoch  91: 220/307] 	 train loss: 0.181384 	 lr: 0.00024
[epoch  91: 240/307] 	 train loss: 0.115006 	 lr: 0.00024
[epoch  91: 260/307] 	 train loss: 0.290427 	 lr: 0.00024

val loss: 0.340363 	 acc: 0.912075

[epoch  91: 280/307] 	 train loss: 0.059170 	 lr: 0.00024
[epoch  91: 300/307] 	 train loss: 0.295816 	 lr: 0.00024
[epoch  92:   0/307] 	 train loss: 0.174712 	 lr: 0.00024
[epoch  92:  20/307] 	 train loss: 0.300532 	 lr: 0.00024
[epoch  92:  40/307] 	 train loss: 0.092310 	 lr: 0.00024
[epoch  92:  60/307] 	 train loss: 0.081558 	 lr: 0.00024
[epoch  92:  80/307] 	 train loss: 0.300233 	 lr: 0.00024
[epoch  92: 100/307] 	 train loss: 0.176789 	 lr: 0.00024
[epoch  92: 120/307] 	 train loss: 0.220662 	 lr: 0.00024

val loss: 0.342171 	 acc: 0.911669

[epoch  92: 140/307] 	 train loss: 0.148273 	 lr: 0.00024
[epoch  92: 160/307] 	 train loss: 0.624433 	 lr: 0.00024
[epoch  92: 180/307] 	 train loss: 0.067366 	 lr: 0.00024
[epoch  92: 200/307] 	 train loss: 0.060717 	 lr: 0.00024
[epoch  92: 220/307] 	 train loss: 0.127401 	 lr: 0.00024
[epoch  92: 240/307] 	 train loss: 0.122248 	 lr: 0.00024
[epoch  92: 260/307] 	 train loss: 0.139140 	 lr: 0.00024

val loss: 0.332852 	 acc: 0.913290

[epoch  92: 280/307] 	 train loss: 0.159330 	 lr: 0.00024
[epoch  92: 300/307] 	 train loss: 0.205303 	 lr: 0.00024
[epoch  93:   0/307] 	 train loss: 0.154016 	 lr: 0.00024
[epoch  93:  20/307] 	 train loss: 0.148047 	 lr: 0.00024
[epoch  93:  40/307] 	 train loss: 0.128316 	 lr: 0.00024
[epoch  93:  60/307] 	 train loss: 0.119683 	 lr: 0.00024
[epoch  93:  80/307] 	 train loss: 0.403398 	 lr: 0.00024
[epoch  93: 100/307] 	 train loss: 0.059544 	 lr: 0.00024
[epoch  93: 120/307] 	 train loss: 0.230758 	 lr: 0.00024

val loss: 0.342716 	 acc: 0.912480

[epoch  93: 140/307] 	 train loss: 0.242871 	 lr: 0.00024
[epoch  93: 160/307] 	 train loss: 0.089912 	 lr: 0.00024
[epoch  93: 180/307] 	 train loss: 0.229542 	 lr: 0.00024
[epoch  93: 200/307] 	 train loss: 0.136939 	 lr: 0.00024
[epoch  93: 220/307] 	 train loss: 0.339410 	 lr: 0.00024
[epoch  93: 240/307] 	 train loss: 0.296300 	 lr: 0.00024
[epoch  93: 260/307] 	 train loss: 0.291475 	 lr: 0.00024

val loss: 0.327436 	 acc: 0.915316

[epoch  93: 280/307] 	 train loss: 0.164739 	 lr: 0.00024
[epoch  93: 300/307] 	 train loss: 0.123726 	 lr: 0.00024
[epoch  94:   0/307] 	 train loss: 0.112854 	 lr: 0.00024
[epoch  94:  20/307] 	 train loss: 0.121450 	 lr: 0.00024
[epoch  94:  40/307] 	 train loss: 0.087122 	 lr: 0.00024
[epoch  94:  60/307] 	 train loss: 0.030106 	 lr: 0.00024
[epoch  94:  80/307] 	 train loss: 0.105732 	 lr: 0.00024
[epoch  94: 100/307] 	 train loss: 0.098156 	 lr: 0.00024

val loss: 0.331052 	 acc: 0.913695

[epoch  94: 120/307] 	 train loss: 0.062432 	 lr: 0.00024
[epoch  94: 140/307] 	 train loss: 0.269455 	 lr: 0.00024
[epoch  94: 160/307] 	 train loss: 0.176575 	 lr: 0.00024
[epoch  94: 180/307] 	 train loss: 0.097459 	 lr: 0.00024
[epoch  94: 200/307] 	 train loss: 0.141296 	 lr: 0.00024
[epoch  94: 220/307] 	 train loss: 0.430773 	 lr: 0.00024
[epoch  94: 240/307] 	 train loss: 0.269202 	 lr: 0.00024
[epoch  94: 260/307] 	 train loss: 0.052203 	 lr: 0.00024

val loss: 0.322871 	 acc: 0.917342

[epoch  94: 280/307] 	 train loss: 0.043431 	 lr: 0.00024
[epoch  94: 300/307] 	 train loss: 0.103801 	 lr: 0.00024
[epoch  95:   0/307] 	 train loss: 0.266973 	 lr: 0.00024
[epoch  95:  20/307] 	 train loss: 0.184466 	 lr: 0.00024
[epoch  95:  40/307] 	 train loss: 0.074251 	 lr: 0.00024
[epoch  95:  60/307] 	 train loss: 0.091283 	 lr: 0.00024
[epoch  95:  80/307] 	 train loss: 0.082232 	 lr: 0.00024
[epoch  95: 100/307] 	 train loss: 0.101178 	 lr: 0.00024

val loss: 0.333211 	 acc: 0.916937

[epoch  95: 120/307] 	 train loss: 0.065238 	 lr: 0.00024
[epoch  95: 140/307] 	 train loss: 0.435192 	 lr: 0.00024
[epoch  95: 160/307] 	 train loss: 0.065927 	 lr: 0.00024
[epoch  95: 180/307] 	 train loss: 0.069432 	 lr: 0.00024
[epoch  95: 200/307] 	 train loss: 0.099625 	 lr: 0.00024
[epoch  95: 220/307] 	 train loss: 0.037581 	 lr: 0.00024
[epoch  95: 240/307] 	 train loss: 0.154625 	 lr: 0.00024
[epoch  95: 260/307] 	 train loss: 0.056440 	 lr: 0.00024

val loss: 0.326629 	 acc: 0.915316

[epoch  95: 280/307] 	 train loss: 0.146643 	 lr: 0.00024
[epoch  95: 300/307] 	 train loss: 0.085138 	 lr: 0.00024
[epoch  96:   0/307] 	 train loss: 0.188955 	 lr: 0.00024
[epoch  96:  20/307] 	 train loss: 0.067500 	 lr: 0.00024
[epoch  96:  40/307] 	 train loss: 0.167711 	 lr: 0.00024
[epoch  96:  60/307] 	 train loss: 0.172498 	 lr: 0.00024
[epoch  96:  80/307] 	 train loss: 0.243496 	 lr: 0.00024
[epoch  96: 100/307] 	 train loss: 0.042993 	 lr: 0.00024

val loss: 0.319372 	 acc: 0.918558

[epoch  96: 120/307] 	 train loss: 0.290924 	 lr: 0.00024
[epoch  96: 140/307] 	 train loss: 0.243884 	 lr: 0.00024
[epoch  96: 160/307] 	 train loss: 0.089045 	 lr: 0.00024
[epoch  96: 180/307] 	 train loss: 0.238249 	 lr: 0.00024
[epoch  96: 200/307] 	 train loss: 0.194033 	 lr: 0.00024
[epoch  96: 220/307] 	 train loss: 0.204697 	 lr: 0.00024
[epoch  96: 240/307] 	 train loss: 0.065298 	 lr: 0.00024
[epoch  96: 260/307] 	 train loss: 0.022902 	 lr: 0.00024

val loss: 0.333096 	 acc: 0.908023

[epoch  96: 280/307] 	 train loss: 0.140835 	 lr: 0.00024
[epoch  96: 300/307] 	 train loss: 0.205750 	 lr: 0.00024
[epoch  97:   0/307] 	 train loss: 0.257944 	 lr: 0.00024
[epoch  97:  20/307] 	 train loss: 0.164849 	 lr: 0.00024
[epoch  97:  40/307] 	 train loss: 0.061275 	 lr: 0.00024
[epoch  97:  60/307] 	 train loss: 0.303238 	 lr: 0.00024
[epoch  97:  80/307] 	 train loss: 0.072067 	 lr: 0.00024
[epoch  97: 100/307] 	 train loss: 0.202726 	 lr: 0.00024

val loss: 0.333263 	 acc: 0.910859

[epoch  97: 120/307] 	 train loss: 0.128077 	 lr: 0.00024
[epoch  97: 140/307] 	 train loss: 0.054762 	 lr: 0.00024
[epoch  97: 160/307] 	 train loss: 0.308668 	 lr: 0.00024
[epoch  97: 180/307] 	 train loss: 0.420191 	 lr: 0.00024
[epoch  97: 200/307] 	 train loss: 0.102733 	 lr: 0.00024
[epoch  97: 220/307] 	 train loss: 0.296635 	 lr: 0.00024
[epoch  97: 240/307] 	 train loss: 0.164086 	 lr: 0.00024
[epoch  97: 260/307] 	 train loss: 0.088204 	 lr: 0.00024

val loss: 0.324026 	 acc: 0.912480

[epoch  97: 280/307] 	 train loss: 0.154676 	 lr: 0.00024
[epoch  97: 300/307] 	 train loss: 0.211872 	 lr: 0.00024
[epoch  98:   0/307] 	 train loss: 0.270719 	 lr: 0.00024
[epoch  98:  20/307] 	 train loss: 0.067577 	 lr: 0.00024
[epoch  98:  40/307] 	 train loss: 0.153718 	 lr: 0.00024
[epoch  98:  60/307] 	 train loss: 0.051240 	 lr: 0.00024
[epoch  98:  80/307] 	 train loss: 0.108169 	 lr: 0.00024
[epoch  98: 100/307] 	 train loss: 0.324506 	 lr: 0.00024

val loss: 0.313207 	 acc: 0.916126

[epoch  98: 120/307] 	 train loss: 0.015817 	 lr: 0.00024
[epoch  98: 140/307] 	 train loss: 0.266520 	 lr: 0.00024
[epoch  98: 160/307] 	 train loss: 0.284735 	 lr: 0.00024
[epoch  98: 180/307] 	 train loss: 0.188276 	 lr: 0.00024
[epoch  98: 200/307] 	 train loss: 0.144601 	 lr: 0.00024
[epoch  98: 220/307] 	 train loss: 0.126848 	 lr: 0.00024
[epoch  98: 240/307] 	 train loss: 0.114369 	 lr: 0.00024
[epoch  98: 260/307] 	 train loss: 0.069442 	 lr: 0.00024

val loss: 0.323494 	 acc: 0.913290

[epoch  98: 280/307] 	 train loss: 0.074543 	 lr: 0.00024
[epoch  98: 300/307] 	 train loss: 0.222921 	 lr: 0.00024
[epoch  99:   0/307] 	 train loss: 0.157712 	 lr: 0.00024
[epoch  99:  20/307] 	 train loss: 0.033084 	 lr: 0.00024
[epoch  99:  40/307] 	 train loss: 0.174844 	 lr: 0.00024
[epoch  99:  60/307] 	 train loss: 0.150129 	 lr: 0.00024
[epoch  99:  80/307] 	 train loss: 0.156340 	 lr: 0.00024
[epoch  99: 100/307] 	 train loss: 0.283075 	 lr: 0.00024

val loss: 0.312438 	 acc: 0.917747

[epoch  99: 120/307] 	 train loss: 0.068716 	 lr: 0.00024
[epoch  99: 140/307] 	 train loss: 0.246489 	 lr: 0.00024
[epoch  99: 160/307] 	 train loss: 0.088311 	 lr: 0.00024
[epoch  99: 180/307] 	 train loss: 0.223017 	 lr: 0.00024
[epoch  99: 200/307] 	 train loss: 0.415652 	 lr: 0.00024
[epoch  99: 220/307] 	 train loss: 0.071510 	 lr: 0.00024
[epoch  99: 240/307] 	 train loss: 0.166529 	 lr: 0.00024
[epoch  99: 260/307] 	 train loss: 0.337854 	 lr: 0.00024

val loss: 0.323225 	 acc: 0.915721

[epoch  99: 280/307] 	 train loss: 0.001926 	 lr: 0.00024
[epoch  99: 300/307] 	 train loss: 0.257737 	 lr: 0.00024
[epoch 100:   0/307] 	 train loss: 0.272779 	 lr: 0.00024
[epoch 100:  20/307] 	 train loss: 0.070684 	 lr: 0.00024
[epoch 100:  40/307] 	 train loss: 0.251714 	 lr: 0.00024
[epoch 100:  60/307] 	 train loss: 0.086836 	 lr: 0.00024
[epoch 100:  80/307] 	 train loss: 0.015198 	 lr: 0.00024
[epoch 100: 100/307] 	 train loss: 0.483263 	 lr: 0.00024

val loss: 0.313377 	 acc: 0.920989

saved model with accuracy %0.6f:  0.9209886547811994
[epoch 100: 120/307] 	 train loss: 0.493595 	 lr: 0.00024
[epoch 100: 140/307] 	 train loss: 0.277016 	 lr: 0.00024
[epoch 100: 160/307] 	 train loss: 0.350846 	 lr: 0.00024
[epoch 100: 180/307] 	 train loss: 0.188680 	 lr: 0.00024
[epoch 100: 200/307] 	 train loss: 0.039788 	 lr: 0.00024
[epoch 100: 220/307] 	 train loss: 0.135536 	 lr: 0.00024
[epoch 100: 240/307] 	 train loss: 0.163531 	 lr: 0.00024
[epoch 100: 260/307] 	 train loss: 0.119063 	 lr: 0.00024

val loss: 0.328041 	 acc: 0.915721

[epoch 100: 280/307] 	 train loss: 0.146718 	 lr: 0.00024
[epoch 100: 300/307] 	 train loss: 0.029462 	 lr: 0.00024
[epoch 101:   0/307] 	 train loss: 0.139615 	 lr: 0.00024
[epoch 101:  20/307] 	 train loss: 0.172991 	 lr: 0.00024
[epoch 101:  40/307] 	 train loss: 0.077879 	 lr: 0.00024
[epoch 101:  60/307] 	 train loss: 0.064371 	 lr: 0.00024
[epoch 101:  80/307] 	 train loss: 0.302350 	 lr: 0.00024
[epoch 101: 100/307] 	 train loss: 0.161824 	 lr: 0.00024

val loss: 0.327249 	 acc: 0.913290

[epoch 101: 120/307] 	 train loss: 0.150951 	 lr: 0.00024
[epoch 101: 140/307] 	 train loss: 0.203684 	 lr: 0.00024
[epoch 101: 160/307] 	 train loss: 0.087442 	 lr: 0.00024
[epoch 101: 180/307] 	 train loss: 0.171030 	 lr: 0.00024
[epoch 101: 200/307] 	 train loss: 0.037099 	 lr: 0.00024
[epoch 101: 220/307] 	 train loss: 0.081618 	 lr: 0.00024
[epoch 101: 240/307] 	 train loss: 0.303254 	 lr: 0.00024

val loss: 0.329288 	 acc: 0.910454

[epoch 101: 260/307] 	 train loss: 0.244245 	 lr: 0.00024
[epoch 101: 280/307] 	 train loss: 0.054310 	 lr: 0.00024
[epoch 101: 300/307] 	 train loss: 0.163845 	 lr: 0.00024
[epoch 102:   0/307] 	 train loss: 0.149869 	 lr: 0.00024
[epoch 102:  20/307] 	 train loss: 0.132510 	 lr: 0.00024
[epoch 102:  40/307] 	 train loss: 0.154234 	 lr: 0.00024
[epoch 102:  60/307] 	 train loss: 0.157223 	 lr: 0.00024
[epoch 102:  80/307] 	 train loss: 0.046740 	 lr: 0.00024
[epoch 102: 100/307] 	 train loss: 0.259160 	 lr: 0.00024

val loss: 0.319934 	 acc: 0.916532

[epoch 102: 120/307] 	 train loss: 0.031697 	 lr: 0.00024
[epoch 102: 140/307] 	 train loss: 0.145842 	 lr: 0.00024
[epoch 102: 160/307] 	 train loss: 0.133851 	 lr: 0.00024
[epoch 102: 180/307] 	 train loss: 0.291515 	 lr: 0.00024
[epoch 102: 200/307] 	 train loss: 0.023781 	 lr: 0.00024
[epoch 102: 220/307] 	 train loss: 0.095053 	 lr: 0.00024
[epoch 102: 240/307] 	 train loss: 0.123476 	 lr: 0.00024

val loss: 0.325832 	 acc: 0.909643

[epoch 102: 260/307] 	 train loss: 0.134919 	 lr: 0.00024
[epoch 102: 280/307] 	 train loss: 0.133692 	 lr: 0.00024
[epoch 102: 300/307] 	 train loss: 0.422196 	 lr: 0.00024
[epoch 103:   0/307] 	 train loss: 0.169654 	 lr: 0.00024
[epoch 103:  20/307] 	 train loss: 0.168023 	 lr: 0.00024
[epoch 103:  40/307] 	 train loss: 0.204527 	 lr: 0.00024
[epoch 103:  60/307] 	 train loss: 0.129355 	 lr: 0.00024
[epoch 103:  80/307] 	 train loss: 0.246488 	 lr: 0.00024
[epoch 103: 100/307] 	 train loss: 0.112308 	 lr: 0.00024

val loss: 0.329409 	 acc: 0.911669

[epoch 103: 120/307] 	 train loss: 0.128312 	 lr: 0.00024
[epoch 103: 140/307] 	 train loss: 0.203606 	 lr: 0.00024
[epoch 103: 160/307] 	 train loss: 0.155515 	 lr: 0.00024
[epoch 103: 180/307] 	 train loss: 0.114456 	 lr: 0.00024
[epoch 103: 200/307] 	 train loss: 0.142980 	 lr: 0.00024
[epoch 103: 220/307] 	 train loss: 0.065807 	 lr: 0.00024
[epoch 103: 240/307] 	 train loss: 0.056173 	 lr: 0.00024

val loss: 0.329381 	 acc: 0.912075

[epoch 103: 260/307] 	 train loss: 0.072836 	 lr: 0.00024
[epoch 103: 280/307] 	 train loss: 0.300523 	 lr: 0.00024
[epoch 103: 300/307] 	 train loss: 0.090943 	 lr: 0.00024
[epoch 104:   0/307] 	 train loss: 0.184353 	 lr: 0.00024
[epoch 104:  20/307] 	 train loss: 0.081539 	 lr: 0.00024
[epoch 104:  40/307] 	 train loss: 0.198850 	 lr: 0.00024
[epoch 104:  60/307] 	 train loss: 0.053568 	 lr: 0.00024
[epoch 104:  80/307] 	 train loss: 0.137588 	 lr: 0.00024

val loss: 0.318798 	 acc: 0.915316

[epoch 104: 100/307] 	 train loss: 0.204631 	 lr: 0.00024
[epoch 104: 120/307] 	 train loss: 0.035513 	 lr: 0.00024
[epoch 104: 140/307] 	 train loss: 0.255175 	 lr: 0.00024
[epoch 104: 160/307] 	 train loss: 0.348647 	 lr: 0.00024
[epoch 104: 180/307] 	 train loss: 0.117240 	 lr: 0.00024
[epoch 104: 200/307] 	 train loss: 0.070749 	 lr: 0.00024
[epoch 104: 220/307] 	 train loss: 0.162269 	 lr: 0.00024
[epoch 104: 240/307] 	 train loss: 0.095916 	 lr: 0.00024

val loss: 0.320690 	 acc: 0.913290

[epoch 104: 260/307] 	 train loss: 0.142528 	 lr: 0.00024
[epoch 104: 280/307] 	 train loss: 0.128055 	 lr: 0.00024
[epoch 104: 300/307] 	 train loss: 0.131733 	 lr: 0.00024
[epoch 105:   0/307] 	 train loss: 0.164290 	 lr: 0.00024
[epoch 105:  20/307] 	 train loss: 0.092568 	 lr: 0.00024
[epoch 105:  40/307] 	 train loss: 0.041562 	 lr: 0.00024
[epoch 105:  60/307] 	 train loss: 0.053347 	 lr: 0.00024
[epoch 105:  80/307] 	 train loss: 0.393641 	 lr: 0.00024

val loss: 0.324151 	 acc: 0.912480

[epoch 105: 100/307] 	 train loss: 0.225963 	 lr: 0.00024
[epoch 105: 120/307] 	 train loss: 0.062841 	 lr: 0.00024
[epoch 105: 140/307] 	 train loss: 0.107083 	 lr: 0.00024
[epoch 105: 160/307] 	 train loss: 0.157606 	 lr: 0.00024
[epoch 105: 180/307] 	 train loss: 0.152110 	 lr: 0.00024
[epoch 105: 200/307] 	 train loss: 0.143476 	 lr: 0.00024
[epoch 105: 220/307] 	 train loss: 0.398488 	 lr: 0.00024
[epoch 105: 240/307] 	 train loss: 0.146575 	 lr: 0.00024

val loss: 0.327704 	 acc: 0.910049

[epoch 105: 260/307] 	 train loss: 0.122819 	 lr: 0.00024
[epoch 105: 280/307] 	 train loss: 0.060189 	 lr: 0.00024
[epoch 105: 300/307] 	 train loss: 0.366607 	 lr: 0.00024
[epoch 106:   0/307] 	 train loss: 0.023826 	 lr: 0.00017
[epoch 106:  20/307] 	 train loss: 0.066171 	 lr: 0.00017
[epoch 106:  40/307] 	 train loss: 0.078190 	 lr: 0.00017
[epoch 106:  60/307] 	 train loss: 0.140830 	 lr: 0.00017
[epoch 106:  80/307] 	 train loss: 0.136547 	 lr: 0.00017

val loss: 0.320007 	 acc: 0.918558

[epoch 106: 100/307] 	 train loss: 0.366852 	 lr: 0.00017
[epoch 106: 120/307] 	 train loss: 0.109081 	 lr: 0.00017
[epoch 106: 140/307] 	 train loss: 0.027628 	 lr: 0.00017
[epoch 106: 160/307] 	 train loss: 0.054130 	 lr: 0.00017
[epoch 106: 180/307] 	 train loss: 0.051866 	 lr: 0.00017
[epoch 106: 200/307] 	 train loss: 0.306878 	 lr: 0.00017
[epoch 106: 220/307] 	 train loss: 0.170382 	 lr: 0.00017
[epoch 106: 240/307] 	 train loss: 0.270571 	 lr: 0.00017

val loss: 0.326399 	 acc: 0.914100

[epoch 106: 260/307] 	 train loss: 0.480401 	 lr: 0.00017
[epoch 106: 280/307] 	 train loss: 0.135553 	 lr: 0.00017
[epoch 106: 300/307] 	 train loss: 0.132388 	 lr: 0.00017
[epoch 107:   0/307] 	 train loss: 0.113467 	 lr: 0.00017
[epoch 107:  20/307] 	 train loss: 0.140337 	 lr: 0.00017
[epoch 107:  40/307] 	 train loss: 0.064299 	 lr: 0.00017
[epoch 107:  60/307] 	 train loss: 0.258236 	 lr: 0.00017
[epoch 107:  80/307] 	 train loss: 0.257478 	 lr: 0.00017

val loss: 0.334681 	 acc: 0.913695

[epoch 107: 100/307] 	 train loss: 0.310554 	 lr: 0.00017
[epoch 107: 120/307] 	 train loss: 0.227994 	 lr: 0.00017
[epoch 107: 140/307] 	 train loss: 0.107167 	 lr: 0.00017
[epoch 107: 160/307] 	 train loss: 0.121717 	 lr: 0.00017
[epoch 107: 180/307] 	 train loss: 0.081985 	 lr: 0.00017
[epoch 107: 200/307] 	 train loss: 0.152059 	 lr: 0.00017
[epoch 107: 220/307] 	 train loss: 0.284253 	 lr: 0.00017
[epoch 107: 240/307] 	 train loss: 0.105478 	 lr: 0.00017

val loss: 0.318193 	 acc: 0.911669

[epoch 107: 260/307] 	 train loss: 0.067141 	 lr: 0.00017
[epoch 107: 280/307] 	 train loss: 0.240069 	 lr: 0.00017
[epoch 107: 300/307] 	 train loss: 0.152054 	 lr: 0.00017
[epoch 108:   0/307] 	 train loss: 0.292580 	 lr: 0.00017
[epoch 108:  20/307] 	 train loss: 0.108267 	 lr: 0.00017
[epoch 108:  40/307] 	 train loss: 0.176648 	 lr: 0.00017
[epoch 108:  60/307] 	 train loss: 0.178349 	 lr: 0.00017
[epoch 108:  80/307] 	 train loss: 0.071806 	 lr: 0.00017

val loss: 0.327736 	 acc: 0.912075

[epoch 108: 100/307] 	 train loss: 0.076817 	 lr: 0.00017
[epoch 108: 120/307] 	 train loss: 0.155534 	 lr: 0.00017
[epoch 108: 140/307] 	 train loss: 0.090320 	 lr: 0.00017
[epoch 108: 160/307] 	 train loss: 0.063263 	 lr: 0.00017
[epoch 108: 180/307] 	 train loss: 0.116515 	 lr: 0.00017
[epoch 108: 200/307] 	 train loss: 0.258124 	 lr: 0.00017
[epoch 108: 220/307] 	 train loss: 0.166020 	 lr: 0.00017
[epoch 108: 240/307] 	 train loss: 0.083571 	 lr: 0.00017

val loss: 0.325186 	 acc: 0.914911

[epoch 108: 260/307] 	 train loss: 0.055238 	 lr: 0.00017
[epoch 108: 280/307] 	 train loss: 0.148791 	 lr: 0.00017
[epoch 108: 300/307] 	 train loss: 0.137163 	 lr: 0.00017
[epoch 109:   0/307] 	 train loss: 0.116391 	 lr: 0.00017
[epoch 109:  20/307] 	 train loss: 0.115479 	 lr: 0.00017
[epoch 109:  40/307] 	 train loss: 0.039870 	 lr: 0.00017
[epoch 109:  60/307] 	 train loss: 0.124423 	 lr: 0.00017
[epoch 109:  80/307] 	 train loss: 0.131693 	 lr: 0.00017

val loss: 0.331298 	 acc: 0.911669

[epoch 109: 100/307] 	 train loss: 0.087792 	 lr: 0.00017
[epoch 109: 120/307] 	 train loss: 0.324522 	 lr: 0.00017
[epoch 109: 140/307] 	 train loss: 0.076144 	 lr: 0.00017
[epoch 109: 160/307] 	 train loss: 0.030391 	 lr: 0.00017
[epoch 109: 180/307] 	 train loss: 0.097563 	 lr: 0.00017
[epoch 109: 200/307] 	 train loss: 0.052857 	 lr: 0.00017
[epoch 109: 220/307] 	 train loss: 0.050672 	 lr: 0.00017
[epoch 109: 240/307] 	 train loss: 0.146470 	 lr: 0.00017

val loss: 0.326161 	 acc: 0.915316

[epoch 109: 260/307] 	 train loss: 0.073953 	 lr: 0.00017
[epoch 109: 280/307] 	 train loss: 0.135195 	 lr: 0.00017
[epoch 109: 300/307] 	 train loss: 0.104629 	 lr: 0.00017
[epoch 110:   0/307] 	 train loss: 0.134405 	 lr: 0.00017
[epoch 110:  20/307] 	 train loss: 0.078343 	 lr: 0.00017
[epoch 110:  40/307] 	 train loss: 0.068713 	 lr: 0.00017
[epoch 110:  60/307] 	 train loss: 0.080107 	 lr: 0.00017
[epoch 110:  80/307] 	 train loss: 0.197946 	 lr: 0.00017

val loss: 0.319691 	 acc: 0.915316

[epoch 110: 100/307] 	 train loss: 0.144715 	 lr: 0.00017
[epoch 110: 120/307] 	 train loss: 0.361737 	 lr: 0.00017
[epoch 110: 140/307] 	 train loss: 0.110523 	 lr: 0.00017
[epoch 110: 160/307] 	 train loss: 0.107217 	 lr: 0.00017
[epoch 110: 180/307] 	 train loss: 0.324411 	 lr: 0.00017
[epoch 110: 200/307] 	 train loss: 0.105937 	 lr: 0.00017
[epoch 110: 220/307] 	 train loss: 0.014756 	 lr: 0.00017
[epoch 110: 240/307] 	 train loss: 0.024845 	 lr: 0.00017

val loss: 0.318243 	 acc: 0.913695

[epoch 110: 260/307] 	 train loss: 0.049002 	 lr: 0.00017
[epoch 110: 280/307] 	 train loss: 0.011837 	 lr: 0.00017
[epoch 110: 300/307] 	 train loss: 0.037775 	 lr: 0.00017
[epoch 111:   0/307] 	 train loss: 0.265896 	 lr: 0.00017
[epoch 111:  20/307] 	 train loss: 0.058264 	 lr: 0.00017
[epoch 111:  40/307] 	 train loss: 0.068585 	 lr: 0.00017
[epoch 111:  60/307] 	 train loss: 0.022102 	 lr: 0.00017
[epoch 111:  80/307] 	 train loss: 0.173363 	 lr: 0.00017

val loss: 0.329683 	 acc: 0.911264

[epoch 111: 100/307] 	 train loss: 0.182680 	 lr: 0.00017
[epoch 111: 120/307] 	 train loss: 0.290262 	 lr: 0.00017
[epoch 111: 140/307] 	 train loss: 0.255290 	 lr: 0.00017
[epoch 111: 160/307] 	 train loss: 0.141083 	 lr: 0.00017
[epoch 111: 180/307] 	 train loss: 0.195107 	 lr: 0.00017
[epoch 111: 200/307] 	 train loss: 0.082083 	 lr: 0.00017
[epoch 111: 220/307] 	 train loss: 0.046678 	 lr: 0.00017

val loss: 0.332743 	 acc: 0.914100

[epoch 111: 240/307] 	 train loss: 0.232048 	 lr: 0.00017
[epoch 111: 260/307] 	 train loss: 0.079328 	 lr: 0.00017
[epoch 111: 280/307] 	 train loss: 0.123191 	 lr: 0.00017
[epoch 111: 300/307] 	 train loss: 0.259400 	 lr: 0.00017
[epoch 112:   0/307] 	 train loss: 0.442599 	 lr: 0.00017
[epoch 112:  20/307] 	 train loss: 0.246291 	 lr: 0.00017
[epoch 112:  40/307] 	 train loss: 0.162970 	 lr: 0.00017
[epoch 112:  60/307] 	 train loss: 0.086425 	 lr: 0.00017
[epoch 112:  80/307] 	 train loss: 0.252923 	 lr: 0.00017

val loss: 0.322209 	 acc: 0.912885

[epoch 112: 100/307] 	 train loss: 0.048646 	 lr: 0.00017
[epoch 112: 120/307] 	 train loss: 0.107554 	 lr: 0.00017
[epoch 112: 140/307] 	 train loss: 0.256184 	 lr: 0.00017
[epoch 112: 160/307] 	 train loss: 0.342428 	 lr: 0.00017
[epoch 112: 180/307] 	 train loss: 0.198506 	 lr: 0.00017
[epoch 112: 200/307] 	 train loss: 0.110920 	 lr: 0.00017
[epoch 112: 220/307] 	 train loss: 0.069264 	 lr: 0.00017

val loss: 0.328944 	 acc: 0.915316

[epoch 112: 240/307] 	 train loss: 0.165879 	 lr: 0.00017
[epoch 112: 260/307] 	 train loss: 0.106142 	 lr: 0.00017
[epoch 112: 280/307] 	 train loss: 0.075914 	 lr: 0.00017
[epoch 112: 300/307] 	 train loss: 0.036387 	 lr: 0.00017
[epoch 113:   0/307] 	 train loss: 0.075641 	 lr: 0.00017
[epoch 113:  20/307] 	 train loss: 0.235633 	 lr: 0.00017
[epoch 113:  40/307] 	 train loss: 0.412311 	 lr: 0.00017
[epoch 113:  60/307] 	 train loss: 0.025282 	 lr: 0.00017
[epoch 113:  80/307] 	 train loss: 0.102179 	 lr: 0.00017

val loss: 0.327021 	 acc: 0.912075

[epoch 113: 100/307] 	 train loss: 0.117296 	 lr: 0.00017
[epoch 113: 120/307] 	 train loss: 0.038480 	 lr: 0.00017
[epoch 113: 140/307] 	 train loss: 0.020949 	 lr: 0.00017
[epoch 113: 160/307] 	 train loss: 0.032420 	 lr: 0.00017
[epoch 113: 180/307] 	 train loss: 0.076393 	 lr: 0.00017
[epoch 113: 200/307] 	 train loss: 0.054034 	 lr: 0.00017
[epoch 113: 220/307] 	 train loss: 0.145800 	 lr: 0.00017

val loss: 0.318470 	 acc: 0.914911

[epoch 113: 240/307] 	 train loss: 0.135504 	 lr: 0.00017
[epoch 113: 260/307] 	 train loss: 0.044686 	 lr: 0.00017
[epoch 113: 280/307] 	 train loss: 0.102767 	 lr: 0.00017
[epoch 113: 300/307] 	 train loss: 0.229038 	 lr: 0.00017
[epoch 114:   0/307] 	 train loss: 0.333678 	 lr: 0.00017
[epoch 114:  20/307] 	 train loss: 0.091466 	 lr: 0.00017
[epoch 114:  40/307] 	 train loss: 0.169296 	 lr: 0.00017
[epoch 114:  60/307] 	 train loss: 0.111627 	 lr: 0.00017

val loss: 0.317006 	 acc: 0.915721

[epoch 114:  80/307] 	 train loss: 0.156103 	 lr: 0.00017
[epoch 114: 100/307] 	 train loss: 0.104316 	 lr: 0.00017
[epoch 114: 120/307] 	 train loss: 0.083301 	 lr: 0.00017
[epoch 114: 140/307] 	 train loss: 0.121445 	 lr: 0.00017
[epoch 114: 160/307] 	 train loss: 0.095732 	 lr: 0.00017
[epoch 114: 180/307] 	 train loss: 0.192163 	 lr: 0.00017
[epoch 114: 200/307] 	 train loss: 0.213658 	 lr: 0.00017
[epoch 114: 220/307] 	 train loss: 0.128592 	 lr: 0.00017

val loss: 0.320796 	 acc: 0.914506

[epoch 114: 240/307] 	 train loss: 0.241080 	 lr: 0.00017
[epoch 114: 260/307] 	 train loss: 0.161614 	 lr: 0.00017
[epoch 114: 280/307] 	 train loss: 0.072222 	 lr: 0.00017
[epoch 114: 300/307] 	 train loss: 0.150091 	 lr: 0.00017
[epoch 115:   0/307] 	 train loss: 0.319089 	 lr: 0.00017
[epoch 115:  20/307] 	 train loss: 0.133388 	 lr: 0.00017
[epoch 115:  40/307] 	 train loss: 0.153931 	 lr: 0.00017
[epoch 115:  60/307] 	 train loss: 0.090250 	 lr: 0.00017

val loss: 0.320926 	 acc: 0.914100

[epoch 115:  80/307] 	 train loss: 0.140165 	 lr: 0.00017
[epoch 115: 100/307] 	 train loss: 0.065974 	 lr: 0.00017
[epoch 115: 120/307] 	 train loss: 0.258116 	 lr: 0.00017
[epoch 115: 140/307] 	 train loss: 0.193061 	 lr: 0.00017
[epoch 115: 160/307] 	 train loss: 0.254333 	 lr: 0.00017
[epoch 115: 180/307] 	 train loss: 0.148286 	 lr: 0.00017
[epoch 115: 200/307] 	 train loss: 0.371030 	 lr: 0.00017
[epoch 115: 220/307] 	 train loss: 0.323602 	 lr: 0.00017

val loss: 0.323452 	 acc: 0.913695

[epoch 115: 240/307] 	 train loss: 0.209300 	 lr: 0.00017
[epoch 115: 260/307] 	 train loss: 0.154592 	 lr: 0.00017
[epoch 115: 280/307] 	 train loss: 0.026300 	 lr: 0.00017
[epoch 115: 300/307] 	 train loss: 0.031260 	 lr: 0.00017
[epoch 116:   0/307] 	 train loss: 0.074765 	 lr: 0.00017
[epoch 116:  20/307] 	 train loss: 0.244512 	 lr: 0.00017
[epoch 116:  40/307] 	 train loss: 0.260351 	 lr: 0.00017
[epoch 116:  60/307] 	 train loss: 0.031211 	 lr: 0.00017

val loss: 0.333997 	 acc: 0.914506

[epoch 116:  80/307] 	 train loss: 0.171852 	 lr: 0.00017
[epoch 116: 100/307] 	 train loss: 0.175556 	 lr: 0.00017
[epoch 116: 120/307] 	 train loss: 0.124297 	 lr: 0.00017
[epoch 116: 140/307] 	 train loss: 0.231834 	 lr: 0.00017
[epoch 116: 160/307] 	 train loss: 0.242294 	 lr: 0.00017
[epoch 116: 180/307] 	 train loss: 0.243884 	 lr: 0.00017
[epoch 116: 200/307] 	 train loss: 0.212928 	 lr: 0.00017
[epoch 116: 220/307] 	 train loss: 0.247726 	 lr: 0.00017

val loss: 0.331741 	 acc: 0.910859

[epoch 116: 240/307] 	 train loss: 0.087992 	 lr: 0.00017
[epoch 116: 260/307] 	 train loss: 0.187455 	 lr: 0.00017
[epoch 116: 280/307] 	 train loss: 0.379570 	 lr: 0.00017
[epoch 116: 300/307] 	 train loss: 0.039659 	 lr: 0.00017
[epoch 117:   0/307] 	 train loss: 0.137152 	 lr: 0.00017
[epoch 117:  20/307] 	 train loss: 0.213083 	 lr: 0.00017
[epoch 117:  40/307] 	 train loss: 0.093744 	 lr: 0.00017
[epoch 117:  60/307] 	 train loss: 0.147443 	 lr: 0.00017

val loss: 0.334075 	 acc: 0.908023

[epoch 117:  80/307] 	 train loss: 0.045130 	 lr: 0.00017
[epoch 117: 100/307] 	 train loss: 0.024430 	 lr: 0.00017
[epoch 117: 120/307] 	 train loss: 0.067814 	 lr: 0.00017
[epoch 117: 140/307] 	 train loss: 0.022999 	 lr: 0.00017
[epoch 117: 160/307] 	 train loss: 0.240590 	 lr: 0.00017
[epoch 117: 180/307] 	 train loss: 0.135779 	 lr: 0.00017
[epoch 117: 200/307] 	 train loss: 0.218972 	 lr: 0.00017
[epoch 117: 220/307] 	 train loss: 0.136008 	 lr: 0.00017

val loss: 0.321414 	 acc: 0.913290

[epoch 117: 240/307] 	 train loss: 0.065728 	 lr: 0.00017
[epoch 117: 260/307] 	 train loss: 0.163590 	 lr: 0.00017
[epoch 117: 280/307] 	 train loss: 0.186259 	 lr: 0.00017
[epoch 117: 300/307] 	 train loss: 0.020156 	 lr: 0.00017
[epoch 118:   0/307] 	 train loss: 0.070518 	 lr: 0.00017
[epoch 118:  20/307] 	 train loss: 0.166294 	 lr: 0.00017
[epoch 118:  40/307] 	 train loss: 0.131690 	 lr: 0.00017
[epoch 118:  60/307] 	 train loss: 0.031897 	 lr: 0.00017

val loss: 0.340312 	 acc: 0.914100

[epoch 118:  80/307] 	 train loss: 0.021608 	 lr: 0.00017
[epoch 118: 100/307] 	 train loss: 0.113686 	 lr: 0.00017
[epoch 118: 120/307] 	 train loss: 0.283714 	 lr: 0.00017
[epoch 118: 140/307] 	 train loss: 0.035253 	 lr: 0.00017
[epoch 118: 160/307] 	 train loss: 0.165897 	 lr: 0.00017
[epoch 118: 180/307] 	 train loss: 0.206199 	 lr: 0.00017
[epoch 118: 200/307] 	 train loss: 0.142999 	 lr: 0.00017
[epoch 118: 220/307] 	 train loss: 0.027925 	 lr: 0.00017

val loss: 0.339629 	 acc: 0.911669

[epoch 118: 240/307] 	 train loss: 0.061581 	 lr: 0.00017
[epoch 118: 260/307] 	 train loss: 0.196091 	 lr: 0.00017
[epoch 118: 280/307] 	 train loss: 0.091614 	 lr: 0.00017
[epoch 118: 300/307] 	 train loss: 0.234270 	 lr: 0.00017
[epoch 119:   0/307] 	 train loss: 0.126723 	 lr: 0.00017
[epoch 119:  20/307] 	 train loss: 0.448801 	 lr: 0.00017
[epoch 119:  40/307] 	 train loss: 0.058157 	 lr: 0.00017
[epoch 119:  60/307] 	 train loss: 0.103802 	 lr: 0.00017

val loss: 0.336233 	 acc: 0.909643

[epoch 119:  80/307] 	 train loss: 0.091601 	 lr: 0.00017
[epoch 119: 100/307] 	 train loss: 0.133387 	 lr: 0.00017
[epoch 119: 120/307] 	 train loss: 0.361358 	 lr: 0.00017
[epoch 119: 140/307] 	 train loss: 0.172540 	 lr: 0.00017
[epoch 119: 160/307] 	 train loss: 0.051823 	 lr: 0.00017
[epoch 119: 180/307] 	 train loss: 0.175278 	 lr: 0.00017
[epoch 119: 200/307] 	 train loss: 0.058492 	 lr: 0.00017
[epoch 119: 220/307] 	 train loss: 0.053944 	 lr: 0.00017

val loss: 0.335358 	 acc: 0.914100

[epoch 119: 240/307] 	 train loss: 0.067362 	 lr: 0.00017
[epoch 119: 260/307] 	 train loss: 0.107270 	 lr: 0.00017
[epoch 119: 280/307] 	 train loss: 0.058169 	 lr: 0.00017
[epoch 119: 300/307] 	 train loss: 0.170546 	 lr: 0.00017
[epoch 120:   0/307] 	 train loss: 0.177894 	 lr: 0.00017
[epoch 120:  20/307] 	 train loss: 0.033270 	 lr: 0.00017
[epoch 120:  40/307] 	 train loss: 0.075307 	 lr: 0.00017
[epoch 120:  60/307] 	 train loss: 0.095717 	 lr: 0.00017

val loss: 0.333957 	 acc: 0.911264

[epoch 120:  80/307] 	 train loss: 0.268113 	 lr: 0.00017
[epoch 120: 100/307] 	 train loss: 0.128315 	 lr: 0.00017
[epoch 120: 120/307] 	 train loss: 0.196742 	 lr: 0.00017
[epoch 120: 140/307] 	 train loss: 0.049110 	 lr: 0.00017
[epoch 120: 160/307] 	 train loss: 0.507268 	 lr: 0.00017
[epoch 120: 180/307] 	 train loss: 0.115979 	 lr: 0.00017
[epoch 120: 200/307] 	 train loss: 0.084503 	 lr: 0.00017
[epoch 120: 220/307] 	 train loss: 0.253038 	 lr: 0.00017

val loss: 0.331591 	 acc: 0.914506

[epoch 120: 240/307] 	 train loss: 0.108684 	 lr: 0.00017
[epoch 120: 260/307] 	 train loss: 0.053997 	 lr: 0.00017
[epoch 120: 280/307] 	 train loss: 0.032671 	 lr: 0.00017
[epoch 120: 300/307] 	 train loss: 0.222568 	 lr: 0.00017
[epoch 121:   0/307] 	 train loss: 0.133421 	 lr: 0.00017
[epoch 121:  20/307] 	 train loss: 0.014758 	 lr: 0.00017
[epoch 121:  40/307] 	 train loss: 0.254206 	 lr: 0.00017
[epoch 121:  60/307] 	 train loss: 0.074051 	 lr: 0.00017

val loss: 0.349061 	 acc: 0.910859

[epoch 121:  80/307] 	 train loss: 0.216477 	 lr: 0.00017
[epoch 121: 100/307] 	 train loss: 0.135684 	 lr: 0.00017
[epoch 121: 120/307] 	 train loss: 0.054633 	 lr: 0.00017
[epoch 121: 140/307] 	 train loss: 0.099157 	 lr: 0.00017
[epoch 121: 160/307] 	 train loss: 0.042738 	 lr: 0.00017
[epoch 121: 180/307] 	 train loss: 0.069021 	 lr: 0.00017
[epoch 121: 200/307] 	 train loss: 0.087299 	 lr: 0.00017

val loss: 0.329393 	 acc: 0.915721

[epoch 121: 220/307] 	 train loss: 0.294024 	 lr: 0.00017
[epoch 121: 240/307] 	 train loss: 0.087851 	 lr: 0.00017
[epoch 121: 260/307] 	 train loss: 0.104817 	 lr: 0.00017
[epoch 121: 280/307] 	 train loss: 0.391080 	 lr: 0.00017
[epoch 121: 300/307] 	 train loss: 0.290403 	 lr: 0.00017
[epoch 122:   0/307] 	 train loss: 0.155064 	 lr: 0.00017
[epoch 122:  20/307] 	 train loss: 0.110680 	 lr: 0.00017
[epoch 122:  40/307] 	 train loss: 0.190222 	 lr: 0.00017
[epoch 122:  60/307] 	 train loss: 0.058515 	 lr: 0.00017

val loss: 0.333314 	 acc: 0.913695

[epoch 122:  80/307] 	 train loss: 0.193538 	 lr: 0.00017
[epoch 122: 100/307] 	 train loss: 0.094107 	 lr: 0.00017
[epoch 122: 120/307] 	 train loss: 0.144805 	 lr: 0.00017
[epoch 122: 140/307] 	 train loss: 0.140688 	 lr: 0.00017
[epoch 122: 160/307] 	 train loss: 0.124280 	 lr: 0.00017
[epoch 122: 180/307] 	 train loss: 0.049554 	 lr: 0.00017
[epoch 122: 200/307] 	 train loss: 0.125969 	 lr: 0.00017

val loss: 0.345347 	 acc: 0.909238

[epoch 122: 220/307] 	 train loss: 0.347036 	 lr: 0.00017
[epoch 122: 240/307] 	 train loss: 0.135613 	 lr: 0.00017
[epoch 122: 260/307] 	 train loss: 0.122997 	 lr: 0.00017
[epoch 122: 280/307] 	 train loss: 0.128557 	 lr: 0.00017
[epoch 122: 300/307] 	 train loss: 0.055662 	 lr: 0.00017
[epoch 123:   0/307] 	 train loss: 0.165011 	 lr: 0.00017
[epoch 123:  20/307] 	 train loss: 0.104278 	 lr: 0.00017
[epoch 123:  40/307] 	 train loss: 0.195899 	 lr: 0.00017
[epoch 123:  60/307] 	 train loss: 0.072754 	 lr: 0.00017

val loss: 0.345500 	 acc: 0.908023

[epoch 123:  80/307] 	 train loss: 0.284199 	 lr: 0.00017
[epoch 123: 100/307] 	 train loss: 0.256274 	 lr: 0.00017
[epoch 123: 120/307] 	 train loss: 0.094219 	 lr: 0.00017
[epoch 123: 140/307] 	 train loss: 0.175658 	 lr: 0.00017
[epoch 123: 160/307] 	 train loss: 0.156492 	 lr: 0.00017
[epoch 123: 180/307] 	 train loss: 0.150671 	 lr: 0.00017
[epoch 123: 200/307] 	 train loss: 0.097845 	 lr: 0.00017

val loss: 0.348318 	 acc: 0.906807

[epoch 123: 220/307] 	 train loss: 0.215920 	 lr: 0.00017
[epoch 123: 240/307] 	 train loss: 0.012932 	 lr: 0.00017
[epoch 123: 260/307] 	 train loss: 0.240803 	 lr: 0.00017
[epoch 123: 280/307] 	 train loss: 0.119095 	 lr: 0.00017
[epoch 123: 300/307] 	 train loss: 0.131552 	 lr: 0.00017
[epoch 124:   0/307] 	 train loss: 0.104289 	 lr: 0.00017
[epoch 124:  20/307] 	 train loss: 0.118274 	 lr: 0.00017
[epoch 124:  40/307] 	 train loss: 0.139952 	 lr: 0.00017

val loss: 0.343773 	 acc: 0.911669

[epoch 124:  60/307] 	 train loss: 0.064096 	 lr: 0.00017
[epoch 124:  80/307] 	 train loss: 0.087898 	 lr: 0.00017
[epoch 124: 100/307] 	 train loss: 0.027858 	 lr: 0.00017
[epoch 124: 120/307] 	 train loss: 0.268472 	 lr: 0.00017
[epoch 124: 140/307] 	 train loss: 0.035064 	 lr: 0.00017
[epoch 124: 160/307] 	 train loss: 0.429996 	 lr: 0.00017
[epoch 124: 180/307] 	 train loss: 0.358698 	 lr: 0.00017
[epoch 124: 200/307] 	 train loss: 0.336404 	 lr: 0.00017

val loss: 0.337483 	 acc: 0.914506

[epoch 124: 220/307] 	 train loss: 0.183598 	 lr: 0.00017
[epoch 124: 240/307] 	 train loss: 0.171989 	 lr: 0.00017
[epoch 124: 260/307] 	 train loss: 0.170369 	 lr: 0.00017
[epoch 124: 280/307] 	 train loss: 0.010589 	 lr: 0.00017
[epoch 124: 300/307] 	 train loss: 0.119298 	 lr: 0.00017
[epoch 125:   0/307] 	 train loss: 0.145523 	 lr: 0.00017
[epoch 125:  20/307] 	 train loss: 0.091840 	 lr: 0.00017
[epoch 125:  40/307] 	 train loss: 0.062368 	 lr: 0.00017

val loss: 0.323431 	 acc: 0.917747

[epoch 125:  60/307] 	 train loss: 0.053068 	 lr: 0.00017
[epoch 125:  80/307] 	 train loss: 0.119768 	 lr: 0.00017
[epoch 125: 100/307] 	 train loss: 0.069954 	 lr: 0.00017
[epoch 125: 120/307] 	 train loss: 0.125667 	 lr: 0.00017
[epoch 125: 140/307] 	 train loss: 0.255727 	 lr: 0.00017
[epoch 125: 160/307] 	 train loss: 0.052231 	 lr: 0.00017
[epoch 125: 180/307] 	 train loss: 0.108726 	 lr: 0.00017
[epoch 125: 200/307] 	 train loss: 0.198105 	 lr: 0.00017

val loss: 0.335792 	 acc: 0.911264

[epoch 125: 220/307] 	 train loss: 0.142066 	 lr: 0.00017
[epoch 125: 240/307] 	 train loss: 0.119936 	 lr: 0.00017
[epoch 125: 260/307] 	 train loss: 0.107849 	 lr: 0.00017
[epoch 125: 280/307] 	 train loss: 0.024152 	 lr: 0.00017
[epoch 125: 300/307] 	 train loss: 0.109052 	 lr: 0.00017
[epoch 126:   0/307] 	 train loss: 0.145192 	 lr: 0.00017
[epoch 126:  20/307] 	 train loss: 0.396500 	 lr: 0.00017
[epoch 126:  40/307] 	 train loss: 0.251121 	 lr: 0.00017

val loss: 0.352556 	 acc: 0.910454

[epoch 126:  60/307] 	 train loss: 0.066040 	 lr: 0.00017
[epoch 126:  80/307] 	 train loss: 0.202058 	 lr: 0.00017
[epoch 126: 100/307] 	 train loss: 0.314073 	 lr: 0.00017
[epoch 126: 120/307] 	 train loss: 0.152256 	 lr: 0.00017
[epoch 126: 140/307] 	 train loss: 0.080089 	 lr: 0.00017
[epoch 126: 160/307] 	 train loss: 0.364403 	 lr: 0.00017
[epoch 126: 180/307] 	 train loss: 0.080807 	 lr: 0.00017
[epoch 126: 200/307] 	 train loss: 0.044325 	 lr: 0.00017

val loss: 0.334103 	 acc: 0.912885

[epoch 126: 220/307] 	 train loss: 0.132534 	 lr: 0.00017
[epoch 126: 240/307] 	 train loss: 0.092734 	 lr: 0.00017
[epoch 126: 260/307] 	 train loss: 0.152746 	 lr: 0.00017
[epoch 126: 280/307] 	 train loss: 0.106765 	 lr: 0.00017
[epoch 126: 300/307] 	 train loss: 0.185788 	 lr: 0.00017
[epoch 127:   0/307] 	 train loss: 0.223669 	 lr: 0.00012
[epoch 127:  20/307] 	 train loss: 0.080248 	 lr: 0.00012
[epoch 127:  40/307] 	 train loss: 0.126565 	 lr: 0.00012

val loss: 0.333455 	 acc: 0.914506

[epoch 127:  60/307] 	 train loss: 0.168803 	 lr: 0.00012
[epoch 127:  80/307] 	 train loss: 0.114082 	 lr: 0.00012
[epoch 127: 100/307] 	 train loss: 0.087432 	 lr: 0.00012
[epoch 127: 120/307] 	 train loss: 0.135900 	 lr: 0.00012
[epoch 127: 140/307] 	 train loss: 0.025973 	 lr: 0.00012
[epoch 127: 160/307] 	 train loss: 0.256589 	 lr: 0.00012
[epoch 127: 180/307] 	 train loss: 0.377074 	 lr: 0.00012
[epoch 127: 200/307] 	 train loss: 0.103169 	 lr: 0.00012

val loss: 0.329231 	 acc: 0.915316

[epoch 127: 220/307] 	 train loss: 0.143025 	 lr: 0.00012
[epoch 127: 240/307] 	 train loss: 0.047903 	 lr: 0.00012
[epoch 127: 260/307] 	 train loss: 0.047805 	 lr: 0.00012
[epoch 127: 280/307] 	 train loss: 0.190111 	 lr: 0.00012
[epoch 127: 300/307] 	 train loss: 0.032590 	 lr: 0.00012
[epoch 128:   0/307] 	 train loss: 0.108242 	 lr: 0.00012
[epoch 128:  20/307] 	 train loss: 0.055675 	 lr: 0.00012
[epoch 128:  40/307] 	 train loss: 0.099890 	 lr: 0.00012

val loss: 0.330694 	 acc: 0.912480

[epoch 128:  60/307] 	 train loss: 0.039121 	 lr: 0.00012
[epoch 128:  80/307] 	 train loss: 0.247481 	 lr: 0.00012
[epoch 128: 100/307] 	 train loss: 0.526868 	 lr: 0.00012
[epoch 128: 120/307] 	 train loss: 0.049477 	 lr: 0.00012
[epoch 128: 140/307] 	 train loss: 0.190618 	 lr: 0.00012
[epoch 128: 160/307] 	 train loss: 0.186504 	 lr: 0.00012
[epoch 128: 180/307] 	 train loss: 0.109444 	 lr: 0.00012
[epoch 128: 200/307] 	 train loss: 0.152336 	 lr: 0.00012

val loss: 0.333076 	 acc: 0.913290

[epoch 128: 220/307] 	 train loss: 0.020108 	 lr: 0.00012
[epoch 128: 240/307] 	 train loss: 0.019896 	 lr: 0.00012
[epoch 128: 260/307] 	 train loss: 0.043255 	 lr: 0.00012
[epoch 128: 280/307] 	 train loss: 0.107015 	 lr: 0.00012
[epoch 128: 300/307] 	 train loss: 0.154323 	 lr: 0.00012
[epoch 129:   0/307] 	 train loss: 0.087692 	 lr: 0.00012
[epoch 129:  20/307] 	 train loss: 0.117180 	 lr: 0.00012
[epoch 129:  40/307] 	 train loss: 0.023216 	 lr: 0.00012

val loss: 0.333475 	 acc: 0.916126

[epoch 129:  60/307] 	 train loss: 0.172413 	 lr: 0.00012
[epoch 129:  80/307] 	 train loss: 0.137971 	 lr: 0.00012
[epoch 129: 100/307] 	 train loss: 0.233218 	 lr: 0.00012
[epoch 129: 120/307] 	 train loss: 0.016628 	 lr: 0.00012
[epoch 129: 140/307] 	 train loss: 0.165323 	 lr: 0.00012
[epoch 129: 160/307] 	 train loss: 0.291606 	 lr: 0.00012
[epoch 129: 180/307] 	 train loss: 0.123030 	 lr: 0.00012
[epoch 129: 200/307] 	 train loss: 0.035199 	 lr: 0.00012

val loss: 0.331305 	 acc: 0.914100

[epoch 129: 220/307] 	 train loss: 0.283593 	 lr: 0.00012
[epoch 129: 240/307] 	 train loss: 0.052263 	 lr: 0.00012
[epoch 129: 260/307] 	 train loss: 0.081204 	 lr: 0.00012
[epoch 129: 280/307] 	 train loss: 0.096216 	 lr: 0.00012
[epoch 129: 300/307] 	 train loss: 0.172177 	 lr: 0.00012
[epoch 130:   0/307] 	 train loss: 0.094223 	 lr: 0.00012
[epoch 130:  20/307] 	 train loss: 0.335789 	 lr: 0.00012
[epoch 130:  40/307] 	 train loss: 0.175819 	 lr: 0.00012

val loss: 0.331362 	 acc: 0.916126

[epoch 130:  60/307] 	 train loss: 0.104704 	 lr: 0.00012
[epoch 130:  80/307] 	 train loss: 0.048340 	 lr: 0.00012
[epoch 130: 100/307] 	 train loss: 0.397470 	 lr: 0.00012
[epoch 130: 120/307] 	 train loss: 0.016471 	 lr: 0.00012
[epoch 130: 140/307] 	 train loss: 0.344324 	 lr: 0.00012
[epoch 130: 160/307] 	 train loss: 0.121922 	 lr: 0.00012
[epoch 130: 180/307] 	 train loss: 0.157023 	 lr: 0.00012
[epoch 130: 200/307] 	 train loss: 0.080111 	 lr: 0.00012

val loss: 0.325580 	 acc: 0.916126

[epoch 130: 220/307] 	 train loss: 0.037997 	 lr: 0.00012
[epoch 130: 240/307] 	 train loss: 0.080772 	 lr: 0.00012
[epoch 130: 260/307] 	 train loss: 0.135030 	 lr: 0.00012
[epoch 130: 280/307] 	 train loss: 0.152022 	 lr: 0.00012
[epoch 130: 300/307] 	 train loss: 0.151302 	 lr: 0.00012
[epoch 131:   0/307] 	 train loss: 0.219841 	 lr: 0.00012
[epoch 131:  20/307] 	 train loss: 0.059335 	 lr: 0.00012
[epoch 131:  40/307] 	 train loss: 0.273078 	 lr: 0.00012

val loss: 0.333853 	 acc: 0.917342

[epoch 131:  60/307] 	 train loss: 0.150724 	 lr: 0.00012
[epoch 131:  80/307] 	 train loss: 0.159660 	 lr: 0.00012
[epoch 131: 100/307] 	 train loss: 0.193117 	 lr: 0.00012
[epoch 131: 120/307] 	 train loss: 0.127502 	 lr: 0.00012
[epoch 131: 140/307] 	 train loss: 0.030655 	 lr: 0.00012
[epoch 131: 160/307] 	 train loss: 0.038264 	 lr: 0.00012
[epoch 131: 180/307] 	 train loss: 0.126797 	 lr: 0.00012

val loss: 0.333062 	 acc: 0.914506

[epoch 131: 200/307] 	 train loss: 0.089915 	 lr: 0.00012
[epoch 131: 220/307] 	 train loss: 0.137428 	 lr: 0.00012
[epoch 131: 240/307] 	 train loss: 0.099734 	 lr: 0.00012
[epoch 131: 260/307] 	 train loss: 0.024864 	 lr: 0.00012
[epoch 131: 280/307] 	 train loss: 0.140733 	 lr: 0.00012
[epoch 131: 300/307] 	 train loss: 0.128542 	 lr: 0.00012
[epoch 132:   0/307] 	 train loss: 0.155780 	 lr: 0.00012
[epoch 132:  20/307] 	 train loss: 0.133649 	 lr: 0.00012
[epoch 132:  40/307] 	 train loss: 0.231348 	 lr: 0.00012

val loss: 0.340387 	 acc: 0.910454

[epoch 132:  60/307] 	 train loss: 0.052003 	 lr: 0.00012
[epoch 132:  80/307] 	 train loss: 0.010995 	 lr: 0.00012
[epoch 132: 100/307] 	 train loss: 0.218906 	 lr: 0.00012
[epoch 132: 120/307] 	 train loss: 0.124235 	 lr: 0.00012
[epoch 132: 140/307] 	 train loss: 0.091296 	 lr: 0.00012
[epoch 132: 160/307] 	 train loss: 0.069976 	 lr: 0.00012
[epoch 132: 180/307] 	 train loss: 0.049601 	 lr: 0.00012

val loss: 0.323978 	 acc: 0.916126

[epoch 132: 200/307] 	 train loss: 0.333510 	 lr: 0.00012
[epoch 132: 220/307] 	 train loss: 0.018445 	 lr: 0.00012
[epoch 132: 240/307] 	 train loss: 0.151190 	 lr: 0.00012
[epoch 132: 260/307] 	 train loss: 0.082911 	 lr: 0.00012
[epoch 132: 280/307] 	 train loss: 0.127474 	 lr: 0.00012
[epoch 132: 300/307] 	 train loss: 0.095695 	 lr: 0.00012
[epoch 133:   0/307] 	 train loss: 0.194873 	 lr: 0.00012
[epoch 133:  20/307] 	 train loss: 0.124335 	 lr: 0.00012
[epoch 133:  40/307] 	 train loss: 0.120682 	 lr: 0.00012

val loss: 0.327614 	 acc: 0.914506

[epoch 133:  60/307] 	 train loss: 0.098023 	 lr: 0.00012
[epoch 133:  80/307] 	 train loss: 0.068852 	 lr: 0.00012
[epoch 133: 100/307] 	 train loss: 0.121801 	 lr: 0.00012
[epoch 133: 120/307] 	 train loss: 0.123594 	 lr: 0.00012
[epoch 133: 140/307] 	 train loss: 0.208370 	 lr: 0.00012
[epoch 133: 160/307] 	 train loss: 0.178485 	 lr: 0.00012
[epoch 133: 180/307] 	 train loss: 0.056283 	 lr: 0.00012

val loss: 0.339300 	 acc: 0.914100

[epoch 133: 200/307] 	 train loss: 0.117910 	 lr: 0.00012
[epoch 133: 220/307] 	 train loss: 0.204307 	 lr: 0.00012
[epoch 133: 240/307] 	 train loss: 0.121699 	 lr: 0.00012
[epoch 133: 260/307] 	 train loss: 0.056761 	 lr: 0.00012
[epoch 133: 280/307] 	 train loss: 0.038563 	 lr: 0.00012
[epoch 133: 300/307] 	 train loss: 0.030241 	 lr: 0.00012
[epoch 134:   0/307] 	 train loss: 0.103455 	 lr: 0.00012
[epoch 134:  20/307] 	 train loss: 0.133035 	 lr: 0.00012

val loss: 0.345709 	 acc: 0.910454

[epoch 134:  40/307] 	 train loss: 0.037964 	 lr: 0.00012
[epoch 134:  60/307] 	 train loss: 0.101257 	 lr: 0.00012
[epoch 134:  80/307] 	 train loss: 0.073954 	 lr: 0.00012
[epoch 134: 100/307] 	 train loss: 0.100461 	 lr: 0.00012
[epoch 134: 120/307] 	 train loss: 0.039083 	 lr: 0.00012
[epoch 134: 140/307] 	 train loss: 0.029300 	 lr: 0.00012
[epoch 134: 160/307] 	 train loss: 0.127710 	 lr: 0.00012
[epoch 134: 180/307] 	 train loss: 0.067669 	 lr: 0.00012

val loss: 0.330084 	 acc: 0.917342

[epoch 134: 200/307] 	 train loss: 0.143087 	 lr: 0.00012
[epoch 134: 220/307] 	 train loss: 0.096953 	 lr: 0.00012
[epoch 134: 240/307] 	 train loss: 0.094246 	 lr: 0.00012
[epoch 134: 260/307] 	 train loss: 0.009764 	 lr: 0.00012
[epoch 134: 280/307] 	 train loss: 0.217663 	 lr: 0.00012
[epoch 134: 300/307] 	 train loss: 0.078777 	 lr: 0.00012
[epoch 135:   0/307] 	 train loss: 0.190890 	 lr: 0.00012
[epoch 135:  20/307] 	 train loss: 0.047626 	 lr: 0.00012

val loss: 0.328365 	 acc: 0.912885

[epoch 135:  40/307] 	 train loss: 0.070308 	 lr: 0.00012
[epoch 135:  60/307] 	 train loss: 0.124319 	 lr: 0.00012
[epoch 135:  80/307] 	 train loss: 0.115780 	 lr: 0.00012
[epoch 135: 100/307] 	 train loss: 0.034297 	 lr: 0.00012
[epoch 135: 120/307] 	 train loss: 0.048596 	 lr: 0.00012
[epoch 135: 140/307] 	 train loss: 0.063154 	 lr: 0.00012
[epoch 135: 160/307] 	 train loss: 0.135764 	 lr: 0.00012
[epoch 135: 180/307] 	 train loss: 0.144623 	 lr: 0.00012

val loss: 0.335534 	 acc: 0.913695

[epoch 135: 200/307] 	 train loss: 0.055108 	 lr: 0.00012
[epoch 135: 220/307] 	 train loss: 0.099391 	 lr: 0.00012
[epoch 135: 240/307] 	 train loss: 0.207728 	 lr: 0.00012
[epoch 135: 260/307] 	 train loss: 0.111935 	 lr: 0.00012
[epoch 135: 280/307] 	 train loss: 0.115784 	 lr: 0.00012
[epoch 135: 300/307] 	 train loss: 0.080928 	 lr: 0.00012
[epoch 136:   0/307] 	 train loss: 0.134575 	 lr: 0.00012
[epoch 136:  20/307] 	 train loss: 0.338302 	 lr: 0.00012

val loss: 0.331620 	 acc: 0.914100

[epoch 136:  40/307] 	 train loss: 0.244710 	 lr: 0.00012
[epoch 136:  60/307] 	 train loss: 0.267075 	 lr: 0.00012
[epoch 136:  80/307] 	 train loss: 0.126481 	 lr: 0.00012
[epoch 136: 100/307] 	 train loss: 0.146276 	 lr: 0.00012
[epoch 136: 120/307] 	 train loss: 0.061816 	 lr: 0.00012
[epoch 136: 140/307] 	 train loss: 0.415666 	 lr: 0.00012
[epoch 136: 160/307] 	 train loss: 0.042397 	 lr: 0.00012
[epoch 136: 180/307] 	 train loss: 0.025751 	 lr: 0.00012

val loss: 0.336478 	 acc: 0.917342

[epoch 136: 200/307] 	 train loss: 0.064508 	 lr: 0.00012
[epoch 136: 220/307] 	 train loss: 0.033884 	 lr: 0.00012
[epoch 136: 240/307] 	 train loss: 0.152896 	 lr: 0.00012
[epoch 136: 260/307] 	 train loss: 0.191460 	 lr: 0.00012
[epoch 136: 280/307] 	 train loss: 0.251614 	 lr: 0.00012
[epoch 136: 300/307] 	 train loss: 0.097317 	 lr: 0.00012
[epoch 137:   0/307] 	 train loss: 0.035237 	 lr: 0.00012
[epoch 137:  20/307] 	 train loss: 0.085491 	 lr: 0.00012

val loss: 0.336209 	 acc: 0.915316

[epoch 137:  40/307] 	 train loss: 0.068476 	 lr: 0.00012
[epoch 137:  60/307] 	 train loss: 0.142676 	 lr: 0.00012
[epoch 137:  80/307] 	 train loss: 0.061649 	 lr: 0.00012
[epoch 137: 100/307] 	 train loss: 0.088714 	 lr: 0.00012
[epoch 137: 120/307] 	 train loss: 0.129766 	 lr: 0.00012
[epoch 137: 140/307] 	 train loss: 0.023508 	 lr: 0.00012
[epoch 137: 160/307] 	 train loss: 0.037779 	 lr: 0.00012
[epoch 137: 180/307] 	 train loss: 0.127449 	 lr: 0.00012

val loss: 0.340272 	 acc: 0.915721

[epoch 137: 200/307] 	 train loss: 0.165183 	 lr: 0.00012
[epoch 137: 220/307] 	 train loss: 0.098764 	 lr: 0.00012
[epoch 137: 240/307] 	 train loss: 0.028733 	 lr: 0.00012
[epoch 137: 260/307] 	 train loss: 0.201639 	 lr: 0.00012
[epoch 137: 280/307] 	 train loss: 0.109425 	 lr: 0.00012
[epoch 137: 300/307] 	 train loss: 0.149421 	 lr: 0.00012
[epoch 138:   0/307] 	 train loss: 0.060519 	 lr: 0.00012
[epoch 138:  20/307] 	 train loss: 0.144825 	 lr: 0.00012

val loss: 0.333269 	 acc: 0.912885

[epoch 138:  40/307] 	 train loss: 0.033115 	 lr: 0.00012
[epoch 138:  60/307] 	 train loss: 0.119288 	 lr: 0.00012
[epoch 138:  80/307] 	 train loss: 0.107632 	 lr: 0.00012
[epoch 138: 100/307] 	 train loss: 0.089763 	 lr: 0.00012
[epoch 138: 120/307] 	 train loss: 0.195629 	 lr: 0.00012
[epoch 138: 140/307] 	 train loss: 0.243140 	 lr: 0.00012
[epoch 138: 160/307] 	 train loss: 0.077004 	 lr: 0.00012
[epoch 138: 180/307] 	 train loss: 0.159386 	 lr: 0.00012

val loss: 0.335692 	 acc: 0.912885

[epoch 138: 200/307] 	 train loss: 0.099121 	 lr: 0.00012
[epoch 138: 220/307] 	 train loss: 0.155626 	 lr: 0.00012
[epoch 138: 240/307] 	 train loss: 0.131171 	 lr: 0.00012
[epoch 138: 260/307] 	 train loss: 0.124735 	 lr: 0.00012
[epoch 138: 280/307] 	 train loss: 0.030293 	 lr: 0.00012
[epoch 138: 300/307] 	 train loss: 0.172103 	 lr: 0.00012
[epoch 139:   0/307] 	 train loss: 0.150747 	 lr: 0.00012
[epoch 139:  20/307] 	 train loss: 0.074408 	 lr: 0.00012

val loss: 0.346509 	 acc: 0.910454

[epoch 139:  40/307] 	 train loss: 0.153915 	 lr: 0.00012
[epoch 139:  60/307] 	 train loss: 0.070324 	 lr: 0.00012
[epoch 139:  80/307] 	 train loss: 0.109720 	 lr: 0.00012
[epoch 139: 100/307] 	 train loss: 0.259675 	 lr: 0.00012
[epoch 139: 120/307] 	 train loss: 0.157292 	 lr: 0.00012
[epoch 139: 140/307] 	 train loss: 0.353628 	 lr: 0.00012
[epoch 139: 160/307] 	 train loss: 0.111726 	 lr: 0.00012
[epoch 139: 180/307] 	 train loss: 0.121903 	 lr: 0.00012

val loss: 0.349296 	 acc: 0.910859

[epoch 139: 200/307] 	 train loss: 0.155002 	 lr: 0.00012
[epoch 139: 220/307] 	 train loss: 0.251638 	 lr: 0.00012
[epoch 139: 240/307] 	 train loss: 0.104470 	 lr: 0.00012
[epoch 139: 260/307] 	 train loss: 0.091217 	 lr: 0.00012
[epoch 139: 280/307] 	 train loss: 0.101546 	 lr: 0.00012
[epoch 139: 300/307] 	 train loss: 0.070667 	 lr: 0.00012
[epoch 140:   0/307] 	 train loss: 0.131480 	 lr: 0.00012
[epoch 140:  20/307] 	 train loss: 0.125407 	 lr: 0.00012

val loss: 0.334508 	 acc: 0.910859

[epoch 140:  40/307] 	 train loss: 0.081092 	 lr: 0.00012
[epoch 140:  60/307] 	 train loss: 0.126064 	 lr: 0.00012
[epoch 140:  80/307] 	 train loss: 0.083981 	 lr: 0.00012
[epoch 140: 100/307] 	 train loss: 0.167299 	 lr: 0.00012
[epoch 140: 120/307] 	 train loss: 0.209707 	 lr: 0.00012
[epoch 140: 140/307] 	 train loss: 0.286520 	 lr: 0.00012
[epoch 140: 160/307] 	 train loss: 0.107625 	 lr: 0.00012
[epoch 140: 180/307] 	 train loss: 0.094995 	 lr: 0.00012

val loss: 0.347520 	 acc: 0.911669

[epoch 140: 200/307] 	 train loss: 0.046776 	 lr: 0.00012
[epoch 140: 220/307] 	 train loss: 0.286724 	 lr: 0.00012
[epoch 140: 240/307] 	 train loss: 0.182226 	 lr: 0.00012
[epoch 140: 260/307] 	 train loss: 0.031080 	 lr: 0.00012
[epoch 140: 280/307] 	 train loss: 0.065385 	 lr: 0.00012
[epoch 140: 300/307] 	 train loss: 0.048549 	 lr: 0.00012
[epoch 141:   0/307] 	 train loss: 0.361621 	 lr: 0.00012
[epoch 141:  20/307] 	 train loss: 0.107982 	 lr: 0.00012

val loss: 0.335164 	 acc: 0.910859

[epoch 141:  40/307] 	 train loss: 0.131009 	 lr: 0.00012
[epoch 141:  60/307] 	 train loss: 0.138370 	 lr: 0.00012
[epoch 141:  80/307] 	 train loss: 0.507473 	 lr: 0.00012
[epoch 141: 100/307] 	 train loss: 0.150642 	 lr: 0.00012
[epoch 141: 120/307] 	 train loss: 0.021765 	 lr: 0.00012
[epoch 141: 140/307] 	 train loss: 0.337697 	 lr: 0.00012
[epoch 141: 160/307] 	 train loss: 0.150432 	 lr: 0.00012

val loss: 0.349505 	 acc: 0.911669

[epoch 141: 180/307] 	 train loss: 0.057121 	 lr: 0.00012
[epoch 141: 200/307] 	 train loss: 0.257696 	 lr: 0.00012
[epoch 141: 220/307] 	 train loss: 0.064311 	 lr: 0.00012
[epoch 141: 240/307] 	 train loss: 0.045691 	 lr: 0.00012
[epoch 141: 260/307] 	 train loss: 0.099300 	 lr: 0.00012
[epoch 141: 280/307] 	 train loss: 0.327765 	 lr: 0.00012
[epoch 141: 300/307] 	 train loss: 0.040158 	 lr: 0.00012
[epoch 142:   0/307] 	 train loss: 0.104744 	 lr: 0.00012
[epoch 142:  20/307] 	 train loss: 0.107975 	 lr: 0.00012

val loss: 0.343752 	 acc: 0.907618

[epoch 142:  40/307] 	 train loss: 0.088842 	 lr: 0.00012
[epoch 142:  60/307] 	 train loss: 0.042466 	 lr: 0.00012
[epoch 142:  80/307] 	 train loss: 0.021253 	 lr: 0.00012
[epoch 142: 100/307] 	 train loss: 0.172756 	 lr: 0.00012
[epoch 142: 120/307] 	 train loss: 0.142596 	 lr: 0.00012
[epoch 142: 140/307] 	 train loss: 0.125800 	 lr: 0.00012
[epoch 142: 160/307] 	 train loss: 0.062370 	 lr: 0.00012

val loss: 0.341472 	 acc: 0.912885

[epoch 142: 180/307] 	 train loss: 0.290390 	 lr: 0.00012
[epoch 142: 200/307] 	 train loss: 0.101755 	 lr: 0.00012
[epoch 142: 220/307] 	 train loss: 0.149024 	 lr: 0.00012
[epoch 142: 240/307] 	 train loss: 0.040628 	 lr: 0.00012
[epoch 142: 260/307] 	 train loss: 0.066621 	 lr: 0.00012
[epoch 142: 280/307] 	 train loss: 0.106403 	 lr: 0.00012
[epoch 142: 300/307] 	 train loss: 0.174729 	 lr: 0.00012
[epoch 143:   0/307] 	 train loss: 0.111895 	 lr: 0.00012
[epoch 143:  20/307] 	 train loss: 0.049312 	 lr: 0.00012

val loss: 0.341695 	 acc: 0.912885

[epoch 143:  40/307] 	 train loss: 0.032706 	 lr: 0.00012
[epoch 143:  60/307] 	 train loss: 0.239712 	 lr: 0.00012
[epoch 143:  80/307] 	 train loss: 0.300702 	 lr: 0.00012
[epoch 143: 100/307] 	 train loss: 0.201992 	 lr: 0.00012
[epoch 143: 120/307] 	 train loss: 0.101881 	 lr: 0.00012
[epoch 143: 140/307] 	 train loss: 0.037848 	 lr: 0.00012
[epoch 143: 160/307] 	 train loss: 0.280487 	 lr: 0.00012

val loss: 0.340077 	 acc: 0.912075

[epoch 143: 180/307] 	 train loss: 0.018629 	 lr: 0.00012
[epoch 143: 200/307] 	 train loss: 0.061273 	 lr: 0.00012
[epoch 143: 220/307] 	 train loss: 0.237726 	 lr: 0.00012
[epoch 143: 240/307] 	 train loss: 0.168288 	 lr: 0.00012
[epoch 143: 260/307] 	 train loss: 0.191792 	 lr: 0.00012
[epoch 143: 280/307] 	 train loss: 0.101547 	 lr: 0.00012
[epoch 143: 300/307] 	 train loss: 0.156664 	 lr: 0.00012
[epoch 144:   0/307] 	 train loss: 0.081141 	 lr: 0.00012

val loss: 0.343146 	 acc: 0.914100

[epoch 144:  20/307] 	 train loss: 0.116470 	 lr: 0.00012
[epoch 144:  40/307] 	 train loss: 0.287779 	 lr: 0.00012
[epoch 144:  60/307] 	 train loss: 0.035994 	 lr: 0.00012
[epoch 144:  80/307] 	 train loss: 0.276805 	 lr: 0.00012
[epoch 144: 100/307] 	 train loss: 0.101054 	 lr: 0.00012
[epoch 144: 120/307] 	 train loss: 0.182164 	 lr: 0.00012
[epoch 144: 140/307] 	 train loss: 0.035369 	 lr: 0.00012
[epoch 144: 160/307] 	 train loss: 0.021843 	 lr: 0.00012

val loss: 0.348898 	 acc: 0.910859

[epoch 144: 180/307] 	 train loss: 0.082871 	 lr: 0.00012
[epoch 144: 200/307] 	 train loss: 0.260086 	 lr: 0.00012
[epoch 144: 220/307] 	 train loss: 0.232657 	 lr: 0.00012
[epoch 144: 240/307] 	 train loss: 0.057745 	 lr: 0.00012
[epoch 144: 260/307] 	 train loss: 0.065352 	 lr: 0.00012
[epoch 144: 280/307] 	 train loss: 0.077909 	 lr: 0.00012
[epoch 144: 300/307] 	 train loss: 0.239092 	 lr: 0.00012
[epoch 145:   0/307] 	 train loss: 0.154810 	 lr: 0.00012

val loss: 0.345216 	 acc: 0.910454

[epoch 145:  20/307] 	 train loss: 0.099053 	 lr: 0.00012
[epoch 145:  40/307] 	 train loss: 0.106463 	 lr: 0.00012
[epoch 145:  60/307] 	 train loss: 0.104818 	 lr: 0.00012
[epoch 145:  80/307] 	 train loss: 0.174920 	 lr: 0.00012
[epoch 145: 100/307] 	 train loss: 0.087414 	 lr: 0.00012
[epoch 145: 120/307] 	 train loss: 0.084645 	 lr: 0.00012
[epoch 145: 140/307] 	 train loss: 0.061978 	 lr: 0.00012
[epoch 145: 160/307] 	 train loss: 0.191291 	 lr: 0.00012

val loss: 0.342046 	 acc: 0.911669

[epoch 145: 180/307] 	 train loss: 0.378233 	 lr: 0.00012
[epoch 145: 200/307] 	 train loss: 0.140241 	 lr: 0.00012
[epoch 145: 220/307] 	 train loss: 0.178160 	 lr: 0.00012
[epoch 145: 240/307] 	 train loss: 0.119548 	 lr: 0.00012
[epoch 145: 260/307] 	 train loss: 0.120949 	 lr: 0.00012
[epoch 145: 280/307] 	 train loss: 0.022096 	 lr: 0.00012
[epoch 145: 300/307] 	 train loss: 0.187597 	 lr: 0.00012
[epoch 146:   0/307] 	 train loss: 0.233382 	 lr: 0.00012

val loss: 0.345048 	 acc: 0.912885

[epoch 146:  20/307] 	 train loss: 0.209922 	 lr: 0.00012
[epoch 146:  40/307] 	 train loss: 0.036869 	 lr: 0.00012
[epoch 146:  60/307] 	 train loss: 0.159525 	 lr: 0.00012
[epoch 146:  80/307] 	 train loss: 0.069850 	 lr: 0.00012
[epoch 146: 100/307] 	 train loss: 0.250591 	 lr: 0.00012
[epoch 146: 120/307] 	 train loss: 0.072822 	 lr: 0.00012
[epoch 146: 140/307] 	 train loss: 0.166108 	 lr: 0.00012
[epoch 146: 160/307] 	 train loss: 0.005925 	 lr: 0.00012

val loss: 0.340245 	 acc: 0.911264

[epoch 146: 180/307] 	 train loss: 0.058851 	 lr: 0.00012
[epoch 146: 200/307] 	 train loss: 0.047798 	 lr: 0.00012
[epoch 146: 220/307] 	 train loss: 0.107906 	 lr: 0.00012
[epoch 146: 240/307] 	 train loss: 0.086208 	 lr: 0.00012
[epoch 146: 260/307] 	 train loss: 0.222097 	 lr: 0.00012
[epoch 146: 280/307] 	 train loss: 0.052632 	 lr: 0.00012
[epoch 146: 300/307] 	 train loss: 0.046578 	 lr: 0.00012
[epoch 147:   0/307] 	 train loss: 0.064452 	 lr: 0.00012

val loss: 0.346075 	 acc: 0.912075

[epoch 147:  20/307] 	 train loss: 0.131100 	 lr: 0.00012
[epoch 147:  40/307] 	 train loss: 0.075978 	 lr: 0.00012
[epoch 147:  60/307] 	 train loss: 0.093957 	 lr: 0.00012
[epoch 147:  80/307] 	 train loss: 0.069590 	 lr: 0.00012
[epoch 147: 100/307] 	 train loss: 0.228066 	 lr: 0.00012
[epoch 147: 120/307] 	 train loss: 0.097537 	 lr: 0.00012
[epoch 147: 140/307] 	 train loss: 0.164112 	 lr: 0.00012
[epoch 147: 160/307] 	 train loss: 0.104113 	 lr: 0.00012

val loss: 0.343627 	 acc: 0.911669

[epoch 147: 180/307] 	 train loss: 0.062869 	 lr: 0.00012
[epoch 147: 200/307] 	 train loss: 0.021354 	 lr: 0.00012
[epoch 147: 220/307] 	 train loss: 0.124503 	 lr: 0.00012
[epoch 147: 240/307] 	 train loss: 0.067949 	 lr: 0.00012
[epoch 147: 260/307] 	 train loss: 0.233536 	 lr: 0.00012
[epoch 147: 280/307] 	 train loss: 0.252707 	 lr: 0.00012
[epoch 147: 300/307] 	 train loss: 0.274198 	 lr: 0.00012
[epoch 148:   0/307] 	 train loss: 0.048343 	 lr: 0.00008

val loss: 0.350626 	 acc: 0.906807

[epoch 148:  20/307] 	 train loss: 0.102637 	 lr: 0.00008
[epoch 148:  40/307] 	 train loss: 0.093679 	 lr: 0.00008
[epoch 148:  60/307] 	 train loss: 0.065932 	 lr: 0.00008
[epoch 148:  80/307] 	 train loss: 0.126256 	 lr: 0.00008
[epoch 148: 100/307] 	 train loss: 0.082812 	 lr: 0.00008
[epoch 148: 120/307] 	 train loss: 0.222021 	 lr: 0.00008
[epoch 148: 140/307] 	 train loss: 0.313287 	 lr: 0.00008
[epoch 148: 160/307] 	 train loss: 0.171340 	 lr: 0.00008

val loss: 0.336551 	 acc: 0.914100

[epoch 148: 180/307] 	 train loss: 0.084643 	 lr: 0.00008
[epoch 148: 200/307] 	 train loss: 0.201204 	 lr: 0.00008
[epoch 148: 220/307] 	 train loss: 0.256910 	 lr: 0.00008
[epoch 148: 240/307] 	 train loss: 0.212857 	 lr: 0.00008
[epoch 148: 260/307] 	 train loss: 0.101511 	 lr: 0.00008
[epoch 148: 280/307] 	 train loss: 0.110418 	 lr: 0.00008
[epoch 148: 300/307] 	 train loss: 0.039859 	 lr: 0.00008
[epoch 149:   0/307] 	 train loss: 0.093746 	 lr: 0.00008

val loss: 0.341586 	 acc: 0.911669

[epoch 149:  20/307] 	 train loss: 0.026898 	 lr: 0.00008
[epoch 149:  40/307] 	 train loss: 0.005779 	 lr: 0.00008
[epoch 149:  60/307] 	 train loss: 0.065057 	 lr: 0.00008
[epoch 149:  80/307] 	 train loss: 0.126890 	 lr: 0.00008
[epoch 149: 100/307] 	 train loss: 0.047414 	 lr: 0.00008
[epoch 149: 120/307] 	 train loss: 0.106058 	 lr: 0.00008
[epoch 149: 140/307] 	 train loss: 0.033081 	 lr: 0.00008
[epoch 149: 160/307] 	 train loss: 0.263925 	 lr: 0.00008

val loss: 0.339462 	 acc: 0.911669

[epoch 149: 180/307] 	 train loss: 0.098950 	 lr: 0.00008
[epoch 149: 200/307] 	 train loss: 0.097342 	 lr: 0.00008
[epoch 149: 220/307] 	 train loss: 0.094737 	 lr: 0.00008
[epoch 149: 240/307] 	 train loss: 0.034388 	 lr: 0.00008
[epoch 149: 260/307] 	 train loss: 0.034504 	 lr: 0.00008
[epoch 149: 280/307] 	 train loss: 0.230488 	 lr: 0.00008
[epoch 149: 300/307] 	 train loss: 0.114547 	 lr: 0.00008
[epoch 150:   0/307] 	 train loss: 0.034964 	 lr: 0.00008

val loss: 0.336069 	 acc: 0.910859

[epoch 150:  20/307] 	 train loss: 0.154555 	 lr: 0.00008
[epoch 150:  40/307] 	 train loss: 0.189064 	 lr: 0.00008
[epoch 150:  60/307] 	 train loss: 0.131780 	 lr: 0.00008
[epoch 150:  80/307] 	 train loss: 0.067147 	 lr: 0.00008
[epoch 150: 100/307] 	 train loss: 0.204646 	 lr: 0.00008
[epoch 150: 120/307] 	 train loss: 0.279443 	 lr: 0.00008
[epoch 150: 140/307] 	 train loss: 0.071868 	 lr: 0.00008
[epoch 150: 160/307] 	 train loss: 0.098720 	 lr: 0.00008

val loss: 0.338427 	 acc: 0.911669

[epoch 150: 180/307] 	 train loss: 0.161744 	 lr: 0.00008
[epoch 150: 200/307] 	 train loss: 0.410864 	 lr: 0.00008
[epoch 150: 220/307] 	 train loss: 0.119443 	 lr: 0.00008
[epoch 150: 240/307] 	 train loss: 0.108810 	 lr: 0.00008
[epoch 150: 260/307] 	 train loss: 0.046805 	 lr: 0.00008
[epoch 150: 280/307] 	 train loss: 0.117945 	 lr: 0.00008
[epoch 150: 300/307] 	 train loss: 0.046895 	 lr: 0.00008
[epoch 151:   0/307] 	 train loss: 0.033493 	 lr: 0.00008

val loss: 0.338554 	 acc: 0.910049

[epoch 151:  20/307] 	 train loss: 0.083040 	 lr: 0.00008
[epoch 151:  40/307] 	 train loss: 0.164813 	 lr: 0.00008
[epoch 151:  60/307] 	 train loss: 0.119629 	 lr: 0.00008
[epoch 151:  80/307] 	 train loss: 0.091103 	 lr: 0.00008
[epoch 151: 100/307] 	 train loss: 0.088353 	 lr: 0.00008
[epoch 151: 120/307] 	 train loss: 0.084927 	 lr: 0.00008
[epoch 151: 140/307] 	 train loss: 0.066362 	 lr: 0.00008

val loss: 0.343875 	 acc: 0.909238

[epoch 151: 160/307] 	 train loss: 0.083669 	 lr: 0.00008
[epoch 151: 180/307] 	 train loss: 0.126829 	 lr: 0.00008
[epoch 151: 200/307] 	 train loss: 0.366757 	 lr: 0.00008
[epoch 151: 220/307] 	 train loss: 0.024387 	 lr: 0.00008
[epoch 151: 240/307] 	 train loss: 0.086006 	 lr: 0.00008
[epoch 151: 260/307] 	 train loss: 0.133537 	 lr: 0.00008
[epoch 151: 280/307] 	 train loss: 0.303833 	 lr: 0.00008
[epoch 151: 300/307] 	 train loss: 0.061468 	 lr: 0.00008
[epoch 152:   0/307] 	 train loss: 0.050072 	 lr: 0.00008

val loss: 0.339723 	 acc: 0.908023

[epoch 152:  20/307] 	 train loss: 0.037750 	 lr: 0.00008
[epoch 152:  40/307] 	 train loss: 0.352520 	 lr: 0.00008
[epoch 152:  60/307] 	 train loss: 0.207574 	 lr: 0.00008
[epoch 152:  80/307] 	 train loss: 0.046930 	 lr: 0.00008
[epoch 152: 100/307] 	 train loss: 0.153530 	 lr: 0.00008
[epoch 152: 120/307] 	 train loss: 0.030641 	 lr: 0.00008
[epoch 152: 140/307] 	 train loss: 0.083029 	 lr: 0.00008

val loss: 0.326713 	 acc: 0.912885

[epoch 152: 160/307] 	 train loss: 0.032786 	 lr: 0.00008
[epoch 152: 180/307] 	 train loss: 0.147699 	 lr: 0.00008
[epoch 152: 200/307] 	 train loss: 0.355136 	 lr: 0.00008
[epoch 152: 220/307] 	 train loss: 0.051977 	 lr: 0.00008
[epoch 152: 240/307] 	 train loss: 0.107021 	 lr: 0.00008
[epoch 152: 260/307] 	 train loss: 0.246993 	 lr: 0.00008
[epoch 152: 280/307] 	 train loss: 0.033627 	 lr: 0.00008
[epoch 152: 300/307] 	 train loss: 0.198257 	 lr: 0.00008
[epoch 153:   0/307] 	 train loss: 0.090947 	 lr: 0.00008

val loss: 0.336233 	 acc: 0.910049

[epoch 153:  20/307] 	 train loss: 0.038720 	 lr: 0.00008
[epoch 153:  40/307] 	 train loss: 0.285091 	 lr: 0.00008
[epoch 153:  60/307] 	 train loss: 0.108844 	 lr: 0.00008
[epoch 153:  80/307] 	 train loss: 0.512009 	 lr: 0.00008
[epoch 153: 100/307] 	 train loss: 0.112901 	 lr: 0.00008
[epoch 153: 120/307] 	 train loss: 0.062234 	 lr: 0.00008
[epoch 153: 140/307] 	 train loss: 0.152765 	 lr: 0.00008

val loss: 0.330694 	 acc: 0.912885

[epoch 153: 160/307] 	 train loss: 0.182740 	 lr: 0.00008
[epoch 153: 180/307] 	 train loss: 0.109074 	 lr: 0.00008
[epoch 153: 200/307] 	 train loss: 0.045837 	 lr: 0.00008
[epoch 153: 220/307] 	 train loss: 0.042927 	 lr: 0.00008
[epoch 153: 240/307] 	 train loss: 0.209361 	 lr: 0.00008
[epoch 153: 260/307] 	 train loss: 0.096502 	 lr: 0.00008
[epoch 153: 280/307] 	 train loss: 0.125492 	 lr: 0.00008
[epoch 153: 300/307] 	 train loss: 0.203463 	 lr: 0.00008

val loss: 0.334451 	 acc: 0.910049

[epoch 154:   0/307] 	 train loss: 0.071109 	 lr: 0.00008
[epoch 154:  20/307] 	 train loss: 0.067633 	 lr: 0.00008
[epoch 154:  40/307] 	 train loss: 0.165268 	 lr: 0.00008
[epoch 154:  60/307] 	 train loss: 0.190211 	 lr: 0.00008
[epoch 154:  80/307] 	 train loss: 0.405813 	 lr: 0.00008
[epoch 154: 100/307] 	 train loss: 0.069276 	 lr: 0.00008
[epoch 154: 120/307] 	 train loss: 0.211131 	 lr: 0.00008
[epoch 154: 140/307] 	 train loss: 0.024408 	 lr: 0.00008

val loss: 0.333899 	 acc: 0.910454

[epoch 154: 160/307] 	 train loss: 0.150300 	 lr: 0.00008
[epoch 154: 180/307] 	 train loss: 0.109235 	 lr: 0.00008
[epoch 154: 200/307] 	 train loss: 0.080391 	 lr: 0.00008
[epoch 154: 220/307] 	 train loss: 0.210203 	 lr: 0.00008
[epoch 154: 240/307] 	 train loss: 0.023903 	 lr: 0.00008
[epoch 154: 260/307] 	 train loss: 0.106077 	 lr: 0.00008
[epoch 154: 280/307] 	 train loss: 0.080100 	 lr: 0.00008
[epoch 154: 300/307] 	 train loss: 0.023917 	 lr: 0.00008

val loss: 0.346129 	 acc: 0.909238

[epoch 155:   0/307] 	 train loss: 0.114211 	 lr: 0.00008
[epoch 155:  20/307] 	 train loss: 0.223588 	 lr: 0.00008
[epoch 155:  40/307] 	 train loss: 0.084615 	 lr: 0.00008
[epoch 155:  60/307] 	 train loss: 0.262896 	 lr: 0.00008
[epoch 155:  80/307] 	 train loss: 0.038656 	 lr: 0.00008
[epoch 155: 100/307] 	 train loss: 0.272773 	 lr: 0.00008
[epoch 155: 120/307] 	 train loss: 0.177481 	 lr: 0.00008
[epoch 155: 140/307] 	 train loss: 0.068886 	 lr: 0.00008

val loss: 0.331034 	 acc: 0.914100

[epoch 155: 160/307] 	 train loss: 0.112181 	 lr: 0.00008
[epoch 155: 180/307] 	 train loss: 0.073378 	 lr: 0.00008
[epoch 155: 200/307] 	 train loss: 0.201415 	 lr: 0.00008
[epoch 155: 220/307] 	 train loss: 0.218985 	 lr: 0.00008
[epoch 155: 240/307] 	 train loss: 0.157637 	 lr: 0.00008
[epoch 155: 260/307] 	 train loss: 0.051675 	 lr: 0.00008
[epoch 155: 280/307] 	 train loss: 0.387481 	 lr: 0.00008
[epoch 155: 300/307] 	 train loss: 0.105273 	 lr: 0.00008

val loss: 0.331772 	 acc: 0.913290

[epoch 156:   0/307] 	 train loss: 0.116530 	 lr: 0.00008
[epoch 156:  20/307] 	 train loss: 0.023969 	 lr: 0.00008
[epoch 156:  40/307] 	 train loss: 0.409487 	 lr: 0.00008
[epoch 156:  60/307] 	 train loss: 0.142069 	 lr: 0.00008
[epoch 156:  80/307] 	 train loss: 0.057810 	 lr: 0.00008
[epoch 156: 100/307] 	 train loss: 0.081002 	 lr: 0.00008
[epoch 156: 120/307] 	 train loss: 0.076010 	 lr: 0.00008
[epoch 156: 140/307] 	 train loss: 0.102169 	 lr: 0.00008

val loss: 0.325351 	 acc: 0.914506

[epoch 156: 160/307] 	 train loss: 0.078829 	 lr: 0.00008
[epoch 156: 180/307] 	 train loss: 0.171809 	 lr: 0.00008
[epoch 156: 200/307] 	 train loss: 0.306127 	 lr: 0.00008
[epoch 156: 220/307] 	 train loss: 0.060562 	 lr: 0.00008
[epoch 156: 240/307] 	 train loss: 0.046610 	 lr: 0.00008
[epoch 156: 260/307] 	 train loss: 0.155901 	 lr: 0.00008
[epoch 156: 280/307] 	 train loss: 0.271203 	 lr: 0.00008
[epoch 156: 300/307] 	 train loss: 0.176308 	 lr: 0.00008

val loss: 0.335075 	 acc: 0.912480

[epoch 157:   0/307] 	 train loss: 0.121185 	 lr: 0.00008
[epoch 157:  20/307] 	 train loss: 0.081430 	 lr: 0.00008
[epoch 157:  40/307] 	 train loss: 0.206298 	 lr: 0.00008
[epoch 157:  60/307] 	 train loss: 0.080347 	 lr: 0.00008
[epoch 157:  80/307] 	 train loss: 0.141689 	 lr: 0.00008
[epoch 157: 100/307] 	 train loss: 0.182425 	 lr: 0.00008
[epoch 157: 120/307] 	 train loss: 0.018683 	 lr: 0.00008
[epoch 157: 140/307] 	 train loss: 0.007615 	 lr: 0.00008

val loss: 0.337825 	 acc: 0.911669

[epoch 157: 160/307] 	 train loss: 0.148207 	 lr: 0.00008
[epoch 157: 180/307] 	 train loss: 0.016753 	 lr: 0.00008
[epoch 157: 200/307] 	 train loss: 0.020431 	 lr: 0.00008
[epoch 157: 220/307] 	 train loss: 0.049799 	 lr: 0.00008
[epoch 157: 240/307] 	 train loss: 0.126060 	 lr: 0.00008
[epoch 157: 260/307] 	 train loss: 0.100354 	 lr: 0.00008
[epoch 157: 280/307] 	 train loss: 0.274597 	 lr: 0.00008

val loss: 0.336833 	 acc: 0.910859

[epoch 157: 300/307] 	 train loss: 0.138797 	 lr: 0.00008
[epoch 158:   0/307] 	 train loss: 0.034802 	 lr: 0.00008
[epoch 158:  20/307] 	 train loss: 0.098394 	 lr: 0.00008
[epoch 158:  40/307] 	 train loss: 0.015785 	 lr: 0.00008
[epoch 158:  60/307] 	 train loss: 0.158411 	 lr: 0.00008
[epoch 158:  80/307] 	 train loss: 0.226616 	 lr: 0.00008
[epoch 158: 100/307] 	 train loss: 0.053715 	 lr: 0.00008
[epoch 158: 120/307] 	 train loss: 0.175494 	 lr: 0.00008
[epoch 158: 140/307] 	 train loss: 0.097702 	 lr: 0.00008

val loss: 0.334834 	 acc: 0.908833

[epoch 158: 160/307] 	 train loss: 0.164931 	 lr: 0.00008
[epoch 158: 180/307] 	 train loss: 0.118412 	 lr: 0.00008
[epoch 158: 200/307] 	 train loss: 0.130091 	 lr: 0.00008
[epoch 158: 220/307] 	 train loss: 0.095841 	 lr: 0.00008
[epoch 158: 240/307] 	 train loss: 0.085865 	 lr: 0.00008
[epoch 158: 260/307] 	 train loss: 0.111187 	 lr: 0.00008
[epoch 158: 280/307] 	 train loss: 0.106911 	 lr: 0.00008

val loss: 0.335133 	 acc: 0.911264

[epoch 158: 300/307] 	 train loss: 0.103425 	 lr: 0.00008
[epoch 159:   0/307] 	 train loss: 0.063785 	 lr: 0.00008
[epoch 159:  20/307] 	 train loss: 0.101186 	 lr: 0.00008
[epoch 159:  40/307] 	 train loss: 0.081166 	 lr: 0.00008
[epoch 159:  60/307] 	 train loss: 0.026916 	 lr: 0.00008
[epoch 159:  80/307] 	 train loss: 0.137075 	 lr: 0.00008
[epoch 159: 100/307] 	 train loss: 0.171546 	 lr: 0.00008
[epoch 159: 120/307] 	 train loss: 0.279360 	 lr: 0.00008
[epoch 159: 140/307] 	 train loss: 0.282982 	 lr: 0.00008

val loss: 0.335496 	 acc: 0.910049

[epoch 159: 160/307] 	 train loss: 0.049509 	 lr: 0.00008
[epoch 159: 180/307] 	 train loss: 0.162593 	 lr: 0.00008
[epoch 159: 200/307] 	 train loss: 0.122320 	 lr: 0.00008
[epoch 159: 220/307] 	 train loss: 0.159891 	 lr: 0.00008
[epoch 159: 240/307] 	 train loss: 0.161312 	 lr: 0.00008
[epoch 159: 260/307] 	 train loss: 0.043636 	 lr: 0.00008
[epoch 159: 280/307] 	 train loss: 0.054659 	 lr: 0.00008

val loss: 0.330590 	 acc: 0.911669

[epoch 159: 300/307] 	 train loss: 0.144609 	 lr: 0.00008
[epoch 160:   0/307] 	 train loss: 0.039049 	 lr: 0.00008
[epoch 160:  20/307] 	 train loss: 0.054374 	 lr: 0.00008
[epoch 160:  40/307] 	 train loss: 0.070018 	 lr: 0.00008
[epoch 160:  60/307] 	 train loss: 0.071048 	 lr: 0.00008
[epoch 160:  80/307] 	 train loss: 0.171332 	 lr: 0.00008
[epoch 160: 100/307] 	 train loss: 0.119412 	 lr: 0.00008
[epoch 160: 120/307] 	 train loss: 0.102936 	 lr: 0.00008
[epoch 160: 140/307] 	 train loss: 0.015413 	 lr: 0.00008

val loss: 0.324455 	 acc: 0.914100

[epoch 160: 160/307] 	 train loss: 0.095234 	 lr: 0.00008
[epoch 160: 180/307] 	 train loss: 0.190928 	 lr: 0.00008
[epoch 160: 200/307] 	 train loss: 0.075726 	 lr: 0.00008
[epoch 160: 220/307] 	 train loss: 0.067749 	 lr: 0.00008
[epoch 160: 240/307] 	 train loss: 0.142226 	 lr: 0.00008
[epoch 160: 260/307] 	 train loss: 0.086318 	 lr: 0.00008
[epoch 160: 280/307] 	 train loss: 0.274770 	 lr: 0.00008

val loss: 0.325723 	 acc: 0.914100

[epoch 160: 300/307] 	 train loss: 0.119590 	 lr: 0.00008
[epoch 161:   0/307] 	 train loss: 0.231230 	 lr: 0.00008
[epoch 161:  20/307] 	 train loss: 0.045627 	 lr: 0.00008
[epoch 161:  40/307] 	 train loss: 0.202420 	 lr: 0.00008
[epoch 161:  60/307] 	 train loss: 0.077470 	 lr: 0.00008
[epoch 161:  80/307] 	 train loss: 0.032616 	 lr: 0.00008
[epoch 161: 100/307] 	 train loss: 0.685254 	 lr: 0.00008
[epoch 161: 120/307] 	 train loss: 0.147955 	 lr: 0.00008

val loss: 0.332809 	 acc: 0.914100

[epoch 161: 140/307] 	 train loss: 0.153864 	 lr: 0.00008
[epoch 161: 160/307] 	 train loss: 0.177008 	 lr: 0.00008
[epoch 161: 180/307] 	 train loss: 0.175435 	 lr: 0.00008
[epoch 161: 200/307] 	 train loss: 0.070582 	 lr: 0.00008
[epoch 161: 220/307] 	 train loss: 0.087901 	 lr: 0.00008
[epoch 161: 240/307] 	 train loss: 0.089157 	 lr: 0.00008
[epoch 161: 260/307] 	 train loss: 0.068197 	 lr: 0.00008
[epoch 161: 280/307] 	 train loss: 0.029936 	 lr: 0.00008

val loss: 0.341233 	 acc: 0.909643

[epoch 161: 300/307] 	 train loss: 0.109754 	 lr: 0.00008
[epoch 162:   0/307] 	 train loss: 0.102904 	 lr: 0.00008
[epoch 162:  20/307] 	 train loss: 0.183437 	 lr: 0.00008
[epoch 162:  40/307] 	 train loss: 0.109309 	 lr: 0.00008
[epoch 162:  60/307] 	 train loss: 0.258209 	 lr: 0.00008
[epoch 162:  80/307] 	 train loss: 0.045256 	 lr: 0.00008
[epoch 162: 100/307] 	 train loss: 0.176838 	 lr: 0.00008
[epoch 162: 120/307] 	 train loss: 0.116933 	 lr: 0.00008

val loss: 0.330793 	 acc: 0.912480

[epoch 162: 140/307] 	 train loss: 0.079167 	 lr: 0.00008
[epoch 162: 160/307] 	 train loss: 0.083376 	 lr: 0.00008
[epoch 162: 180/307] 	 train loss: 0.054739 	 lr: 0.00008
[epoch 162: 200/307] 	 train loss: 0.037396 	 lr: 0.00008
[epoch 162: 220/307] 	 train loss: 0.173198 	 lr: 0.00008
[epoch 162: 240/307] 	 train loss: 0.239721 	 lr: 0.00008
[epoch 162: 260/307] 	 train loss: 0.358609 	 lr: 0.00008
[epoch 162: 280/307] 	 train loss: 0.033172 	 lr: 0.00008

val loss: 0.342497 	 acc: 0.909238

[epoch 162: 300/307] 	 train loss: 0.048548 	 lr: 0.00008
[epoch 163:   0/307] 	 train loss: 0.308345 	 lr: 0.00008
[epoch 163:  20/307] 	 train loss: 0.072533 	 lr: 0.00008
[epoch 163:  40/307] 	 train loss: 0.016490 	 lr: 0.00008
[epoch 163:  60/307] 	 train loss: 0.163509 	 lr: 0.00008
[epoch 163:  80/307] 	 train loss: 0.082501 	 lr: 0.00008
[epoch 163: 100/307] 	 train loss: 0.187603 	 lr: 0.00008
[epoch 163: 120/307] 	 train loss: 0.030585 	 lr: 0.00008

val loss: 0.337204 	 acc: 0.910859

[epoch 163: 140/307] 	 train loss: 0.099686 	 lr: 0.00008
[epoch 163: 160/307] 	 train loss: 0.368613 	 lr: 0.00008
[epoch 163: 180/307] 	 train loss: 0.118392 	 lr: 0.00008
[epoch 163: 200/307] 	 train loss: 0.165205 	 lr: 0.00008
[epoch 163: 220/307] 	 train loss: 0.045650 	 lr: 0.00008
[epoch 163: 240/307] 	 train loss: 0.032973 	 lr: 0.00008
[epoch 163: 260/307] 	 train loss: 0.144050 	 lr: 0.00008
[epoch 163: 280/307] 	 train loss: 0.109810 	 lr: 0.00008

val loss: 0.340455 	 acc: 0.908833

[epoch 163: 300/307] 	 train loss: 0.047727 	 lr: 0.00008
[epoch 164:   0/307] 	 train loss: 0.192870 	 lr: 0.00008
[epoch 164:  20/307] 	 train loss: 0.279312 	 lr: 0.00008
[epoch 164:  40/307] 	 train loss: 0.151805 	 lr: 0.00008
[epoch 164:  60/307] 	 train loss: 0.144191 	 lr: 0.00008
[epoch 164:  80/307] 	 train loss: 0.033674 	 lr: 0.00008
[epoch 164: 100/307] 	 train loss: 0.174582 	 lr: 0.00008
[epoch 164: 120/307] 	 train loss: 0.093431 	 lr: 0.00008

val loss: 0.334123 	 acc: 0.909643

[epoch 164: 140/307] 	 train loss: 0.056928 	 lr: 0.00008
[epoch 164: 160/307] 	 train loss: 0.055051 	 lr: 0.00008
[epoch 164: 180/307] 	 train loss: 0.272702 	 lr: 0.00008
[epoch 164: 200/307] 	 train loss: 0.266378 	 lr: 0.00008
[epoch 164: 220/307] 	 train loss: 0.037386 	 lr: 0.00008
[epoch 164: 240/307] 	 train loss: 0.119171 	 lr: 0.00008
[epoch 164: 260/307] 	 train loss: 0.039811 	 lr: 0.00008
[epoch 164: 280/307] 	 train loss: 0.057883 	 lr: 0.00008

val loss: 0.339388 	 acc: 0.911264

[epoch 164: 300/307] 	 train loss: 0.139787 	 lr: 0.00008
[epoch 165:   0/307] 	 train loss: 0.054079 	 lr: 0.00008
[epoch 165:  20/307] 	 train loss: 0.074708 	 lr: 0.00008
[epoch 165:  40/307] 	 train loss: 0.061177 	 lr: 0.00008
[epoch 165:  60/307] 	 train loss: 0.185288 	 lr: 0.00008
[epoch 165:  80/307] 	 train loss: 0.107834 	 lr: 0.00008
[epoch 165: 100/307] 	 train loss: 0.150091 	 lr: 0.00008
[epoch 165: 120/307] 	 train loss: 0.128375 	 lr: 0.00008

val loss: 0.343972 	 acc: 0.911669

[epoch 165: 140/307] 	 train loss: 0.301062 	 lr: 0.00008
[epoch 165: 160/307] 	 train loss: 0.180052 	 lr: 0.00008
[epoch 165: 180/307] 	 train loss: 0.230278 	 lr: 0.00008
[epoch 165: 200/307] 	 train loss: 0.171937 	 lr: 0.00008
[epoch 165: 220/307] 	 train loss: 0.087901 	 lr: 0.00008
[epoch 165: 240/307] 	 train loss: 0.118509 	 lr: 0.00008
[epoch 165: 260/307] 	 train loss: 0.104782 	 lr: 0.00008
[epoch 165: 280/307] 	 train loss: 0.201414 	 lr: 0.00008

val loss: 0.335782 	 acc: 0.912885

[epoch 165: 300/307] 	 train loss: 0.020018 	 lr: 0.00008
[epoch 166:   0/307] 	 train loss: 0.175770 	 lr: 0.00008
[epoch 166:  20/307] 	 train loss: 0.054482 	 lr: 0.00008
[epoch 166:  40/307] 	 train loss: 0.365387 	 lr: 0.00008
[epoch 166:  60/307] 	 train loss: 0.106469 	 lr: 0.00008
[epoch 166:  80/307] 	 train loss: 0.173744 	 lr: 0.00008
[epoch 166: 100/307] 	 train loss: 0.079110 	 lr: 0.00008
[epoch 166: 120/307] 	 train loss: 0.406385 	 lr: 0.00008

val loss: 0.336208 	 acc: 0.915721

[epoch 166: 140/307] 	 train loss: 0.045808 	 lr: 0.00008
[epoch 166: 160/307] 	 train loss: 0.201124 	 lr: 0.00008
[epoch 166: 180/307] 	 train loss: 0.173385 	 lr: 0.00008
[epoch 166: 200/307] 	 train loss: 0.102709 	 lr: 0.00008
[epoch 166: 220/307] 	 train loss: 0.148690 	 lr: 0.00008
[epoch 166: 240/307] 	 train loss: 0.376314 	 lr: 0.00008
[epoch 166: 260/307] 	 train loss: 0.020841 	 lr: 0.00008
[epoch 166: 280/307] 	 train loss: 0.100519 	 lr: 0.00008

val loss: 0.340099 	 acc: 0.913695

[epoch 166: 300/307] 	 train loss: 0.142130 	 lr: 0.00008
[epoch 167:   0/307] 	 train loss: 0.154268 	 lr: 0.00008
[epoch 167:  20/307] 	 train loss: 0.120823 	 lr: 0.00008
[epoch 167:  40/307] 	 train loss: 0.136245 	 lr: 0.00008
[epoch 167:  60/307] 	 train loss: 0.078990 	 lr: 0.00008
[epoch 167:  80/307] 	 train loss: 0.074978 	 lr: 0.00008
[epoch 167: 100/307] 	 train loss: 0.040787 	 lr: 0.00008
[epoch 167: 120/307] 	 train loss: 0.070689 	 lr: 0.00008

val loss: 0.345752 	 acc: 0.909643

[epoch 167: 140/307] 	 train loss: 0.091954 	 lr: 0.00008
[epoch 167: 160/307] 	 train loss: 0.065000 	 lr: 0.00008
[epoch 167: 180/307] 	 train loss: 0.310261 	 lr: 0.00008
[epoch 167: 200/307] 	 train loss: 0.073522 	 lr: 0.00008
[epoch 167: 220/307] 	 train loss: 0.027700 	 lr: 0.00008
[epoch 167: 240/307] 	 train loss: 0.045314 	 lr: 0.00008
[epoch 167: 260/307] 	 train loss: 0.064957 	 lr: 0.00008

val loss: 0.355881 	 acc: 0.907618

[epoch 167: 280/307] 	 train loss: 0.265332 	 lr: 0.00008
[epoch 167: 300/307] 	 train loss: 0.082060 	 lr: 0.00008
[epoch 168:   0/307] 	 train loss: 0.039797 	 lr: 0.00008
[epoch 168:  20/307] 	 train loss: 0.075526 	 lr: 0.00008
[epoch 168:  40/307] 	 train loss: 0.094274 	 lr: 0.00008
[epoch 168:  60/307] 	 train loss: 0.158594 	 lr: 0.00008
[epoch 168:  80/307] 	 train loss: 0.173787 	 lr: 0.00008
[epoch 168: 100/307] 	 train loss: 0.073796 	 lr: 0.00008
[epoch 168: 120/307] 	 train loss: 0.010560 	 lr: 0.00008

val loss: 0.345110 	 acc: 0.909238

[epoch 168: 140/307] 	 train loss: 0.219476 	 lr: 0.00008
[epoch 168: 160/307] 	 train loss: 0.102442 	 lr: 0.00008
[epoch 168: 180/307] 	 train loss: 0.070274 	 lr: 0.00008
[epoch 168: 200/307] 	 train loss: 0.028854 	 lr: 0.00008
[epoch 168: 220/307] 	 train loss: 0.125048 	 lr: 0.00008
[epoch 168: 240/307] 	 train loss: 0.215280 	 lr: 0.00008
[epoch 168: 260/307] 	 train loss: 0.052679 	 lr: 0.00008

val loss: 0.345713 	 acc: 0.909238

[epoch 168: 280/307] 	 train loss: 0.075544 	 lr: 0.00008
[epoch 168: 300/307] 	 train loss: 0.139825 	 lr: 0.00008
[epoch 169:   0/307] 	 train loss: 0.082870 	 lr: 0.00006
[epoch 169:  20/307] 	 train loss: 0.073527 	 lr: 0.00006
[epoch 169:  40/307] 	 train loss: 0.052512 	 lr: 0.00006
[epoch 169:  60/307] 	 train loss: 0.218260 	 lr: 0.00006
[epoch 169:  80/307] 	 train loss: 0.306239 	 lr: 0.00006
[epoch 169: 100/307] 	 train loss: 0.058948 	 lr: 0.00006
[epoch 169: 120/307] 	 train loss: 0.226605 	 lr: 0.00006

val loss: 0.343254 	 acc: 0.910454

[epoch 169: 140/307] 	 train loss: 0.013895 	 lr: 0.00006
[epoch 169: 160/307] 	 train loss: 0.089236 	 lr: 0.00006
[epoch 169: 180/307] 	 train loss: 0.365016 	 lr: 0.00006
[epoch 169: 200/307] 	 train loss: 0.056718 	 lr: 0.00006
[epoch 169: 220/307] 	 train loss: 0.077512 	 lr: 0.00006
[epoch 169: 240/307] 	 train loss: 0.203563 	 lr: 0.00006
[epoch 169: 260/307] 	 train loss: 0.200434 	 lr: 0.00006

val loss: 0.342480 	 acc: 0.911264

[epoch 169: 280/307] 	 train loss: 0.308272 	 lr: 0.00006
[epoch 169: 300/307] 	 train loss: 0.201405 	 lr: 0.00006
[epoch 170:   0/307] 	 train loss: 0.265223 	 lr: 0.00006
[epoch 170:  20/307] 	 train loss: 0.315332 	 lr: 0.00006
[epoch 170:  40/307] 	 train loss: 0.063077 	 lr: 0.00006
[epoch 170:  60/307] 	 train loss: 0.020877 	 lr: 0.00006
[epoch 170:  80/307] 	 train loss: 0.142031 	 lr: 0.00006
[epoch 170: 100/307] 	 train loss: 0.251871 	 lr: 0.00006
[epoch 170: 120/307] 	 train loss: 0.099580 	 lr: 0.00006

val loss: 0.342596 	 acc: 0.911669

[epoch 170: 140/307] 	 train loss: 0.205680 	 lr: 0.00006
[epoch 170: 160/307] 	 train loss: 0.136522 	 lr: 0.00006
[epoch 170: 180/307] 	 train loss: 0.062347 	 lr: 0.00006
[epoch 170: 200/307] 	 train loss: 0.157428 	 lr: 0.00006
[epoch 170: 220/307] 	 train loss: 0.150443 	 lr: 0.00006
[epoch 170: 240/307] 	 train loss: 0.063217 	 lr: 0.00006
[epoch 170: 260/307] 	 train loss: 0.115146 	 lr: 0.00006

val loss: 0.343340 	 acc: 0.910049

[epoch 170: 280/307] 	 train loss: 0.136432 	 lr: 0.00006
[epoch 170: 300/307] 	 train loss: 0.141437 	 lr: 0.00006
[epoch 171:   0/307] 	 train loss: 0.123240 	 lr: 0.00006
[epoch 171:  20/307] 	 train loss: 0.029873 	 lr: 0.00006
[epoch 171:  40/307] 	 train loss: 0.295515 	 lr: 0.00006
[epoch 171:  60/307] 	 train loss: 0.096505 	 lr: 0.00006
[epoch 171:  80/307] 	 train loss: 0.269903 	 lr: 0.00006
[epoch 171: 100/307] 	 train loss: 0.395442 	 lr: 0.00006

val loss: 0.342070 	 acc: 0.910859

[epoch 171: 120/307] 	 train loss: 0.140624 	 lr: 0.00006
[epoch 171: 140/307] 	 train loss: 0.141962 	 lr: 0.00006
[epoch 171: 160/307] 	 train loss: 0.093470 	 lr: 0.00006
[epoch 171: 180/307] 	 train loss: 0.147951 	 lr: 0.00006
[epoch 171: 200/307] 	 train loss: 0.182289 	 lr: 0.00006
[epoch 171: 220/307] 	 train loss: 0.105488 	 lr: 0.00006
[epoch 171: 240/307] 	 train loss: 0.107790 	 lr: 0.00006
[epoch 171: 260/307] 	 train loss: 0.173250 	 lr: 0.00006

val loss: 0.347684 	 acc: 0.912480

[epoch 171: 280/307] 	 train loss: 0.085488 	 lr: 0.00006
[epoch 171: 300/307] 	 train loss: 0.116243 	 lr: 0.00006
[epoch 172:   0/307] 	 train loss: 0.069870 	 lr: 0.00006
[epoch 172:  20/307] 	 train loss: 0.119096 	 lr: 0.00006
[epoch 172:  40/307] 	 train loss: 0.140401 	 lr: 0.00006
[epoch 172:  60/307] 	 train loss: 0.223752 	 lr: 0.00006
[epoch 172:  80/307] 	 train loss: 0.116427 	 lr: 0.00006
[epoch 172: 100/307] 	 train loss: 0.075481 	 lr: 0.00006

val loss: 0.346485 	 acc: 0.912075

[epoch 172: 120/307] 	 train loss: 0.243759 	 lr: 0.00006
[epoch 172: 140/307] 	 train loss: 0.150725 	 lr: 0.00006
[epoch 172: 160/307] 	 train loss: 0.279977 	 lr: 0.00006
[epoch 172: 180/307] 	 train loss: 0.045541 	 lr: 0.00006
[epoch 172: 200/307] 	 train loss: 0.075565 	 lr: 0.00006
[epoch 172: 220/307] 	 train loss: 0.066043 	 lr: 0.00006
[epoch 172: 240/307] 	 train loss: 0.048485 	 lr: 0.00006
[epoch 172: 260/307] 	 train loss: 0.085662 	 lr: 0.00006

val loss: 0.342637 	 acc: 0.912885

[epoch 172: 280/307] 	 train loss: 0.010324 	 lr: 0.00006
[epoch 172: 300/307] 	 train loss: 0.084815 	 lr: 0.00006
[epoch 173:   0/307] 	 train loss: 0.235143 	 lr: 0.00006
[epoch 173:  20/307] 	 train loss: 0.065254 	 lr: 0.00006
[epoch 173:  40/307] 	 train loss: 0.139477 	 lr: 0.00006
[epoch 173:  60/307] 	 train loss: 0.278540 	 lr: 0.00006
[epoch 173:  80/307] 	 train loss: 0.112782 	 lr: 0.00006
[epoch 173: 100/307] 	 train loss: 0.065064 	 lr: 0.00006

val loss: 0.345692 	 acc: 0.912885

[epoch 173: 120/307] 	 train loss: 0.190259 	 lr: 0.00006
[epoch 173: 140/307] 	 train loss: 0.073411 	 lr: 0.00006
[epoch 173: 160/307] 	 train loss: 0.347385 	 lr: 0.00006
[epoch 173: 180/307] 	 train loss: 0.035001 	 lr: 0.00006
[epoch 173: 200/307] 	 train loss: 0.320573 	 lr: 0.00006
[epoch 173: 220/307] 	 train loss: 0.163981 	 lr: 0.00006
[epoch 173: 240/307] 	 train loss: 0.060180 	 lr: 0.00006
[epoch 173: 260/307] 	 train loss: 0.110372 	 lr: 0.00006

val loss: 0.341334 	 acc: 0.913695

[epoch 173: 280/307] 	 train loss: 0.118983 	 lr: 0.00006
[epoch 173: 300/307] 	 train loss: 0.076174 	 lr: 0.00006
[epoch 174:   0/307] 	 train loss: 0.129926 	 lr: 0.00006
[epoch 174:  20/307] 	 train loss: 0.204680 	 lr: 0.00006
[epoch 174:  40/307] 	 train loss: 0.170386 	 lr: 0.00006
[epoch 174:  60/307] 	 train loss: 0.102513 	 lr: 0.00006
[epoch 174:  80/307] 	 train loss: 0.095659 	 lr: 0.00006
[epoch 174: 100/307] 	 train loss: 0.107192 	 lr: 0.00006

val loss: 0.337554 	 acc: 0.911264

[epoch 174: 120/307] 	 train loss: 0.110458 	 lr: 0.00006
[epoch 174: 140/307] 	 train loss: 0.176586 	 lr: 0.00006
[epoch 174: 160/307] 	 train loss: 0.060294 	 lr: 0.00006
[epoch 174: 180/307] 	 train loss: 0.014206 	 lr: 0.00006
[epoch 174: 200/307] 	 train loss: 0.016634 	 lr: 0.00006
[epoch 174: 220/307] 	 train loss: 0.092130 	 lr: 0.00006
[epoch 174: 240/307] 	 train loss: 0.009712 	 lr: 0.00006
[epoch 174: 260/307] 	 train loss: 0.219170 	 lr: 0.00006

val loss: 0.344373 	 acc: 0.911264

[epoch 174: 280/307] 	 train loss: 0.015126 	 lr: 0.00006
[epoch 174: 300/307] 	 train loss: 0.372521 	 lr: 0.00006
[epoch 175:   0/307] 	 train loss: 0.060969 	 lr: 0.00006
[epoch 175:  20/307] 	 train loss: 0.098688 	 lr: 0.00006
[epoch 175:  40/307] 	 train loss: 0.093273 	 lr: 0.00006
[epoch 175:  60/307] 	 train loss: 0.195260 	 lr: 0.00006
[epoch 175:  80/307] 	 train loss: 0.084796 	 lr: 0.00006
[epoch 175: 100/307] 	 train loss: 0.150163 	 lr: 0.00006

val loss: 0.342520 	 acc: 0.910454

[epoch 175: 120/307] 	 train loss: 0.277274 	 lr: 0.00006
[epoch 175: 140/307] 	 train loss: 0.211635 	 lr: 0.00006
[epoch 175: 160/307] 	 train loss: 0.328825 	 lr: 0.00006
[epoch 175: 180/307] 	 train loss: 0.112387 	 lr: 0.00006
[epoch 175: 200/307] 	 train loss: 0.006309 	 lr: 0.00006
[epoch 175: 220/307] 	 train loss: 0.193236 	 lr: 0.00006
[epoch 175: 240/307] 	 train loss: 0.061510 	 lr: 0.00006
[epoch 175: 260/307] 	 train loss: 0.220686 	 lr: 0.00006

val loss: 0.341785 	 acc: 0.912480

[epoch 175: 280/307] 	 train loss: 0.254274 	 lr: 0.00006
[epoch 175: 300/307] 	 train loss: 0.036241 	 lr: 0.00006
[epoch 176:   0/307] 	 train loss: 0.024363 	 lr: 0.00006
[epoch 176:  20/307] 	 train loss: 0.055893 	 lr: 0.00006
[epoch 176:  40/307] 	 train loss: 0.252893 	 lr: 0.00006
[epoch 176:  60/307] 	 train loss: 0.118245 	 lr: 0.00006
[epoch 176:  80/307] 	 train loss: 0.049207 	 lr: 0.00006
[epoch 176: 100/307] 	 train loss: 0.042102 	 lr: 0.00006

val loss: 0.337160 	 acc: 0.911669

[epoch 176: 120/307] 	 train loss: 0.122360 	 lr: 0.00006
[epoch 176: 140/307] 	 train loss: 0.221802 	 lr: 0.00006
[epoch 176: 160/307] 	 train loss: 0.092664 	 lr: 0.00006
[epoch 176: 180/307] 	 train loss: 0.062712 	 lr: 0.00006
[epoch 176: 200/307] 	 train loss: 0.034829 	 lr: 0.00006
[epoch 176: 220/307] 	 train loss: 0.019508 	 lr: 0.00006
[epoch 176: 240/307] 	 train loss: 0.083767 	 lr: 0.00006
[epoch 176: 260/307] 	 train loss: 0.053536 	 lr: 0.00006

val loss: 0.337358 	 acc: 0.911669

[epoch 176: 280/307] 	 train loss: 0.253586 	 lr: 0.00006
[epoch 176: 300/307] 	 train loss: 0.160050 	 lr: 0.00006
[epoch 177:   0/307] 	 train loss: 0.022914 	 lr: 0.00006
[epoch 177:  20/307] 	 train loss: 0.195265 	 lr: 0.00006
[epoch 177:  40/307] 	 train loss: 0.075316 	 lr: 0.00006
[epoch 177:  60/307] 	 train loss: 0.124698 	 lr: 0.00006
[epoch 177:  80/307] 	 train loss: 0.065725 	 lr: 0.00006
[epoch 177: 100/307] 	 train loss: 0.238512 	 lr: 0.00006

val loss: 0.340070 	 acc: 0.909643

[epoch 177: 120/307] 	 train loss: 0.140607 	 lr: 0.00006
[epoch 177: 140/307] 	 train loss: 0.038553 	 lr: 0.00006
[epoch 177: 160/307] 	 train loss: 0.101417 	 lr: 0.00006
[epoch 177: 180/307] 	 train loss: 0.368096 	 lr: 0.00006
[epoch 177: 200/307] 	 train loss: 0.050140 	 lr: 0.00006
[epoch 177: 220/307] 	 train loss: 0.169663 	 lr: 0.00006
[epoch 177: 240/307] 	 train loss: 0.032150 	 lr: 0.00006

val loss: 0.341656 	 acc: 0.910049

[epoch 177: 260/307] 	 train loss: 0.256974 	 lr: 0.00006
[epoch 177: 280/307] 	 train loss: 0.072880 	 lr: 0.00006
[epoch 177: 300/307] 	 train loss: 0.103707 	 lr: 0.00006
[epoch 178:   0/307] 	 train loss: 0.027009 	 lr: 0.00006
[epoch 178:  20/307] 	 train loss: 0.075847 	 lr: 0.00006
[epoch 178:  40/307] 	 train loss: 0.139764 	 lr: 0.00006
[epoch 178:  60/307] 	 train loss: 0.078498 	 lr: 0.00006
[epoch 178:  80/307] 	 train loss: 0.123143 	 lr: 0.00006
[epoch 178: 100/307] 	 train loss: 0.083100 	 lr: 0.00006

val loss: 0.340187 	 acc: 0.911669

[epoch 178: 120/307] 	 train loss: 0.075101 	 lr: 0.00006
[epoch 178: 140/307] 	 train loss: 0.045404 	 lr: 0.00006
[epoch 178: 160/307] 	 train loss: 0.027697 	 lr: 0.00006
[epoch 178: 180/307] 	 train loss: 0.042567 	 lr: 0.00006
[epoch 178: 200/307] 	 train loss: 0.066290 	 lr: 0.00006
[epoch 178: 220/307] 	 train loss: 0.089186 	 lr: 0.00006
[epoch 178: 240/307] 	 train loss: 0.079475 	 lr: 0.00006

val loss: 0.339702 	 acc: 0.913290

[epoch 178: 260/307] 	 train loss: 0.078388 	 lr: 0.00006
[epoch 178: 280/307] 	 train loss: 0.059679 	 lr: 0.00006
[epoch 178: 300/307] 	 train loss: 0.032705 	 lr: 0.00006
[epoch 179:   0/307] 	 train loss: 0.023312 	 lr: 0.00006
[epoch 179:  20/307] 	 train loss: 0.159634 	 lr: 0.00006
[epoch 179:  40/307] 	 train loss: 0.192424 	 lr: 0.00006
[epoch 179:  60/307] 	 train loss: 0.190714 	 lr: 0.00006
[epoch 179:  80/307] 	 train loss: 0.007417 	 lr: 0.00006
[epoch 179: 100/307] 	 train loss: 0.293821 	 lr: 0.00006

val loss: 0.344171 	 acc: 0.912480

[epoch 179: 120/307] 	 train loss: 0.289971 	 lr: 0.00006
[epoch 179: 140/307] 	 train loss: 0.202511 	 lr: 0.00006
[epoch 179: 160/307] 	 train loss: 0.153070 	 lr: 0.00006
[epoch 179: 180/307] 	 train loss: 0.112536 	 lr: 0.00006
[epoch 179: 200/307] 	 train loss: 0.137532 	 lr: 0.00006
[epoch 179: 220/307] 	 train loss: 0.125882 	 lr: 0.00006
[epoch 179: 240/307] 	 train loss: 0.058761 	 lr: 0.00006

val loss: 0.341534 	 acc: 0.911669

[epoch 179: 260/307] 	 train loss: 0.148967 	 lr: 0.00006
[epoch 179: 280/307] 	 train loss: 0.232571 	 lr: 0.00006
[epoch 179: 300/307] 	 train loss: 0.059260 	 lr: 0.00006
[epoch 180:   0/307] 	 train loss: 0.136766 	 lr: 0.00006
[epoch 180:  20/307] 	 train loss: 0.025063 	 lr: 0.00006
[epoch 180:  40/307] 	 train loss: 0.147357 	 lr: 0.00006
[epoch 180:  60/307] 	 train loss: 0.073746 	 lr: 0.00006
[epoch 180:  80/307] 	 train loss: 0.153343 	 lr: 0.00006
[epoch 180: 100/307] 	 train loss: 0.128100 	 lr: 0.00006

val loss: 0.340347 	 acc: 0.912480

[epoch 180: 120/307] 	 train loss: 0.052302 	 lr: 0.00006
[epoch 180: 140/307] 	 train loss: 0.308652 	 lr: 0.00006
[epoch 180: 160/307] 	 train loss: 0.132967 	 lr: 0.00006
[epoch 180: 180/307] 	 train loss: 0.150512 	 lr: 0.00006
[epoch 180: 200/307] 	 train loss: 0.034651 	 lr: 0.00006
[epoch 180: 220/307] 	 train loss: 0.225356 	 lr: 0.00006
[epoch 180: 240/307] 	 train loss: 0.095886 	 lr: 0.00006

val loss: 0.345650 	 acc: 0.912480

[epoch 180: 260/307] 	 train loss: 0.073222 	 lr: 0.00006
[epoch 180: 280/307] 	 train loss: 0.203833 	 lr: 0.00006
[epoch 180: 300/307] 	 train loss: 0.271239 	 lr: 0.00006
[epoch 181:   0/307] 	 train loss: 0.053136 	 lr: 0.00006
[epoch 181:  20/307] 	 train loss: 0.086694 	 lr: 0.00006
[epoch 181:  40/307] 	 train loss: 0.205289 	 lr: 0.00006
[epoch 181:  60/307] 	 train loss: 0.135080 	 lr: 0.00006
[epoch 181:  80/307] 	 train loss: 0.148942 	 lr: 0.00006

val loss: 0.346810 	 acc: 0.910859

[epoch 181: 100/307] 	 train loss: 0.047710 	 lr: 0.00006
[epoch 181: 120/307] 	 train loss: 0.063301 	 lr: 0.00006
[epoch 181: 140/307] 	 train loss: 0.087948 	 lr: 0.00006
[epoch 181: 160/307] 	 train loss: 0.288432 	 lr: 0.00006
[epoch 181: 180/307] 	 train loss: 0.053437 	 lr: 0.00006
[epoch 181: 200/307] 	 train loss: 0.039218 	 lr: 0.00006
[epoch 181: 220/307] 	 train loss: 0.333463 	 lr: 0.00006
[epoch 181: 240/307] 	 train loss: 0.046607 	 lr: 0.00006

val loss: 0.346112 	 acc: 0.910049

[epoch 181: 260/307] 	 train loss: 0.118753 	 lr: 0.00006
[epoch 181: 280/307] 	 train loss: 0.241506 	 lr: 0.00006
[epoch 181: 300/307] 	 train loss: 0.209099 	 lr: 0.00006
[epoch 182:   0/307] 	 train loss: 0.079731 	 lr: 0.00006
[epoch 182:  20/307] 	 train loss: 0.147263 	 lr: 0.00006
[epoch 182:  40/307] 	 train loss: 0.178390 	 lr: 0.00006
[epoch 182:  60/307] 	 train loss: 0.217334 	 lr: 0.00006
[epoch 182:  80/307] 	 train loss: 0.024919 	 lr: 0.00006

val loss: 0.338152 	 acc: 0.909643

[epoch 182: 100/307] 	 train loss: 0.040949 	 lr: 0.00006
[epoch 182: 120/307] 	 train loss: 0.150736 	 lr: 0.00006
[epoch 182: 140/307] 	 train loss: 0.079761 	 lr: 0.00006
[epoch 182: 160/307] 	 train loss: 0.122856 	 lr: 0.00006
[epoch 182: 180/307] 	 train loss: 0.098972 	 lr: 0.00006
[epoch 182: 200/307] 	 train loss: 0.065137 	 lr: 0.00006
[epoch 182: 220/307] 	 train loss: 0.085909 	 lr: 0.00006
[epoch 182: 240/307] 	 train loss: 0.167835 	 lr: 0.00006

val loss: 0.343616 	 acc: 0.912480

[epoch 182: 260/307] 	 train loss: 0.044662 	 lr: 0.00006
[epoch 182: 280/307] 	 train loss: 0.129981 	 lr: 0.00006
[epoch 182: 300/307] 	 train loss: 0.038842 	 lr: 0.00006
[epoch 183:   0/307] 	 train loss: 0.076281 	 lr: 0.00006
[epoch 183:  20/307] 	 train loss: 0.047512 	 lr: 0.00006
[epoch 183:  40/307] 	 train loss: 0.098031 	 lr: 0.00006
[epoch 183:  60/307] 	 train loss: 0.138769 	 lr: 0.00006
[epoch 183:  80/307] 	 train loss: 0.096147 	 lr: 0.00006

val loss: 0.341224 	 acc: 0.910454

[epoch 183: 100/307] 	 train loss: 0.339790 	 lr: 0.00006
[epoch 183: 120/307] 	 train loss: 0.265684 	 lr: 0.00006
[epoch 183: 140/307] 	 train loss: 0.264822 	 lr: 0.00006
[epoch 183: 160/307] 	 train loss: 0.177551 	 lr: 0.00006
[epoch 183: 180/307] 	 train loss: 0.031537 	 lr: 0.00006
[epoch 183: 200/307] 	 train loss: 0.220425 	 lr: 0.00006
[epoch 183: 220/307] 	 train loss: 0.061891 	 lr: 0.00006
[epoch 183: 240/307] 	 train loss: 0.100640 	 lr: 0.00006

val loss: 0.339427 	 acc: 0.908833

[epoch 183: 260/307] 	 train loss: 0.122561 	 lr: 0.00006
[epoch 183: 280/307] 	 train loss: 0.176655 	 lr: 0.00006
[epoch 183: 300/307] 	 train loss: 0.225267 	 lr: 0.00006
[epoch 184:   0/307] 	 train loss: 0.086137 	 lr: 0.00006
[epoch 184:  20/307] 	 train loss: 0.087409 	 lr: 0.00006
[epoch 184:  40/307] 	 train loss: 0.225641 	 lr: 0.00006
[epoch 184:  60/307] 	 train loss: 0.285983 	 lr: 0.00006
[epoch 184:  80/307] 	 train loss: 0.302694 	 lr: 0.00006

val loss: 0.339386 	 acc: 0.910454

[epoch 184: 100/307] 	 train loss: 0.109297 	 lr: 0.00006
[epoch 184: 120/307] 	 train loss: 0.189005 	 lr: 0.00006
[epoch 184: 140/307] 	 train loss: 0.177727 	 lr: 0.00006
[epoch 184: 160/307] 	 train loss: 0.030512 	 lr: 0.00006
[epoch 184: 180/307] 	 train loss: 0.066420 	 lr: 0.00006
[epoch 184: 200/307] 	 train loss: 0.023247 	 lr: 0.00006
[epoch 184: 220/307] 	 train loss: 0.027381 	 lr: 0.00006
[epoch 184: 240/307] 	 train loss: 0.415539 	 lr: 0.00006

val loss: 0.342601 	 acc: 0.910454

[epoch 184: 260/307] 	 train loss: 0.120396 	 lr: 0.00006
[epoch 184: 280/307] 	 train loss: 0.152003 	 lr: 0.00006
[epoch 184: 300/307] 	 train loss: 0.156064 	 lr: 0.00006
[epoch 185:   0/307] 	 train loss: 0.248550 	 lr: 0.00006
[epoch 185:  20/307] 	 train loss: 0.059535 	 lr: 0.00006
[epoch 185:  40/307] 	 train loss: 0.369883 	 lr: 0.00006
[epoch 185:  60/307] 	 train loss: 0.012284 	 lr: 0.00006
[epoch 185:  80/307] 	 train loss: 0.108063 	 lr: 0.00006

val loss: 0.348552 	 acc: 0.907212

[epoch 185: 100/307] 	 train loss: 0.135689 	 lr: 0.00006
[epoch 185: 120/307] 	 train loss: 0.049045 	 lr: 0.00006
[epoch 185: 140/307] 	 train loss: 0.023416 	 lr: 0.00006
[epoch 185: 160/307] 	 train loss: 0.039603 	 lr: 0.00006
[epoch 185: 180/307] 	 train loss: 0.034640 	 lr: 0.00006
[epoch 185: 200/307] 	 train loss: 0.285550 	 lr: 0.00006
[epoch 185: 220/307] 	 train loss: 0.137023 	 lr: 0.00006
[epoch 185: 240/307] 	 train loss: 0.444784 	 lr: 0.00006

val loss: 0.338990 	 acc: 0.908833

[epoch 185: 260/307] 	 train loss: 0.115299 	 lr: 0.00006
[epoch 185: 280/307] 	 train loss: 0.079039 	 lr: 0.00006
[epoch 185: 300/307] 	 train loss: 0.018450 	 lr: 0.00006
[epoch 186:   0/307] 	 train loss: 0.536035 	 lr: 0.00006
[epoch 186:  20/307] 	 train loss: 0.062856 	 lr: 0.00006
[epoch 186:  40/307] 	 train loss: 0.002108 	 lr: 0.00006
[epoch 186:  60/307] 	 train loss: 0.050554 	 lr: 0.00006
[epoch 186:  80/307] 	 train loss: 0.078554 	 lr: 0.00006

val loss: 0.349610 	 acc: 0.908833

[epoch 186: 100/307] 	 train loss: 0.174440 	 lr: 0.00006
[epoch 186: 120/307] 	 train loss: 0.201396 	 lr: 0.00006
[epoch 186: 140/307] 	 train loss: 0.073497 	 lr: 0.00006
[epoch 186: 160/307] 	 train loss: 0.051813 	 lr: 0.00006
[epoch 186: 180/307] 	 train loss: 0.257770 	 lr: 0.00006
[epoch 186: 200/307] 	 train loss: 0.101939 	 lr: 0.00006
[epoch 186: 220/307] 	 train loss: 0.064433 	 lr: 0.00006
[epoch 186: 240/307] 	 train loss: 0.129997 	 lr: 0.00006

val loss: 0.343656 	 acc: 0.912480

[epoch 186: 260/307] 	 train loss: 0.006111 	 lr: 0.00006
[epoch 186: 280/307] 	 train loss: 0.033968 	 lr: 0.00006
[epoch 186: 300/307] 	 train loss: 0.017183 	 lr: 0.00006
[epoch 187:   0/307] 	 train loss: 0.046848 	 lr: 0.00006
[epoch 187:  20/307] 	 train loss: 0.056683 	 lr: 0.00006
[epoch 187:  40/307] 	 train loss: 0.054207 	 lr: 0.00006
[epoch 187:  60/307] 	 train loss: 0.041719 	 lr: 0.00006
[epoch 187:  80/307] 	 train loss: 0.213051 	 lr: 0.00006

val loss: 0.347710 	 acc: 0.910454

[epoch 187: 100/307] 	 train loss: 0.082028 	 lr: 0.00006
[epoch 187: 120/307] 	 train loss: 0.087485 	 lr: 0.00006
[epoch 187: 140/307] 	 train loss: 0.015039 	 lr: 0.00006
[epoch 187: 160/307] 	 train loss: 0.064819 	 lr: 0.00006
[epoch 187: 180/307] 	 train loss: 0.293988 	 lr: 0.00006
[epoch 187: 200/307] 	 train loss: 0.272636 	 lr: 0.00006
[epoch 187: 220/307] 	 train loss: 0.021499 	 lr: 0.00006

val loss: 0.348181 	 acc: 0.909643

[epoch 187: 240/307] 	 train loss: 0.052609 	 lr: 0.00006
[epoch 187: 260/307] 	 train loss: 0.116281 	 lr: 0.00006
[epoch 187: 280/307] 	 train loss: 0.033373 	 lr: 0.00006
[epoch 187: 300/307] 	 train loss: 0.086344 	 lr: 0.00006
[epoch 188:   0/307] 	 train loss: 0.072572 	 lr: 0.00006
[epoch 188:  20/307] 	 train loss: 0.148725 	 lr: 0.00006
[epoch 188:  40/307] 	 train loss: 0.070026 	 lr: 0.00006
[epoch 188:  60/307] 	 train loss: 0.162148 	 lr: 0.00006
[epoch 188:  80/307] 	 train loss: 0.079895 	 lr: 0.00006

val loss: 0.351203 	 acc: 0.910859

[epoch 188: 100/307] 	 train loss: 0.149330 	 lr: 0.00006
[epoch 188: 120/307] 	 train loss: 0.126818 	 lr: 0.00006
[epoch 188: 140/307] 	 train loss: 0.161172 	 lr: 0.00006
[epoch 188: 160/307] 	 train loss: 0.130542 	 lr: 0.00006
[epoch 188: 180/307] 	 train loss: 0.202214 	 lr: 0.00006
[epoch 188: 200/307] 	 train loss: 0.084145 	 lr: 0.00006
[epoch 188: 220/307] 	 train loss: 0.062553 	 lr: 0.00006

val loss: 0.346366 	 acc: 0.910049

[epoch 188: 240/307] 	 train loss: 0.018427 	 lr: 0.00006
[epoch 188: 260/307] 	 train loss: 0.171071 	 lr: 0.00006
[epoch 188: 280/307] 	 train loss: 0.028318 	 lr: 0.00006
[epoch 188: 300/307] 	 train loss: 0.360587 	 lr: 0.00006
[epoch 189:   0/307] 	 train loss: 0.065029 	 lr: 0.00006
[epoch 189:  20/307] 	 train loss: 0.162109 	 lr: 0.00006
[epoch 189:  40/307] 	 train loss: 0.118050 	 lr: 0.00006
[epoch 189:  60/307] 	 train loss: 0.125490 	 lr: 0.00006
[epoch 189:  80/307] 	 train loss: 0.106957 	 lr: 0.00006

val loss: 0.346878 	 acc: 0.907212

[epoch 189: 100/307] 	 train loss: 0.134491 	 lr: 0.00006
[epoch 189: 120/307] 	 train loss: 0.125622 	 lr: 0.00006
[epoch 189: 140/307] 	 train loss: 0.122861 	 lr: 0.00006
[epoch 189: 160/307] 	 train loss: 0.108339 	 lr: 0.00006
[epoch 189: 180/307] 	 train loss: 0.073619 	 lr: 0.00006
[epoch 189: 200/307] 	 train loss: 0.185525 	 lr: 0.00006
[epoch 189: 220/307] 	 train loss: 0.048791 	 lr: 0.00006

val loss: 0.338762 	 acc: 0.912075

[epoch 189: 240/307] 	 train loss: 0.130011 	 lr: 0.00006
[epoch 189: 260/307] 	 train loss: 0.170718 	 lr: 0.00006
[epoch 189: 280/307] 	 train loss: 0.113637 	 lr: 0.00006
[epoch 189: 300/307] 	 train loss: 0.125126 	 lr: 0.00006
[epoch 190:   0/307] 	 train loss: 0.135323 	 lr: 0.00004
[epoch 190:  20/307] 	 train loss: 0.179287 	 lr: 0.00004
[epoch 190:  40/307] 	 train loss: 0.070693 	 lr: 0.00004
[epoch 190:  60/307] 	 train loss: 0.248537 	 lr: 0.00004
[epoch 190:  80/307] 	 train loss: 0.019819 	 lr: 0.00004

val loss: 0.347886 	 acc: 0.910049

[epoch 190: 100/307] 	 train loss: 0.150385 	 lr: 0.00004
[epoch 190: 120/307] 	 train loss: 0.044169 	 lr: 0.00004
[epoch 190: 140/307] 	 train loss: 0.102401 	 lr: 0.00004
[epoch 190: 160/307] 	 train loss: 0.036255 	 lr: 0.00004
[epoch 190: 180/307] 	 train loss: 0.099653 	 lr: 0.00004
[epoch 190: 200/307] 	 train loss: 0.026874 	 lr: 0.00004
[epoch 190: 220/307] 	 train loss: 0.250506 	 lr: 0.00004

val loss: 0.347283 	 acc: 0.910859

[epoch 190: 240/307] 	 train loss: 0.298620 	 lr: 0.00004
[epoch 190: 260/307] 	 train loss: 0.258922 	 lr: 0.00004
[epoch 190: 280/307] 	 train loss: 0.140443 	 lr: 0.00004
[epoch 190: 300/307] 	 train loss: 0.125680 	 lr: 0.00004
[epoch 191:   0/307] 	 train loss: 0.253268 	 lr: 0.00004
[epoch 191:  20/307] 	 train loss: 0.158898 	 lr: 0.00004
[epoch 191:  40/307] 	 train loss: 0.140843 	 lr: 0.00004
[epoch 191:  60/307] 	 train loss: 0.175443 	 lr: 0.00004

val loss: 0.347155 	 acc: 0.910049

[epoch 191:  80/307] 	 train loss: 0.035904 	 lr: 0.00004
[epoch 191: 100/307] 	 train loss: 0.022868 	 lr: 0.00004
[epoch 191: 120/307] 	 train loss: 0.101357 	 lr: 0.00004
[epoch 191: 140/307] 	 train loss: 0.029046 	 lr: 0.00004
[epoch 191: 160/307] 	 train loss: 0.065591 	 lr: 0.00004
[epoch 191: 180/307] 	 train loss: 0.186792 	 lr: 0.00004
[epoch 191: 200/307] 	 train loss: 0.037004 	 lr: 0.00004
[epoch 191: 220/307] 	 train loss: 0.185436 	 lr: 0.00004

val loss: 0.341135 	 acc: 0.912885

[epoch 191: 240/307] 	 train loss: 0.087533 	 lr: 0.00004
[epoch 191: 260/307] 	 train loss: 0.234117 	 lr: 0.00004
[epoch 191: 280/307] 	 train loss: 0.075832 	 lr: 0.00004
[epoch 191: 300/307] 	 train loss: 0.109996 	 lr: 0.00004
[epoch 192:   0/307] 	 train loss: 0.047921 	 lr: 0.00004
[epoch 192:  20/307] 	 train loss: 0.092009 	 lr: 0.00004
[epoch 192:  40/307] 	 train loss: 0.035811 	 lr: 0.00004
[epoch 192:  60/307] 	 train loss: 0.160061 	 lr: 0.00004

val loss: 0.342905 	 acc: 0.912480

[epoch 192:  80/307] 	 train loss: 0.081985 	 lr: 0.00004
[epoch 192: 100/307] 	 train loss: 0.121433 	 lr: 0.00004
[epoch 192: 120/307] 	 train loss: 0.016967 	 lr: 0.00004
[epoch 192: 140/307] 	 train loss: 0.040738 	 lr: 0.00004
[epoch 192: 160/307] 	 train loss: 0.103196 	 lr: 0.00004
[epoch 192: 180/307] 	 train loss: 0.062344 	 lr: 0.00004
[epoch 192: 200/307] 	 train loss: 0.229221 	 lr: 0.00004
[epoch 192: 220/307] 	 train loss: 0.234763 	 lr: 0.00004

val loss: 0.343406 	 acc: 0.911669

[epoch 192: 240/307] 	 train loss: 0.051516 	 lr: 0.00004
[epoch 192: 260/307] 	 train loss: 0.056125 	 lr: 0.00004
[epoch 192: 280/307] 	 train loss: 0.048979 	 lr: 0.00004
[epoch 192: 300/307] 	 train loss: 0.092673 	 lr: 0.00004
[epoch 193:   0/307] 	 train loss: 0.156744 	 lr: 0.00004
[epoch 193:  20/307] 	 train loss: 0.257549 	 lr: 0.00004
[epoch 193:  40/307] 	 train loss: 0.078124 	 lr: 0.00004
[epoch 193:  60/307] 	 train loss: 0.074673 	 lr: 0.00004

val loss: 0.351041 	 acc: 0.910049

[epoch 193:  80/307] 	 train loss: 0.087591 	 lr: 0.00004
[epoch 193: 100/307] 	 train loss: 0.216528 	 lr: 0.00004
[epoch 193: 120/307] 	 train loss: 0.180459 	 lr: 0.00004
[epoch 193: 140/307] 	 train loss: 0.178580 	 lr: 0.00004
[epoch 193: 160/307] 	 train loss: 0.026451 	 lr: 0.00004
[epoch 193: 180/307] 	 train loss: 0.060498 	 lr: 0.00004
[epoch 193: 200/307] 	 train loss: 0.078302 	 lr: 0.00004
[epoch 193: 220/307] 	 train loss: 0.063058 	 lr: 0.00004

val loss: 0.355449 	 acc: 0.910454

[epoch 193: 240/307] 	 train loss: 0.262397 	 lr: 0.00004
[epoch 193: 260/307] 	 train loss: 0.037034 	 lr: 0.00004
[epoch 193: 280/307] 	 train loss: 0.370751 	 lr: 0.00004
[epoch 193: 300/307] 	 train loss: 0.210645 	 lr: 0.00004
[epoch 194:   0/307] 	 train loss: 0.085589 	 lr: 0.00004
[epoch 194:  20/307] 	 train loss: 0.041993 	 lr: 0.00004
[epoch 194:  40/307] 	 train loss: 0.161204 	 lr: 0.00004
[epoch 194:  60/307] 	 train loss: 0.105753 	 lr: 0.00004

val loss: 0.344872 	 acc: 0.912480

[epoch 194:  80/307] 	 train loss: 0.013306 	 lr: 0.00004
[epoch 194: 100/307] 	 train loss: 0.071573 	 lr: 0.00004
[epoch 194: 120/307] 	 train loss: 0.042824 	 lr: 0.00004
[epoch 194: 140/307] 	 train loss: 0.029579 	 lr: 0.00004
[epoch 194: 160/307] 	 train loss: 0.144026 	 lr: 0.00004
[epoch 194: 180/307] 	 train loss: 0.042071 	 lr: 0.00004
[epoch 194: 200/307] 	 train loss: 0.036486 	 lr: 0.00004
[epoch 194: 220/307] 	 train loss: 0.112467 	 lr: 0.00004

val loss: 0.345714 	 acc: 0.913290

[epoch 194: 240/307] 	 train loss: 0.039054 	 lr: 0.00004
[epoch 194: 260/307] 	 train loss: 0.046227 	 lr: 0.00004
[epoch 194: 280/307] 	 train loss: 0.140888 	 lr: 0.00004
[epoch 194: 300/307] 	 train loss: 0.096457 	 lr: 0.00004
[epoch 195:   0/307] 	 train loss: 0.128847 	 lr: 0.00004
[epoch 195:  20/307] 	 train loss: 0.164774 	 lr: 0.00004
[epoch 195:  40/307] 	 train loss: 0.062474 	 lr: 0.00004
[epoch 195:  60/307] 	 train loss: 0.374517 	 lr: 0.00004

val loss: 0.348599 	 acc: 0.912885

[epoch 195:  80/307] 	 train loss: 0.079875 	 lr: 0.00004
[epoch 195: 100/307] 	 train loss: 0.065032 	 lr: 0.00004
[epoch 195: 120/307] 	 train loss: 0.057699 	 lr: 0.00004
[epoch 195: 140/307] 	 train loss: 0.034501 	 lr: 0.00004
[epoch 195: 160/307] 	 train loss: 0.170858 	 lr: 0.00004
[epoch 195: 180/307] 	 train loss: 0.153017 	 lr: 0.00004
[epoch 195: 200/307] 	 train loss: 0.116582 	 lr: 0.00004
[epoch 195: 220/307] 	 train loss: 0.241796 	 lr: 0.00004

val loss: 0.347699 	 acc: 0.911669

[epoch 195: 240/307] 	 train loss: 0.160000 	 lr: 0.00004
[epoch 195: 260/307] 	 train loss: 0.164030 	 lr: 0.00004
[epoch 195: 280/307] 	 train loss: 0.087976 	 lr: 0.00004
[epoch 195: 300/307] 	 train loss: 0.048070 	 lr: 0.00004
[epoch 196:   0/307] 	 train loss: 0.128103 	 lr: 0.00004
[epoch 196:  20/307] 	 train loss: 0.158417 	 lr: 0.00004
[epoch 196:  40/307] 	 train loss: 0.049213 	 lr: 0.00004
[epoch 196:  60/307] 	 train loss: 0.052500 	 lr: 0.00004

val loss: 0.348759 	 acc: 0.910859

[epoch 196:  80/307] 	 train loss: 0.219902 	 lr: 0.00004
[epoch 196: 100/307] 	 train loss: 0.092995 	 lr: 0.00004
[epoch 196: 120/307] 	 train loss: 0.034273 	 lr: 0.00004
[epoch 196: 140/307] 	 train loss: 0.129350 	 lr: 0.00004
[epoch 196: 160/307] 	 train loss: 0.051478 	 lr: 0.00004
[epoch 196: 180/307] 	 train loss: 0.150300 	 lr: 0.00004
[epoch 196: 200/307] 	 train loss: 0.078824 	 lr: 0.00004
[epoch 196: 220/307] 	 train loss: 0.273882 	 lr: 0.00004

val loss: 0.347739 	 acc: 0.909643

[epoch 196: 240/307] 	 train loss: 0.061097 	 lr: 0.00004
[epoch 196: 260/307] 	 train loss: 0.052746 	 lr: 0.00004
[epoch 196: 280/307] 	 train loss: 0.024861 	 lr: 0.00004
[epoch 196: 300/307] 	 train loss: 0.236691 	 lr: 0.00004
[epoch 197:   0/307] 	 train loss: 0.046372 	 lr: 0.00004
[epoch 197:  20/307] 	 train loss: 0.044657 	 lr: 0.00004
[epoch 197:  40/307] 	 train loss: 0.035343 	 lr: 0.00004
[epoch 197:  60/307] 	 train loss: 0.218615 	 lr: 0.00004

val loss: 0.351331 	 acc: 0.909643

[epoch 197:  80/307] 	 train loss: 0.029712 	 lr: 0.00004
[epoch 197: 100/307] 	 train loss: 0.119840 	 lr: 0.00004
[epoch 197: 120/307] 	 train loss: 0.011259 	 lr: 0.00004
[epoch 197: 140/307] 	 train loss: 0.048853 	 lr: 0.00004
[epoch 197: 160/307] 	 train loss: 0.323917 	 lr: 0.00004
[epoch 197: 180/307] 	 train loss: 0.185201 	 lr: 0.00004
[epoch 197: 200/307] 	 train loss: 0.144758 	 lr: 0.00004

val loss: 0.345718 	 acc: 0.911669

[epoch 197: 220/307] 	 train loss: 0.165829 	 lr: 0.00004
[epoch 197: 240/307] 	 train loss: 0.004186 	 lr: 0.00004
[epoch 197: 260/307] 	 train loss: 0.050283 	 lr: 0.00004
[epoch 197: 280/307] 	 train loss: 0.166782 	 lr: 0.00004
[epoch 197: 300/307] 	 train loss: 0.066861 	 lr: 0.00004
[epoch 198:   0/307] 	 train loss: 0.052441 	 lr: 0.00004
[epoch 198:  20/307] 	 train loss: 0.047172 	 lr: 0.00004
[epoch 198:  40/307] 	 train loss: 0.113016 	 lr: 0.00004
[epoch 198:  60/307] 	 train loss: 0.071039 	 lr: 0.00004

val loss: 0.342063 	 acc: 0.914100

[epoch 198:  80/307] 	 train loss: 0.336903 	 lr: 0.00004
[epoch 198: 100/307] 	 train loss: 0.123589 	 lr: 0.00004
[epoch 198: 120/307] 	 train loss: 0.143611 	 lr: 0.00004
[epoch 198: 140/307] 	 train loss: 0.141749 	 lr: 0.00004
[epoch 198: 160/307] 	 train loss: 0.027117 	 lr: 0.00004
[epoch 198: 180/307] 	 train loss: 0.111432 	 lr: 0.00004
[epoch 198: 200/307] 	 train loss: 0.185683 	 lr: 0.00004

val loss: 0.341629 	 acc: 0.911669

[epoch 198: 220/307] 	 train loss: 0.145250 	 lr: 0.00004
[epoch 198: 240/307] 	 train loss: 0.199381 	 lr: 0.00004
[epoch 198: 260/307] 	 train loss: 0.351894 	 lr: 0.00004
[epoch 198: 280/307] 	 train loss: 0.196363 	 lr: 0.00004
[epoch 198: 300/307] 	 train loss: 0.157654 	 lr: 0.00004
[epoch 199:   0/307] 	 train loss: 0.067998 	 lr: 0.00004
[epoch 199:  20/307] 	 train loss: 0.041258 	 lr: 0.00004
[epoch 199:  40/307] 	 train loss: 0.110280 	 lr: 0.00004
[epoch 199:  60/307] 	 train loss: 0.163877 	 lr: 0.00004

val loss: 0.346983 	 acc: 0.909238

[epoch 199:  80/307] 	 train loss: 0.105796 	 lr: 0.00004
[epoch 199: 100/307] 	 train loss: 0.093187 	 lr: 0.00004
[epoch 199: 120/307] 	 train loss: 0.041809 	 lr: 0.00004
[epoch 199: 140/307] 	 train loss: 0.127489 	 lr: 0.00004
[epoch 199: 160/307] 	 train loss: 0.046193 	 lr: 0.00004
[epoch 199: 180/307] 	 train loss: 0.123234 	 lr: 0.00004
[epoch 199: 200/307] 	 train loss: 0.110547 	 lr: 0.00004

val loss: 0.345044 	 acc: 0.910859

[epoch 199: 220/307] 	 train loss: 0.165572 	 lr: 0.00004
[epoch 199: 240/307] 	 train loss: 0.262520 	 lr: 0.00004
[epoch 199: 260/307] 	 train loss: 0.094264 	 lr: 0.00004
[epoch 199: 280/307] 	 train loss: 0.089779 	 lr: 0.00004
[epoch 199: 300/307] 	 train loss: 0.257340 	 lr: 0.00004
[epoch 200:   0/307] 	 train loss: 0.018467 	 lr: 0.00004
[epoch 200:  20/307] 	 train loss: 0.055559 	 lr: 0.00004
[epoch 200:  40/307] 	 train loss: 0.216876 	 lr: 0.00004
[epoch 200:  60/307] 	 train loss: 0.050858 	 lr: 0.00004

val loss: 0.350851 	 acc: 0.911669

[epoch 200:  80/307] 	 train loss: 0.037658 	 lr: 0.00004
[epoch 200: 100/307] 	 train loss: 0.028723 	 lr: 0.00004
[epoch 200: 120/307] 	 train loss: 0.087167 	 lr: 0.00004
[epoch 200: 140/307] 	 train loss: 0.234541 	 lr: 0.00004
[epoch 200: 160/307] 	 train loss: 0.110604 	 lr: 0.00004
[epoch 200: 180/307] 	 train loss: 0.028872 	 lr: 0.00004
[epoch 200: 200/307] 	 train loss: 0.124775 	 lr: 0.00004

val loss: 0.349800 	 acc: 0.910049

[epoch 200: 220/307] 	 train loss: 0.057083 	 lr: 0.00004
[epoch 200: 240/307] 	 train loss: 0.066448 	 lr: 0.00004
[epoch 200: 260/307] 	 train loss: 0.110039 	 lr: 0.00004
[epoch 200: 280/307] 	 train loss: 0.092261 	 lr: 0.00004
[epoch 200: 300/307] 	 train loss: 0.061641 	 lr: 0.00004
[epoch 201:   0/307] 	 train loss: 0.151410 	 lr: 0.00004
[epoch 201:  20/307] 	 train loss: 0.046984 	 lr: 0.00004
[epoch 201:  40/307] 	 train loss: 0.122088 	 lr: 0.00004

val loss: 0.345411 	 acc: 0.912480

[epoch 201:  60/307] 	 train loss: 0.059710 	 lr: 0.00004
[epoch 201:  80/307] 	 train loss: 0.078148 	 lr: 0.00004
[epoch 201: 100/307] 	 train loss: 0.061245 	 lr: 0.00004
[epoch 201: 120/307] 	 train loss: 0.088660 	 lr: 0.00004
[epoch 201: 140/307] 	 train loss: 0.091558 	 lr: 0.00004
[epoch 201: 160/307] 	 train loss: 0.209475 	 lr: 0.00004
[epoch 201: 180/307] 	 train loss: 0.075524 	 lr: 0.00004
[epoch 201: 200/307] 	 train loss: 0.091102 	 lr: 0.00004

val loss: 0.346477 	 acc: 0.912885

[epoch 201: 220/307] 	 train loss: 0.088124 	 lr: 0.00004
[epoch 201: 240/307] 	 train loss: 0.081968 	 lr: 0.00004
[epoch 201: 260/307] 	 train loss: 0.099886 	 lr: 0.00004
[epoch 201: 280/307] 	 train loss: 0.193252 	 lr: 0.00004
[epoch 201: 300/307] 	 train loss: 0.058421 	 lr: 0.00004
[epoch 202:   0/307] 	 train loss: 0.301670 	 lr: 0.00004
[epoch 202:  20/307] 	 train loss: 0.151386 	 lr: 0.00004
[epoch 202:  40/307] 	 train loss: 0.096502 	 lr: 0.00004

val loss: 0.351836 	 acc: 0.910454

[epoch 202:  60/307] 	 train loss: 0.045439 	 lr: 0.00004
[epoch 202:  80/307] 	 train loss: 0.113184 	 lr: 0.00004
[epoch 202: 100/307] 	 train loss: 0.184053 	 lr: 0.00004
[epoch 202: 120/307] 	 train loss: 0.050976 	 lr: 0.00004
[epoch 202: 140/307] 	 train loss: 0.048420 	 lr: 0.00004
[epoch 202: 160/307] 	 train loss: 0.094357 	 lr: 0.00004
[epoch 202: 180/307] 	 train loss: 0.144191 	 lr: 0.00004
[epoch 202: 200/307] 	 train loss: 0.010122 	 lr: 0.00004

val loss: 0.354782 	 acc: 0.910859

[epoch 202: 220/307] 	 train loss: 0.061775 	 lr: 0.00004
[epoch 202: 240/307] 	 train loss: 0.069707 	 lr: 0.00004
[epoch 202: 260/307] 	 train loss: 0.028306 	 lr: 0.00004
[epoch 202: 280/307] 	 train loss: 0.229751 	 lr: 0.00004
[epoch 202: 300/307] 	 train loss: 0.037547 	 lr: 0.00004
[epoch 203:   0/307] 	 train loss: 0.108296 	 lr: 0.00004
[epoch 203:  20/307] 	 train loss: 0.032847 	 lr: 0.00004
[epoch 203:  40/307] 	 train loss: 0.273046 	 lr: 0.00004

val loss: 0.348132 	 acc: 0.910859

[epoch 203:  60/307] 	 train loss: 0.165457 	 lr: 0.00004
[epoch 203:  80/307] 	 train loss: 0.089492 	 lr: 0.00004
[epoch 203: 100/307] 	 train loss: 0.007722 	 lr: 0.00004
[epoch 203: 120/307] 	 train loss: 0.180141 	 lr: 0.00004
[epoch 203: 140/307] 	 train loss: 0.074768 	 lr: 0.00004
[epoch 203: 160/307] 	 train loss: 0.047076 	 lr: 0.00004
[epoch 203: 180/307] 	 train loss: 0.328883 	 lr: 0.00004
[epoch 203: 200/307] 	 train loss: 0.102773 	 lr: 0.00004

val loss: 0.349928 	 acc: 0.909643

[epoch 203: 220/307] 	 train loss: 0.204005 	 lr: 0.00004
[epoch 203: 240/307] 	 train loss: 0.082884 	 lr: 0.00004
[epoch 203: 260/307] 	 train loss: 0.028317 	 lr: 0.00004
[epoch 203: 280/307] 	 train loss: 0.069481 	 lr: 0.00004
[epoch 203: 300/307] 	 train loss: 0.135542 	 lr: 0.00004
[epoch 204:   0/307] 	 train loss: 0.157084 	 lr: 0.00004
[epoch 204:  20/307] 	 train loss: 0.238554 	 lr: 0.00004
[epoch 204:  40/307] 	 train loss: 0.229121 	 lr: 0.00004

val loss: 0.350132 	 acc: 0.908428

[epoch 204:  60/307] 	 train loss: 0.031467 	 lr: 0.00004
[epoch 204:  80/307] 	 train loss: 0.218753 	 lr: 0.00004
[epoch 204: 100/307] 	 train loss: 0.178844 	 lr: 0.00004
[epoch 204: 120/307] 	 train loss: 0.042457 	 lr: 0.00004
[epoch 204: 140/307] 	 train loss: 0.134434 	 lr: 0.00004
[epoch 204: 160/307] 	 train loss: 0.049025 	 lr: 0.00004
[epoch 204: 180/307] 	 train loss: 0.424844 	 lr: 0.00004
[epoch 204: 200/307] 	 train loss: 0.046749 	 lr: 0.00004

val loss: 0.347120 	 acc: 0.910049

[epoch 204: 220/307] 	 train loss: 0.036752 	 lr: 0.00004
[epoch 204: 240/307] 	 train loss: 0.266578 	 lr: 0.00004
[epoch 204: 260/307] 	 train loss: 0.044283 	 lr: 0.00004
[epoch 204: 280/307] 	 train loss: 0.045631 	 lr: 0.00004
[epoch 204: 300/307] 	 train loss: 0.064181 	 lr: 0.00004
[epoch 205:   0/307] 	 train loss: 0.101222 	 lr: 0.00004
[epoch 205:  20/307] 	 train loss: 0.090200 	 lr: 0.00004
[epoch 205:  40/307] 	 train loss: 0.028684 	 lr: 0.00004

val loss: 0.347004 	 acc: 0.912480

[epoch 205:  60/307] 	 train loss: 0.046074 	 lr: 0.00004
[epoch 205:  80/307] 	 train loss: 0.072896 	 lr: 0.00004
[epoch 205: 100/307] 	 train loss: 0.112561 	 lr: 0.00004
[epoch 205: 120/307] 	 train loss: 0.244983 	 lr: 0.00004
[epoch 205: 140/307] 	 train loss: 0.093384 	 lr: 0.00004
[epoch 205: 160/307] 	 train loss: 0.053878 	 lr: 0.00004
[epoch 205: 180/307] 	 train loss: 0.193883 	 lr: 0.00004
[epoch 205: 200/307] 	 train loss: 0.066733 	 lr: 0.00004

val loss: 0.342048 	 acc: 0.908833

[epoch 205: 220/307] 	 train loss: 0.241332 	 lr: 0.00004
[epoch 205: 240/307] 	 train loss: 0.174251 	 lr: 0.00004
[epoch 205: 260/307] 	 train loss: 0.086286 	 lr: 0.00004
[epoch 205: 280/307] 	 train loss: 0.049333 	 lr: 0.00004
[epoch 205: 300/307] 	 train loss: 0.065910 	 lr: 0.00004
[epoch 206:   0/307] 	 train loss: 0.382883 	 lr: 0.00004
[epoch 206:  20/307] 	 train loss: 0.022297 	 lr: 0.00004
[epoch 206:  40/307] 	 train loss: 0.106873 	 lr: 0.00004

val loss: 0.342231 	 acc: 0.908428

[epoch 206:  60/307] 	 train loss: 0.252707 	 lr: 0.00004
[epoch 206:  80/307] 	 train loss: 0.057366 	 lr: 0.00004
[epoch 206: 100/307] 	 train loss: 0.033815 	 lr: 0.00004
[epoch 206: 120/307] 	 train loss: 0.048667 	 lr: 0.00004
[epoch 206: 140/307] 	 train loss: 0.023331 	 lr: 0.00004
[epoch 206: 160/307] 	 train loss: 0.155539 	 lr: 0.00004
[epoch 206: 180/307] 	 train loss: 0.035014 	 lr: 0.00004
[epoch 206: 200/307] 	 train loss: 0.046721 	 lr: 0.00004

val loss: 0.343637 	 acc: 0.914100

[epoch 206: 220/307] 	 train loss: 0.088909 	 lr: 0.00004
[epoch 206: 240/307] 	 train loss: 0.173964 	 lr: 0.00004
[epoch 206: 260/307] 	 train loss: 0.267525 	 lr: 0.00004
[epoch 206: 280/307] 	 train loss: 0.161699 	 lr: 0.00004
[epoch 206: 300/307] 	 train loss: 0.059619 	 lr: 0.00004
[epoch 207:   0/307] 	 train loss: 0.049671 	 lr: 0.00004
[epoch 207:  20/307] 	 train loss: 0.059906 	 lr: 0.00004
[epoch 207:  40/307] 	 train loss: 0.037128 	 lr: 0.00004

val loss: 0.349234 	 acc: 0.912885

[epoch 207:  60/307] 	 train loss: 0.059839 	 lr: 0.00004
[epoch 207:  80/307] 	 train loss: 0.221541 	 lr: 0.00004
[epoch 207: 100/307] 	 train loss: 0.140974 	 lr: 0.00004
[epoch 207: 120/307] 	 train loss: 0.072854 	 lr: 0.00004
[epoch 207: 140/307] 	 train loss: 0.094131 	 lr: 0.00004
[epoch 207: 160/307] 	 train loss: 0.471701 	 lr: 0.00004
[epoch 207: 180/307] 	 train loss: 0.225570 	 lr: 0.00004

val loss: 0.349100 	 acc: 0.914506

[epoch 207: 200/307] 	 train loss: 0.070179 	 lr: 0.00004
[epoch 207: 220/307] 	 train loss: 0.057462 	 lr: 0.00004
[epoch 207: 240/307] 	 train loss: 0.318797 	 lr: 0.00004
[epoch 207: 260/307] 	 train loss: 0.131824 	 lr: 0.00004
[epoch 207: 280/307] 	 train loss: 0.023683 	 lr: 0.00004
[epoch 207: 300/307] 	 train loss: 0.034392 	 lr: 0.00004
[epoch 208:   0/307] 	 train loss: 0.020822 	 lr: 0.00004
[epoch 208:  20/307] 	 train loss: 0.095950 	 lr: 0.00004
[epoch 208:  40/307] 	 train loss: 0.020377 	 lr: 0.00004

val loss: 0.348244 	 acc: 0.912075

[epoch 208:  60/307] 	 train loss: 0.107359 	 lr: 0.00004
[epoch 208:  80/307] 	 train loss: 0.186287 	 lr: 0.00004
[epoch 208: 100/307] 	 train loss: 0.412801 	 lr: 0.00004
[epoch 208: 120/307] 	 train loss: 0.062330 	 lr: 0.00004
[epoch 208: 140/307] 	 train loss: 0.068775 	 lr: 0.00004
[epoch 208: 160/307] 	 train loss: 0.040797 	 lr: 0.00004
[epoch 208: 180/307] 	 train loss: 0.047370 	 lr: 0.00004

val loss: 0.349413 	 acc: 0.912885

[epoch 208: 200/307] 	 train loss: 0.056882 	 lr: 0.00004
[epoch 208: 220/307] 	 train loss: 0.019367 	 lr: 0.00004
[epoch 208: 240/307] 	 train loss: 0.151657 	 lr: 0.00004
[epoch 208: 260/307] 	 train loss: 0.054875 	 lr: 0.00004
[epoch 208: 280/307] 	 train loss: 0.103624 	 lr: 0.00004
[epoch 208: 300/307] 	 train loss: 0.127030 	 lr: 0.00004
[epoch 209:   0/307] 	 train loss: 0.024472 	 lr: 0.00004
[epoch 209:  20/307] 	 train loss: 0.039533 	 lr: 0.00004
[epoch 209:  40/307] 	 train loss: 0.014288 	 lr: 0.00004

val loss: 0.344894 	 acc: 0.912885

[epoch 209:  60/307] 	 train loss: 0.128732 	 lr: 0.00004
[epoch 209:  80/307] 	 train loss: 0.059245 	 lr: 0.00004
[epoch 209: 100/307] 	 train loss: 0.150114 	 lr: 0.00004
[epoch 209: 120/307] 	 train loss: 0.149417 	 lr: 0.00004
[epoch 209: 140/307] 	 train loss: 0.233363 	 lr: 0.00004
[epoch 209: 160/307] 	 train loss: 0.168874 	 lr: 0.00004
[epoch 209: 180/307] 	 train loss: 0.012139 	 lr: 0.00004

val loss: 0.344224 	 acc: 0.913695

[epoch 209: 200/307] 	 train loss: 0.184863 	 lr: 0.00004
[epoch 209: 220/307] 	 train loss: 0.042011 	 lr: 0.00004
[epoch 209: 240/307] 	 train loss: 0.069564 	 lr: 0.00004
[epoch 209: 260/307] 	 train loss: 0.223535 	 lr: 0.00004
[epoch 209: 280/307] 	 train loss: 0.035911 	 lr: 0.00004
[epoch 209: 300/307] 	 train loss: 0.113093 	 lr: 0.00004
[epoch 210:   0/307] 	 train loss: 0.329999 	 lr: 0.00004
[epoch 210:  20/307] 	 train loss: 0.031285 	 lr: 0.00004
[epoch 210:  40/307] 	 train loss: 0.336581 	 lr: 0.00004

val loss: 0.342029 	 acc: 0.913290

[epoch 210:  60/307] 	 train loss: 0.204383 	 lr: 0.00004
[epoch 210:  80/307] 	 train loss: 0.163863 	 lr: 0.00004
[epoch 210: 100/307] 	 train loss: 0.125255 	 lr: 0.00004
[epoch 210: 120/307] 	 train loss: 0.281301 	 lr: 0.00004
[epoch 210: 140/307] 	 train loss: 0.099742 	 lr: 0.00004
[epoch 210: 160/307] 	 train loss: 0.021107 	 lr: 0.00004
[epoch 210: 180/307] 	 train loss: 0.143644 	 lr: 0.00004

val loss: 0.349035 	 acc: 0.912480

[epoch 210: 200/307] 	 train loss: 0.174113 	 lr: 0.00004
[epoch 210: 220/307] 	 train loss: 0.043985 	 lr: 0.00004
[epoch 210: 240/307] 	 train loss: 0.219207 	 lr: 0.00004
[epoch 210: 260/307] 	 train loss: 0.091204 	 lr: 0.00004
[epoch 210: 280/307] 	 train loss: 0.081857 	 lr: 0.00004
[epoch 210: 300/307] 	 train loss: 0.104575 	 lr: 0.00004
[epoch 211:   0/307] 	 train loss: 0.161435 	 lr: 0.00003
[epoch 211:  20/307] 	 train loss: 0.269190 	 lr: 0.00003

val loss: 0.348158 	 acc: 0.914506

[epoch 211:  40/307] 	 train loss: 0.328588 	 lr: 0.00003
[epoch 211:  60/307] 	 train loss: 0.039283 	 lr: 0.00003
[epoch 211:  80/307] 	 train loss: 0.187330 	 lr: 0.00003
[epoch 211: 100/307] 	 train loss: 0.066446 	 lr: 0.00003
[epoch 211: 120/307] 	 train loss: 0.037236 	 lr: 0.00003
[epoch 211: 140/307] 	 train loss: 0.081205 	 lr: 0.00003
[epoch 211: 160/307] 	 train loss: 0.059676 	 lr: 0.00003
[epoch 211: 180/307] 	 train loss: 0.059834 	 lr: 0.00003

val loss: 0.350115 	 acc: 0.912885

[epoch 211: 200/307] 	 train loss: 0.090154 	 lr: 0.00003
[epoch 211: 220/307] 	 train loss: 0.149916 	 lr: 0.00003
[epoch 211: 240/307] 	 train loss: 0.058907 	 lr: 0.00003
[epoch 211: 260/307] 	 train loss: 0.115233 	 lr: 0.00003
[epoch 211: 280/307] 	 train loss: 0.246735 	 lr: 0.00003
[epoch 211: 300/307] 	 train loss: 0.128489 	 lr: 0.00003
[epoch 212:   0/307] 	 train loss: 0.007919 	 lr: 0.00003
[epoch 212:  20/307] 	 train loss: 0.125094 	 lr: 0.00003

val loss: 0.346979 	 acc: 0.911264

[epoch 212:  40/307] 	 train loss: 0.235314 	 lr: 0.00003
[epoch 212:  60/307] 	 train loss: 0.044748 	 lr: 0.00003
[epoch 212:  80/307] 	 train loss: 0.060256 	 lr: 0.00003
[epoch 212: 100/307] 	 train loss: 0.103516 	 lr: 0.00003
[epoch 212: 120/307] 	 train loss: 0.064920 	 lr: 0.00003
[epoch 212: 140/307] 	 train loss: 0.083473 	 lr: 0.00003
[epoch 212: 160/307] 	 train loss: 0.093018 	 lr: 0.00003
[epoch 212: 180/307] 	 train loss: 0.091488 	 lr: 0.00003

val loss: 0.347861 	 acc: 0.913290

[epoch 212: 200/307] 	 train loss: 0.069247 	 lr: 0.00003
[epoch 212: 220/307] 	 train loss: 0.080366 	 lr: 0.00003
[epoch 212: 240/307] 	 train loss: 0.028733 	 lr: 0.00003
[epoch 212: 260/307] 	 train loss: 0.041271 	 lr: 0.00003
[epoch 212: 280/307] 	 train loss: 0.146291 	 lr: 0.00003
[epoch 212: 300/307] 	 train loss: 0.080599 	 lr: 0.00003
[epoch 213:   0/307] 	 train loss: 0.188022 	 lr: 0.00003
[epoch 213:  20/307] 	 train loss: 0.024437 	 lr: 0.00003

val loss: 0.345772 	 acc: 0.912075

[epoch 213:  40/307] 	 train loss: 0.036428 	 lr: 0.00003
[epoch 213:  60/307] 	 train loss: 0.132031 	 lr: 0.00003
[epoch 213:  80/307] 	 train loss: 0.037356 	 lr: 0.00003
[epoch 213: 100/307] 	 train loss: 0.074033 	 lr: 0.00003
[epoch 213: 120/307] 	 train loss: 0.069255 	 lr: 0.00003
[epoch 213: 140/307] 	 train loss: 0.105367 	 lr: 0.00003
[epoch 213: 160/307] 	 train loss: 0.083921 	 lr: 0.00003
[epoch 213: 180/307] 	 train loss: 0.205992 	 lr: 0.00003

val loss: 0.346113 	 acc: 0.912885

[epoch 213: 200/307] 	 train loss: 0.014011 	 lr: 0.00003
[epoch 213: 220/307] 	 train loss: 0.124108 	 lr: 0.00003
[epoch 213: 240/307] 	 train loss: 0.031660 	 lr: 0.00003
[epoch 213: 260/307] 	 train loss: 0.143606 	 lr: 0.00003
[epoch 213: 280/307] 	 train loss: 0.143946 	 lr: 0.00003
[epoch 213: 300/307] 	 train loss: 0.166201 	 lr: 0.00003
[epoch 214:   0/307] 	 train loss: 0.004302 	 lr: 0.00003
[epoch 214:  20/307] 	 train loss: 0.108197 	 lr: 0.00003

val loss: 0.351741 	 acc: 0.913695

[epoch 214:  40/307] 	 train loss: 0.081359 	 lr: 0.00003
[epoch 214:  60/307] 	 train loss: 0.011163 	 lr: 0.00003
[epoch 214:  80/307] 	 train loss: 0.044058 	 lr: 0.00003
[epoch 214: 100/307] 	 train loss: 0.161198 	 lr: 0.00003
[epoch 214: 120/307] 	 train loss: 0.167059 	 lr: 0.00003
[epoch 214: 140/307] 	 train loss: 0.136738 	 lr: 0.00003
[epoch 214: 160/307] 	 train loss: 0.120573 	 lr: 0.00003
[epoch 214: 180/307] 	 train loss: 0.217324 	 lr: 0.00003

val loss: 0.346488 	 acc: 0.914100

[epoch 214: 200/307] 	 train loss: 0.122275 	 lr: 0.00003
[epoch 214: 220/307] 	 train loss: 0.173861 	 lr: 0.00003
[epoch 214: 240/307] 	 train loss: 0.078325 	 lr: 0.00003
[epoch 214: 260/307] 	 train loss: 0.080201 	 lr: 0.00003
[epoch 214: 280/307] 	 train loss: 0.257504 	 lr: 0.00003
[epoch 214: 300/307] 	 train loss: 0.160359 	 lr: 0.00003
[epoch 215:   0/307] 	 train loss: 0.097716 	 lr: 0.00003
[epoch 215:  20/307] 	 train loss: 0.048910 	 lr: 0.00003

val loss: 0.350824 	 acc: 0.913695

[epoch 215:  40/307] 	 train loss: 0.094438 	 lr: 0.00003
[epoch 215:  60/307] 	 train loss: 0.035936 	 lr: 0.00003
[epoch 215:  80/307] 	 train loss: 0.087900 	 lr: 0.00003
[epoch 215: 100/307] 	 train loss: 0.230384 	 lr: 0.00003
[epoch 215: 120/307] 	 train loss: 0.038424 	 lr: 0.00003
[epoch 215: 140/307] 	 train loss: 0.300651 	 lr: 0.00003
[epoch 215: 160/307] 	 train loss: 0.044337 	 lr: 0.00003
[epoch 215: 180/307] 	 train loss: 0.061496 	 lr: 0.00003

val loss: 0.349105 	 acc: 0.914911

[epoch 215: 200/307] 	 train loss: 0.184740 	 lr: 0.00003
[epoch 215: 220/307] 	 train loss: 0.109425 	 lr: 0.00003
[epoch 215: 240/307] 	 train loss: 0.038183 	 lr: 0.00003
[epoch 215: 260/307] 	 train loss: 0.074788 	 lr: 0.00003
[epoch 215: 280/307] 	 train loss: 0.056932 	 lr: 0.00003
[epoch 215: 300/307] 	 train loss: 0.056919 	 lr: 0.00003
[epoch 216:   0/307] 	 train loss: 0.145017 	 lr: 0.00003
[epoch 216:  20/307] 	 train loss: 0.139663 	 lr: 0.00003

val loss: 0.344395 	 acc: 0.912480

[epoch 216:  40/307] 	 train loss: 0.093775 	 lr: 0.00003
[epoch 216:  60/307] 	 train loss: 0.102992 	 lr: 0.00003
[epoch 216:  80/307] 	 train loss: 0.010904 	 lr: 0.00003
[epoch 216: 100/307] 	 train loss: 0.133448 	 lr: 0.00003
[epoch 216: 120/307] 	 train loss: 0.054945 	 lr: 0.00003
[epoch 216: 140/307] 	 train loss: 0.132128 	 lr: 0.00003
[epoch 216: 160/307] 	 train loss: 0.016623 	 lr: 0.00003
[epoch 216: 180/307] 	 train loss: 0.090932 	 lr: 0.00003

val loss: 0.345694 	 acc: 0.913290

[epoch 216: 200/307] 	 train loss: 0.060474 	 lr: 0.00003
[epoch 216: 220/307] 	 train loss: 0.108531 	 lr: 0.00003
[epoch 216: 240/307] 	 train loss: 0.052525 	 lr: 0.00003
[epoch 216: 260/307] 	 train loss: 0.019424 	 lr: 0.00003
[epoch 216: 280/307] 	 train loss: 0.109579 	 lr: 0.00003
[epoch 216: 300/307] 	 train loss: 0.188925 	 lr: 0.00003
[epoch 217:   0/307] 	 train loss: 0.089543 	 lr: 0.00003
[epoch 217:  20/307] 	 train loss: 0.075190 	 lr: 0.00003

val loss: 0.349696 	 acc: 0.913695

[epoch 217:  40/307] 	 train loss: 0.147183 	 lr: 0.00003
[epoch 217:  60/307] 	 train loss: 0.340308 	 lr: 0.00003
[epoch 217:  80/307] 	 train loss: 0.052278 	 lr: 0.00003
[epoch 217: 100/307] 	 train loss: 0.088954 	 lr: 0.00003
[epoch 217: 120/307] 	 train loss: 0.172498 	 lr: 0.00003
[epoch 217: 140/307] 	 train loss: 0.038004 	 lr: 0.00003
[epoch 217: 160/307] 	 train loss: 0.296186 	 lr: 0.00003

val loss: 0.346722 	 acc: 0.911669

[epoch 217: 180/307] 	 train loss: 0.080659 	 lr: 0.00003
[epoch 217: 200/307] 	 train loss: 0.080642 	 lr: 0.00003
[epoch 217: 220/307] 	 train loss: 0.181407 	 lr: 0.00003
[epoch 217: 240/307] 	 train loss: 0.068332 	 lr: 0.00003
[epoch 217: 260/307] 	 train loss: 0.021029 	 lr: 0.00003
[epoch 217: 280/307] 	 train loss: 0.084128 	 lr: 0.00003
[epoch 217: 300/307] 	 train loss: 0.101404 	 lr: 0.00003
[epoch 218:   0/307] 	 train loss: 0.094986 	 lr: 0.00003
[epoch 218:  20/307] 	 train loss: 0.044344 	 lr: 0.00003

val loss: 0.346758 	 acc: 0.912885

[epoch 218:  40/307] 	 train loss: 0.107261 	 lr: 0.00003
[epoch 218:  60/307] 	 train loss: 0.062532 	 lr: 0.00003
[epoch 218:  80/307] 	 train loss: 0.018575 	 lr: 0.00003
[epoch 218: 100/307] 	 train loss: 0.071552 	 lr: 0.00003
[epoch 218: 120/307] 	 train loss: 0.072064 	 lr: 0.00003
[epoch 218: 140/307] 	 train loss: 0.100256 	 lr: 0.00003
[epoch 218: 160/307] 	 train loss: 0.237768 	 lr: 0.00003

val loss: 0.345109 	 acc: 0.914100

[epoch 218: 180/307] 	 train loss: 0.098802 	 lr: 0.00003
[epoch 218: 200/307] 	 train loss: 0.073360 	 lr: 0.00003
[epoch 218: 220/307] 	 train loss: 0.084856 	 lr: 0.00003
[epoch 218: 240/307] 	 train loss: 0.135389 	 lr: 0.00003
[epoch 218: 260/307] 	 train loss: 0.031451 	 lr: 0.00003
[epoch 218: 280/307] 	 train loss: 0.050668 	 lr: 0.00003
[epoch 218: 300/307] 	 train loss: 0.032448 	 lr: 0.00003
[epoch 219:   0/307] 	 train loss: 0.199505 	 lr: 0.00003
[epoch 219:  20/307] 	 train loss: 0.056282 	 lr: 0.00003

val loss: 0.343712 	 acc: 0.913695

[epoch 219:  40/307] 	 train loss: 0.118966 	 lr: 0.00003
[epoch 219:  60/307] 	 train loss: 0.078990 	 lr: 0.00003
[epoch 219:  80/307] 	 train loss: 0.236178 	 lr: 0.00003
[epoch 219: 100/307] 	 train loss: 0.103698 	 lr: 0.00003
[epoch 219: 120/307] 	 train loss: 0.102793 	 lr: 0.00003
[epoch 219: 140/307] 	 train loss: 0.179681 	 lr: 0.00003
[epoch 219: 160/307] 	 train loss: 0.103663 	 lr: 0.00003

val loss: 0.346856 	 acc: 0.912480

[epoch 219: 180/307] 	 train loss: 0.173485 	 lr: 0.00003
[epoch 219: 200/307] 	 train loss: 0.049083 	 lr: 0.00003
[epoch 219: 220/307] 	 train loss: 0.037633 	 lr: 0.00003
[epoch 219: 240/307] 	 train loss: 0.226677 	 lr: 0.00003
[epoch 219: 260/307] 	 train loss: 0.071729 	 lr: 0.00003
[epoch 219: 280/307] 	 train loss: 0.155725 	 lr: 0.00003
[epoch 219: 300/307] 	 train loss: 0.094431 	 lr: 0.00003
[epoch 220:   0/307] 	 train loss: 0.174777 	 lr: 0.00003
[epoch 220:  20/307] 	 train loss: 0.160049 	 lr: 0.00003

val loss: 0.348113 	 acc: 0.911264

[epoch 220:  40/307] 	 train loss: 0.153283 	 lr: 0.00003
[epoch 220:  60/307] 	 train loss: 0.006058 	 lr: 0.00003
[epoch 220:  80/307] 	 train loss: 0.183604 	 lr: 0.00003
[epoch 220: 100/307] 	 train loss: 0.319066 	 lr: 0.00003
[epoch 220: 120/307] 	 train loss: 0.322298 	 lr: 0.00003
[epoch 220: 140/307] 	 train loss: 0.218778 	 lr: 0.00003
[epoch 220: 160/307] 	 train loss: 0.260720 	 lr: 0.00003

val loss: 0.346220 	 acc: 0.914506

[epoch 220: 180/307] 	 train loss: 0.037711 	 lr: 0.00003
[epoch 220: 200/307] 	 train loss: 0.065782 	 lr: 0.00003
[epoch 220: 220/307] 	 train loss: 0.030446 	 lr: 0.00003
[epoch 220: 240/307] 	 train loss: 0.144690 	 lr: 0.00003
[epoch 220: 260/307] 	 train loss: 0.133271 	 lr: 0.00003
[epoch 220: 280/307] 	 train loss: 0.150099 	 lr: 0.00003
[epoch 220: 300/307] 	 train loss: 0.018839 	 lr: 0.00003
[epoch 221:   0/307] 	 train loss: 0.158723 	 lr: 0.00003

val loss: 0.344366 	 acc: 0.912885

[epoch 221:  20/307] 	 train loss: 0.137587 	 lr: 0.00003
[epoch 221:  40/307] 	 train loss: 0.286465 	 lr: 0.00003
[epoch 221:  60/307] 	 train loss: 0.086502 	 lr: 0.00003
[epoch 221:  80/307] 	 train loss: 0.152036 	 lr: 0.00003
[epoch 221: 100/307] 	 train loss: 0.243217 	 lr: 0.00003
[epoch 221: 120/307] 	 train loss: 0.121516 	 lr: 0.00003
[epoch 221: 140/307] 	 train loss: 0.094258 	 lr: 0.00003
[epoch 221: 160/307] 	 train loss: 0.069601 	 lr: 0.00003

val loss: 0.343513 	 acc: 0.912885

[epoch 221: 180/307] 	 train loss: 0.042873 	 lr: 0.00003
[epoch 221: 200/307] 	 train loss: 0.095135 	 lr: 0.00003
[epoch 221: 220/307] 	 train loss: 0.031507 	 lr: 0.00003
[epoch 221: 240/307] 	 train loss: 0.107723 	 lr: 0.00003
[epoch 221: 260/307] 	 train loss: 0.073666 	 lr: 0.00003
[epoch 221: 280/307] 	 train loss: 0.108815 	 lr: 0.00003
[epoch 221: 300/307] 	 train loss: 0.264745 	 lr: 0.00003
[epoch 222:   0/307] 	 train loss: 0.145991 	 lr: 0.00003

val loss: 0.348360 	 acc: 0.913695

[epoch 222:  20/307] 	 train loss: 0.153090 	 lr: 0.00003
[epoch 222:  40/307] 	 train loss: 0.183452 	 lr: 0.00003
[epoch 222:  60/307] 	 train loss: 0.064450 	 lr: 0.00003
[epoch 222:  80/307] 	 train loss: 0.185784 	 lr: 0.00003
[epoch 222: 100/307] 	 train loss: 0.160706 	 lr: 0.00003
[epoch 222: 120/307] 	 train loss: 0.178152 	 lr: 0.00003
[epoch 222: 140/307] 	 train loss: 0.126329 	 lr: 0.00003
[epoch 222: 160/307] 	 train loss: 0.146320 	 lr: 0.00003

val loss: 0.347964 	 acc: 0.911669

[epoch 222: 180/307] 	 train loss: 0.094894 	 lr: 0.00003
[epoch 222: 200/307] 	 train loss: 0.080824 	 lr: 0.00003
[epoch 222: 220/307] 	 train loss: 0.132961 	 lr: 0.00003
[epoch 222: 240/307] 	 train loss: 0.121289 	 lr: 0.00003
[epoch 222: 260/307] 	 train loss: 0.045276 	 lr: 0.00003
[epoch 222: 280/307] 	 train loss: 0.218240 	 lr: 0.00003
[epoch 222: 300/307] 	 train loss: 0.113042 	 lr: 0.00003
[epoch 223:   0/307] 	 train loss: 0.464596 	 lr: 0.00003

val loss: 0.350740 	 acc: 0.913290

[epoch 223:  20/307] 	 train loss: 0.102174 	 lr: 0.00003
[epoch 223:  40/307] 	 train loss: 0.022506 	 lr: 0.00003
[epoch 223:  60/307] 	 train loss: 0.042285 	 lr: 0.00003
[epoch 223:  80/307] 	 train loss: 0.180447 	 lr: 0.00003
[epoch 223: 100/307] 	 train loss: 0.146862 	 lr: 0.00003
[epoch 223: 120/307] 	 train loss: 0.017142 	 lr: 0.00003
[epoch 223: 140/307] 	 train loss: 0.082482 	 lr: 0.00003
[epoch 223: 160/307] 	 train loss: 0.062798 	 lr: 0.00003

val loss: 0.348781 	 acc: 0.911669

[epoch 223: 180/307] 	 train loss: 0.032073 	 lr: 0.00003
[epoch 223: 200/307] 	 train loss: 0.041804 	 lr: 0.00003
[epoch 223: 220/307] 	 train loss: 0.293349 	 lr: 0.00003
[epoch 223: 240/307] 	 train loss: 0.075248 	 lr: 0.00003
[epoch 223: 260/307] 	 train loss: 0.202144 	 lr: 0.00003
[epoch 223: 280/307] 	 train loss: 0.114997 	 lr: 0.00003
[epoch 223: 300/307] 	 train loss: 0.149785 	 lr: 0.00003
[epoch 224:   0/307] 	 train loss: 0.230002 	 lr: 0.00003

val loss: 0.351927 	 acc: 0.912075

[epoch 224:  20/307] 	 train loss: 0.027559 	 lr: 0.00003
[epoch 224:  40/307] 	 train loss: 0.053341 	 lr: 0.00003
[epoch 224:  60/307] 	 train loss: 0.034487 	 lr: 0.00003
[epoch 224:  80/307] 	 train loss: 0.110831 	 lr: 0.00003
[epoch 224: 100/307] 	 train loss: 0.450445 	 lr: 0.00003
[epoch 224: 120/307] 	 train loss: 0.188395 	 lr: 0.00003
[epoch 224: 140/307] 	 train loss: 0.107151 	 lr: 0.00003
[epoch 224: 160/307] 	 train loss: 0.010091 	 lr: 0.00003

val loss: 0.351851 	 acc: 0.912885

[epoch 224: 180/307] 	 train loss: 0.091179 	 lr: 0.00003
[epoch 224: 200/307] 	 train loss: 0.054369 	 lr: 0.00003
[epoch 224: 220/307] 	 train loss: 0.127984 	 lr: 0.00003
[epoch 224: 240/307] 	 train loss: 0.088845 	 lr: 0.00003
[epoch 224: 260/307] 	 train loss: 0.430809 	 lr: 0.00003
[epoch 224: 280/307] 	 train loss: 0.263737 	 lr: 0.00003
[epoch 224: 300/307] 	 train loss: 0.136823 	 lr: 0.00003
[epoch 225:   0/307] 	 train loss: 0.155604 	 lr: 0.00003

val loss: 0.348603 	 acc: 0.911669

[epoch 225:  20/307] 	 train loss: 0.095468 	 lr: 0.00003
[epoch 225:  40/307] 	 train loss: 0.041701 	 lr: 0.00003
[epoch 225:  60/307] 	 train loss: 0.042221 	 lr: 0.00003
[epoch 225:  80/307] 	 train loss: 0.017059 	 lr: 0.00003
[epoch 225: 100/307] 	 train loss: 0.238149 	 lr: 0.00003
[epoch 225: 120/307] 	 train loss: 0.171907 	 lr: 0.00003
[epoch 225: 140/307] 	 train loss: 0.108800 	 lr: 0.00003
[epoch 225: 160/307] 	 train loss: 0.046888 	 lr: 0.00003

val loss: 0.348205 	 acc: 0.915721

[epoch 225: 180/307] 	 train loss: 0.089933 	 lr: 0.00003
[epoch 225: 200/307] 	 train loss: 0.033040 	 lr: 0.00003
[epoch 225: 220/307] 	 train loss: 0.062424 	 lr: 0.00003
[epoch 225: 240/307] 	 train loss: 0.078886 	 lr: 0.00003
[epoch 225: 260/307] 	 train loss: 0.013914 	 lr: 0.00003
[epoch 225: 280/307] 	 train loss: 0.020330 	 lr: 0.00003
[epoch 225: 300/307] 	 train loss: 0.193845 	 lr: 0.00003
[epoch 226:   0/307] 	 train loss: 0.269833 	 lr: 0.00003

val loss: 0.348820 	 acc: 0.912480

[epoch 226:  20/307] 	 train loss: 0.112386 	 lr: 0.00003
[epoch 226:  40/307] 	 train loss: 0.155259 	 lr: 0.00003
[epoch 226:  60/307] 	 train loss: 0.036006 	 lr: 0.00003
[epoch 226:  80/307] 	 train loss: 0.026179 	 lr: 0.00003
[epoch 226: 100/307] 	 train loss: 0.071670 	 lr: 0.00003
[epoch 226: 120/307] 	 train loss: 0.082919 	 lr: 0.00003
[epoch 226: 140/307] 	 train loss: 0.160040 	 lr: 0.00003
[epoch 226: 160/307] 	 train loss: 0.039467 	 lr: 0.00003

val loss: 0.351287 	 acc: 0.910049

[epoch 226: 180/307] 	 train loss: 0.030311 	 lr: 0.00003
[epoch 226: 200/307] 	 train loss: 0.170519 	 lr: 0.00003
[epoch 226: 220/307] 	 train loss: 0.036879 	 lr: 0.00003
[epoch 226: 240/307] 	 train loss: 0.059902 	 lr: 0.00003
[epoch 226: 260/307] 	 train loss: 0.147850 	 lr: 0.00003
[epoch 226: 280/307] 	 train loss: 0.133313 	 lr: 0.00003
[epoch 226: 300/307] 	 train loss: 0.056631 	 lr: 0.00003
[epoch 227:   0/307] 	 train loss: 0.242703 	 lr: 0.00003

val loss: 0.348545 	 acc: 0.910859

[epoch 227:  20/307] 	 train loss: 0.151734 	 lr: 0.00003
[epoch 227:  40/307] 	 train loss: 0.082773 	 lr: 0.00003
[epoch 227:  60/307] 	 train loss: 0.161134 	 lr: 0.00003
[epoch 227:  80/307] 	 train loss: 0.147501 	 lr: 0.00003
[epoch 227: 100/307] 	 train loss: 0.014859 	 lr: 0.00003
[epoch 227: 120/307] 	 train loss: 0.062442 	 lr: 0.00003
[epoch 227: 140/307] 	 train loss: 0.103963 	 lr: 0.00003

val loss: 0.346517 	 acc: 0.910859

[epoch 227: 160/307] 	 train loss: 0.315024 	 lr: 0.00003
[epoch 227: 180/307] 	 train loss: 0.089306 	 lr: 0.00003
[epoch 227: 200/307] 	 train loss: 0.075755 	 lr: 0.00003
[epoch 227: 220/307] 	 train loss: 0.228190 	 lr: 0.00003
[epoch 227: 240/307] 	 train loss: 0.088863 	 lr: 0.00003
[epoch 227: 260/307] 	 train loss: 0.089821 	 lr: 0.00003
[epoch 227: 280/307] 	 train loss: 0.259496 	 lr: 0.00003
[epoch 227: 300/307] 	 train loss: 0.065502 	 lr: 0.00003
[epoch 228:   0/307] 	 train loss: 0.038303 	 lr: 0.00003

val loss: 0.348621 	 acc: 0.910859

[epoch 228:  20/307] 	 train loss: 0.194383 	 lr: 0.00003
[epoch 228:  40/307] 	 train loss: 0.021792 	 lr: 0.00003
[epoch 228:  60/307] 	 train loss: 0.100003 	 lr: 0.00003
[epoch 228:  80/307] 	 train loss: 0.029816 	 lr: 0.00003
[epoch 228: 100/307] 	 train loss: 0.235617 	 lr: 0.00003
[epoch 228: 120/307] 	 train loss: 0.103769 	 lr: 0.00003
[epoch 228: 140/307] 	 train loss: 0.151238 	 lr: 0.00003

val loss: 0.347069 	 acc: 0.912480

[epoch 228: 160/307] 	 train loss: 0.088806 	 lr: 0.00003
[epoch 228: 180/307] 	 train loss: 0.103999 	 lr: 0.00003
[epoch 228: 200/307] 	 train loss: 0.037779 	 lr: 0.00003
[epoch 228: 220/307] 	 train loss: 0.187413 	 lr: 0.00003
[epoch 228: 240/307] 	 train loss: 0.046792 	 lr: 0.00003
[epoch 228: 260/307] 	 train loss: 0.080852 	 lr: 0.00003
[epoch 228: 280/307] 	 train loss: 0.019496 	 lr: 0.00003
[epoch 228: 300/307] 	 train loss: 0.100234 	 lr: 0.00003
[epoch 229:   0/307] 	 train loss: 0.028121 	 lr: 0.00003

val loss: 0.349983 	 acc: 0.910859

[epoch 229:  20/307] 	 train loss: 0.037779 	 lr: 0.00003
[epoch 229:  40/307] 	 train loss: 0.099343 	 lr: 0.00003
[epoch 229:  60/307] 	 train loss: 0.062228 	 lr: 0.00003
[epoch 229:  80/307] 	 train loss: 0.076546 	 lr: 0.00003
[epoch 229: 100/307] 	 train loss: 0.073604 	 lr: 0.00003
[epoch 229: 120/307] 	 train loss: 0.100289 	 lr: 0.00003
[epoch 229: 140/307] 	 train loss: 0.190909 	 lr: 0.00003

val loss: 0.343742 	 acc: 0.912075

[epoch 229: 160/307] 	 train loss: 0.098074 	 lr: 0.00003
[epoch 229: 180/307] 	 train loss: 0.066950 	 lr: 0.00003
[epoch 229: 200/307] 	 train loss: 0.136751 	 lr: 0.00003
[epoch 229: 220/307] 	 train loss: 0.027060 	 lr: 0.00003
[epoch 229: 240/307] 	 train loss: 0.066148 	 lr: 0.00003
[epoch 229: 260/307] 	 train loss: 0.064237 	 lr: 0.00003
[epoch 229: 280/307] 	 train loss: 0.049081 	 lr: 0.00003
[epoch 229: 300/307] 	 train loss: 0.032838 	 lr: 0.00003
[epoch 230:   0/307] 	 train loss: 0.116185 	 lr: 0.00003

val loss: 0.346788 	 acc: 0.913695

[epoch 230:  20/307] 	 train loss: 0.080899 	 lr: 0.00003
[epoch 230:  40/307] 	 train loss: 0.205267 	 lr: 0.00003
[epoch 230:  60/307] 	 train loss: 0.165140 	 lr: 0.00003
[epoch 230:  80/307] 	 train loss: 0.078729 	 lr: 0.00003
[epoch 230: 100/307] 	 train loss: 0.264659 	 lr: 0.00003
[epoch 230: 120/307] 	 train loss: 0.207688 	 lr: 0.00003
[epoch 230: 140/307] 	 train loss: 0.460875 	 lr: 0.00003

val loss: 0.346709 	 acc: 0.910049

[epoch 230: 160/307] 	 train loss: 0.311012 	 lr: 0.00003
[epoch 230: 180/307] 	 train loss: 0.093974 	 lr: 0.00003
[epoch 230: 200/307] 	 train loss: 0.106443 	 lr: 0.00003
[epoch 230: 220/307] 	 train loss: 0.110871 	 lr: 0.00003
[epoch 230: 240/307] 	 train loss: 0.064952 	 lr: 0.00003
[epoch 230: 260/307] 	 train loss: 0.121830 	 lr: 0.00003
[epoch 230: 280/307] 	 train loss: 0.041870 	 lr: 0.00003
[epoch 230: 300/307] 	 train loss: 0.144648 	 lr: 0.00003

val loss: 0.347958 	 acc: 0.912480

[epoch 231:   0/307] 	 train loss: 0.200452 	 lr: 0.00003
[epoch 231:  20/307] 	 train loss: 0.275497 	 lr: 0.00003
[epoch 231:  40/307] 	 train loss: 0.039230 	 lr: 0.00003
[epoch 231:  60/307] 	 train loss: 0.098416 	 lr: 0.00003
[epoch 231:  80/307] 	 train loss: 0.038610 	 lr: 0.00003
[epoch 231: 100/307] 	 train loss: 0.042925 	 lr: 0.00003
[epoch 231: 120/307] 	 train loss: 0.055141 	 lr: 0.00003
[epoch 231: 140/307] 	 train loss: 0.195856 	 lr: 0.00003

val loss: 0.344073 	 acc: 0.911264

[epoch 231: 160/307] 	 train loss: 0.378426 	 lr: 0.00003
[epoch 231: 180/307] 	 train loss: 0.056222 	 lr: 0.00003
[epoch 231: 200/307] 	 train loss: 0.047515 	 lr: 0.00003
[epoch 231: 220/307] 	 train loss: 0.176220 	 lr: 0.00003
[epoch 231: 240/307] 	 train loss: 0.127612 	 lr: 0.00003
[epoch 231: 260/307] 	 train loss: 0.144643 	 lr: 0.00003
[epoch 231: 280/307] 	 train loss: 0.226415 	 lr: 0.00003
[epoch 231: 300/307] 	 train loss: 0.065326 	 lr: 0.00003

val loss: 0.347901 	 acc: 0.913290

[epoch 232:   0/307] 	 train loss: 0.209322 	 lr: 0.00002
[epoch 232:  20/307] 	 train loss: 0.129080 	 lr: 0.00002
[epoch 232:  40/307] 	 train loss: 0.189628 	 lr: 0.00002
[epoch 232:  60/307] 	 train loss: 0.102349 	 lr: 0.00002
[epoch 232:  80/307] 	 train loss: 0.070628 	 lr: 0.00002
[epoch 232: 100/307] 	 train loss: 0.188299 	 lr: 0.00002
[epoch 232: 120/307] 	 train loss: 0.157114 	 lr: 0.00002
[epoch 232: 140/307] 	 train loss: 0.151521 	 lr: 0.00002

val loss: 0.345133 	 acc: 0.912075

[epoch 232: 160/307] 	 train loss: 0.016192 	 lr: 0.00002
[epoch 232: 180/307] 	 train loss: 0.067268 	 lr: 0.00002
[epoch 232: 200/307] 	 train loss: 0.100840 	 lr: 0.00002
[epoch 232: 220/307] 	 train loss: 0.056429 	 lr: 0.00002
[epoch 232: 240/307] 	 train loss: 0.073208 	 lr: 0.00002
[epoch 232: 260/307] 	 train loss: 0.028310 	 lr: 0.00002
[epoch 232: 280/307] 	 train loss: 0.127804 	 lr: 0.00002
[epoch 232: 300/307] 	 train loss: 0.041852 	 lr: 0.00002

val loss: 0.346124 	 acc: 0.912885

[epoch 233:   0/307] 	 train loss: 0.156728 	 lr: 0.00002
[epoch 233:  20/307] 	 train loss: 0.268990 	 lr: 0.00002
[epoch 233:  40/307] 	 train loss: 0.125125 	 lr: 0.00002
[epoch 233:  60/307] 	 train loss: 0.170120 	 lr: 0.00002
[epoch 233:  80/307] 	 train loss: 0.021842 	 lr: 0.00002
[epoch 233: 100/307] 	 train loss: 0.077100 	 lr: 0.00002
[epoch 233: 120/307] 	 train loss: 0.024163 	 lr: 0.00002
[epoch 233: 140/307] 	 train loss: 0.160524 	 lr: 0.00002

val loss: 0.346043 	 acc: 0.912075

[epoch 233: 160/307] 	 train loss: 0.095336 	 lr: 0.00002
[epoch 233: 180/307] 	 train loss: 0.039825 	 lr: 0.00002
[epoch 233: 200/307] 	 train loss: 0.075336 	 lr: 0.00002
[epoch 233: 220/307] 	 train loss: 0.401521 	 lr: 0.00002
[epoch 233: 240/307] 	 train loss: 0.130916 	 lr: 0.00002
[epoch 233: 260/307] 	 train loss: 0.146802 	 lr: 0.00002
[epoch 233: 280/307] 	 train loss: 0.056211 	 lr: 0.00002
[epoch 233: 300/307] 	 train loss: 0.291349 	 lr: 0.00002

val loss: 0.347047 	 acc: 0.911264

[epoch 234:   0/307] 	 train loss: 0.221175 	 lr: 0.00002
[epoch 234:  20/307] 	 train loss: 0.008333 	 lr: 0.00002
[epoch 234:  40/307] 	 train loss: 0.112249 	 lr: 0.00002
[epoch 234:  60/307] 	 train loss: 0.033354 	 lr: 0.00002
[epoch 234:  80/307] 	 train loss: 0.120839 	 lr: 0.00002
[epoch 234: 100/307] 	 train loss: 0.142769 	 lr: 0.00002
[epoch 234: 120/307] 	 train loss: 0.097601 	 lr: 0.00002
[epoch 234: 140/307] 	 train loss: 0.054854 	 lr: 0.00002

val loss: 0.347935 	 acc: 0.910454

[epoch 234: 160/307] 	 train loss: 0.161479 	 lr: 0.00002
[epoch 234: 180/307] 	 train loss: 0.075701 	 lr: 0.00002
[epoch 234: 200/307] 	 train loss: 0.036056 	 lr: 0.00002
[epoch 234: 220/307] 	 train loss: 0.200331 	 lr: 0.00002
[epoch 234: 240/307] 	 train loss: 0.129173 	 lr: 0.00002
[epoch 234: 260/307] 	 train loss: 0.085438 	 lr: 0.00002
[epoch 234: 280/307] 	 train loss: 0.220178 	 lr: 0.00002

val loss: 0.346623 	 acc: 0.913290

[epoch 234: 300/307] 	 train loss: 0.220701 	 lr: 0.00002
[epoch 235:   0/307] 	 train loss: 0.008703 	 lr: 0.00002
[epoch 235:  20/307] 	 train loss: 0.093727 	 lr: 0.00002
[epoch 235:  40/307] 	 train loss: 0.083165 	 lr: 0.00002
[epoch 235:  60/307] 	 train loss: 0.143912 	 lr: 0.00002
[epoch 235:  80/307] 	 train loss: 0.008835 	 lr: 0.00002
[epoch 235: 100/307] 	 train loss: 0.248065 	 lr: 0.00002
[epoch 235: 120/307] 	 train loss: 0.047212 	 lr: 0.00002
[epoch 235: 140/307] 	 train loss: 0.202893 	 lr: 0.00002

val loss: 0.345729 	 acc: 0.912480

[epoch 235: 160/307] 	 train loss: 0.032463 	 lr: 0.00002
[epoch 235: 180/307] 	 train loss: 0.092553 	 lr: 0.00002
[epoch 235: 200/307] 	 train loss: 0.017615 	 lr: 0.00002
[epoch 235: 220/307] 	 train loss: 0.133739 	 lr: 0.00002
[epoch 235: 240/307] 	 train loss: 0.241650 	 lr: 0.00002
[epoch 235: 260/307] 	 train loss: 0.131939 	 lr: 0.00002
[epoch 235: 280/307] 	 train loss: 0.099636 	 lr: 0.00002

val loss: 0.344934 	 acc: 0.914100

[epoch 235: 300/307] 	 train loss: 0.213156 	 lr: 0.00002
[epoch 236:   0/307] 	 train loss: 0.057133 	 lr: 0.00002
[epoch 236:  20/307] 	 train loss: 0.171278 	 lr: 0.00002
[epoch 236:  40/307] 	 train loss: 0.073997 	 lr: 0.00002
[epoch 236:  60/307] 	 train loss: 0.077282 	 lr: 0.00002
[epoch 236:  80/307] 	 train loss: 0.108652 	 lr: 0.00002
[epoch 236: 100/307] 	 train loss: 0.031707 	 lr: 0.00002
[epoch 236: 120/307] 	 train loss: 0.050104 	 lr: 0.00002
[epoch 236: 140/307] 	 train loss: 0.123245 	 lr: 0.00002

val loss: 0.348373 	 acc: 0.913695

[epoch 236: 160/307] 	 train loss: 0.056243 	 lr: 0.00002
[epoch 236: 180/307] 	 train loss: 0.268210 	 lr: 0.00002
[epoch 236: 200/307] 	 train loss: 0.119213 	 lr: 0.00002
[epoch 236: 220/307] 	 train loss: 0.065910 	 lr: 0.00002
[epoch 236: 240/307] 	 train loss: 0.283640 	 lr: 0.00002
[epoch 236: 260/307] 	 train loss: 0.034405 	 lr: 0.00002
[epoch 236: 280/307] 	 train loss: 0.167652 	 lr: 0.00002

val loss: 0.349072 	 acc: 0.912480

[epoch 236: 300/307] 	 train loss: 0.038729 	 lr: 0.00002
[epoch 237:   0/307] 	 train loss: 0.106775 	 lr: 0.00002
[epoch 237:  20/307] 	 train loss: 0.047315 	 lr: 0.00002
[epoch 237:  40/307] 	 train loss: 0.090691 	 lr: 0.00002
[epoch 237:  60/307] 	 train loss: 0.012080 	 lr: 0.00002
[epoch 237:  80/307] 	 train loss: 0.137190 	 lr: 0.00002
[epoch 237: 100/307] 	 train loss: 0.097136 	 lr: 0.00002
[epoch 237: 120/307] 	 train loss: 0.220614 	 lr: 0.00002

val loss: 0.348173 	 acc: 0.910859

[epoch 237: 140/307] 	 train loss: 0.033670 	 lr: 0.00002
[epoch 237: 160/307] 	 train loss: 0.044056 	 lr: 0.00002
[epoch 237: 180/307] 	 train loss: 0.148728 	 lr: 0.00002
[epoch 237: 200/307] 	 train loss: 0.093326 	 lr: 0.00002
[epoch 237: 220/307] 	 train loss: 0.060746 	 lr: 0.00002
[epoch 237: 240/307] 	 train loss: 0.152946 	 lr: 0.00002
[epoch 237: 260/307] 	 train loss: 0.078691 	 lr: 0.00002
[epoch 237: 280/307] 	 train loss: 0.225744 	 lr: 0.00002

val loss: 0.349893 	 acc: 0.910454

[epoch 237: 300/307] 	 train loss: 0.058826 	 lr: 0.00002
[epoch 238:   0/307] 	 train loss: 0.195838 	 lr: 0.00002
[epoch 238:  20/307] 	 train loss: 0.060985 	 lr: 0.00002
[epoch 238:  40/307] 	 train loss: 0.064216 	 lr: 0.00002
[epoch 238:  60/307] 	 train loss: 0.100465 	 lr: 0.00002
[epoch 238:  80/307] 	 train loss: 0.079975 	 lr: 0.00002
[epoch 238: 100/307] 	 train loss: 0.237816 	 lr: 0.00002
[epoch 238: 120/307] 	 train loss: 0.290752 	 lr: 0.00002

val loss: 0.349690 	 acc: 0.911669

[epoch 238: 140/307] 	 train loss: 0.041010 	 lr: 0.00002
[epoch 238: 160/307] 	 train loss: 0.071036 	 lr: 0.00002
[epoch 238: 180/307] 	 train loss: 0.073419 	 lr: 0.00002
[epoch 238: 200/307] 	 train loss: 0.034127 	 lr: 0.00002
[epoch 238: 220/307] 	 train loss: 0.019662 	 lr: 0.00002
[epoch 238: 240/307] 	 train loss: 0.011373 	 lr: 0.00002
[epoch 238: 260/307] 	 train loss: 0.055327 	 lr: 0.00002
[epoch 238: 280/307] 	 train loss: 0.024187 	 lr: 0.00002

val loss: 0.351461 	 acc: 0.910859

[epoch 238: 300/307] 	 train loss: 0.128461 	 lr: 0.00002
[epoch 239:   0/307] 	 train loss: 0.046342 	 lr: 0.00002
[epoch 239:  20/307] 	 train loss: 0.133064 	 lr: 0.00002
[epoch 239:  40/307] 	 train loss: 0.239002 	 lr: 0.00002
[epoch 239:  60/307] 	 train loss: 0.462388 	 lr: 0.00002
[epoch 239:  80/307] 	 train loss: 0.102247 	 lr: 0.00002
[epoch 239: 100/307] 	 train loss: 0.015500 	 lr: 0.00002
[epoch 239: 120/307] 	 train loss: 0.026504 	 lr: 0.00002

val loss: 0.352997 	 acc: 0.910454

[epoch 239: 140/307] 	 train loss: 0.058074 	 lr: 0.00002
[epoch 239: 160/307] 	 train loss: 0.069184 	 lr: 0.00002
[epoch 239: 180/307] 	 train loss: 0.108531 	 lr: 0.00002
[epoch 239: 200/307] 	 train loss: 0.055545 	 lr: 0.00002
[epoch 239: 220/307] 	 train loss: 0.103858 	 lr: 0.00002
[epoch 239: 240/307] 	 train loss: 0.167241 	 lr: 0.00002
[epoch 239: 260/307] 	 train loss: 0.068897 	 lr: 0.00002
[epoch 239: 280/307] 	 train loss: 0.033984 	 lr: 0.00002

val loss: 0.348694 	 acc: 0.910859

[epoch 239: 300/307] 	 train loss: 0.056010 	 lr: 0.00002
[epoch 240:   0/307] 	 train loss: 0.222748 	 lr: 0.00002
[epoch 240:  20/307] 	 train loss: 0.145399 	 lr: 0.00002
[epoch 240:  40/307] 	 train loss: 0.103254 	 lr: 0.00002
[epoch 240:  60/307] 	 train loss: 0.044029 	 lr: 0.00002
[epoch 240:  80/307] 	 train loss: 0.091863 	 lr: 0.00002
[epoch 240: 100/307] 	 train loss: 0.058640 	 lr: 0.00002
[epoch 240: 120/307] 	 train loss: 0.160180 	 lr: 0.00002

val loss: 0.350559 	 acc: 0.910049

[epoch 240: 140/307] 	 train loss: 0.071082 	 lr: 0.00002
[epoch 240: 160/307] 	 train loss: 0.053615 	 lr: 0.00002
[epoch 240: 180/307] 	 train loss: 0.070161 	 lr: 0.00002
[epoch 240: 200/307] 	 train loss: 0.028902 	 lr: 0.00002
[epoch 240: 220/307] 	 train loss: 0.169685 	 lr: 0.00002
[epoch 240: 240/307] 	 train loss: 0.063186 	 lr: 0.00002
[epoch 240: 260/307] 	 train loss: 0.105295 	 lr: 0.00002
[epoch 240: 280/307] 	 train loss: 0.076497 	 lr: 0.00002

val loss: 0.351360 	 acc: 0.909643

[epoch 240: 300/307] 	 train loss: 0.122360 	 lr: 0.00002
[epoch 241:   0/307] 	 train loss: 0.086940 	 lr: 0.00002
[epoch 241:  20/307] 	 train loss: 0.073432 	 lr: 0.00002
[epoch 241:  40/307] 	 train loss: 0.059057 	 lr: 0.00002
[epoch 241:  60/307] 	 train loss: 0.144255 	 lr: 0.00002
[epoch 241:  80/307] 	 train loss: 0.210868 	 lr: 0.00002
[epoch 241: 100/307] 	 train loss: 0.197611 	 lr: 0.00002
[epoch 241: 120/307] 	 train loss: 0.083975 	 lr: 0.00002

val loss: 0.353750 	 acc: 0.910859

[epoch 241: 140/307] 	 train loss: 0.086761 	 lr: 0.00002
[epoch 241: 160/307] 	 train loss: 0.065773 	 lr: 0.00002
[epoch 241: 180/307] 	 train loss: 0.152798 	 lr: 0.00002
[epoch 241: 200/307] 	 train loss: 0.007763 	 lr: 0.00002
[epoch 241: 220/307] 	 train loss: 0.074537 	 lr: 0.00002
[epoch 241: 240/307] 	 train loss: 0.149942 	 lr: 0.00002
[epoch 241: 260/307] 	 train loss: 0.024139 	 lr: 0.00002
[epoch 241: 280/307] 	 train loss: 0.020006 	 lr: 0.00002

val loss: 0.351315 	 acc: 0.910454

[epoch 241: 300/307] 	 train loss: 0.056924 	 lr: 0.00002
[epoch 242:   0/307] 	 train loss: 0.096880 	 lr: 0.00002
[epoch 242:  20/307] 	 train loss: 0.103217 	 lr: 0.00002
[epoch 242:  40/307] 	 train loss: 0.033848 	 lr: 0.00002
[epoch 242:  60/307] 	 train loss: 0.050541 	 lr: 0.00002
[epoch 242:  80/307] 	 train loss: 0.203731 	 lr: 0.00002
[epoch 242: 100/307] 	 train loss: 0.035424 	 lr: 0.00002
[epoch 242: 120/307] 	 train loss: 0.106627 	 lr: 0.00002

val loss: 0.354591 	 acc: 0.911264

[epoch 242: 140/307] 	 train loss: 0.178006 	 lr: 0.00002
[epoch 242: 160/307] 	 train loss: 0.337823 	 lr: 0.00002
[epoch 242: 180/307] 	 train loss: 0.048392 	 lr: 0.00002
[epoch 242: 200/307] 	 train loss: 0.091012 	 lr: 0.00002
[epoch 242: 220/307] 	 train loss: 0.026291 	 lr: 0.00002
[epoch 242: 240/307] 	 train loss: 0.019900 	 lr: 0.00002
[epoch 242: 260/307] 	 train loss: 0.129598 	 lr: 0.00002
[epoch 242: 280/307] 	 train loss: 0.050332 	 lr: 0.00002

val loss: 0.354397 	 acc: 0.910859

[epoch 242: 300/307] 	 train loss: 0.208894 	 lr: 0.00002
[epoch 243:   0/307] 	 train loss: 0.075655 	 lr: 0.00002
[epoch 243:  20/307] 	 train loss: 0.075433 	 lr: 0.00002
[epoch 243:  40/307] 	 train loss: 0.011330 	 lr: 0.00002
[epoch 243:  60/307] 	 train loss: 0.109893 	 lr: 0.00002
[epoch 243:  80/307] 	 train loss: 0.231542 	 lr: 0.00002
[epoch 243: 100/307] 	 train loss: 0.062932 	 lr: 0.00002
[epoch 243: 120/307] 	 train loss: 0.112523 	 lr: 0.00002

val loss: 0.355033 	 acc: 0.909238

[epoch 243: 140/307] 	 train loss: 0.048131 	 lr: 0.00002
[epoch 243: 160/307] 	 train loss: 0.083398 	 lr: 0.00002
[epoch 243: 180/307] 	 train loss: 0.029082 	 lr: 0.00002
[epoch 243: 200/307] 	 train loss: 0.260182 	 lr: 0.00002
[epoch 243: 220/307] 	 train loss: 0.025526 	 lr: 0.00002
[epoch 243: 240/307] 	 train loss: 0.130874 	 lr: 0.00002
[epoch 243: 260/307] 	 train loss: 0.055940 	 lr: 0.00002
[epoch 243: 280/307] 	 train loss: 0.178735 	 lr: 0.00002

val loss: 0.354067 	 acc: 0.909643

[epoch 243: 300/307] 	 train loss: 0.156879 	 lr: 0.00002
[epoch 244:   0/307] 	 train loss: 0.041995 	 lr: 0.00002
[epoch 244:  20/307] 	 train loss: 0.163582 	 lr: 0.00002
[epoch 244:  40/307] 	 train loss: 0.098881 	 lr: 0.00002
[epoch 244:  60/307] 	 train loss: 0.059893 	 lr: 0.00002
[epoch 244:  80/307] 	 train loss: 0.046003 	 lr: 0.00002
[epoch 244: 100/307] 	 train loss: 0.057080 	 lr: 0.00002
[epoch 244: 120/307] 	 train loss: 0.101075 	 lr: 0.00002

val loss: 0.354083 	 acc: 0.911669

[epoch 244: 140/307] 	 train loss: 0.073523 	 lr: 0.00002
[epoch 244: 160/307] 	 train loss: 0.007555 	 lr: 0.00002
[epoch 244: 180/307] 	 train loss: 0.036480 	 lr: 0.00002
[epoch 244: 200/307] 	 train loss: 0.191454 	 lr: 0.00002
[epoch 244: 220/307] 	 train loss: 0.084784 	 lr: 0.00002
[epoch 244: 240/307] 	 train loss: 0.102118 	 lr: 0.00002
[epoch 244: 260/307] 	 train loss: 0.484394 	 lr: 0.00002

val loss: 0.353689 	 acc: 0.911264

[epoch 244: 280/307] 	 train loss: 0.033679 	 lr: 0.00002
[epoch 244: 300/307] 	 train loss: 0.092079 	 lr: 0.00002
[epoch 245:   0/307] 	 train loss: 0.235649 	 lr: 0.00002
[epoch 245:  20/307] 	 train loss: 0.048310 	 lr: 0.00002
[epoch 245:  40/307] 	 train loss: 0.092733 	 lr: 0.00002
[epoch 245:  60/307] 	 train loss: 0.110446 	 lr: 0.00002
[epoch 245:  80/307] 	 train loss: 0.121424 	 lr: 0.00002
[epoch 245: 100/307] 	 train loss: 0.037819 	 lr: 0.00002
[epoch 245: 120/307] 	 train loss: 0.216420 	 lr: 0.00002

val loss: 0.353439 	 acc: 0.911264

[epoch 245: 140/307] 	 train loss: 0.026779 	 lr: 0.00002
[epoch 245: 160/307] 	 train loss: 0.053440 	 lr: 0.00002
[epoch 245: 180/307] 	 train loss: 0.062121 	 lr: 0.00002
[epoch 245: 200/307] 	 train loss: 0.082779 	 lr: 0.00002
[epoch 245: 220/307] 	 train loss: 0.048399 	 lr: 0.00002
[epoch 245: 240/307] 	 train loss: 0.162667 	 lr: 0.00002
[epoch 245: 260/307] 	 train loss: 0.028910 	 lr: 0.00002

val loss: 0.351552 	 acc: 0.912885

[epoch 245: 280/307] 	 train loss: 0.011496 	 lr: 0.00002
[epoch 245: 300/307] 	 train loss: 0.089280 	 lr: 0.00002
[epoch 246:   0/307] 	 train loss: 0.116097 	 lr: 0.00002
[epoch 246:  20/307] 	 train loss: 0.224797 	 lr: 0.00002
[epoch 246:  40/307] 	 train loss: 0.103195 	 lr: 0.00002
[epoch 246:  60/307] 	 train loss: 0.085915 	 lr: 0.00002
[epoch 246:  80/307] 	 train loss: 0.023837 	 lr: 0.00002
[epoch 246: 100/307] 	 train loss: 0.187322 	 lr: 0.00002
[epoch 246: 120/307] 	 train loss: 0.179547 	 lr: 0.00002

val loss: 0.353370 	 acc: 0.909643

[epoch 246: 140/307] 	 train loss: 0.078358 	 lr: 0.00002
[epoch 246: 160/307] 	 train loss: 0.161406 	 lr: 0.00002
[epoch 246: 180/307] 	 train loss: 0.184250 	 lr: 0.00002
[epoch 246: 200/307] 	 train loss: 0.087416 	 lr: 0.00002
[epoch 246: 220/307] 	 train loss: 0.048628 	 lr: 0.00002
[epoch 246: 240/307] 	 train loss: 0.125208 	 lr: 0.00002
[epoch 246: 260/307] 	 train loss: 0.208723 	 lr: 0.00002

val loss: 0.351925 	 acc: 0.910454

[epoch 246: 280/307] 	 train loss: 0.072105 	 lr: 0.00002
[epoch 246: 300/307] 	 train loss: 0.082617 	 lr: 0.00002
[epoch 247:   0/307] 	 train loss: 0.247122 	 lr: 0.00002
[epoch 247:  20/307] 	 train loss: 0.186550 	 lr: 0.00002
[epoch 247:  40/307] 	 train loss: 0.072377 	 lr: 0.00002
[epoch 247:  60/307] 	 train loss: 0.135451 	 lr: 0.00002
[epoch 247:  80/307] 	 train loss: 0.064697 	 lr: 0.00002
[epoch 247: 100/307] 	 train loss: 0.087709 	 lr: 0.00002

val loss: 0.354113 	 acc: 0.909238

[epoch 247: 120/307] 	 train loss: 0.179346 	 lr: 0.00002
[epoch 247: 140/307] 	 train loss: 0.080829 	 lr: 0.00002
[epoch 247: 160/307] 	 train loss: 0.153295 	 lr: 0.00002
[epoch 247: 180/307] 	 train loss: 0.032633 	 lr: 0.00002
[epoch 247: 200/307] 	 train loss: 0.145620 	 lr: 0.00002
[epoch 247: 220/307] 	 train loss: 0.068486 	 lr: 0.00002
[epoch 247: 240/307] 	 train loss: 0.388104 	 lr: 0.00002
[epoch 247: 260/307] 	 train loss: 0.217436 	 lr: 0.00002

val loss: 0.356136 	 acc: 0.909643

[epoch 247: 280/307] 	 train loss: 0.191033 	 lr: 0.00002
[epoch 247: 300/307] 	 train loss: 0.126222 	 lr: 0.00002
[epoch 248:   0/307] 	 train loss: 0.016465 	 lr: 0.00002
[epoch 248:  20/307] 	 train loss: 0.227371 	 lr: 0.00002
[epoch 248:  40/307] 	 train loss: 0.187587 	 lr: 0.00002
[epoch 248:  60/307] 	 train loss: 0.165690 	 lr: 0.00002
[epoch 248:  80/307] 	 train loss: 0.029434 	 lr: 0.00002
[epoch 248: 100/307] 	 train loss: 0.111179 	 lr: 0.00002

val loss: 0.354418 	 acc: 0.911264

[epoch 248: 120/307] 	 train loss: 0.229023 	 lr: 0.00002
[epoch 248: 140/307] 	 train loss: 0.060777 	 lr: 0.00002
[epoch 248: 160/307] 	 train loss: 0.214848 	 lr: 0.00002
[epoch 248: 180/307] 	 train loss: 0.054156 	 lr: 0.00002
[epoch 248: 200/307] 	 train loss: 0.050405 	 lr: 0.00002
[epoch 248: 220/307] 	 train loss: 0.127241 	 lr: 0.00002
[epoch 248: 240/307] 	 train loss: 0.074229 	 lr: 0.00002
[epoch 248: 260/307] 	 train loss: 0.312610 	 lr: 0.00002

val loss: 0.354634 	 acc: 0.913695

[epoch 248: 280/307] 	 train loss: 0.197800 	 lr: 0.00002
[epoch 248: 300/307] 	 train loss: 0.110719 	 lr: 0.00002
[epoch 249:   0/307] 	 train loss: 0.146383 	 lr: 0.00002
[epoch 249:  20/307] 	 train loss: 0.039047 	 lr: 0.00002
[epoch 249:  40/307] 	 train loss: 0.063793 	 lr: 0.00002
[epoch 249:  60/307] 	 train loss: 0.079156 	 lr: 0.00002
[epoch 249:  80/307] 	 train loss: 0.140191 	 lr: 0.00002
[epoch 249: 100/307] 	 train loss: 0.158641 	 lr: 0.00002

val loss: 0.358633 	 acc: 0.912480

[epoch 249: 120/307] 	 train loss: 0.212160 	 lr: 0.00002
[epoch 249: 140/307] 	 train loss: 0.149047 	 lr: 0.00002
[epoch 249: 160/307] 	 train loss: 0.183581 	 lr: 0.00002
[epoch 249: 180/307] 	 train loss: 0.093858 	 lr: 0.00002
[epoch 249: 200/307] 	 train loss: 0.080692 	 lr: 0.00002
[epoch 249: 220/307] 	 train loss: 0.146959 	 lr: 0.00002
[epoch 249: 240/307] 	 train loss: 0.106492 	 lr: 0.00002
[epoch 249: 260/307] 	 train loss: 0.115331 	 lr: 0.00002

val loss: 0.356921 	 acc: 0.910049

[epoch 249: 280/307] 	 train loss: 0.044166 	 lr: 0.00002
[epoch 249: 300/307] 	 train loss: 0.089116 	 lr: 0.00002
[epoch 250:   0/307] 	 train loss: 0.130462 	 lr: 0.00002
[epoch 250:  20/307] 	 train loss: 0.251017 	 lr: 0.00002
[epoch 250:  40/307] 	 train loss: 0.087249 	 lr: 0.00002
[epoch 250:  60/307] 	 train loss: 0.088509 	 lr: 0.00002
[epoch 250:  80/307] 	 train loss: 0.066621 	 lr: 0.00002
[epoch 250: 100/307] 	 train loss: 0.061754 	 lr: 0.00002

val loss: 0.353755 	 acc: 0.910049

[epoch 250: 120/307] 	 train loss: 0.262385 	 lr: 0.00002
[epoch 250: 140/307] 	 train loss: 0.132209 	 lr: 0.00002
[epoch 250: 160/307] 	 train loss: 0.223903 	 lr: 0.00002
[epoch 250: 180/307] 	 train loss: 0.018441 	 lr: 0.00002
[epoch 250: 200/307] 	 train loss: 0.073531 	 lr: 0.00002
[epoch 250: 220/307] 	 train loss: 0.070932 	 lr: 0.00002
[epoch 250: 240/307] 	 train loss: 0.094105 	 lr: 0.00002
[epoch 250: 260/307] 	 train loss: 0.139386 	 lr: 0.00002

val loss: 0.355480 	 acc: 0.912480

[epoch 250: 280/307] 	 train loss: 0.063867 	 lr: 0.00002
[epoch 250: 300/307] 	 train loss: 0.077632 	 lr: 0.00002
[epoch 251:   0/307] 	 train loss: 0.042236 	 lr: 0.00002
[epoch 251:  20/307] 	 train loss: 0.125180 	 lr: 0.00002
[epoch 251:  40/307] 	 train loss: 0.273731 	 lr: 0.00002
[epoch 251:  60/307] 	 train loss: 0.023271 	 lr: 0.00002
[epoch 251:  80/307] 	 train loss: 0.090828 	 lr: 0.00002
[epoch 251: 100/307] 	 train loss: 0.214162 	 lr: 0.00002

val loss: 0.354735 	 acc: 0.912075

[epoch 251: 120/307] 	 train loss: 0.057947 	 lr: 0.00002
[epoch 251: 140/307] 	 train loss: 0.100535 	 lr: 0.00002
[epoch 251: 160/307] 	 train loss: 0.103413 	 lr: 0.00002
[epoch 251: 180/307] 	 train loss: 0.100604 	 lr: 0.00002
[epoch 251: 200/307] 	 train loss: 0.047896 	 lr: 0.00002
[epoch 251: 220/307] 	 train loss: 0.040226 	 lr: 0.00002
[epoch 251: 240/307] 	 train loss: 0.100282 	 lr: 0.00002
[epoch 251: 260/307] 	 train loss: 0.186908 	 lr: 0.00002

val loss: 0.351482 	 acc: 0.911264

[epoch 251: 280/307] 	 train loss: 0.098010 	 lr: 0.00002
[epoch 251: 300/307] 	 train loss: 0.017611 	 lr: 0.00002
[epoch 252:   0/307] 	 train loss: 0.104676 	 lr: 0.00002
[epoch 252:  20/307] 	 train loss: 0.047805 	 lr: 0.00002
[epoch 252:  40/307] 	 train loss: 0.114298 	 lr: 0.00002
[epoch 252:  60/307] 	 train loss: 0.078549 	 lr: 0.00002
[epoch 252:  80/307] 	 train loss: 0.110164 	 lr: 0.00002
[epoch 252: 100/307] 	 train loss: 0.052522 	 lr: 0.00002

val loss: 0.353848 	 acc: 0.912480

[epoch 252: 120/307] 	 train loss: 0.034399 	 lr: 0.00002
[epoch 252: 140/307] 	 train loss: 0.093905 	 lr: 0.00002
[epoch 252: 160/307] 	 train loss: 0.132055 	 lr: 0.00002
[epoch 252: 180/307] 	 train loss: 0.033594 	 lr: 0.00002
[epoch 252: 200/307] 	 train loss: 0.014437 	 lr: 0.00002
[epoch 252: 220/307] 	 train loss: 0.112125 	 lr: 0.00002
[epoch 252: 240/307] 	 train loss: 0.046946 	 lr: 0.00002
[epoch 252: 260/307] 	 train loss: 0.103768 	 lr: 0.00002

val loss: 0.351595 	 acc: 0.912885

[epoch 252: 280/307] 	 train loss: 0.126862 	 lr: 0.00002
[epoch 252: 300/307] 	 train loss: 0.114418 	 lr: 0.00002
[epoch 253:   0/307] 	 train loss: 0.031253 	 lr: 0.00001
[epoch 253:  20/307] 	 train loss: 0.052553 	 lr: 0.00001
[epoch 253:  40/307] 	 train loss: 0.164337 	 lr: 0.00001
[epoch 253:  60/307] 	 train loss: 0.081417 	 lr: 0.00001
[epoch 253:  80/307] 	 train loss: 0.111731 	 lr: 0.00001
[epoch 253: 100/307] 	 train loss: 0.220359 	 lr: 0.00001

val loss: 0.350143 	 acc: 0.912885

[epoch 253: 120/307] 	 train loss: 0.092120 	 lr: 0.00001
[epoch 253: 140/307] 	 train loss: 0.028712 	 lr: 0.00001
[epoch 253: 160/307] 	 train loss: 0.104527 	 lr: 0.00001
[epoch 253: 180/307] 	 train loss: 0.203853 	 lr: 0.00001
[epoch 253: 200/307] 	 train loss: 0.334124 	 lr: 0.00001
[epoch 253: 220/307] 	 train loss: 0.045268 	 lr: 0.00001
[epoch 253: 240/307] 	 train loss: 0.152380 	 lr: 0.00001
[epoch 253: 260/307] 	 train loss: 0.065178 	 lr: 0.00001

val loss: 0.350431 	 acc: 0.913290

[epoch 253: 280/307] 	 train loss: 0.092043 	 lr: 0.00001
[epoch 253: 300/307] 	 train loss: 0.035454 	 lr: 0.00001
[epoch 254:   0/307] 	 train loss: 0.117987 	 lr: 0.00001
[epoch 254:  20/307] 	 train loss: 0.007599 	 lr: 0.00001
[epoch 254:  40/307] 	 train loss: 0.036313 	 lr: 0.00001
[epoch 254:  60/307] 	 train loss: 0.092710 	 lr: 0.00001
[epoch 254:  80/307] 	 train loss: 0.013895 	 lr: 0.00001
[epoch 254: 100/307] 	 train loss: 0.120353 	 lr: 0.00001

val loss: 0.352571 	 acc: 0.913290

[epoch 254: 120/307] 	 train loss: 0.036109 	 lr: 0.00001
[epoch 254: 140/307] 	 train loss: 0.242628 	 lr: 0.00001
[epoch 254: 160/307] 	 train loss: 0.152603 	 lr: 0.00001
[epoch 254: 180/307] 	 train loss: 0.139039 	 lr: 0.00001
[epoch 254: 200/307] 	 train loss: 0.060155 	 lr: 0.00001
[epoch 254: 220/307] 	 train loss: 0.078708 	 lr: 0.00001
[epoch 254: 240/307] 	 train loss: 0.037123 	 lr: 0.00001

val loss: 0.353837 	 acc: 0.912885

[epoch 254: 260/307] 	 train loss: 0.147381 	 lr: 0.00001
[epoch 254: 280/307] 	 train loss: 0.110440 	 lr: 0.00001
[epoch 254: 300/307] 	 train loss: 0.142908 	 lr: 0.00001
[epoch 255:   0/307] 	 train loss: 0.142390 	 lr: 0.00001
[epoch 255:  20/307] 	 train loss: 0.015713 	 lr: 0.00001
[epoch 255:  40/307] 	 train loss: 0.054759 	 lr: 0.00001
[epoch 255:  60/307] 	 train loss: 0.108245 	 lr: 0.00001
[epoch 255:  80/307] 	 train loss: 0.067722 	 lr: 0.00001
[epoch 255: 100/307] 	 train loss: 0.070328 	 lr: 0.00001

val loss: 0.352360 	 acc: 0.912885

[epoch 255: 120/307] 	 train loss: 0.167928 	 lr: 0.00001
[epoch 255: 140/307] 	 train loss: 0.142486 	 lr: 0.00001
[epoch 255: 160/307] 	 train loss: 0.038819 	 lr: 0.00001
[epoch 255: 180/307] 	 train loss: 0.076185 	 lr: 0.00001
[epoch 255: 200/307] 	 train loss: 0.131183 	 lr: 0.00001
[epoch 255: 220/307] 	 train loss: 0.111356 	 lr: 0.00001
[epoch 255: 240/307] 	 train loss: 0.117754 	 lr: 0.00001

val loss: 0.351138 	 acc: 0.913290

[epoch 255: 260/307] 	 train loss: 0.108452 	 lr: 0.00001
[epoch 255: 280/307] 	 train loss: 0.120059 	 lr: 0.00001
[epoch 255: 300/307] 	 train loss: 0.078913 	 lr: 0.00001
[epoch 256:   0/307] 	 train loss: 0.076134 	 lr: 0.00001
[epoch 256:  20/307] 	 train loss: 0.141562 	 lr: 0.00001
[epoch 256:  40/307] 	 train loss: 0.145508 	 lr: 0.00001
[epoch 256:  60/307] 	 train loss: 0.261389 	 lr: 0.00001
[epoch 256:  80/307] 	 train loss: 0.080909 	 lr: 0.00001
[epoch 256: 100/307] 	 train loss: 0.010389 	 lr: 0.00001

val loss: 0.351191 	 acc: 0.913695

[epoch 256: 120/307] 	 train loss: 0.113440 	 lr: 0.00001
[epoch 256: 140/307] 	 train loss: 0.060712 	 lr: 0.00001
[epoch 256: 160/307] 	 train loss: 0.202831 	 lr: 0.00001
[epoch 256: 180/307] 	 train loss: 0.311229 	 lr: 0.00001
[epoch 256: 200/307] 	 train loss: 0.161187 	 lr: 0.00001
[epoch 256: 220/307] 	 train loss: 0.235131 	 lr: 0.00001
[epoch 256: 240/307] 	 train loss: 0.106168 	 lr: 0.00001

val loss: 0.351536 	 acc: 0.913695

[epoch 256: 260/307] 	 train loss: 0.111376 	 lr: 0.00001
[epoch 256: 280/307] 	 train loss: 0.124562 	 lr: 0.00001
[epoch 256: 300/307] 	 train loss: 0.099489 	 lr: 0.00001
[epoch 257:   0/307] 	 train loss: 0.077423 	 lr: 0.00001
[epoch 257:  20/307] 	 train loss: 0.151417 	 lr: 0.00001
[epoch 257:  40/307] 	 train loss: 0.026547 	 lr: 0.00001
[epoch 257:  60/307] 	 train loss: 0.060621 	 lr: 0.00001
[epoch 257:  80/307] 	 train loss: 0.177812 	 lr: 0.00001

val loss: 0.348470 	 acc: 0.914100

[epoch 257: 100/307] 	 train loss: 0.044043 	 lr: 0.00001
[epoch 257: 120/307] 	 train loss: 0.090816 	 lr: 0.00001
[epoch 257: 140/307] 	 train loss: 0.163752 	 lr: 0.00001
[epoch 257: 160/307] 	 train loss: 0.140495 	 lr: 0.00001
[epoch 257: 180/307] 	 train loss: 0.216679 	 lr: 0.00001
[epoch 257: 200/307] 	 train loss: 0.083160 	 lr: 0.00001
[epoch 257: 220/307] 	 train loss: 0.083296 	 lr: 0.00001
[epoch 257: 240/307] 	 train loss: 0.059475 	 lr: 0.00001

val loss: 0.350871 	 acc: 0.912075

[epoch 257: 260/307] 	 train loss: 0.111186 	 lr: 0.00001
[epoch 257: 280/307] 	 train loss: 0.079486 	 lr: 0.00001
[epoch 257: 300/307] 	 train loss: 0.072732 	 lr: 0.00001
[epoch 258:   0/307] 	 train loss: 0.089939 	 lr: 0.00001
[epoch 258:  20/307] 	 train loss: 0.030150 	 lr: 0.00001
[epoch 258:  40/307] 	 train loss: 0.085150 	 lr: 0.00001
[epoch 258:  60/307] 	 train loss: 0.248575 	 lr: 0.00001
[epoch 258:  80/307] 	 train loss: 0.149775 	 lr: 0.00001

val loss: 0.352769 	 acc: 0.912075

[epoch 258: 100/307] 	 train loss: 0.023923 	 lr: 0.00001
[epoch 258: 120/307] 	 train loss: 0.074340 	 lr: 0.00001
[epoch 258: 140/307] 	 train loss: 0.159096 	 lr: 0.00001
[epoch 258: 160/307] 	 train loss: 0.098438 	 lr: 0.00001
[epoch 258: 180/307] 	 train loss: 0.045441 	 lr: 0.00001
[epoch 258: 200/307] 	 train loss: 0.162061 	 lr: 0.00001
[epoch 258: 220/307] 	 train loss: 0.032088 	 lr: 0.00001
[epoch 258: 240/307] 	 train loss: 0.076246 	 lr: 0.00001

val loss: 0.352154 	 acc: 0.911264

[epoch 258: 260/307] 	 train loss: 0.103829 	 lr: 0.00001
[epoch 258: 280/307] 	 train loss: 0.121145 	 lr: 0.00001
[epoch 258: 300/307] 	 train loss: 0.118803 	 lr: 0.00001
[epoch 259:   0/307] 	 train loss: 0.259775 	 lr: 0.00001
[epoch 259:  20/307] 	 train loss: 0.146458 	 lr: 0.00001
[epoch 259:  40/307] 	 train loss: 0.253515 	 lr: 0.00001
[epoch 259:  60/307] 	 train loss: 0.084311 	 lr: 0.00001
[epoch 259:  80/307] 	 train loss: 0.034965 	 lr: 0.00001

val loss: 0.353302 	 acc: 0.912075

[epoch 259: 100/307] 	 train loss: 0.014730 	 lr: 0.00001
[epoch 259: 120/307] 	 train loss: 0.119343 	 lr: 0.00001
[epoch 259: 140/307] 	 train loss: 0.093116 	 lr: 0.00001
[epoch 259: 160/307] 	 train loss: 0.019386 	 lr: 0.00001
[epoch 259: 180/307] 	 train loss: 0.140498 	 lr: 0.00001
[epoch 259: 200/307] 	 train loss: 0.036553 	 lr: 0.00001
[epoch 259: 220/307] 	 train loss: 0.055033 	 lr: 0.00001
[epoch 259: 240/307] 	 train loss: 0.033372 	 lr: 0.00001

val loss: 0.354696 	 acc: 0.911264

[epoch 259: 260/307] 	 train loss: 0.055799 	 lr: 0.00001
[epoch 259: 280/307] 	 train loss: 0.037714 	 lr: 0.00001
[epoch 259: 300/307] 	 train loss: 0.073839 	 lr: 0.00001
[epoch 260:   0/307] 	 train loss: 0.131627 	 lr: 0.00001
[epoch 260:  20/307] 	 train loss: 0.173588 	 lr: 0.00001
[epoch 260:  40/307] 	 train loss: 0.306772 	 lr: 0.00001
[epoch 260:  60/307] 	 train loss: 0.071820 	 lr: 0.00001
[epoch 260:  80/307] 	 train loss: 0.039446 	 lr: 0.00001

val loss: 0.357130 	 acc: 0.910859

[epoch 260: 100/307] 	 train loss: 0.074955 	 lr: 0.00001
[epoch 260: 120/307] 	 train loss: 0.103714 	 lr: 0.00001
[epoch 260: 140/307] 	 train loss: 0.163785 	 lr: 0.00001
[epoch 260: 160/307] 	 train loss: 0.120458 	 lr: 0.00001
[epoch 260: 180/307] 	 train loss: 0.542716 	 lr: 0.00001
[epoch 260: 200/307] 	 train loss: 0.063209 	 lr: 0.00001
[epoch 260: 220/307] 	 train loss: 0.101921 	 lr: 0.00001
[epoch 260: 240/307] 	 train loss: 0.223234 	 lr: 0.00001

val loss: 0.354169 	 acc: 0.911264

[epoch 260: 260/307] 	 train loss: 0.158602 	 lr: 0.00001
[epoch 260: 280/307] 	 train loss: 0.124637 	 lr: 0.00001
[epoch 260: 300/307] 	 train loss: 0.178489 	 lr: 0.00001
[epoch 261:   0/307] 	 train loss: 0.204667 	 lr: 0.00001
[epoch 261:  20/307] 	 train loss: 0.104398 	 lr: 0.00001
[epoch 261:  40/307] 	 train loss: 0.018539 	 lr: 0.00001
[epoch 261:  60/307] 	 train loss: 0.149766 	 lr: 0.00001
[epoch 261:  80/307] 	 train loss: 0.175221 	 lr: 0.00001

val loss: 0.355878 	 acc: 0.912075

[epoch 261: 100/307] 	 train loss: 0.053326 	 lr: 0.00001
[epoch 261: 120/307] 	 train loss: 0.116472 	 lr: 0.00001
[epoch 261: 140/307] 	 train loss: 0.042144 	 lr: 0.00001
[epoch 261: 160/307] 	 train loss: 0.250710 	 lr: 0.00001
[epoch 261: 180/307] 	 train loss: 0.097510 	 lr: 0.00001
[epoch 261: 200/307] 	 train loss: 0.030068 	 lr: 0.00001
[epoch 261: 220/307] 	 train loss: 0.230265 	 lr: 0.00001
[epoch 261: 240/307] 	 train loss: 0.042223 	 lr: 0.00001

val loss: 0.355102 	 acc: 0.910049

[epoch 261: 260/307] 	 train loss: 0.087207 	 lr: 0.00001
[epoch 261: 280/307] 	 train loss: 0.039704 	 lr: 0.00001
[epoch 261: 300/307] 	 train loss: 0.101023 	 lr: 0.00001
[epoch 262:   0/307] 	 train loss: 0.056288 	 lr: 0.00001
[epoch 262:  20/307] 	 train loss: 0.130190 	 lr: 0.00001
[epoch 262:  40/307] 	 train loss: 0.094187 	 lr: 0.00001
[epoch 262:  60/307] 	 train loss: 0.283619 	 lr: 0.00001
[epoch 262:  80/307] 	 train loss: 0.020263 	 lr: 0.00001

val loss: 0.355584 	 acc: 0.911264

[epoch 262: 100/307] 	 train loss: 0.042019 	 lr: 0.00001
[epoch 262: 120/307] 	 train loss: 0.103365 	 lr: 0.00001
[epoch 262: 140/307] 	 train loss: 0.030367 	 lr: 0.00001
[epoch 262: 160/307] 	 train loss: 0.124283 	 lr: 0.00001
[epoch 262: 180/307] 	 train loss: 0.069649 	 lr: 0.00001
[epoch 262: 200/307] 	 train loss: 0.140282 	 lr: 0.00001
[epoch 262: 220/307] 	 train loss: 0.069301 	 lr: 0.00001
[epoch 262: 240/307] 	 train loss: 0.121893 	 lr: 0.00001

val loss: 0.351974 	 acc: 0.912075

[epoch 262: 260/307] 	 train loss: 0.055142 	 lr: 0.00001
[epoch 262: 280/307] 	 train loss: 0.281389 	 lr: 0.00001
[epoch 262: 300/307] 	 train loss: 0.240397 	 lr: 0.00001
[epoch 263:   0/307] 	 train loss: 0.147988 	 lr: 0.00001
[epoch 263:  20/307] 	 train loss: 0.072480 	 lr: 0.00001
[epoch 263:  40/307] 	 train loss: 0.159802 	 lr: 0.00001
[epoch 263:  60/307] 	 train loss: 0.029126 	 lr: 0.00001
[epoch 263:  80/307] 	 train loss: 0.131171 	 lr: 0.00001

val loss: 0.352316 	 acc: 0.913695

[epoch 263: 100/307] 	 train loss: 0.099519 	 lr: 0.00001
[epoch 263: 120/307] 	 train loss: 0.154578 	 lr: 0.00001
[epoch 263: 140/307] 	 train loss: 0.181686 	 lr: 0.00001
[epoch 263: 160/307] 	 train loss: 0.083852 	 lr: 0.00001
[epoch 263: 180/307] 	 train loss: 0.061350 	 lr: 0.00001
[epoch 263: 200/307] 	 train loss: 0.101740 	 lr: 0.00001
[epoch 263: 220/307] 	 train loss: 0.148874 	 lr: 0.00001
[epoch 263: 240/307] 	 train loss: 0.131405 	 lr: 0.00001

val loss: 0.350766 	 acc: 0.911669

[epoch 263: 260/307] 	 train loss: 0.045276 	 lr: 0.00001
[epoch 263: 280/307] 	 train loss: 0.029987 	 lr: 0.00001
[epoch 263: 300/307] 	 train loss: 0.075264 	 lr: 0.00001
[epoch 264:   0/307] 	 train loss: 0.013199 	 lr: 0.00001
[epoch 264:  20/307] 	 train loss: 0.067632 	 lr: 0.00001
[epoch 264:  40/307] 	 train loss: 0.129067 	 lr: 0.00001
[epoch 264:  60/307] 	 train loss: 0.083620 	 lr: 0.00001
[epoch 264:  80/307] 	 train loss: 0.071459 	 lr: 0.00001

val loss: 0.353221 	 acc: 0.913290

[epoch 264: 100/307] 	 train loss: 0.166121 	 lr: 0.00001
[epoch 264: 120/307] 	 train loss: 0.014599 	 lr: 0.00001
[epoch 264: 140/307] 	 train loss: 0.053677 	 lr: 0.00001
[epoch 264: 160/307] 	 train loss: 0.195219 	 lr: 0.00001
[epoch 264: 180/307] 	 train loss: 0.117546 	 lr: 0.00001
[epoch 264: 200/307] 	 train loss: 0.098463 	 lr: 0.00001
[epoch 264: 220/307] 	 train loss: 0.023865 	 lr: 0.00001

val loss: 0.355140 	 acc: 0.913290

[epoch 264: 240/307] 	 train loss: 0.059811 	 lr: 0.00001
[epoch 264: 260/307] 	 train loss: 0.058341 	 lr: 0.00001
[epoch 264: 280/307] 	 train loss: 0.136217 	 lr: 0.00001
[epoch 264: 300/307] 	 train loss: 0.055200 	 lr: 0.00001
[epoch 265:   0/307] 	 train loss: 0.327999 	 lr: 0.00001
[epoch 265:  20/307] 	 train loss: 0.065119 	 lr: 0.00001
[epoch 265:  40/307] 	 train loss: 0.133747 	 lr: 0.00001
[epoch 265:  60/307] 	 train loss: 0.202573 	 lr: 0.00001
[epoch 265:  80/307] 	 train loss: 0.031895 	 lr: 0.00001

val loss: 0.351160 	 acc: 0.913290

[epoch 265: 100/307] 	 train loss: 0.068309 	 lr: 0.00001
[epoch 265: 120/307] 	 train loss: 0.079589 	 lr: 0.00001
[epoch 265: 140/307] 	 train loss: 0.334901 	 lr: 0.00001
[epoch 265: 160/307] 	 train loss: 0.148154 	 lr: 0.00001
[epoch 265: 180/307] 	 train loss: 0.175915 	 lr: 0.00001
[epoch 265: 200/307] 	 train loss: 0.044600 	 lr: 0.00001
[epoch 265: 220/307] 	 train loss: 0.089257 	 lr: 0.00001

val loss: 0.351957 	 acc: 0.912480

[epoch 265: 240/307] 	 train loss: 0.163130 	 lr: 0.00001
[epoch 265: 260/307] 	 train loss: 0.022292 	 lr: 0.00001
[epoch 265: 280/307] 	 train loss: 0.243172 	 lr: 0.00001
[epoch 265: 300/307] 	 train loss: 0.065936 	 lr: 0.00001
[epoch 266:   0/307] 	 train loss: 0.153115 	 lr: 0.00001
[epoch 266:  20/307] 	 train loss: 0.042496 	 lr: 0.00001
[epoch 266:  40/307] 	 train loss: 0.037956 	 lr: 0.00001
[epoch 266:  60/307] 	 train loss: 0.034893 	 lr: 0.00001
[epoch 266:  80/307] 	 train loss: 0.158550 	 lr: 0.00001

val loss: 0.350674 	 acc: 0.913695

[epoch 266: 100/307] 	 train loss: 0.349529 	 lr: 0.00001
[epoch 266: 120/307] 	 train loss: 0.158486 	 lr: 0.00001
[epoch 266: 140/307] 	 train loss: 0.374526 	 lr: 0.00001
[epoch 266: 160/307] 	 train loss: 0.329378 	 lr: 0.00001
[epoch 266: 180/307] 	 train loss: 0.021540 	 lr: 0.00001
[epoch 266: 200/307] 	 train loss: 0.092084 	 lr: 0.00001
[epoch 266: 220/307] 	 train loss: 0.096828 	 lr: 0.00001

val loss: 0.350811 	 acc: 0.913290

[epoch 266: 240/307] 	 train loss: 0.092574 	 lr: 0.00001
[epoch 266: 260/307] 	 train loss: 0.185966 	 lr: 0.00001
[epoch 266: 280/307] 	 train loss: 0.056637 	 lr: 0.00001
[epoch 266: 300/307] 	 train loss: 0.088121 	 lr: 0.00001
[epoch 267:   0/307] 	 train loss: 0.016887 	 lr: 0.00001
[epoch 267:  20/307] 	 train loss: 0.086929 	 lr: 0.00001
[epoch 267:  40/307] 	 train loss: 0.053572 	 lr: 0.00001
[epoch 267:  60/307] 	 train loss: 0.122320 	 lr: 0.00001

val loss: 0.348859 	 acc: 0.914100

[epoch 267:  80/307] 	 train loss: 0.028218 	 lr: 0.00001
[epoch 267: 100/307] 	 train loss: 0.151234 	 lr: 0.00001
[epoch 267: 120/307] 	 train loss: 0.063472 	 lr: 0.00001
[epoch 267: 140/307] 	 train loss: 0.223675 	 lr: 0.00001
[epoch 267: 160/307] 	 train loss: 0.061636 	 lr: 0.00001
[epoch 267: 180/307] 	 train loss: 0.216217 	 lr: 0.00001
[epoch 267: 200/307] 	 train loss: 0.103558 	 lr: 0.00001
[epoch 267: 220/307] 	 train loss: 0.040943 	 lr: 0.00001

val loss: 0.349490 	 acc: 0.912075

[epoch 267: 240/307] 	 train loss: 0.189057 	 lr: 0.00001
[epoch 267: 260/307] 	 train loss: 0.185404 	 lr: 0.00001
[epoch 267: 280/307] 	 train loss: 0.136770 	 lr: 0.00001
[epoch 267: 300/307] 	 train loss: 0.025361 	 lr: 0.00001
[epoch 268:   0/307] 	 train loss: 0.107044 	 lr: 0.00001
[epoch 268:  20/307] 	 train loss: 0.077906 	 lr: 0.00001
[epoch 268:  40/307] 	 train loss: 0.147316 	 lr: 0.00001
[epoch 268:  60/307] 	 train loss: 0.167353 	 lr: 0.00001

val loss: 0.352579 	 acc: 0.912480

[epoch 268:  80/307] 	 train loss: 0.040424 	 lr: 0.00001
[epoch 268: 100/307] 	 train loss: 0.103765 	 lr: 0.00001
[epoch 268: 120/307] 	 train loss: 0.100842 	 lr: 0.00001
[epoch 268: 140/307] 	 train loss: 0.134140 	 lr: 0.00001
[epoch 268: 160/307] 	 train loss: 0.171547 	 lr: 0.00001
[epoch 268: 180/307] 	 train loss: 0.073067 	 lr: 0.00001
[epoch 268: 200/307] 	 train loss: 0.053018 	 lr: 0.00001
[epoch 268: 220/307] 	 train loss: 0.049594 	 lr: 0.00001

val loss: 0.350364 	 acc: 0.913695

[epoch 268: 240/307] 	 train loss: 0.111181 	 lr: 0.00001
[epoch 268: 260/307] 	 train loss: 0.038123 	 lr: 0.00001
[epoch 268: 280/307] 	 train loss: 0.101640 	 lr: 0.00001
[epoch 268: 300/307] 	 train loss: 0.275479 	 lr: 0.00001
[epoch 269:   0/307] 	 train loss: 0.119567 	 lr: 0.00001
[epoch 269:  20/307] 	 train loss: 0.162692 	 lr: 0.00001
[epoch 269:  40/307] 	 train loss: 0.018454 	 lr: 0.00001
[epoch 269:  60/307] 	 train loss: 0.020420 	 lr: 0.00001

val loss: 0.351135 	 acc: 0.910454

[epoch 269:  80/307] 	 train loss: 0.427666 	 lr: 0.00001
[epoch 269: 100/307] 	 train loss: 0.090640 	 lr: 0.00001
[epoch 269: 120/307] 	 train loss: 0.058670 	 lr: 0.00001
[epoch 269: 140/307] 	 train loss: 0.034204 	 lr: 0.00001
[epoch 269: 160/307] 	 train loss: 0.089086 	 lr: 0.00001
[epoch 269: 180/307] 	 train loss: 0.353385 	 lr: 0.00001
[epoch 269: 200/307] 	 train loss: 0.069415 	 lr: 0.00001
[epoch 269: 220/307] 	 train loss: 0.038321 	 lr: 0.00001

val loss: 0.351081 	 acc: 0.912075

[epoch 269: 240/307] 	 train loss: 0.050349 	 lr: 0.00001
[epoch 269: 260/307] 	 train loss: 0.037593 	 lr: 0.00001
[epoch 269: 280/307] 	 train loss: 0.090616 	 lr: 0.00001
[epoch 269: 300/307] 	 train loss: 0.053828 	 lr: 0.00001
[epoch 270:   0/307] 	 train loss: 0.085345 	 lr: 0.00001
[epoch 270:  20/307] 	 train loss: 0.089673 	 lr: 0.00001
[epoch 270:  40/307] 	 train loss: 0.049747 	 lr: 0.00001
[epoch 270:  60/307] 	 train loss: 0.129057 	 lr: 0.00001

val loss: 0.347687 	 acc: 0.912885

[epoch 270:  80/307] 	 train loss: 0.068784 	 lr: 0.00001
[epoch 270: 100/307] 	 train loss: 0.066938 	 lr: 0.00001
[epoch 270: 120/307] 	 train loss: 0.056523 	 lr: 0.00001
[epoch 270: 140/307] 	 train loss: 0.081248 	 lr: 0.00001
[epoch 270: 160/307] 	 train loss: 0.017685 	 lr: 0.00001
[epoch 270: 180/307] 	 train loss: 0.045962 	 lr: 0.00001
[epoch 270: 200/307] 	 train loss: 0.354572 	 lr: 0.00001
[epoch 270: 220/307] 	 train loss: 0.091112 	 lr: 0.00001

val loss: 0.349696 	 acc: 0.913290

[epoch 270: 240/307] 	 train loss: 0.028561 	 lr: 0.00001
[epoch 270: 260/307] 	 train loss: 0.059478 	 lr: 0.00001
[epoch 270: 280/307] 	 train loss: 0.023671 	 lr: 0.00001
[epoch 270: 300/307] 	 train loss: 0.057084 	 lr: 0.00001
[epoch 271:   0/307] 	 train loss: 0.074053 	 lr: 0.00001
[epoch 271:  20/307] 	 train loss: 0.011271 	 lr: 0.00001
[epoch 271:  40/307] 	 train loss: 0.105651 	 lr: 0.00001
[epoch 271:  60/307] 	 train loss: 0.097117 	 lr: 0.00001

val loss: 0.351538 	 acc: 0.914100

[epoch 271:  80/307] 	 train loss: 0.087583 	 lr: 0.00001
[epoch 271: 100/307] 	 train loss: 0.022149 	 lr: 0.00001
[epoch 271: 120/307] 	 train loss: 0.250094 	 lr: 0.00001
[epoch 271: 140/307] 	 train loss: 0.126504 	 lr: 0.00001
[epoch 271: 160/307] 	 train loss: 0.079785 	 lr: 0.00001
[epoch 271: 180/307] 	 train loss: 0.195532 	 lr: 0.00001
[epoch 271: 200/307] 	 train loss: 0.070475 	 lr: 0.00001
[epoch 271: 220/307] 	 train loss: 0.051253 	 lr: 0.00001

val loss: 0.351971 	 acc: 0.912885

[epoch 271: 240/307] 	 train loss: 0.032462 	 lr: 0.00001
[epoch 271: 260/307] 	 train loss: 0.098091 	 lr: 0.00001
[epoch 271: 280/307] 	 train loss: 0.229571 	 lr: 0.00001
[epoch 271: 300/307] 	 train loss: 0.052168 	 lr: 0.00001
[epoch 272:   0/307] 	 train loss: 0.047450 	 lr: 0.00001
[epoch 272:  20/307] 	 train loss: 0.049690 	 lr: 0.00001
[epoch 272:  40/307] 	 train loss: 0.082306 	 lr: 0.00001
[epoch 272:  60/307] 	 train loss: 0.042976 	 lr: 0.00001

val loss: 0.350652 	 acc: 0.911669

[epoch 272:  80/307] 	 train loss: 0.214965 	 lr: 0.00001
[epoch 272: 100/307] 	 train loss: 0.092905 	 lr: 0.00001
[epoch 272: 120/307] 	 train loss: 0.066528 	 lr: 0.00001
[epoch 272: 140/307] 	 train loss: 0.056997 	 lr: 0.00001
[epoch 272: 160/307] 	 train loss: 0.127899 	 lr: 0.00001
[epoch 272: 180/307] 	 train loss: 0.086600 	 lr: 0.00001
[epoch 272: 200/307] 	 train loss: 0.120491 	 lr: 0.00001
[epoch 272: 220/307] 	 train loss: 0.073653 	 lr: 0.00001

val loss: 0.350531 	 acc: 0.911669

[epoch 272: 240/307] 	 train loss: 0.057370 	 lr: 0.00001
[epoch 272: 260/307] 	 train loss: 0.053693 	 lr: 0.00001
[epoch 272: 280/307] 	 train loss: 0.191883 	 lr: 0.00001
[epoch 272: 300/307] 	 train loss: 0.156083 	 lr: 0.00001
[epoch 273:   0/307] 	 train loss: 0.252291 	 lr: 0.00001
[epoch 273:  20/307] 	 train loss: 0.081785 	 lr: 0.00001
[epoch 273:  40/307] 	 train loss: 0.193542 	 lr: 0.00001
[epoch 273:  60/307] 	 train loss: 0.062127 	 lr: 0.00001

val loss: 0.347771 	 acc: 0.911669

[epoch 273:  80/307] 	 train loss: 0.021999 	 lr: 0.00001
[epoch 273: 100/307] 	 train loss: 0.101180 	 lr: 0.00001
[epoch 273: 120/307] 	 train loss: 0.088491 	 lr: 0.00001
[epoch 273: 140/307] 	 train loss: 0.053800 	 lr: 0.00001
[epoch 273: 160/307] 	 train loss: 0.131222 	 lr: 0.00001
[epoch 273: 180/307] 	 train loss: 0.091793 	 lr: 0.00001
[epoch 273: 200/307] 	 train loss: 0.060596 	 lr: 0.00001
[epoch 273: 220/307] 	 train loss: 0.222758 	 lr: 0.00001

val loss: 0.351094 	 acc: 0.914911

[epoch 273: 240/307] 	 train loss: 0.042896 	 lr: 0.00001
[epoch 273: 260/307] 	 train loss: 0.099268 	 lr: 0.00001
[epoch 273: 280/307] 	 train loss: 0.104296 	 lr: 0.00001
[epoch 273: 300/307] 	 train loss: 0.019716 	 lr: 0.00001
[epoch 274:   0/307] 	 train loss: 0.143873 	 lr: 0.00001
[epoch 274:  20/307] 	 train loss: 0.059671 	 lr: 0.00001
[epoch 274:  40/307] 	 train loss: 0.191455 	 lr: 0.00001
[epoch 274:  60/307] 	 train loss: 0.279771 	 lr: 0.00001

val loss: 0.350856 	 acc: 0.913290

[epoch 274:  80/307] 	 train loss: 0.164354 	 lr: 0.00001
[epoch 274: 100/307] 	 train loss: 0.092170 	 lr: 0.00001
[epoch 274: 120/307] 	 train loss: 0.101383 	 lr: 0.00001
[epoch 274: 140/307] 	 train loss: 0.053037 	 lr: 0.00001
[epoch 274: 160/307] 	 train loss: 0.087724 	 lr: 0.00001
[epoch 274: 180/307] 	 train loss: 0.449429 	 lr: 0.00001
[epoch 274: 200/307] 	 train loss: 0.041463 	 lr: 0.00001

val loss: 0.350196 	 acc: 0.914100

[epoch 274: 220/307] 	 train loss: 0.222784 	 lr: 0.00001
[epoch 274: 240/307] 	 train loss: 0.073057 	 lr: 0.00001
[epoch 274: 260/307] 	 train loss: 0.069178 	 lr: 0.00001
[epoch 274: 280/307] 	 train loss: 0.079594 	 lr: 0.00001
[epoch 274: 300/307] 	 train loss: 0.099400 	 lr: 0.00001
[epoch 275:   0/307] 	 train loss: 0.045930 	 lr: 0.00001
[epoch 275:  20/307] 	 train loss: 0.079358 	 lr: 0.00001
[epoch 275:  40/307] 	 train loss: 0.101982 	 lr: 0.00001
[epoch 275:  60/307] 	 train loss: 0.045920 	 lr: 0.00001

val loss: 0.349349 	 acc: 0.912885

[epoch 275:  80/307] 	 train loss: 0.372938 	 lr: 0.00001
[epoch 275: 100/307] 	 train loss: 0.029010 	 lr: 0.00001
[epoch 275: 120/307] 	 train loss: 0.054523 	 lr: 0.00001
[epoch 275: 140/307] 	 train loss: 0.144036 	 lr: 0.00001
[epoch 275: 160/307] 	 train loss: 0.030440 	 lr: 0.00001
[epoch 275: 180/307] 	 train loss: 0.072360 	 lr: 0.00001
[epoch 275: 200/307] 	 train loss: 0.019064 	 lr: 0.00001

val loss: 0.349595 	 acc: 0.912480

[epoch 275: 220/307] 	 train loss: 0.150504 	 lr: 0.00001
[epoch 275: 240/307] 	 train loss: 0.158752 	 lr: 0.00001
[epoch 275: 260/307] 	 train loss: 0.236311 	 lr: 0.00001
[epoch 275: 280/307] 	 train loss: 0.148885 	 lr: 0.00001
[epoch 275: 300/307] 	 train loss: 0.181171 	 lr: 0.00001
[epoch 276:   0/307] 	 train loss: 0.109657 	 lr: 0.00001
[epoch 276:  20/307] 	 train loss: 0.204134 	 lr: 0.00001
[epoch 276:  40/307] 	 train loss: 0.034223 	 lr: 0.00001
[epoch 276:  60/307] 	 train loss: 0.103567 	 lr: 0.00001

val loss: 0.350300 	 acc: 0.914911

[epoch 276:  80/307] 	 train loss: 0.131475 	 lr: 0.00001
[epoch 276: 100/307] 	 train loss: 0.007926 	 lr: 0.00001
[epoch 276: 120/307] 	 train loss: 0.012800 	 lr: 0.00001
[epoch 276: 140/307] 	 train loss: 0.166990 	 lr: 0.00001
[epoch 276: 160/307] 	 train loss: 0.016735 	 lr: 0.00001
[epoch 276: 180/307] 	 train loss: 0.027566 	 lr: 0.00001
[epoch 276: 200/307] 	 train loss: 0.012855 	 lr: 0.00001

val loss: 0.350383 	 acc: 0.913290

[epoch 276: 220/307] 	 train loss: 0.064718 	 lr: 0.00001
[epoch 276: 240/307] 	 train loss: 0.113237 	 lr: 0.00001
[epoch 276: 260/307] 	 train loss: 0.126222 	 lr: 0.00001
[epoch 276: 280/307] 	 train loss: 0.055475 	 lr: 0.00001
[epoch 276: 300/307] 	 train loss: 0.107289 	 lr: 0.00001
[epoch 277:   0/307] 	 train loss: 0.198211 	 lr: 0.00001
[epoch 277:  20/307] 	 train loss: 0.097338 	 lr: 0.00001
[epoch 277:  40/307] 	 train loss: 0.086546 	 lr: 0.00001

val loss: 0.351151 	 acc: 0.912480

[epoch 277:  60/307] 	 train loss: 0.100578 	 lr: 0.00001
[epoch 277:  80/307] 	 train loss: 0.052507 	 lr: 0.00001
[epoch 277: 100/307] 	 train loss: 0.121536 	 lr: 0.00001
[epoch 277: 120/307] 	 train loss: 0.187600 	 lr: 0.00001
[epoch 277: 140/307] 	 train loss: 0.057494 	 lr: 0.00001
[epoch 277: 160/307] 	 train loss: 0.124694 	 lr: 0.00001
[epoch 277: 180/307] 	 train loss: 0.174435 	 lr: 0.00001
[epoch 277: 200/307] 	 train loss: 0.054186 	 lr: 0.00001

val loss: 0.351237 	 acc: 0.912885

[epoch 277: 220/307] 	 train loss: 0.031798 	 lr: 0.00001
[epoch 277: 240/307] 	 train loss: 0.098912 	 lr: 0.00001
[epoch 277: 260/307] 	 train loss: 0.087360 	 lr: 0.00001
[epoch 277: 280/307] 	 train loss: 0.012604 	 lr: 0.00001
[epoch 277: 300/307] 	 train loss: 0.184229 	 lr: 0.00001
[epoch 278:   0/307] 	 train loss: 0.159813 	 lr: 0.00001
[epoch 278:  20/307] 	 train loss: 0.133313 	 lr: 0.00001
[epoch 278:  40/307] 	 train loss: 0.099778 	 lr: 0.00001

val loss: 0.351158 	 acc: 0.913695

[epoch 278:  60/307] 	 train loss: 0.087497 	 lr: 0.00001
[epoch 278:  80/307] 	 train loss: 0.035590 	 lr: 0.00001
[epoch 278: 100/307] 	 train loss: 0.164829 	 lr: 0.00001
[epoch 278: 120/307] 	 train loss: 0.063138 	 lr: 0.00001
[epoch 278: 140/307] 	 train loss: 0.085529 	 lr: 0.00001
[epoch 278: 160/307] 	 train loss: 0.064557 	 lr: 0.00001
[epoch 278: 180/307] 	 train loss: 0.171689 	 lr: 0.00001
[epoch 278: 200/307] 	 train loss: 0.028527 	 lr: 0.00001

val loss: 0.350850 	 acc: 0.914506

[epoch 278: 220/307] 	 train loss: 0.058736 	 lr: 0.00001
[epoch 278: 240/307] 	 train loss: 0.017519 	 lr: 0.00001
[epoch 278: 260/307] 	 train loss: 0.112967 	 lr: 0.00001
[epoch 278: 280/307] 	 train loss: 0.033204 	 lr: 0.00001
[epoch 278: 300/307] 	 train loss: 0.022445 	 lr: 0.00001
[epoch 279:   0/307] 	 train loss: 0.116180 	 lr: 0.00001
[epoch 279:  20/307] 	 train loss: 0.023568 	 lr: 0.00001
[epoch 279:  40/307] 	 train loss: 0.056468 	 lr: 0.00001

val loss: 0.349832 	 acc: 0.912885

[epoch 279:  60/307] 	 train loss: 0.031014 	 lr: 0.00001
[epoch 279:  80/307] 	 train loss: 0.114557 	 lr: 0.00001
[epoch 279: 100/307] 	 train loss: 0.115347 	 lr: 0.00001
[epoch 279: 120/307] 	 train loss: 0.075442 	 lr: 0.00001
[epoch 279: 140/307] 	 train loss: 0.082991 	 lr: 0.00001
[epoch 279: 160/307] 	 train loss: 0.172552 	 lr: 0.00001
[epoch 279: 180/307] 	 train loss: 0.089121 	 lr: 0.00001
[epoch 279: 200/307] 	 train loss: 0.091576 	 lr: 0.00001

val loss: 0.349360 	 acc: 0.909643

[epoch 279: 220/307] 	 train loss: 0.123382 	 lr: 0.00001
[epoch 279: 240/307] 	 train loss: 0.121897 	 lr: 0.00001
[epoch 279: 260/307] 	 train loss: 0.106495 	 lr: 0.00001
[epoch 279: 280/307] 	 train loss: 0.124503 	 lr: 0.00001
[epoch 279: 300/307] 	 train loss: 0.031701 	 lr: 0.00001
[epoch 280:   0/307] 	 train loss: 0.113173 	 lr: 0.00001
[epoch 280:  20/307] 	 train loss: 0.270649 	 lr: 0.00001
[epoch 280:  40/307] 	 train loss: 0.150928 	 lr: 0.00001

val loss: 0.349354 	 acc: 0.912480

[epoch 280:  60/307] 	 train loss: 0.095017 	 lr: 0.00001
[epoch 280:  80/307] 	 train loss: 0.335010 	 lr: 0.00001
[epoch 280: 100/307] 	 train loss: 0.059826 	 lr: 0.00001
[epoch 280: 120/307] 	 train loss: 0.193611 	 lr: 0.00001
[epoch 280: 140/307] 	 train loss: 0.130522 	 lr: 0.00001
[epoch 280: 160/307] 	 train loss: 0.109136 	 lr: 0.00001
[epoch 280: 180/307] 	 train loss: 0.093301 	 lr: 0.00001
[epoch 280: 200/307] 	 train loss: 0.054332 	 lr: 0.00001

val loss: 0.350165 	 acc: 0.912885

[epoch 280: 220/307] 	 train loss: 0.222324 	 lr: 0.00001
[epoch 280: 240/307] 	 train loss: 0.103306 	 lr: 0.00001
[epoch 280: 260/307] 	 train loss: 0.085172 	 lr: 0.00001
[epoch 280: 280/307] 	 train loss: 0.223007 	 lr: 0.00001
[epoch 280: 300/307] 	 train loss: 0.121990 	 lr: 0.00001
[epoch 281:   0/307] 	 train loss: 0.168548 	 lr: 0.00001
[epoch 281:  20/307] 	 train loss: 0.138778 	 lr: 0.00001
[epoch 281:  40/307] 	 train loss: 0.217856 	 lr: 0.00001

val loss: 0.351665 	 acc: 0.911669

[epoch 281:  60/307] 	 train loss: 0.056754 	 lr: 0.00001
[epoch 281:  80/307] 	 train loss: 0.133644 	 lr: 0.00001
[epoch 281: 100/307] 	 train loss: 0.177986 	 lr: 0.00001
[epoch 281: 120/307] 	 train loss: 0.096987 	 lr: 0.00001
[epoch 281: 140/307] 	 train loss: 0.101847 	 lr: 0.00001
[epoch 281: 160/307] 	 train loss: 0.110991 	 lr: 0.00001
[epoch 281: 180/307] 	 train loss: 0.087624 	 lr: 0.00001
[epoch 281: 200/307] 	 train loss: 0.007004 	 lr: 0.00001

val loss: 0.351279 	 acc: 0.910049

[epoch 281: 220/307] 	 train loss: 0.133796 	 lr: 0.00001
[epoch 281: 240/307] 	 train loss: 0.042717 	 lr: 0.00001
[epoch 281: 260/307] 	 train loss: 0.120716 	 lr: 0.00001
[epoch 281: 280/307] 	 train loss: 0.088894 	 lr: 0.00001
[epoch 281: 300/307] 	 train loss: 0.139511 	 lr: 0.00001
[epoch 282:   0/307] 	 train loss: 0.024895 	 lr: 0.00001
[epoch 282:  20/307] 	 train loss: 0.098768 	 lr: 0.00001
[epoch 282:  40/307] 	 train loss: 0.047080 	 lr: 0.00001

val loss: 0.352000 	 acc: 0.911264

[epoch 282:  60/307] 	 train loss: 0.059629 	 lr: 0.00001
[epoch 282:  80/307] 	 train loss: 0.069766 	 lr: 0.00001
[epoch 282: 100/307] 	 train loss: 0.146532 	 lr: 0.00001
[epoch 282: 120/307] 	 train loss: 0.019822 	 lr: 0.00001
[epoch 282: 140/307] 	 train loss: 0.070956 	 lr: 0.00001
[epoch 282: 160/307] 	 train loss: 0.281442 	 lr: 0.00001
[epoch 282: 180/307] 	 train loss: 0.014137 	 lr: 0.00001
[epoch 282: 200/307] 	 train loss: 0.043388 	 lr: 0.00001

val loss: 0.351808 	 acc: 0.914100

[epoch 282: 220/307] 	 train loss: 0.069559 	 lr: 0.00001
[epoch 282: 240/307] 	 train loss: 0.189072 	 lr: 0.00001
[epoch 282: 260/307] 	 train loss: 0.151416 	 lr: 0.00001
[epoch 282: 280/307] 	 train loss: 0.059490 	 lr: 0.00001
[epoch 282: 300/307] 	 train loss: 0.035779 	 lr: 0.00001
[epoch 283:   0/307] 	 train loss: 0.064846 	 lr: 0.00001
[epoch 283:  20/307] 	 train loss: 0.015951 	 lr: 0.00001
[epoch 283:  40/307] 	 train loss: 0.186465 	 lr: 0.00001

val loss: 0.352839 	 acc: 0.913290

[epoch 283:  60/307] 	 train loss: 0.162322 	 lr: 0.00001
[epoch 283:  80/307] 	 train loss: 0.191632 	 lr: 0.00001
[epoch 283: 100/307] 	 train loss: 0.167263 	 lr: 0.00001
[epoch 283: 120/307] 	 train loss: 0.138825 	 lr: 0.00001
[epoch 283: 140/307] 	 train loss: 0.122281 	 lr: 0.00001
[epoch 283: 160/307] 	 train loss: 0.127364 	 lr: 0.00001
[epoch 283: 180/307] 	 train loss: 0.164796 	 lr: 0.00001
[epoch 283: 200/307] 	 train loss: 0.335954 	 lr: 0.00001

val loss: 0.352275 	 acc: 0.914100

[epoch 283: 220/307] 	 train loss: 0.027126 	 lr: 0.00001
[epoch 283: 240/307] 	 train loss: 0.034926 	 lr: 0.00001
[epoch 283: 260/307] 	 train loss: 0.391207 	 lr: 0.00001
[epoch 283: 280/307] 	 train loss: 0.134210 	 lr: 0.00001
[epoch 283: 300/307] 	 train loss: 0.009379 	 lr: 0.00001
[epoch 284:   0/307] 	 train loss: 0.055048 	 lr: 0.00001
[epoch 284:  20/307] 	 train loss: 0.029035 	 lr: 0.00001
[epoch 284:  40/307] 	 train loss: 0.232232 	 lr: 0.00001

val loss: 0.351233 	 acc: 0.914100

[epoch 284:  60/307] 	 train loss: 0.195197 	 lr: 0.00001
[epoch 284:  80/307] 	 train loss: 0.118275 	 lr: 0.00001
[epoch 284: 100/307] 	 train loss: 0.180050 	 lr: 0.00001
[epoch 284: 120/307] 	 train loss: 0.068023 	 lr: 0.00001
[epoch 284: 140/307] 	 train loss: 0.192322 	 lr: 0.00001
[epoch 284: 160/307] 	 train loss: 0.192204 	 lr: 0.00001
[epoch 284: 180/307] 	 train loss: 0.031383 	 lr: 0.00001

val loss: 0.354146 	 acc: 0.913695

[epoch 284: 200/307] 	 train loss: 0.174075 	 lr: 0.00001
[epoch 284: 220/307] 	 train loss: 0.075678 	 lr: 0.00001
[epoch 284: 240/307] 	 train loss: 0.040032 	 lr: 0.00001
[epoch 284: 260/307] 	 train loss: 0.195791 	 lr: 0.00001
[epoch 284: 280/307] 	 train loss: 0.091926 	 lr: 0.00001
[epoch 284: 300/307] 	 train loss: 0.124716 	 lr: 0.00001
[epoch 285:   0/307] 	 train loss: 0.083857 	 lr: 0.00001
[epoch 285:  20/307] 	 train loss: 0.155049 	 lr: 0.00001
[epoch 285:  40/307] 	 train loss: 0.088895 	 lr: 0.00001

val loss: 0.352417 	 acc: 0.913695

[epoch 285:  60/307] 	 train loss: 0.037903 	 lr: 0.00001
[epoch 285:  80/307] 	 train loss: 0.260910 	 lr: 0.00001
[epoch 285: 100/307] 	 train loss: 0.081154 	 lr: 0.00001
[epoch 285: 120/307] 	 train loss: 0.123806 	 lr: 0.00001
[epoch 285: 140/307] 	 train loss: 0.226521 	 lr: 0.00001
[epoch 285: 160/307] 	 train loss: 0.018710 	 lr: 0.00001
[epoch 285: 180/307] 	 train loss: 0.057970 	 lr: 0.00001

val loss: 0.353403 	 acc: 0.914100

[epoch 285: 200/307] 	 train loss: 0.071215 	 lr: 0.00001
[epoch 285: 220/307] 	 train loss: 0.024378 	 lr: 0.00001
[epoch 285: 240/307] 	 train loss: 0.156698 	 lr: 0.00001
[epoch 285: 260/307] 	 train loss: 0.087800 	 lr: 0.00001
[epoch 285: 280/307] 	 train loss: 0.093769 	 lr: 0.00001
[epoch 285: 300/307] 	 train loss: 0.063404 	 lr: 0.00001
[epoch 286:   0/307] 	 train loss: 0.135933 	 lr: 0.00001
[epoch 286:  20/307] 	 train loss: 0.162421 	 lr: 0.00001
[epoch 286:  40/307] 	 train loss: 0.056843 	 lr: 0.00001

val loss: 0.354990 	 acc: 0.912480

[epoch 286:  60/307] 	 train loss: 0.038692 	 lr: 0.00001
[epoch 286:  80/307] 	 train loss: 0.061753 	 lr: 0.00001
[epoch 286: 100/307] 	 train loss: 0.199189 	 lr: 0.00001
[epoch 286: 120/307] 	 train loss: 0.040775 	 lr: 0.00001
[epoch 286: 140/307] 	 train loss: 0.159613 	 lr: 0.00001
[epoch 286: 160/307] 	 train loss: 0.080395 	 lr: 0.00001
[epoch 286: 180/307] 	 train loss: 0.244755 	 lr: 0.00001

val loss: 0.353821 	 acc: 0.913290

[epoch 286: 200/307] 	 train loss: 0.033137 	 lr: 0.00001
[epoch 286: 220/307] 	 train loss: 0.009142 	 lr: 0.00001
[epoch 286: 240/307] 	 train loss: 0.207132 	 lr: 0.00001
[epoch 286: 260/307] 	 train loss: 0.188671 	 lr: 0.00001
[epoch 286: 280/307] 	 train loss: 0.040350 	 lr: 0.00001
[epoch 286: 300/307] 	 train loss: 0.099212 	 lr: 0.00001
[epoch 287:   0/307] 	 train loss: 0.045588 	 lr: 0.00001
[epoch 287:  20/307] 	 train loss: 0.125919 	 lr: 0.00001

val loss: 0.352636 	 acc: 0.911669

[epoch 287:  40/307] 	 train loss: 0.054720 	 lr: 0.00001
[epoch 287:  60/307] 	 train loss: 0.022646 	 lr: 0.00001
[epoch 287:  80/307] 	 train loss: 0.344118 	 lr: 0.00001
[epoch 287: 100/307] 	 train loss: 0.153830 	 lr: 0.00001
[epoch 287: 120/307] 	 train loss: 0.044931 	 lr: 0.00001
[epoch 287: 140/307] 	 train loss: 0.120974 	 lr: 0.00001
[epoch 287: 160/307] 	 train loss: 0.288832 	 lr: 0.00001
[epoch 287: 180/307] 	 train loss: 0.036711 	 lr: 0.00001

val loss: 0.353575 	 acc: 0.912075

[epoch 287: 200/307] 	 train loss: 0.065341 	 lr: 0.00001
[epoch 287: 220/307] 	 train loss: 0.063111 	 lr: 0.00001
[epoch 287: 240/307] 	 train loss: 0.070995 	 lr: 0.00001
[epoch 287: 260/307] 	 train loss: 0.053693 	 lr: 0.00001
[epoch 287: 280/307] 	 train loss: 0.186697 	 lr: 0.00001
[epoch 287: 300/307] 	 train loss: 0.143567 	 lr: 0.00001
[epoch 288:   0/307] 	 train loss: 0.039744 	 lr: 0.00001
[epoch 288:  20/307] 	 train loss: 0.062145 	 lr: 0.00001

val loss: 0.350552 	 acc: 0.909643

[epoch 288:  40/307] 	 train loss: 0.265229 	 lr: 0.00001
[epoch 288:  60/307] 	 train loss: 0.196367 	 lr: 0.00001
[epoch 288:  80/307] 	 train loss: 0.101332 	 lr: 0.00001
[epoch 288: 100/307] 	 train loss: 0.200746 	 lr: 0.00001
[epoch 288: 120/307] 	 train loss: 0.097211 	 lr: 0.00001
[epoch 288: 140/307] 	 train loss: 0.249876 	 lr: 0.00001
[epoch 288: 160/307] 	 train loss: 0.098796 	 lr: 0.00001
[epoch 288: 180/307] 	 train loss: 0.032838 	 lr: 0.00001

val loss: 0.350728 	 acc: 0.912075

[epoch 288: 200/307] 	 train loss: 0.132578 	 lr: 0.00001
[epoch 288: 220/307] 	 train loss: 0.060489 	 lr: 0.00001
[epoch 288: 240/307] 	 train loss: 0.067053 	 lr: 0.00001
[epoch 288: 260/307] 	 train loss: 0.152855 	 lr: 0.00001
[epoch 288: 280/307] 	 train loss: 0.145174 	 lr: 0.00001
[epoch 288: 300/307] 	 train loss: 0.070179 	 lr: 0.00001
[epoch 289:   0/307] 	 train loss: 0.241285 	 lr: 0.00001
[epoch 289:  20/307] 	 train loss: 0.019299 	 lr: 0.00001

val loss: 0.351353 	 acc: 0.912075

[epoch 289:  40/307] 	 train loss: 0.160036 	 lr: 0.00001
[epoch 289:  60/307] 	 train loss: 0.081260 	 lr: 0.00001
[epoch 289:  80/307] 	 train loss: 0.106665 	 lr: 0.00001
[epoch 289: 100/307] 	 train loss: 0.171681 	 lr: 0.00001
[epoch 289: 120/307] 	 train loss: 0.044971 	 lr: 0.00001
[epoch 289: 140/307] 	 train loss: 0.272313 	 lr: 0.00001
[epoch 289: 160/307] 	 train loss: 0.057366 	 lr: 0.00001
[epoch 289: 180/307] 	 train loss: 0.251190 	 lr: 0.00001

val loss: 0.352462 	 acc: 0.913290

[epoch 289: 200/307] 	 train loss: 0.066286 	 lr: 0.00001
[epoch 289: 220/307] 	 train loss: 0.032792 	 lr: 0.00001
[epoch 289: 240/307] 	 train loss: 0.065590 	 lr: 0.00001
[epoch 289: 260/307] 	 train loss: 0.134536 	 lr: 0.00001
[epoch 289: 280/307] 	 train loss: 0.212607 	 lr: 0.00001
[epoch 289: 300/307] 	 train loss: 0.073849 	 lr: 0.00001
[epoch 290:   0/307] 	 train loss: 0.096633 	 lr: 0.00001
[epoch 290:  20/307] 	 train loss: 0.172018 	 lr: 0.00001

val loss: 0.350178 	 acc: 0.912885

[epoch 290:  40/307] 	 train loss: 0.101352 	 lr: 0.00001
[epoch 290:  60/307] 	 train loss: 0.280033 	 lr: 0.00001
[epoch 290:  80/307] 	 train loss: 0.081409 	 lr: 0.00001
[epoch 290: 100/307] 	 train loss: 0.108672 	 lr: 0.00001
[epoch 290: 120/307] 	 train loss: 0.028615 	 lr: 0.00001
[epoch 290: 140/307] 	 train loss: 0.017895 	 lr: 0.00001
[epoch 290: 160/307] 	 train loss: 0.163889 	 lr: 0.00001
[epoch 290: 180/307] 	 train loss: 0.258503 	 lr: 0.00001

val loss: 0.351854 	 acc: 0.912885

[epoch 290: 200/307] 	 train loss: 0.044431 	 lr: 0.00001
[epoch 290: 220/307] 	 train loss: 0.124301 	 lr: 0.00001
[epoch 290: 240/307] 	 train loss: 0.053987 	 lr: 0.00001
[epoch 290: 260/307] 	 train loss: 0.057688 	 lr: 0.00001
[epoch 290: 280/307] 	 train loss: 0.141725 	 lr: 0.00001
[epoch 290: 300/307] 	 train loss: 0.123183 	 lr: 0.00001
[epoch 291:   0/307] 	 train loss: 0.039189 	 lr: 0.00001
[epoch 291:  20/307] 	 train loss: 0.187751 	 lr: 0.00001

val loss: 0.351097 	 acc: 0.912885

[epoch 291:  40/307] 	 train loss: 0.081646 	 lr: 0.00001
[epoch 291:  60/307] 	 train loss: 0.041887 	 lr: 0.00001
[epoch 291:  80/307] 	 train loss: 0.080792 	 lr: 0.00001
[epoch 291: 100/307] 	 train loss: 0.057690 	 lr: 0.00001
[epoch 291: 120/307] 	 train loss: 0.086718 	 lr: 0.00001
[epoch 291: 140/307] 	 train loss: 0.169346 	 lr: 0.00001
[epoch 291: 160/307] 	 train loss: 0.073487 	 lr: 0.00001
[epoch 291: 180/307] 	 train loss: 0.202442 	 lr: 0.00001

val loss: 0.350484 	 acc: 0.914100

[epoch 291: 200/307] 	 train loss: 0.198429 	 lr: 0.00001
[epoch 291: 220/307] 	 train loss: 0.091089 	 lr: 0.00001
[epoch 291: 240/307] 	 train loss: 0.110370 	 lr: 0.00001
[epoch 291: 260/307] 	 train loss: 0.166760 	 lr: 0.00001
[epoch 291: 280/307] 	 train loss: 0.100290 	 lr: 0.00001
[epoch 291: 300/307] 	 train loss: 0.042072 	 lr: 0.00001
[epoch 292:   0/307] 	 train loss: 0.136067 	 lr: 0.00001
[epoch 292:  20/307] 	 train loss: 0.103839 	 lr: 0.00001

val loss: 0.349963 	 acc: 0.911669

[epoch 292:  40/307] 	 train loss: 0.033646 	 lr: 0.00001
[epoch 292:  60/307] 	 train loss: 0.119974 	 lr: 0.00001
[epoch 292:  80/307] 	 train loss: 0.278208 	 lr: 0.00001
[epoch 292: 100/307] 	 train loss: 0.045907 	 lr: 0.00001
[epoch 292: 120/307] 	 train loss: 0.175731 	 lr: 0.00001
[epoch 292: 140/307] 	 train loss: 0.021152 	 lr: 0.00001
[epoch 292: 160/307] 	 train loss: 0.012840 	 lr: 0.00001
[epoch 292: 180/307] 	 train loss: 0.018259 	 lr: 0.00001

val loss: 0.347264 	 acc: 0.912885

[epoch 292: 200/307] 	 train loss: 0.047111 	 lr: 0.00001
[epoch 292: 220/307] 	 train loss: 0.091188 	 lr: 0.00001
[epoch 292: 240/307] 	 train loss: 0.149392 	 lr: 0.00001
[epoch 292: 260/307] 	 train loss: 0.135858 	 lr: 0.00001
[epoch 292: 280/307] 	 train loss: 0.174405 	 lr: 0.00001
[epoch 292: 300/307] 	 train loss: 0.124645 	 lr: 0.00001
[epoch 293:   0/307] 	 train loss: 0.055234 	 lr: 0.00001
[epoch 293:  20/307] 	 train loss: 0.044704 	 lr: 0.00001

val loss: 0.349729 	 acc: 0.909238

[epoch 293:  40/307] 	 train loss: 0.089255 	 lr: 0.00001
[epoch 293:  60/307] 	 train loss: 0.058420 	 lr: 0.00001
[epoch 293:  80/307] 	 train loss: 0.050582 	 lr: 0.00001
[epoch 293: 100/307] 	 train loss: 0.045013 	 lr: 0.00001
[epoch 293: 120/307] 	 train loss: 0.023628 	 lr: 0.00001
[epoch 293: 140/307] 	 train loss: 0.086673 	 lr: 0.00001
[epoch 293: 160/307] 	 train loss: 0.218403 	 lr: 0.00001
[epoch 293: 180/307] 	 train loss: 0.284343 	 lr: 0.00001

val loss: 0.349873 	 acc: 0.911264

[epoch 293: 200/307] 	 train loss: 0.178262 	 lr: 0.00001
[epoch 293: 220/307] 	 train loss: 0.044635 	 lr: 0.00001
[epoch 293: 240/307] 	 train loss: 0.233272 	 lr: 0.00001
[epoch 293: 260/307] 	 train loss: 0.021399 	 lr: 0.00001
[epoch 293: 280/307] 	 train loss: 0.463280 	 lr: 0.00001
[epoch 293: 300/307] 	 train loss: 0.203962 	 lr: 0.00001
[epoch 294:   0/307] 	 train loss: 0.267440 	 lr: 0.00001
[epoch 294:  20/307] 	 train loss: 0.084162 	 lr: 0.00001

val loss: 0.350253 	 acc: 0.913290

[epoch 294:  40/307] 	 train loss: 0.177506 	 lr: 0.00001
[epoch 294:  60/307] 	 train loss: 0.053777 	 lr: 0.00001
[epoch 294:  80/307] 	 train loss: 0.069867 	 lr: 0.00001
[epoch 294: 100/307] 	 train loss: 0.083343 	 lr: 0.00001
[epoch 294: 120/307] 	 train loss: 0.058723 	 lr: 0.00001
[epoch 294: 140/307] 	 train loss: 0.251546 	 lr: 0.00001
[epoch 294: 160/307] 	 train loss: 0.178152 	 lr: 0.00001

val loss: 0.349426 	 acc: 0.914911

[epoch 294: 180/307] 	 train loss: 0.310014 	 lr: 0.00001
[epoch 294: 200/307] 	 train loss: 0.168549 	 lr: 0.00001
[epoch 294: 220/307] 	 train loss: 0.042564 	 lr: 0.00001
[epoch 294: 240/307] 	 train loss: 0.156768 	 lr: 0.00001
[epoch 294: 260/307] 	 train loss: 0.062722 	 lr: 0.00001
[epoch 294: 280/307] 	 train loss: 0.028892 	 lr: 0.00001
[epoch 294: 300/307] 	 train loss: 0.063042 	 lr: 0.00001
[epoch 295:   0/307] 	 train loss: 0.311400 	 lr: 0.00001
[epoch 295:  20/307] 	 train loss: 0.028222 	 lr: 0.00001

val loss: 0.350359 	 acc: 0.912480

[epoch 295:  40/307] 	 train loss: 0.127748 	 lr: 0.00001
[epoch 295:  60/307] 	 train loss: 0.055849 	 lr: 0.00001
[epoch 295:  80/307] 	 train loss: 0.083043 	 lr: 0.00001
[epoch 295: 100/307] 	 train loss: 0.091335 	 lr: 0.00001
[epoch 295: 120/307] 	 train loss: 0.238517 	 lr: 0.00001
[epoch 295: 140/307] 	 train loss: 0.095754 	 lr: 0.00001
[epoch 295: 160/307] 	 train loss: 0.045785 	 lr: 0.00001

val loss: 0.350341 	 acc: 0.912075

[epoch 295: 180/307] 	 train loss: 0.061343 	 lr: 0.00001
[epoch 295: 200/307] 	 train loss: 0.144155 	 lr: 0.00001
[epoch 295: 220/307] 	 train loss: 0.051176 	 lr: 0.00001
[epoch 295: 240/307] 	 train loss: 0.182180 	 lr: 0.00001
[epoch 295: 260/307] 	 train loss: 0.101933 	 lr: 0.00001
[epoch 295: 280/307] 	 train loss: 0.067231 	 lr: 0.00001
[epoch 295: 300/307] 	 train loss: 0.221525 	 lr: 0.00001
[epoch 296:   0/307] 	 train loss: 0.034326 	 lr: 0.00001
[epoch 296:  20/307] 	 train loss: 0.039917 	 lr: 0.00001

val loss: 0.349952 	 acc: 0.912885

[epoch 296:  40/307] 	 train loss: 0.171731 	 lr: 0.00001
[epoch 296:  60/307] 	 train loss: 0.056599 	 lr: 0.00001
[epoch 296:  80/307] 	 train loss: 0.088947 	 lr: 0.00001
[epoch 296: 100/307] 	 train loss: 0.035046 	 lr: 0.00001
[epoch 296: 120/307] 	 train loss: 0.039953 	 lr: 0.00001
[epoch 296: 140/307] 	 train loss: 0.048811 	 lr: 0.00001
[epoch 296: 160/307] 	 train loss: 0.153759 	 lr: 0.00001

val loss: 0.351425 	 acc: 0.911264

[epoch 296: 180/307] 	 train loss: 0.094100 	 lr: 0.00001
[epoch 296: 200/307] 	 train loss: 0.066083 	 lr: 0.00001
[epoch 296: 220/307] 	 train loss: 0.197247 	 lr: 0.00001
[epoch 296: 240/307] 	 train loss: 0.054300 	 lr: 0.00001
[epoch 296: 260/307] 	 train loss: 0.028555 	 lr: 0.00001
[epoch 296: 280/307] 	 train loss: 0.082138 	 lr: 0.00001
[epoch 296: 300/307] 	 train loss: 0.058361 	 lr: 0.00001
[epoch 297:   0/307] 	 train loss: 0.044580 	 lr: 0.00001

val loss: 0.353063 	 acc: 0.911264

[epoch 297:  20/307] 	 train loss: 0.125384 	 lr: 0.00001
[epoch 297:  40/307] 	 train loss: 0.022518 	 lr: 0.00001
[epoch 297:  60/307] 	 train loss: 0.246260 	 lr: 0.00001
[epoch 297:  80/307] 	 train loss: 0.021788 	 lr: 0.00001
[epoch 297: 100/307] 	 train loss: 0.013974 	 lr: 0.00001
[epoch 297: 120/307] 	 train loss: 0.059359 	 lr: 0.00001
[epoch 297: 140/307] 	 train loss: 0.043289 	 lr: 0.00001
[epoch 297: 160/307] 	 train loss: 0.131770 	 lr: 0.00001

val loss: 0.352337 	 acc: 0.912885

[epoch 297: 180/307] 	 train loss: 0.082851 	 lr: 0.00001
[epoch 297: 200/307] 	 train loss: 0.054905 	 lr: 0.00001
[epoch 297: 220/307] 	 train loss: 0.026079 	 lr: 0.00001
[epoch 297: 240/307] 	 train loss: 0.076950 	 lr: 0.00001
[epoch 297: 260/307] 	 train loss: 0.083452 	 lr: 0.00001
[epoch 297: 280/307] 	 train loss: 0.094731 	 lr: 0.00001
[epoch 297: 300/307] 	 train loss: 0.050490 	 lr: 0.00001
[epoch 298:   0/307] 	 train loss: 0.047512 	 lr: 0.00001

val loss: 0.349554 	 acc: 0.912075

[epoch 298:  20/307] 	 train loss: 0.074055 	 lr: 0.00001
[epoch 298:  40/307] 	 train loss: 0.168732 	 lr: 0.00001
[epoch 298:  60/307] 	 train loss: 0.117997 	 lr: 0.00001
[epoch 298:  80/307] 	 train loss: 0.078429 	 lr: 0.00001
[epoch 298: 100/307] 	 train loss: 0.077191 	 lr: 0.00001
[epoch 298: 120/307] 	 train loss: 0.182737 	 lr: 0.00001
[epoch 298: 140/307] 	 train loss: 0.322616 	 lr: 0.00001
[epoch 298: 160/307] 	 train loss: 0.097959 	 lr: 0.00001

val loss: 0.349676 	 acc: 0.910859

[epoch 298: 180/307] 	 train loss: 0.025457 	 lr: 0.00001
[epoch 298: 200/307] 	 train loss: 0.264789 	 lr: 0.00001
[epoch 298: 220/307] 	 train loss: 0.122147 	 lr: 0.00001
[epoch 298: 240/307] 	 train loss: 0.173516 	 lr: 0.00001
[epoch 298: 260/307] 	 train loss: 0.024730 	 lr: 0.00001
[epoch 298: 280/307] 	 train loss: 0.163752 	 lr: 0.00001
[epoch 298: 300/307] 	 train loss: 0.155383 	 lr: 0.00001
[epoch 299:   0/307] 	 train loss: 0.088774 	 lr: 0.00001

val loss: 0.349833 	 acc: 0.910454

[epoch 299:  20/307] 	 train loss: 0.066006 	 lr: 0.00001
[epoch 299:  40/307] 	 train loss: 0.046368 	 lr: 0.00001
[epoch 299:  60/307] 	 train loss: 0.179590 	 lr: 0.00001
[epoch 299:  80/307] 	 train loss: 0.058928 	 lr: 0.00001
[epoch 299: 100/307] 	 train loss: 0.034933 	 lr: 0.00001
[epoch 299: 120/307] 	 train loss: 0.114010 	 lr: 0.00001
[epoch 299: 140/307] 	 train loss: 0.133840 	 lr: 0.00001
[epoch 299: 160/307] 	 train loss: 0.103637 	 lr: 0.00001

val loss: 0.348933 	 acc: 0.912885

[epoch 299: 180/307] 	 train loss: 0.132760 	 lr: 0.00001
[epoch 299: 200/307] 	 train loss: 0.083885 	 lr: 0.00001
[epoch 299: 220/307] 	 train loss: 0.104401 	 lr: 0.00001
[epoch 299: 240/307] 	 train loss: 0.153539 	 lr: 0.00001
[epoch 299: 260/307] 	 train loss: 0.165702 	 lr: 0.00001
[epoch 299: 280/307] 	 train loss: 0.085918 	 lr: 0.00001
[epoch 299: 300/307] 	 train loss: 0.037162 	 lr: 0.00001
[epoch 300:   0/307] 	 train loss: 0.056844 	 lr: 0.00001

val loss: 0.348443 	 acc: 0.911669

[epoch 300:  20/307] 	 train loss: 0.055272 	 lr: 0.00001
[epoch 300:  40/307] 	 train loss: 0.038204 	 lr: 0.00001
[epoch 300:  60/307] 	 train loss: 0.199548 	 lr: 0.00001
[epoch 300:  80/307] 	 train loss: 0.433686 	 lr: 0.00001
[epoch 300: 100/307] 	 train loss: 0.052116 	 lr: 0.00001
[epoch 300: 120/307] 	 train loss: 0.066488 	 lr: 0.00001
[epoch 300: 140/307] 	 train loss: 0.130436 	 lr: 0.00001
[epoch 300: 160/307] 	 train loss: 0.009976 	 lr: 0.00001

val loss: 0.350029 	 acc: 0.912480

[epoch 300: 180/307] 	 train loss: 0.119063 	 lr: 0.00001
[epoch 300: 200/307] 	 train loss: 0.086552 	 lr: 0.00001
[epoch 300: 220/307] 	 train loss: 0.032958 	 lr: 0.00001
[epoch 300: 240/307] 	 train loss: 0.133973 	 lr: 0.00001
[epoch 300: 260/307] 	 train loss: 0.130047 	 lr: 0.00001
[epoch 300: 280/307] 	 train loss: 0.262240 	 lr: 0.00001
[epoch 300: 300/307] 	 train loss: 0.429193 	 lr: 0.00001
[epoch 301:   0/307] 	 train loss: 0.100584 	 lr: 0.00001

val loss: 0.347849 	 acc: 0.912885

[epoch 301:  20/307] 	 train loss: 0.139756 	 lr: 0.00001
[epoch 301:  40/307] 	 train loss: 0.063929 	 lr: 0.00001
[epoch 301:  60/307] 	 train loss: 0.049426 	 lr: 0.00001
[epoch 301:  80/307] 	 train loss: 0.009781 	 lr: 0.00001
[epoch 301: 100/307] 	 train loss: 0.007674 	 lr: 0.00001
[epoch 301: 120/307] 	 train loss: 0.159238 	 lr: 0.00001
[epoch 301: 140/307] 	 train loss: 0.328665 	 lr: 0.00001
[epoch 301: 160/307] 	 train loss: 0.018861 	 lr: 0.00001

val loss: 0.348044 	 acc: 0.911669

[epoch 301: 180/307] 	 train loss: 0.094562 	 lr: 0.00001
[epoch 301: 200/307] 	 train loss: 0.033261 	 lr: 0.00001
[epoch 301: 220/307] 	 train loss: 0.044852 	 lr: 0.00001
[epoch 301: 240/307] 	 train loss: 0.105895 	 lr: 0.00001
[epoch 301: 260/307] 	 train loss: 0.106376 	 lr: 0.00001
[epoch 301: 280/307] 	 train loss: 0.108054 	 lr: 0.00001
[epoch 301: 300/307] 	 train loss: 0.019595 	 lr: 0.00001
[epoch 302:   0/307] 	 train loss: 0.156206 	 lr: 0.00001

val loss: 0.352036 	 acc: 0.912885

[epoch 302:  20/307] 	 train loss: 0.093435 	 lr: 0.00001
[epoch 302:  40/307] 	 train loss: 0.072141 	 lr: 0.00001
[epoch 302:  60/307] 	 train loss: 0.095883 	 lr: 0.00001
[epoch 302:  80/307] 	 train loss: 0.067297 	 lr: 0.00001
[epoch 302: 100/307] 	 train loss: 0.372581 	 lr: 0.00001
[epoch 302: 120/307] 	 train loss: 0.149688 	 lr: 0.00001
[epoch 302: 140/307] 	 train loss: 0.089247 	 lr: 0.00001
[epoch 302: 160/307] 	 train loss: 0.042686 	 lr: 0.00001

val loss: 0.350527 	 acc: 0.913695

[epoch 302: 180/307] 	 train loss: 0.088026 	 lr: 0.00001
[epoch 302: 200/307] 	 train loss: 0.050434 	 lr: 0.00001
[epoch 302: 220/307] 	 train loss: 0.133294 	 lr: 0.00001
[epoch 302: 240/307] 	 train loss: 0.084509 	 lr: 0.00001
[epoch 302: 260/307] 	 train loss: 0.078218 	 lr: 0.00001
[epoch 302: 280/307] 	 train loss: 0.207863 	 lr: 0.00001
[epoch 302: 300/307] 	 train loss: 0.031593 	 lr: 0.00001
[epoch 303:   0/307] 	 train loss: 0.234264 	 lr: 0.00001

val loss: 0.350445 	 acc: 0.911264

[epoch 303:  20/307] 	 train loss: 0.205386 	 lr: 0.00001
[epoch 303:  40/307] 	 train loss: 0.022697 	 lr: 0.00001
[epoch 303:  60/307] 	 train loss: 0.066780 	 lr: 0.00001
[epoch 303:  80/307] 	 train loss: 0.031478 	 lr: 0.00001
[epoch 303: 100/307] 	 train loss: 0.054574 	 lr: 0.00001
[epoch 303: 120/307] 	 train loss: 0.086742 	 lr: 0.00001
[epoch 303: 140/307] 	 train loss: 0.024361 	 lr: 0.00001
[epoch 303: 160/307] 	 train loss: 0.101964 	 lr: 0.00001

val loss: 0.352677 	 acc: 0.911669

[epoch 303: 180/307] 	 train loss: 0.096916 	 lr: 0.00001
[epoch 303: 200/307] 	 train loss: 0.094188 	 lr: 0.00001
[epoch 303: 220/307] 	 train loss: 0.301852 	 lr: 0.00001
[epoch 303: 240/307] 	 train loss: 0.132402 	 lr: 0.00001
[epoch 303: 260/307] 	 train loss: 0.132313 	 lr: 0.00001
[epoch 303: 280/307] 	 train loss: 0.029189 	 lr: 0.00001
[epoch 303: 300/307] 	 train loss: 0.024971 	 lr: 0.00001
[epoch 304:   0/307] 	 train loss: 0.242449 	 lr: 0.00001

val loss: 0.350367 	 acc: 0.911669

[epoch 304:  20/307] 	 train loss: 0.109555 	 lr: 0.00001
[epoch 304:  40/307] 	 train loss: 0.087269 	 lr: 0.00001
[epoch 304:  60/307] 	 train loss: 0.075103 	 lr: 0.00001
[epoch 304:  80/307] 	 train loss: 0.028345 	 lr: 0.00001
[epoch 304: 100/307] 	 train loss: 0.008140 	 lr: 0.00001
[epoch 304: 120/307] 	 train loss: 0.026067 	 lr: 0.00001
[epoch 304: 140/307] 	 train loss: 0.087313 	 lr: 0.00001

val loss: 0.349869 	 acc: 0.912480

[epoch 304: 160/307] 	 train loss: 0.028911 	 lr: 0.00001
[epoch 304: 180/307] 	 train loss: 0.106912 	 lr: 0.00001
[epoch 304: 200/307] 	 train loss: 0.232001 	 lr: 0.00001
[epoch 304: 220/307] 	 train loss: 0.031384 	 lr: 0.00001
[epoch 304: 240/307] 	 train loss: 0.090993 	 lr: 0.00001
[epoch 304: 260/307] 	 train loss: 0.212734 	 lr: 0.00001
[epoch 304: 280/307] 	 train loss: 0.121666 	 lr: 0.00001
[epoch 304: 300/307] 	 train loss: 0.015042 	 lr: 0.00001
[epoch 305:   0/307] 	 train loss: 0.177096 	 lr: 0.00001

val loss: 0.350642 	 acc: 0.912480

[epoch 305:  20/307] 	 train loss: 0.077034 	 lr: 0.00001
[epoch 305:  40/307] 	 train loss: 0.083999 	 lr: 0.00001
[epoch 305:  60/307] 	 train loss: 0.274418 	 lr: 0.00001
[epoch 305:  80/307] 	 train loss: 0.109995 	 lr: 0.00001
[epoch 305: 100/307] 	 train loss: 0.126342 	 lr: 0.00001
[epoch 305: 120/307] 	 train loss: 0.100275 	 lr: 0.00001
[epoch 305: 140/307] 	 train loss: 0.139816 	 lr: 0.00001

val loss: 0.352825 	 acc: 0.910049

[epoch 305: 160/307] 	 train loss: 0.102646 	 lr: 0.00001
[epoch 305: 180/307] 	 train loss: 0.017774 	 lr: 0.00001
[epoch 305: 200/307] 	 train loss: 0.122323 	 lr: 0.00001
[epoch 305: 220/307] 	 train loss: 0.212928 	 lr: 0.00001
[epoch 305: 240/307] 	 train loss: 0.188114 	 lr: 0.00001
[epoch 305: 260/307] 	 train loss: 0.044761 	 lr: 0.00001
[epoch 305: 280/307] 	 train loss: 0.121138 	 lr: 0.00001
[epoch 305: 300/307] 	 train loss: 0.068264 	 lr: 0.00001
[epoch 306:   0/307] 	 train loss: 0.213975 	 lr: 0.00001

val loss: 0.352666 	 acc: 0.910859

[epoch 306:  20/307] 	 train loss: 0.210858 	 lr: 0.00001
[epoch 306:  40/307] 	 train loss: 0.043761 	 lr: 0.00001
[epoch 306:  60/307] 	 train loss: 0.121859 	 lr: 0.00001
[epoch 306:  80/307] 	 train loss: 0.105905 	 lr: 0.00001
[epoch 306: 100/307] 	 train loss: 0.110545 	 lr: 0.00001
[epoch 306: 120/307] 	 train loss: 0.065649 	 lr: 0.00001
[epoch 306: 140/307] 	 train loss: 0.068532 	 lr: 0.00001

val loss: 0.351953 	 acc: 0.910049

[epoch 306: 160/307] 	 train loss: 0.116198 	 lr: 0.00001
[epoch 306: 180/307] 	 train loss: 0.141376 	 lr: 0.00001
[epoch 306: 200/307] 	 train loss: 0.091992 	 lr: 0.00001
[epoch 306: 220/307] 	 train loss: 0.006544 	 lr: 0.00001
[epoch 306: 240/307] 	 train loss: 0.126055 	 lr: 0.00001
[epoch 306: 260/307] 	 train loss: 0.449026 	 lr: 0.00001
[epoch 306: 280/307] 	 train loss: 0.070572 	 lr: 0.00001
[epoch 306: 300/307] 	 train loss: 0.094118 	 lr: 0.00001

val loss: 0.351499 	 acc: 0.910049

[epoch 307:   0/307] 	 train loss: 0.060309 	 lr: 0.00001
[epoch 307:  20/307] 	 train loss: 0.087388 	 lr: 0.00001
[epoch 307:  40/307] 	 train loss: 0.121694 	 lr: 0.00001
[epoch 307:  60/307] 	 train loss: 0.106337 	 lr: 0.00001
[epoch 307:  80/307] 	 train loss: 0.134896 	 lr: 0.00001
[epoch 307: 100/307] 	 train loss: 0.121926 	 lr: 0.00001
[epoch 307: 120/307] 	 train loss: 0.118306 	 lr: 0.00001
[epoch 307: 140/307] 	 train loss: 0.230715 	 lr: 0.00001

val loss: 0.353003 	 acc: 0.911264

[epoch 307: 160/307] 	 train loss: 0.138652 	 lr: 0.00001
[epoch 307: 180/307] 	 train loss: 0.072796 	 lr: 0.00001
[epoch 307: 200/307] 	 train loss: 0.321460 	 lr: 0.00001
[epoch 307: 220/307] 	 train loss: 0.006529 	 lr: 0.00001
[epoch 307: 240/307] 	 train loss: 0.067474 	 lr: 0.00001
[epoch 307: 260/307] 	 train loss: 0.227207 	 lr: 0.00001
[epoch 307: 280/307] 	 train loss: 0.158644 	 lr: 0.00001
[epoch 307: 300/307] 	 train loss: 0.202460 	 lr: 0.00001

val loss: 0.352995 	 acc: 0.910859

[epoch 308:   0/307] 	 train loss: 0.041567 	 lr: 0.00001
[epoch 308:  20/307] 	 train loss: 0.069563 	 lr: 0.00001
[epoch 308:  40/307] 	 train loss: 0.072350 	 lr: 0.00001
[epoch 308:  60/307] 	 train loss: 0.126422 	 lr: 0.00001
[epoch 308:  80/307] 	 train loss: 0.042412 	 lr: 0.00001
[epoch 308: 100/307] 	 train loss: 0.061966 	 lr: 0.00001
[epoch 308: 120/307] 	 train loss: 0.026160 	 lr: 0.00001
[epoch 308: 140/307] 	 train loss: 0.310062 	 lr: 0.00001

val loss: 0.351460 	 acc: 0.910049

[epoch 308: 160/307] 	 train loss: 0.233643 	 lr: 0.00001
[epoch 308: 180/307] 	 train loss: 0.057280 	 lr: 0.00001
[epoch 308: 200/307] 	 train loss: 0.272296 	 lr: 0.00001
[epoch 308: 220/307] 	 train loss: 0.103142 	 lr: 0.00001
[epoch 308: 240/307] 	 train loss: 0.040989 	 lr: 0.00001
[epoch 308: 260/307] 	 train loss: 0.094634 	 lr: 0.00001
[epoch 308: 280/307] 	 train loss: 0.180780 	 lr: 0.00001
[epoch 308: 300/307] 	 train loss: 0.063807 	 lr: 0.00001

val loss: 0.350857 	 acc: 0.910859

[epoch 309:   0/307] 	 train loss: 0.082462 	 lr: 0.00001
[epoch 309:  20/307] 	 train loss: 0.198210 	 lr: 0.00001
[epoch 309:  40/307] 	 train loss: 0.162066 	 lr: 0.00001
[epoch 309:  60/307] 	 train loss: 0.128499 	 lr: 0.00001
[epoch 309:  80/307] 	 train loss: 0.296051 	 lr: 0.00001
[epoch 309: 100/307] 	 train loss: 0.029467 	 lr: 0.00001
[epoch 309: 120/307] 	 train loss: 0.005161 	 lr: 0.00001
[epoch 309: 140/307] 	 train loss: 0.007990 	 lr: 0.00001

val loss: 0.351242 	 acc: 0.911264

[epoch 309: 160/307] 	 train loss: 0.007822 	 lr: 0.00001
[epoch 309: 180/307] 	 train loss: 0.034788 	 lr: 0.00001
[epoch 309: 200/307] 	 train loss: 0.049641 	 lr: 0.00001
[epoch 309: 220/307] 	 train loss: 0.266414 	 lr: 0.00001
[epoch 309: 240/307] 	 train loss: 0.115059 	 lr: 0.00001
[epoch 309: 260/307] 	 train loss: 0.147759 	 lr: 0.00001
[epoch 309: 280/307] 	 train loss: 0.162088 	 lr: 0.00001
[epoch 309: 300/307] 	 train loss: 0.109487 	 lr: 0.00001

val loss: 0.350893 	 acc: 0.910049

[epoch 310:   0/307] 	 train loss: 0.025371 	 lr: 0.00001
[epoch 310:  20/307] 	 train loss: 0.068223 	 lr: 0.00001
[epoch 310:  40/307] 	 train loss: 0.022481 	 lr: 0.00001
[epoch 310:  60/307] 	 train loss: 0.176091 	 lr: 0.00001
[epoch 310:  80/307] 	 train loss: 0.126506 	 lr: 0.00001
[epoch 310: 100/307] 	 train loss: 0.055706 	 lr: 0.00001
[epoch 310: 120/307] 	 train loss: 0.047498 	 lr: 0.00001
[epoch 310: 140/307] 	 train loss: 0.057380 	 lr: 0.00001

val loss: 0.352432 	 acc: 0.910454

[epoch 310: 160/307] 	 train loss: 0.066659 	 lr: 0.00001
[epoch 310: 180/307] 	 train loss: 0.214416 	 lr: 0.00001
[epoch 310: 200/307] 	 train loss: 0.025120 	 lr: 0.00001
[epoch 310: 220/307] 	 train loss: 0.041001 	 lr: 0.00001
[epoch 310: 240/307] 	 train loss: 0.078131 	 lr: 0.00001
[epoch 310: 260/307] 	 train loss: 0.110013 	 lr: 0.00001
[epoch 310: 280/307] 	 train loss: 0.062147 	 lr: 0.00001

val loss: 0.351890 	 acc: 0.910859

[epoch 310: 300/307] 	 train loss: 0.124895 	 lr: 0.00001
[epoch 311:   0/307] 	 train loss: 0.058546 	 lr: 0.00001
[epoch 311:  20/307] 	 train loss: 0.113309 	 lr: 0.00001
[epoch 311:  40/307] 	 train loss: 0.092916 	 lr: 0.00001
[epoch 311:  60/307] 	 train loss: 0.120176 	 lr: 0.00001
[epoch 311:  80/307] 	 train loss: 0.134119 	 lr: 0.00001
[epoch 311: 100/307] 	 train loss: 0.227490 	 lr: 0.00001
[epoch 311: 120/307] 	 train loss: 0.044285 	 lr: 0.00001
[epoch 311: 140/307] 	 train loss: 0.092846 	 lr: 0.00001

val loss: 0.352237 	 acc: 0.910454

[epoch 311: 160/307] 	 train loss: 0.047957 	 lr: 0.00001
[epoch 311: 180/307] 	 train loss: 0.140327 	 lr: 0.00001
[epoch 311: 200/307] 	 train loss: 0.059568 	 lr: 0.00001
[epoch 311: 220/307] 	 train loss: 0.053157 	 lr: 0.00001
[epoch 311: 240/307] 	 train loss: 0.016515 	 lr: 0.00001
[epoch 311: 260/307] 	 train loss: 0.157690 	 lr: 0.00001
[epoch 311: 280/307] 	 train loss: 0.084840 	 lr: 0.00001

val loss: 0.354080 	 acc: 0.910859

[epoch 311: 300/307] 	 train loss: 0.342819 	 lr: 0.00001
[epoch 312:   0/307] 	 train loss: 0.043416 	 lr: 0.00001
[epoch 312:  20/307] 	 train loss: 0.312202 	 lr: 0.00001
[epoch 312:  40/307] 	 train loss: 0.071814 	 lr: 0.00001
[epoch 312:  60/307] 	 train loss: 0.055662 	 lr: 0.00001
[epoch 312:  80/307] 	 train loss: 0.052131 	 lr: 0.00001
[epoch 312: 100/307] 	 train loss: 0.068156 	 lr: 0.00001
[epoch 312: 120/307] 	 train loss: 0.143508 	 lr: 0.00001
[epoch 312: 140/307] 	 train loss: 0.043875 	 lr: 0.00001

val loss: 0.353397 	 acc: 0.911264

[epoch 312: 160/307] 	 train loss: 0.023721 	 lr: 0.00001
[epoch 312: 180/307] 	 train loss: 0.057633 	 lr: 0.00001
[epoch 312: 200/307] 	 train loss: 0.052259 	 lr: 0.00001
[epoch 312: 220/307] 	 train loss: 0.081008 	 lr: 0.00001
[epoch 312: 240/307] 	 train loss: 0.046795 	 lr: 0.00001
[epoch 312: 260/307] 	 train loss: 0.056095 	 lr: 0.00001
[epoch 312: 280/307] 	 train loss: 0.110453 	 lr: 0.00001

val loss: 0.352209 	 acc: 0.909238

[epoch 312: 300/307] 	 train loss: 0.049069 	 lr: 0.00001
[epoch 313:   0/307] 	 train loss: 0.138870 	 lr: 0.00001
[epoch 313:  20/307] 	 train loss: 0.175824 	 lr: 0.00001
[epoch 313:  40/307] 	 train loss: 0.212126 	 lr: 0.00001
[epoch 313:  60/307] 	 train loss: 0.049947 	 lr: 0.00001
[epoch 313:  80/307] 	 train loss: 0.129002 	 lr: 0.00001
[epoch 313: 100/307] 	 train loss: 0.124479 	 lr: 0.00001
[epoch 313: 120/307] 	 train loss: 0.059383 	 lr: 0.00001
[epoch 313: 140/307] 	 train loss: 0.014314 	 lr: 0.00001

val loss: 0.350944 	 acc: 0.908833

[epoch 313: 160/307] 	 train loss: 0.134091 	 lr: 0.00001
[epoch 313: 180/307] 	 train loss: 0.102451 	 lr: 0.00001
[epoch 313: 200/307] 	 train loss: 0.006884 	 lr: 0.00001
[epoch 313: 220/307] 	 train loss: 0.013341 	 lr: 0.00001
[epoch 313: 240/307] 	 train loss: 0.130398 	 lr: 0.00001
[epoch 313: 260/307] 	 train loss: 0.057650 	 lr: 0.00001
[epoch 313: 280/307] 	 train loss: 0.183618 	 lr: 0.00001

val loss: 0.351559 	 acc: 0.910049

[epoch 313: 300/307] 	 train loss: 0.049965 	 lr: 0.00001
[epoch 314:   0/307] 	 train loss: 0.168859 	 lr: 0.00001
[epoch 314:  20/307] 	 train loss: 0.195920 	 lr: 0.00001
[epoch 314:  40/307] 	 train loss: 0.049162 	 lr: 0.00001
[epoch 314:  60/307] 	 train loss: 0.192311 	 lr: 0.00001
[epoch 314:  80/307] 	 train loss: 0.025610 	 lr: 0.00001
[epoch 314: 100/307] 	 train loss: 0.224375 	 lr: 0.00001
[epoch 314: 120/307] 	 train loss: 0.014298 	 lr: 0.00001

val loss: 0.350491 	 acc: 0.912075

[epoch 314: 140/307] 	 train loss: 0.025657 	 lr: 0.00001
[epoch 314: 160/307] 	 train loss: 0.091996 	 lr: 0.00001
[epoch 314: 180/307] 	 train loss: 0.332578 	 lr: 0.00001
[epoch 314: 200/307] 	 train loss: 0.231532 	 lr: 0.00001
[epoch 314: 220/307] 	 train loss: 0.108132 	 lr: 0.00001
[epoch 314: 240/307] 	 train loss: 0.095635 	 lr: 0.00001
[epoch 314: 260/307] 	 train loss: 0.044375 	 lr: 0.00001
[epoch 314: 280/307] 	 train loss: 0.072347 	 lr: 0.00001

val loss: 0.350102 	 acc: 0.911264

[epoch 314: 300/307] 	 train loss: 0.435969 	 lr: 0.00001
[epoch 315:   0/307] 	 train loss: 0.105898 	 lr: 0.00001
[epoch 315:  20/307] 	 train loss: 0.049746 	 lr: 0.00001
[epoch 315:  40/307] 	 train loss: 0.053623 	 lr: 0.00001
[epoch 315:  60/307] 	 train loss: 0.236390 	 lr: 0.00001
[epoch 315:  80/307] 	 train loss: 0.054324 	 lr: 0.00001
[epoch 315: 100/307] 	 train loss: 0.078368 	 lr: 0.00001
[epoch 315: 120/307] 	 train loss: 0.057902 	 lr: 0.00001

val loss: 0.349967 	 acc: 0.910859

[epoch 315: 140/307] 	 train loss: 0.259732 	 lr: 0.00001
[epoch 315: 160/307] 	 train loss: 0.196968 	 lr: 0.00001
[epoch 315: 180/307] 	 train loss: 0.042673 	 lr: 0.00001
[epoch 315: 200/307] 	 train loss: 0.229693 	 lr: 0.00001
[epoch 315: 220/307] 	 train loss: 0.234610 	 lr: 0.00001
[epoch 315: 240/307] 	 train loss: 0.094117 	 lr: 0.00001
[epoch 315: 260/307] 	 train loss: 0.450222 	 lr: 0.00001
[epoch 315: 280/307] 	 train loss: 0.042900 	 lr: 0.00001

val loss: 0.350521 	 acc: 0.910049

[epoch 315: 300/307] 	 train loss: 0.014286 	 lr: 0.00001
[epoch 316:   0/307] 	 train loss: 0.092087 	 lr: 0.00001
[epoch 316:  20/307] 	 train loss: 0.012880 	 lr: 0.00001
[epoch 316:  40/307] 	 train loss: 0.046882 	 lr: 0.00001
[epoch 316:  60/307] 	 train loss: 0.044612 	 lr: 0.00001
[epoch 316:  80/307] 	 train loss: 0.054539 	 lr: 0.00001
[epoch 316: 100/307] 	 train loss: 0.218931 	 lr: 0.00001
[epoch 316: 120/307] 	 train loss: 0.131936 	 lr: 0.00001

val loss: 0.350967 	 acc: 0.912480

[epoch 316: 140/307] 	 train loss: 0.049955 	 lr: 0.00001
[epoch 316: 160/307] 	 train loss: 0.022761 	 lr: 0.00001
[epoch 316: 180/307] 	 train loss: 0.023006 	 lr: 0.00001
[epoch 316: 200/307] 	 train loss: 0.122779 	 lr: 0.00001
[epoch 316: 220/307] 	 train loss: 0.170031 	 lr: 0.00001
[epoch 316: 240/307] 	 train loss: 0.091564 	 lr: 0.00001
[epoch 316: 260/307] 	 train loss: 0.070862 	 lr: 0.00001
[epoch 316: 280/307] 	 train loss: 0.067781 	 lr: 0.00001

val loss: 0.351774 	 acc: 0.911264

[epoch 316: 300/307] 	 train loss: 0.039963 	 lr: 0.00001
[epoch 317:   0/307] 	 train loss: 0.039879 	 lr: 0.00001
[epoch 317:  20/307] 	 train loss: 0.209820 	 lr: 0.00001
[epoch 317:  40/307] 	 train loss: 0.061534 	 lr: 0.00001
[epoch 317:  60/307] 	 train loss: 0.130745 	 lr: 0.00001
[epoch 317:  80/307] 	 train loss: 0.208229 	 lr: 0.00001
[epoch 317: 100/307] 	 train loss: 0.024491 	 lr: 0.00001
[epoch 317: 120/307] 	 train loss: 0.121401 	 lr: 0.00001

val loss: 0.351433 	 acc: 0.911264

[epoch 317: 140/307] 	 train loss: 0.082905 	 lr: 0.00001
[epoch 317: 160/307] 	 train loss: 0.238878 	 lr: 0.00001
[epoch 317: 180/307] 	 train loss: 0.094889 	 lr: 0.00001
[epoch 317: 200/307] 	 train loss: 0.088860 	 lr: 0.00001
[epoch 317: 220/307] 	 train loss: 0.069893 	 lr: 0.00001
[epoch 317: 240/307] 	 train loss: 0.088331 	 lr: 0.00001
[epoch 317: 260/307] 	 train loss: 0.033668 	 lr: 0.00001
[epoch 317: 280/307] 	 train loss: 0.016287 	 lr: 0.00001

val loss: 0.352415 	 acc: 0.912480

[epoch 317: 300/307] 	 train loss: 0.094812 	 lr: 0.00001
[epoch 318:   0/307] 	 train loss: 0.089448 	 lr: 0.00001
[epoch 318:  20/307] 	 train loss: 0.016494 	 lr: 0.00001
[epoch 318:  40/307] 	 train loss: 0.221242 	 lr: 0.00001
[epoch 318:  60/307] 	 train loss: 0.209559 	 lr: 0.00001
[epoch 318:  80/307] 	 train loss: 0.085324 	 lr: 0.00001
[epoch 318: 100/307] 	 train loss: 0.114306 	 lr: 0.00001
[epoch 318: 120/307] 	 train loss: 0.089325 	 lr: 0.00001

val loss: 0.352895 	 acc: 0.912480

[epoch 318: 140/307] 	 train loss: 0.045942 	 lr: 0.00001
[epoch 318: 160/307] 	 train loss: 0.058888 	 lr: 0.00001
[epoch 318: 180/307] 	 train loss: 0.047795 	 lr: 0.00001
[epoch 318: 200/307] 	 train loss: 0.062708 	 lr: 0.00001
[epoch 318: 220/307] 	 train loss: 0.075600 	 lr: 0.00001
[epoch 318: 240/307] 	 train loss: 0.161775 	 lr: 0.00001
[epoch 318: 260/307] 	 train loss: 0.136194 	 lr: 0.00001
[epoch 318: 280/307] 	 train loss: 0.122449 	 lr: 0.00001

val loss: 0.350964 	 acc: 0.912480

[epoch 318: 300/307] 	 train loss: 0.040592 	 lr: 0.00001
[epoch 319:   0/307] 	 train loss: 0.033109 	 lr: 0.00001
[epoch 319:  20/307] 	 train loss: 0.053635 	 lr: 0.00001
[epoch 319:  40/307] 	 train loss: 0.273775 	 lr: 0.00001
[epoch 319:  60/307] 	 train loss: 0.011856 	 lr: 0.00001
[epoch 319:  80/307] 	 train loss: 0.096092 	 lr: 0.00001
[epoch 319: 100/307] 	 train loss: 0.046999 	 lr: 0.00001
[epoch 319: 120/307] 	 train loss: 0.455043 	 lr: 0.00001

val loss: 0.349887 	 acc: 0.912885

[epoch 319: 140/307] 	 train loss: 0.015406 	 lr: 0.00001
[epoch 319: 160/307] 	 train loss: 0.247789 	 lr: 0.00001
[epoch 319: 180/307] 	 train loss: 0.075048 	 lr: 0.00001
[epoch 319: 200/307] 	 train loss: 0.058269 	 lr: 0.00001
[epoch 319: 220/307] 	 train loss: 0.069204 	 lr: 0.00001
[epoch 319: 240/307] 	 train loss: 0.083850 	 lr: 0.00001
[epoch 319: 260/307] 	 train loss: 0.073254 	 lr: 0.00001
[epoch 319: 280/307] 	 train loss: 0.100923 	 lr: 0.00001

val loss: 0.351897 	 acc: 0.911669

[epoch 319: 300/307] 	 train loss: 0.031434 	 lr: 0.00001
[epoch 320:   0/307] 	 train loss: 0.163977 	 lr: 0.00001
[epoch 320:  20/307] 	 train loss: 0.070987 	 lr: 0.00001
[epoch 320:  40/307] 	 train loss: 0.061376 	 lr: 0.00001
[epoch 320:  60/307] 	 train loss: 0.019852 	 lr: 0.00001
[epoch 320:  80/307] 	 train loss: 0.064694 	 lr: 0.00001
[epoch 320: 100/307] 	 train loss: 0.356563 	 lr: 0.00001
[epoch 320: 120/307] 	 train loss: 0.046061 	 lr: 0.00001

val loss: 0.351412 	 acc: 0.910859

[epoch 320: 140/307] 	 train loss: 0.248786 	 lr: 0.00001
[epoch 320: 160/307] 	 train loss: 0.110969 	 lr: 0.00001
[epoch 320: 180/307] 	 train loss: 0.223728 	 lr: 0.00001
[epoch 320: 200/307] 	 train loss: 0.093221 	 lr: 0.00001
[epoch 320: 220/307] 	 train loss: 0.058172 	 lr: 0.00001
[epoch 320: 240/307] 	 train loss: 0.112572 	 lr: 0.00001
[epoch 320: 260/307] 	 train loss: 0.078283 	 lr: 0.00001

val loss: 0.351004 	 acc: 0.912480

[epoch 320: 280/307] 	 train loss: 0.041059 	 lr: 0.00001
[epoch 320: 300/307] 	 train loss: 0.172378 	 lr: 0.00001
[epoch 321:   0/307] 	 train loss: 0.126257 	 lr: 0.00001
[epoch 321:  20/307] 	 train loss: 0.062530 	 lr: 0.00001
[epoch 321:  40/307] 	 train loss: 0.044623 	 lr: 0.00001
[epoch 321:  60/307] 	 train loss: 0.039502 	 lr: 0.00001
[epoch 321:  80/307] 	 train loss: 0.050124 	 lr: 0.00001
[epoch 321: 100/307] 	 train loss: 0.112159 	 lr: 0.00001
[epoch 321: 120/307] 	 train loss: 0.024379 	 lr: 0.00001

val loss: 0.352385 	 acc: 0.912885

[epoch 321: 140/307] 	 train loss: 0.060238 	 lr: 0.00001
[epoch 321: 160/307] 	 train loss: 0.032263 	 lr: 0.00001
[epoch 321: 180/307] 	 train loss: 0.086651 	 lr: 0.00001
[epoch 321: 200/307] 	 train loss: 0.086640 	 lr: 0.00001
[epoch 321: 220/307] 	 train loss: 0.167132 	 lr: 0.00001
[epoch 321: 240/307] 	 train loss: 0.092854 	 lr: 0.00001
[epoch 321: 260/307] 	 train loss: 0.143719 	 lr: 0.00001

val loss: 0.352531 	 acc: 0.910454

[epoch 321: 280/307] 	 train loss: 0.209658 	 lr: 0.00001
[epoch 321: 300/307] 	 train loss: 0.037025 	 lr: 0.00001
[epoch 322:   0/307] 	 train loss: 0.360350 	 lr: 0.00001
[epoch 322:  20/307] 	 train loss: 0.049934 	 lr: 0.00001
[epoch 322:  40/307] 	 train loss: 0.092680 	 lr: 0.00001
[epoch 322:  60/307] 	 train loss: 0.376034 	 lr: 0.00001
[epoch 322:  80/307] 	 train loss: 0.077991 	 lr: 0.00001
[epoch 322: 100/307] 	 train loss: 0.079835 	 lr: 0.00001
[epoch 322: 120/307] 	 train loss: 0.085824 	 lr: 0.00001

val loss: 0.353081 	 acc: 0.912075

[epoch 322: 140/307] 	 train loss: 0.120574 	 lr: 0.00001
[epoch 322: 160/307] 	 train loss: 0.005934 	 lr: 0.00001
[epoch 322: 180/307] 	 train loss: 0.046695 	 lr: 0.00001
[epoch 322: 200/307] 	 train loss: 0.082211 	 lr: 0.00001
[epoch 322: 220/307] 	 train loss: 0.047768 	 lr: 0.00001
[epoch 322: 240/307] 	 train loss: 0.182536 	 lr: 0.00001
[epoch 322: 260/307] 	 train loss: 0.071778 	 lr: 0.00001

val loss: 0.351829 	 acc: 0.912885

[epoch 322: 280/307] 	 train loss: 0.017572 	 lr: 0.00001
[epoch 322: 300/307] 	 train loss: 0.239346 	 lr: 0.00001
[epoch 323:   0/307] 	 train loss: 0.130112 	 lr: 0.00001
[epoch 323:  20/307] 	 train loss: 0.096683 	 lr: 0.00001
[epoch 323:  40/307] 	 train loss: 0.127161 	 lr: 0.00001
[epoch 323:  60/307] 	 train loss: 0.030024 	 lr: 0.00001
[epoch 323:  80/307] 	 train loss: 0.161790 	 lr: 0.00001
[epoch 323: 100/307] 	 train loss: 0.195234 	 lr: 0.00001
[epoch 323: 120/307] 	 train loss: 0.242107 	 lr: 0.00001

val loss: 0.351932 	 acc: 0.910049

[epoch 323: 140/307] 	 train loss: 0.063018 	 lr: 0.00001
[epoch 323: 160/307] 	 train loss: 0.134367 	 lr: 0.00001
[epoch 323: 180/307] 	 train loss: 0.136209 	 lr: 0.00001
[epoch 323: 200/307] 	 train loss: 0.017586 	 lr: 0.00001
[epoch 323: 220/307] 	 train loss: 0.104472 	 lr: 0.00001
[epoch 323: 240/307] 	 train loss: 0.061847 	 lr: 0.00001
[epoch 323: 260/307] 	 train loss: 0.096885 	 lr: 0.00001

val loss: 0.353024 	 acc: 0.911669

[epoch 323: 280/307] 	 train loss: 0.096223 	 lr: 0.00001
[epoch 323: 300/307] 	 train loss: 0.016246 	 lr: 0.00001
[epoch 324:   0/307] 	 train loss: 0.112538 	 lr: 0.00001
[epoch 324:  20/307] 	 train loss: 0.186778 	 lr: 0.00001
[epoch 324:  40/307] 	 train loss: 0.016695 	 lr: 0.00001
[epoch 324:  60/307] 	 train loss: 0.172395 	 lr: 0.00001
[epoch 324:  80/307] 	 train loss: 0.053995 	 lr: 0.00001
[epoch 324: 100/307] 	 train loss: 0.165543 	 lr: 0.00001

val loss: 0.351967 	 acc: 0.911669

[epoch 324: 120/307] 	 train loss: 0.105223 	 lr: 0.00001
[epoch 324: 140/307] 	 train loss: 0.016511 	 lr: 0.00001
[epoch 324: 160/307] 	 train loss: 0.192996 	 lr: 0.00001
[epoch 324: 180/307] 	 train loss: 0.207674 	 lr: 0.00001
[epoch 324: 200/307] 	 train loss: 0.091519 	 lr: 0.00001
[epoch 324: 220/307] 	 train loss: 0.157370 	 lr: 0.00001
[epoch 324: 240/307] 	 train loss: 0.057843 	 lr: 0.00001
[epoch 324: 260/307] 	 train loss: 0.085485 	 lr: 0.00001

val loss: 0.354511 	 acc: 0.912075

[epoch 324: 280/307] 	 train loss: 0.038370 	 lr: 0.00001
[epoch 324: 300/307] 	 train loss: 0.193687 	 lr: 0.00001
[epoch 325:   0/307] 	 train loss: 0.392068 	 lr: 0.00001
[epoch 325:  20/307] 	 train loss: 0.048934 	 lr: 0.00001
[epoch 325:  40/307] 	 train loss: 0.043333 	 lr: 0.00001
[epoch 325:  60/307] 	 train loss: 0.111009 	 lr: 0.00001
[epoch 325:  80/307] 	 train loss: 0.138279 	 lr: 0.00001
[epoch 325: 100/307] 	 train loss: 0.126352 	 lr: 0.00001

val loss: 0.354643 	 acc: 0.911669

[epoch 325: 120/307] 	 train loss: 0.059767 	 lr: 0.00001
[epoch 325: 140/307] 	 train loss: 0.178896 	 lr: 0.00001
[epoch 325: 160/307] 	 train loss: 0.248757 	 lr: 0.00001
[epoch 325: 180/307] 	 train loss: 0.031921 	 lr: 0.00001
[epoch 325: 200/307] 	 train loss: 0.326400 	 lr: 0.00001
[epoch 325: 220/307] 	 train loss: 0.046586 	 lr: 0.00001
[epoch 325: 240/307] 	 train loss: 0.158338 	 lr: 0.00001
[epoch 325: 260/307] 	 train loss: 0.051057 	 lr: 0.00001

val loss: 0.351441 	 acc: 0.911669

[epoch 325: 280/307] 	 train loss: 0.108180 	 lr: 0.00001
[epoch 325: 300/307] 	 train loss: 0.117555 	 lr: 0.00001
[epoch 326:   0/307] 	 train loss: 0.088588 	 lr: 0.00001
[epoch 326:  20/307] 	 train loss: 0.335161 	 lr: 0.00001
[epoch 326:  40/307] 	 train loss: 0.189766 	 lr: 0.00001
[epoch 326:  60/307] 	 train loss: 0.093379 	 lr: 0.00001
[epoch 326:  80/307] 	 train loss: 0.056973 	 lr: 0.00001
[epoch 326: 100/307] 	 train loss: 0.113642 	 lr: 0.00001

val loss: 0.353935 	 acc: 0.912075

[epoch 326: 120/307] 	 train loss: 0.032629 	 lr: 0.00001
[epoch 326: 140/307] 	 train loss: 0.050144 	 lr: 0.00001
[epoch 326: 160/307] 	 train loss: 0.286661 	 lr: 0.00001
[epoch 326: 180/307] 	 train loss: 0.183812 	 lr: 0.00001
[epoch 326: 200/307] 	 train loss: 0.085528 	 lr: 0.00001
[epoch 326: 220/307] 	 train loss: 0.086656 	 lr: 0.00001
[epoch 326: 240/307] 	 train loss: 0.305124 	 lr: 0.00001
[epoch 326: 260/307] 	 train loss: 0.356558 	 lr: 0.00001

val loss: 0.352924 	 acc: 0.911669

[epoch 326: 280/307] 	 train loss: 0.029892 	 lr: 0.00001
[epoch 326: 300/307] 	 train loss: 0.159300 	 lr: 0.00001
[epoch 327:   0/307] 	 train loss: 0.070830 	 lr: 0.00001
[epoch 327:  20/307] 	 train loss: 0.007642 	 lr: 0.00001
[epoch 327:  40/307] 	 train loss: 0.080677 	 lr: 0.00001
[epoch 327:  60/307] 	 train loss: 0.034310 	 lr: 0.00001
[epoch 327:  80/307] 	 train loss: 0.070039 	 lr: 0.00001
[epoch 327: 100/307] 	 train loss: 0.090178 	 lr: 0.00001

val loss: 0.353554 	 acc: 0.913290

[epoch 327: 120/307] 	 train loss: 0.032033 	 lr: 0.00001
[epoch 327: 140/307] 	 train loss: 0.013571 	 lr: 0.00001
[epoch 327: 160/307] 	 train loss: 0.056744 	 lr: 0.00001
[epoch 327: 180/307] 	 train loss: 0.074802 	 lr: 0.00001
[epoch 327: 200/307] 	 train loss: 0.430502 	 lr: 0.00001
[epoch 327: 220/307] 	 train loss: 0.188267 	 lr: 0.00001
[epoch 327: 240/307] 	 train loss: 0.141932 	 lr: 0.00001
[epoch 327: 260/307] 	 train loss: 0.055318 	 lr: 0.00001

val loss: 0.352890 	 acc: 0.910859

[epoch 327: 280/307] 	 train loss: 0.157597 	 lr: 0.00001
[epoch 327: 300/307] 	 train loss: 0.056621 	 lr: 0.00001
[epoch 328:   0/307] 	 train loss: 0.096558 	 lr: 0.00001
[epoch 328:  20/307] 	 train loss: 0.031913 	 lr: 0.00001
[epoch 328:  40/307] 	 train loss: 0.174874 	 lr: 0.00001
[epoch 328:  60/307] 	 train loss: 0.155289 	 lr: 0.00001
[epoch 328:  80/307] 	 train loss: 0.285992 	 lr: 0.00001
[epoch 328: 100/307] 	 train loss: 0.105178 	 lr: 0.00001

val loss: 0.351029 	 acc: 0.911264

[epoch 328: 120/307] 	 train loss: 0.063900 	 lr: 0.00001
[epoch 328: 140/307] 	 train loss: 0.115741 	 lr: 0.00001
[epoch 328: 160/307] 	 train loss: 0.103283 	 lr: 0.00001
[epoch 328: 180/307] 	 train loss: 0.053522 	 lr: 0.00001
[epoch 328: 200/307] 	 train loss: 0.017982 	 lr: 0.00001
[epoch 328: 220/307] 	 train loss: 0.161450 	 lr: 0.00001
[epoch 328: 240/307] 	 train loss: 0.187962 	 lr: 0.00001
[epoch 328: 260/307] 	 train loss: 0.035354 	 lr: 0.00001

val loss: 0.351291 	 acc: 0.912075

[epoch 328: 280/307] 	 train loss: 0.043454 	 lr: 0.00001
[epoch 328: 300/307] 	 train loss: 0.114397 	 lr: 0.00001
[epoch 329:   0/307] 	 train loss: 0.106630 	 lr: 0.00001
[epoch 329:  20/307] 	 train loss: 0.088146 	 lr: 0.00001
[epoch 329:  40/307] 	 train loss: 0.210916 	 lr: 0.00001
[epoch 329:  60/307] 	 train loss: 0.080927 	 lr: 0.00001
[epoch 329:  80/307] 	 train loss: 0.193445 	 lr: 0.00001
[epoch 329: 100/307] 	 train loss: 0.226112 	 lr: 0.00001

val loss: 0.352333 	 acc: 0.913695

[epoch 329: 120/307] 	 train loss: 0.094511 	 lr: 0.00001
[epoch 329: 140/307] 	 train loss: 0.047094 	 lr: 0.00001
[epoch 329: 160/307] 	 train loss: 0.040277 	 lr: 0.00001
[epoch 329: 180/307] 	 train loss: 0.093255 	 lr: 0.00001
[epoch 329: 200/307] 	 train loss: 0.037219 	 lr: 0.00001
[epoch 329: 220/307] 	 train loss: 0.046748 	 lr: 0.00001
[epoch 329: 240/307] 	 train loss: 0.273414 	 lr: 0.00001
[epoch 329: 260/307] 	 train loss: 0.426901 	 lr: 0.00001

val loss: 0.352824 	 acc: 0.911669

[epoch 329: 280/307] 	 train loss: 0.029322 	 lr: 0.00001
[epoch 329: 300/307] 	 train loss: 0.033318 	 lr: 0.00001
[epoch 330:   0/307] 	 train loss: 0.011688 	 lr: 0.00001
[epoch 330:  20/307] 	 train loss: 0.021293 	 lr: 0.00001
[epoch 330:  40/307] 	 train loss: 0.005783 	 lr: 0.00001
[epoch 330:  60/307] 	 train loss: 0.158774 	 lr: 0.00001
[epoch 330:  80/307] 	 train loss: 0.087862 	 lr: 0.00001
[epoch 330: 100/307] 	 train loss: 0.122358 	 lr: 0.00001

val loss: 0.351766 	 acc: 0.912885

[epoch 330: 120/307] 	 train loss: 0.109307 	 lr: 0.00001
[epoch 330: 140/307] 	 train loss: 0.102141 	 lr: 0.00001
[epoch 330: 160/307] 	 train loss: 0.180996 	 lr: 0.00001
[epoch 330: 180/307] 	 train loss: 0.251150 	 lr: 0.00001
[epoch 330: 200/307] 	 train loss: 0.141074 	 lr: 0.00001
[epoch 330: 220/307] 	 train loss: 0.160757 	 lr: 0.00001
[epoch 330: 240/307] 	 train loss: 0.027470 	 lr: 0.00001

val loss: 0.352620 	 acc: 0.912480

[epoch 330: 260/307] 	 train loss: 0.087479 	 lr: 0.00001
[epoch 330: 280/307] 	 train loss: 0.034958 	 lr: 0.00001
[epoch 330: 300/307] 	 train loss: 0.043715 	 lr: 0.00001
[epoch 331:   0/307] 	 train loss: 0.148862 	 lr: 0.00001
[epoch 331:  20/307] 	 train loss: 0.053920 	 lr: 0.00001
[epoch 331:  40/307] 	 train loss: 0.165274 	 lr: 0.00001
[epoch 331:  60/307] 	 train loss: 0.077570 	 lr: 0.00001
[epoch 331:  80/307] 	 train loss: 0.108248 	 lr: 0.00001
[epoch 331: 100/307] 	 train loss: 0.030558 	 lr: 0.00001

val loss: 0.352012 	 acc: 0.910454

[epoch 331: 120/307] 	 train loss: 0.033703 	 lr: 0.00001
[epoch 331: 140/307] 	 train loss: 0.022487 	 lr: 0.00001
[epoch 331: 160/307] 	 train loss: 0.080554 	 lr: 0.00001
[epoch 331: 180/307] 	 train loss: 0.028038 	 lr: 0.00001
[epoch 331: 200/307] 	 train loss: 0.034626 	 lr: 0.00001
[epoch 331: 220/307] 	 train loss: 0.132395 	 lr: 0.00001
[epoch 331: 240/307] 	 train loss: 0.089606 	 lr: 0.00001

val loss: 0.353527 	 acc: 0.911264

[epoch 331: 260/307] 	 train loss: 0.079857 	 lr: 0.00001
[epoch 331: 280/307] 	 train loss: 0.114237 	 lr: 0.00001
[epoch 331: 300/307] 	 train loss: 0.036713 	 lr: 0.00001
[epoch 332:   0/307] 	 train loss: 0.066021 	 lr: 0.00001
[epoch 332:  20/307] 	 train loss: 0.144257 	 lr: 0.00001
[epoch 332:  40/307] 	 train loss: 0.102007 	 lr: 0.00001
[epoch 332:  60/307] 	 train loss: 0.058199 	 lr: 0.00001
[epoch 332:  80/307] 	 train loss: 0.278573 	 lr: 0.00001
[epoch 332: 100/307] 	 train loss: 0.026724 	 lr: 0.00001

val loss: 0.352705 	 acc: 0.913290

[epoch 332: 120/307] 	 train loss: 0.148654 	 lr: 0.00001
[epoch 332: 140/307] 	 train loss: 0.024151 	 lr: 0.00001
[epoch 332: 160/307] 	 train loss: 0.068808 	 lr: 0.00001
[epoch 332: 180/307] 	 train loss: 0.126122 	 lr: 0.00001
[epoch 332: 200/307] 	 train loss: 0.078121 	 lr: 0.00001
[epoch 332: 220/307] 	 train loss: 0.130061 	 lr: 0.00001
[epoch 332: 240/307] 	 train loss: 0.105347 	 lr: 0.00001

val loss: 0.352914 	 acc: 0.913290

[epoch 332: 260/307] 	 train loss: 0.221602 	 lr: 0.00001
[epoch 332: 280/307] 	 train loss: 0.022964 	 lr: 0.00001
[epoch 332: 300/307] 	 train loss: 0.159297 	 lr: 0.00001
[epoch 333:   0/307] 	 train loss: 0.039579 	 lr: 0.00001
[epoch 333:  20/307] 	 train loss: 0.232449 	 lr: 0.00001
[epoch 333:  40/307] 	 train loss: 0.065739 	 lr: 0.00001
[epoch 333:  60/307] 	 train loss: 0.181623 	 lr: 0.00001
[epoch 333:  80/307] 	 train loss: 0.080863 	 lr: 0.00001
[epoch 333: 100/307] 	 train loss: 0.054750 	 lr: 0.00001

val loss: 0.352170 	 acc: 0.912885

[epoch 333: 120/307] 	 train loss: 0.022715 	 lr: 0.00001
[epoch 333: 140/307] 	 train loss: 0.046761 	 lr: 0.00001
[epoch 333: 160/307] 	 train loss: 0.035731 	 lr: 0.00001
[epoch 333: 180/307] 	 train loss: 0.043746 	 lr: 0.00001
[epoch 333: 200/307] 	 train loss: 0.020951 	 lr: 0.00001
[epoch 333: 220/307] 	 train loss: 0.105459 	 lr: 0.00001
[epoch 333: 240/307] 	 train loss: 0.044952 	 lr: 0.00001

val loss: 0.348488 	 acc: 0.911669

[epoch 333: 260/307] 	 train loss: 0.076093 	 lr: 0.00001
[epoch 333: 280/307] 	 train loss: 0.134385 	 lr: 0.00001
[epoch 333: 300/307] 	 train loss: 0.115546 	 lr: 0.00001
[epoch 334:   0/307] 	 train loss: 0.099669 	 lr: 0.00001
[epoch 334:  20/307] 	 train loss: 0.110328 	 lr: 0.00001
[epoch 334:  40/307] 	 train loss: 0.060034 	 lr: 0.00001
[epoch 334:  60/307] 	 train loss: 0.093550 	 lr: 0.00001
[epoch 334:  80/307] 	 train loss: 0.038285 	 lr: 0.00001

val loss: 0.350674 	 acc: 0.910049

[epoch 334: 100/307] 	 train loss: 0.087659 	 lr: 0.00001
[epoch 334: 120/307] 	 train loss: 0.236571 	 lr: 0.00001
[epoch 334: 140/307] 	 train loss: 0.056600 	 lr: 0.00001
[epoch 334: 160/307] 	 train loss: 0.015900 	 lr: 0.00001
[epoch 334: 180/307] 	 train loss: 0.091828 	 lr: 0.00001
[epoch 334: 200/307] 	 train loss: 0.068807 	 lr: 0.00001
[epoch 334: 220/307] 	 train loss: 0.296214 	 lr: 0.00001
[epoch 334: 240/307] 	 train loss: 0.055482 	 lr: 0.00001

val loss: 0.350558 	 acc: 0.913290

[epoch 334: 260/307] 	 train loss: 0.092692 	 lr: 0.00001
[epoch 334: 280/307] 	 train loss: 0.226086 	 lr: 0.00001
[epoch 334: 300/307] 	 train loss: 0.114213 	 lr: 0.00001
[epoch 335:   0/307] 	 train loss: 0.075949 	 lr: 0.00001
[epoch 335:  20/307] 	 train loss: 0.022950 	 lr: 0.00001
[epoch 335:  40/307] 	 train loss: 0.088494 	 lr: 0.00001
[epoch 335:  60/307] 	 train loss: 0.123981 	 lr: 0.00001
[epoch 335:  80/307] 	 train loss: 0.139768 	 lr: 0.00001

val loss: 0.350323 	 acc: 0.913695

[epoch 335: 100/307] 	 train loss: 0.036591 	 lr: 0.00001
[epoch 335: 120/307] 	 train loss: 0.015655 	 lr: 0.00001
[epoch 335: 140/307] 	 train loss: 0.164351 	 lr: 0.00001
[epoch 335: 160/307] 	 train loss: 0.305263 	 lr: 0.00001
[epoch 335: 180/307] 	 train loss: 0.019744 	 lr: 0.00001
[epoch 335: 200/307] 	 train loss: 0.052056 	 lr: 0.00001
[epoch 335: 220/307] 	 train loss: 0.071145 	 lr: 0.00001
[epoch 335: 240/307] 	 train loss: 0.129848 	 lr: 0.00001

val loss: 0.349524 	 acc: 0.911669

[epoch 335: 260/307] 	 train loss: 0.240796 	 lr: 0.00001
[epoch 335: 280/307] 	 train loss: 0.046918 	 lr: 0.00001
[epoch 335: 300/307] 	 train loss: 0.053633 	 lr: 0.00001
[epoch 336:   0/307] 	 train loss: 0.026842 	 lr: 0.00001
[epoch 336:  20/307] 	 train loss: 0.379514 	 lr: 0.00001
[epoch 336:  40/307] 	 train loss: 0.058165 	 lr: 0.00001
[epoch 336:  60/307] 	 train loss: 0.038022 	 lr: 0.00001
[epoch 336:  80/307] 	 train loss: 0.161305 	 lr: 0.00001

val loss: 0.348322 	 acc: 0.913290

[epoch 336: 100/307] 	 train loss: 0.178624 	 lr: 0.00001
[epoch 336: 120/307] 	 train loss: 0.353976 	 lr: 0.00001
[epoch 336: 140/307] 	 train loss: 0.016189 	 lr: 0.00001
[epoch 336: 160/307] 	 train loss: 0.142513 	 lr: 0.00001
[epoch 336: 180/307] 	 train loss: 0.077599 	 lr: 0.00001
[epoch 336: 200/307] 	 train loss: 0.183737 	 lr: 0.00001
[epoch 336: 220/307] 	 train loss: 0.073442 	 lr: 0.00001
[epoch 336: 240/307] 	 train loss: 0.034294 	 lr: 0.00001

val loss: 0.350897 	 acc: 0.912885

[epoch 336: 260/307] 	 train loss: 0.309989 	 lr: 0.00001
[epoch 336: 280/307] 	 train loss: 0.067765 	 lr: 0.00001
[epoch 336: 300/307] 	 train loss: 0.030371 	 lr: 0.00001
[epoch 337:   0/307] 	 train loss: 0.028073 	 lr: 0.00001
[epoch 337:  20/307] 	 train loss: 0.133167 	 lr: 0.00001
[epoch 337:  40/307] 	 train loss: 0.230483 	 lr: 0.00001
[epoch 337:  60/307] 	 train loss: 0.101224 	 lr: 0.00001
[epoch 337:  80/307] 	 train loss: 0.055418 	 lr: 0.00001

val loss: 0.350389 	 acc: 0.913290

[epoch 337: 100/307] 	 train loss: 0.052659 	 lr: 0.00001
[epoch 337: 120/307] 	 train loss: 0.033891 	 lr: 0.00001
[epoch 337: 140/307] 	 train loss: 0.053658 	 lr: 0.00001
[epoch 337: 160/307] 	 train loss: 0.077517 	 lr: 0.00001
[epoch 337: 180/307] 	 train loss: 0.062923 	 lr: 0.00001
[epoch 337: 200/307] 	 train loss: 0.024052 	 lr: 0.00001
[epoch 337: 220/307] 	 train loss: 0.279645 	 lr: 0.00001
[epoch 337: 240/307] 	 train loss: 0.120017 	 lr: 0.00001

val loss: 0.351372 	 acc: 0.912075

[epoch 337: 260/307] 	 train loss: 0.244053 	 lr: 0.00001
[epoch 337: 280/307] 	 train loss: 0.064316 	 lr: 0.00001
[epoch 337: 300/307] 	 train loss: 0.126182 	 lr: 0.00001
[epoch 338:   0/307] 	 train loss: 0.135681 	 lr: 0.00001
[epoch 338:  20/307] 	 train loss: 0.047527 	 lr: 0.00001
[epoch 338:  40/307] 	 train loss: 0.210511 	 lr: 0.00001
[epoch 338:  60/307] 	 train loss: 0.030199 	 lr: 0.00001
[epoch 338:  80/307] 	 train loss: 0.142357 	 lr: 0.00001

val loss: 0.351470 	 acc: 0.913290

[epoch 338: 100/307] 	 train loss: 0.273101 	 lr: 0.00001
[epoch 338: 120/307] 	 train loss: 0.067770 	 lr: 0.00001
[epoch 338: 140/307] 	 train loss: 0.111675 	 lr: 0.00001
[epoch 338: 160/307] 	 train loss: 0.189422 	 lr: 0.00001
[epoch 338: 180/307] 	 train loss: 0.105672 	 lr: 0.00001
[epoch 338: 200/307] 	 train loss: 0.017911 	 lr: 0.00001
[epoch 338: 220/307] 	 train loss: 0.099943 	 lr: 0.00001
[epoch 338: 240/307] 	 train loss: 0.111520 	 lr: 0.00001

val loss: 0.350427 	 acc: 0.913290

[epoch 338: 260/307] 	 train loss: 0.079199 	 lr: 0.00001
[epoch 338: 280/307] 	 train loss: 0.009554 	 lr: 0.00001
[epoch 338: 300/307] 	 train loss: 0.072717 	 lr: 0.00001
[epoch 339:   0/307] 	 train loss: 0.119123 	 lr: 0.00001
[epoch 339:  20/307] 	 train loss: 0.057543 	 lr: 0.00001
[epoch 339:  40/307] 	 train loss: 0.203315 	 lr: 0.00001
[epoch 339:  60/307] 	 train loss: 0.097447 	 lr: 0.00001
[epoch 339:  80/307] 	 train loss: 0.131107 	 lr: 0.00001

val loss: 0.352058 	 acc: 0.913695

[epoch 339: 100/307] 	 train loss: 0.241782 	 lr: 0.00001
[epoch 339: 120/307] 	 train loss: 0.026380 	 lr: 0.00001
[epoch 339: 140/307] 	 train loss: 0.134226 	 lr: 0.00001
[epoch 339: 160/307] 	 train loss: 0.023764 	 lr: 0.00001
[epoch 339: 180/307] 	 train loss: 0.087102 	 lr: 0.00001
[epoch 339: 200/307] 	 train loss: 0.077997 	 lr: 0.00001
[epoch 339: 220/307] 	 train loss: 0.102475 	 lr: 0.00001
[epoch 339: 240/307] 	 train loss: 0.159412 	 lr: 0.00001

val loss: 0.352911 	 acc: 0.912885

[epoch 339: 260/307] 	 train loss: 0.198697 	 lr: 0.00001
[epoch 339: 280/307] 	 train loss: 0.029023 	 lr: 0.00001
[epoch 339: 300/307] 	 train loss: 0.061142 	 lr: 0.00001
[epoch 340:   0/307] 	 train loss: 0.062319 	 lr: 0.00001
[epoch 340:  20/307] 	 train loss: 0.039298 	 lr: 0.00001
[epoch 340:  40/307] 	 train loss: 0.033970 	 lr: 0.00001
[epoch 340:  60/307] 	 train loss: 0.035244 	 lr: 0.00001
[epoch 340:  80/307] 	 train loss: 0.136310 	 lr: 0.00001

val loss: 0.353294 	 acc: 0.912075

[epoch 340: 100/307] 	 train loss: 0.043921 	 lr: 0.00001
[epoch 340: 120/307] 	 train loss: 0.107045 	 lr: 0.00001
[epoch 340: 140/307] 	 train loss: 0.015170 	 lr: 0.00001
[epoch 340: 160/307] 	 train loss: 0.101490 	 lr: 0.00001
[epoch 340: 180/307] 	 train loss: 0.091575 	 lr: 0.00001
[epoch 340: 200/307] 	 train loss: 0.009285 	 lr: 0.00001
[epoch 340: 220/307] 	 train loss: 0.111312 	 lr: 0.00001

val loss: 0.353617 	 acc: 0.911669

[epoch 340: 240/307] 	 train loss: 0.033754 	 lr: 0.00001
[epoch 340: 260/307] 	 train loss: 0.051724 	 lr: 0.00001
[epoch 340: 280/307] 	 train loss: 0.076973 	 lr: 0.00001
[epoch 340: 300/307] 	 train loss: 0.163727 	 lr: 0.00001
[epoch 341:   0/307] 	 train loss: 0.240647 	 lr: 0.00001
[epoch 341:  20/307] 	 train loss: 0.047050 	 lr: 0.00001
[epoch 341:  40/307] 	 train loss: 0.113457 	 lr: 0.00001
[epoch 341:  60/307] 	 train loss: 0.339006 	 lr: 0.00001
[epoch 341:  80/307] 	 train loss: 0.050303 	 lr: 0.00001

val loss: 0.353057 	 acc: 0.912480

[epoch 341: 100/307] 	 train loss: 0.037416 	 lr: 0.00001
[epoch 341: 120/307] 	 train loss: 0.042852 	 lr: 0.00001
[epoch 341: 140/307] 	 train loss: 0.404262 	 lr: 0.00001
[epoch 341: 160/307] 	 train loss: 0.501061 	 lr: 0.00001
[epoch 341: 180/307] 	 train loss: 0.250146 	 lr: 0.00001
[epoch 341: 200/307] 	 train loss: 0.208160 	 lr: 0.00001
[epoch 341: 220/307] 	 train loss: 0.026160 	 lr: 0.00001

val loss: 0.351993 	 acc: 0.912885

[epoch 341: 240/307] 	 train loss: 0.116918 	 lr: 0.00001
[epoch 341: 260/307] 	 train loss: 0.108175 	 lr: 0.00001
[epoch 341: 280/307] 	 train loss: 0.136646 	 lr: 0.00001
[epoch 341: 300/307] 	 train loss: 0.290598 	 lr: 0.00001
[epoch 342:   0/307] 	 train loss: 0.059779 	 lr: 0.00001
[epoch 342:  20/307] 	 train loss: 0.208186 	 lr: 0.00001
[epoch 342:  40/307] 	 train loss: 0.494443 	 lr: 0.00001
[epoch 342:  60/307] 	 train loss: 0.190836 	 lr: 0.00001
[epoch 342:  80/307] 	 train loss: 0.088395 	 lr: 0.00001

val loss: 0.351196 	 acc: 0.913290

[epoch 342: 100/307] 	 train loss: 0.206245 	 lr: 0.00001
[epoch 342: 120/307] 	 train loss: 0.144647 	 lr: 0.00001
[epoch 342: 140/307] 	 train loss: 0.096160 	 lr: 0.00001
[epoch 342: 160/307] 	 train loss: 0.066552 	 lr: 0.00001
[epoch 342: 180/307] 	 train loss: 0.278776 	 lr: 0.00001
[epoch 342: 200/307] 	 train loss: 0.025492 	 lr: 0.00001
[epoch 342: 220/307] 	 train loss: 0.187743 	 lr: 0.00001

val loss: 0.353176 	 acc: 0.912885

[epoch 342: 240/307] 	 train loss: 0.111586 	 lr: 0.00001
[epoch 342: 260/307] 	 train loss: 0.147660 	 lr: 0.00001
[epoch 342: 280/307] 	 train loss: 0.059307 	 lr: 0.00001
[epoch 342: 300/307] 	 train loss: 0.038148 	 lr: 0.00001
[epoch 343:   0/307] 	 train loss: 0.139256 	 lr: 0.00001
[epoch 343:  20/307] 	 train loss: 0.036189 	 lr: 0.00001
[epoch 343:  40/307] 	 train loss: 0.040791 	 lr: 0.00001
[epoch 343:  60/307] 	 train loss: 0.132301 	 lr: 0.00001
[epoch 343:  80/307] 	 train loss: 0.090000 	 lr: 0.00001

val loss: 0.353950 	 acc: 0.912480

[epoch 343: 100/307] 	 train loss: 0.165340 	 lr: 0.00001
[epoch 343: 120/307] 	 train loss: 0.009739 	 lr: 0.00001
[epoch 343: 140/307] 	 train loss: 0.027546 	 lr: 0.00001
[epoch 343: 160/307] 	 train loss: 0.059981 	 lr: 0.00001
[epoch 343: 180/307] 	 train loss: 0.108012 	 lr: 0.00001
[epoch 343: 200/307] 	 train loss: 0.153984 	 lr: 0.00001
[epoch 343: 220/307] 	 train loss: 0.080347 	 lr: 0.00001

val loss: 0.351953 	 acc: 0.914100

[epoch 343: 240/307] 	 train loss: 0.286222 	 lr: 0.00001
[epoch 343: 260/307] 	 train loss: 0.079504 	 lr: 0.00001
[epoch 343: 280/307] 	 train loss: 0.022048 	 lr: 0.00001
[epoch 343: 300/307] 	 train loss: 0.025687 	 lr: 0.00001
[epoch 344:   0/307] 	 train loss: 0.054098 	 lr: 0.00001
[epoch 344:  20/307] 	 train loss: 0.055977 	 lr: 0.00001
[epoch 344:  40/307] 	 train loss: 0.022249 	 lr: 0.00001
[epoch 344:  60/307] 	 train loss: 0.043987 	 lr: 0.00001

val loss: 0.355058 	 acc: 0.911669

[epoch 344:  80/307] 	 train loss: 0.038941 	 lr: 0.00001
[epoch 344: 100/307] 	 train loss: 0.062799 	 lr: 0.00001
[epoch 344: 120/307] 	 train loss: 0.256409 	 lr: 0.00001
[epoch 344: 140/307] 	 train loss: 0.123200 	 lr: 0.00001
[epoch 344: 160/307] 	 train loss: 0.056209 	 lr: 0.00001
[epoch 344: 180/307] 	 train loss: 0.078413 	 lr: 0.00001
[epoch 344: 200/307] 	 train loss: 0.188133 	 lr: 0.00001
[epoch 344: 220/307] 	 train loss: 0.116877 	 lr: 0.00001

val loss: 0.353880 	 acc: 0.914506

[epoch 344: 240/307] 	 train loss: 0.262084 	 lr: 0.00001
[epoch 344: 260/307] 	 train loss: 0.204157 	 lr: 0.00001
[epoch 344: 280/307] 	 train loss: 0.140727 	 lr: 0.00001
[epoch 344: 300/307] 	 train loss: 0.033122 	 lr: 0.00001
[epoch 345:   0/307] 	 train loss: 0.124055 	 lr: 0.00001
[epoch 345:  20/307] 	 train loss: 0.187887 	 lr: 0.00001
[epoch 345:  40/307] 	 train loss: 0.028891 	 lr: 0.00001
[epoch 345:  60/307] 	 train loss: 0.028453 	 lr: 0.00001

val loss: 0.353246 	 acc: 0.913290

[epoch 345:  80/307] 	 train loss: 0.014939 	 lr: 0.00001
[epoch 345: 100/307] 	 train loss: 0.027178 	 lr: 0.00001
[epoch 345: 120/307] 	 train loss: 0.064394 	 lr: 0.00001
[epoch 345: 140/307] 	 train loss: 0.026856 	 lr: 0.00001
[epoch 345: 160/307] 	 train loss: 0.158673 	 lr: 0.00001
[epoch 345: 180/307] 	 train loss: 0.242474 	 lr: 0.00001
[epoch 345: 200/307] 	 train loss: 0.124718 	 lr: 0.00001
[epoch 345: 220/307] 	 train loss: 0.193394 	 lr: 0.00001

val loss: 0.351877 	 acc: 0.912075

[epoch 345: 240/307] 	 train loss: 0.024635 	 lr: 0.00001
[epoch 345: 260/307] 	 train loss: 0.039314 	 lr: 0.00001
[epoch 345: 280/307] 	 train loss: 0.044058 	 lr: 0.00001
[epoch 345: 300/307] 	 train loss: 0.053209 	 lr: 0.00001
[epoch 346:   0/307] 	 train loss: 0.085873 	 lr: 0.00001
[epoch 346:  20/307] 	 train loss: 0.311919 	 lr: 0.00001
[epoch 346:  40/307] 	 train loss: 0.145702 	 lr: 0.00001
[epoch 346:  60/307] 	 train loss: 0.008683 	 lr: 0.00001

val loss: 0.351630 	 acc: 0.912885

[epoch 346:  80/307] 	 train loss: 0.099754 	 lr: 0.00001
[epoch 346: 100/307] 	 train loss: 0.079210 	 lr: 0.00001
[epoch 346: 120/307] 	 train loss: 0.028251 	 lr: 0.00001
[epoch 346: 140/307] 	 train loss: 0.078864 	 lr: 0.00001
[epoch 346: 160/307] 	 train loss: 0.118395 	 lr: 0.00001
[epoch 346: 180/307] 	 train loss: 0.037670 	 lr: 0.00001
[epoch 346: 200/307] 	 train loss: 0.099995 	 lr: 0.00001
[epoch 346: 220/307] 	 train loss: 0.069235 	 lr: 0.00001

val loss: 0.352918 	 acc: 0.912885

[epoch 346: 240/307] 	 train loss: 0.106990 	 lr: 0.00001
[epoch 346: 260/307] 	 train loss: 0.003815 	 lr: 0.00001
[epoch 346: 280/307] 	 train loss: 0.027597 	 lr: 0.00001
[epoch 346: 300/307] 	 train loss: 0.121222 	 lr: 0.00001
[epoch 347:   0/307] 	 train loss: 0.170072 	 lr: 0.00001
[epoch 347:  20/307] 	 train loss: 0.030507 	 lr: 0.00001
[epoch 347:  40/307] 	 train loss: 0.119721 	 lr: 0.00001
[epoch 347:  60/307] 	 train loss: 0.138663 	 lr: 0.00001

val loss: 0.353530 	 acc: 0.913695

[epoch 347:  80/307] 	 train loss: 0.102135 	 lr: 0.00001
[epoch 347: 100/307] 	 train loss: 0.018673 	 lr: 0.00001
[epoch 347: 120/307] 	 train loss: 0.071002 	 lr: 0.00001
[epoch 347: 140/307] 	 train loss: 0.144372 	 lr: 0.00001
[epoch 347: 160/307] 	 train loss: 0.092957 	 lr: 0.00001
[epoch 347: 180/307] 	 train loss: 0.013063 	 lr: 0.00001
[epoch 347: 200/307] 	 train loss: 0.068012 	 lr: 0.00001
[epoch 347: 220/307] 	 train loss: 0.140835 	 lr: 0.00001

val loss: 0.351133 	 acc: 0.913290

[epoch 347: 240/307] 	 train loss: 0.062106 	 lr: 0.00001
[epoch 347: 260/307] 	 train loss: 0.046852 	 lr: 0.00001
[epoch 347: 280/307] 	 train loss: 0.036169 	 lr: 0.00001
[epoch 347: 300/307] 	 train loss: 0.087205 	 lr: 0.00001
[epoch 348:   0/307] 	 train loss: 0.029089 	 lr: 0.00001
[epoch 348:  20/307] 	 train loss: 0.094444 	 lr: 0.00001
[epoch 348:  40/307] 	 train loss: 0.094161 	 lr: 0.00001
[epoch 348:  60/307] 	 train loss: 0.030431 	 lr: 0.00001

val loss: 0.351150 	 acc: 0.912885

[epoch 348:  80/307] 	 train loss: 0.105428 	 lr: 0.00001
[epoch 348: 100/307] 	 train loss: 0.138660 	 lr: 0.00001
[epoch 348: 120/307] 	 train loss: 0.077117 	 lr: 0.00001
[epoch 348: 140/307] 	 train loss: 0.138107 	 lr: 0.00001
[epoch 348: 160/307] 	 train loss: 0.099348 	 lr: 0.00001
[epoch 348: 180/307] 	 train loss: 0.159100 	 lr: 0.00001
[epoch 348: 200/307] 	 train loss: 0.055492 	 lr: 0.00001
[epoch 348: 220/307] 	 train loss: 0.060873 	 lr: 0.00001

val loss: 0.352420 	 acc: 0.913290

[epoch 348: 240/307] 	 train loss: 0.060637 	 lr: 0.00001
[epoch 348: 260/307] 	 train loss: 0.123038 	 lr: 0.00001
[epoch 348: 280/307] 	 train loss: 0.008206 	 lr: 0.00001
[epoch 348: 300/307] 	 train loss: 0.202284 	 lr: 0.00001
[epoch 349:   0/307] 	 train loss: 0.184575 	 lr: 0.00001
[epoch 349:  20/307] 	 train loss: 0.220530 	 lr: 0.00001
[epoch 349:  40/307] 	 train loss: 0.024765 	 lr: 0.00001
[epoch 349:  60/307] 	 train loss: 0.068487 	 lr: 0.00001

val loss: 0.353842 	 acc: 0.914100

[epoch 349:  80/307] 	 train loss: 0.206544 	 lr: 0.00001
[epoch 349: 100/307] 	 train loss: 0.216616 	 lr: 0.00001
[epoch 349: 120/307] 	 train loss: 0.378660 	 lr: 0.00001
[epoch 349: 140/307] 	 train loss: 0.092362 	 lr: 0.00001
[epoch 349: 160/307] 	 train loss: 0.026780 	 lr: 0.00001
[epoch 349: 180/307] 	 train loss: 0.076019 	 lr: 0.00001
[epoch 349: 200/307] 	 train loss: 0.166075 	 lr: 0.00001
[epoch 349: 220/307] 	 train loss: 0.063654 	 lr: 0.00001

val loss: 0.354248 	 acc: 0.912480

[epoch 349: 240/307] 	 train loss: 0.247898 	 lr: 0.00001
[epoch 349: 260/307] 	 train loss: 0.055770 	 lr: 0.00001
[epoch 349: 280/307] 	 train loss: 0.188981 	 lr: 0.00001
[epoch 349: 300/307] 	 train loss: 0.148681 	 lr: 0.00001
[epoch 350:   0/307] 	 train loss: 0.154762 	 lr: 0.00001
[epoch 350:  20/307] 	 train loss: 0.123009 	 lr: 0.00001
[epoch 350:  40/307] 	 train loss: 0.041558 	 lr: 0.00001
[epoch 350:  60/307] 	 train loss: 0.210254 	 lr: 0.00001

val loss: 0.352134 	 acc: 0.913695

[epoch 350:  80/307] 	 train loss: 0.059631 	 lr: 0.00001
[epoch 350: 100/307] 	 train loss: 0.020793 	 lr: 0.00001
[epoch 350: 120/307] 	 train loss: 0.203518 	 lr: 0.00001
[epoch 350: 140/307] 	 train loss: 0.070379 	 lr: 0.00001
[epoch 350: 160/307] 	 train loss: 0.362128 	 lr: 0.00001
[epoch 350: 180/307] 	 train loss: 0.019928 	 lr: 0.00001
[epoch 350: 200/307] 	 train loss: 0.042755 	 lr: 0.00001

val loss: 0.353575 	 acc: 0.913695

[epoch 350: 220/307] 	 train loss: 0.035736 	 lr: 0.00001
[epoch 350: 240/307] 	 train loss: 0.257196 	 lr: 0.00001
[epoch 350: 260/307] 	 train loss: 0.039025 	 lr: 0.00001
[epoch 350: 280/307] 	 train loss: 0.123425 	 lr: 0.00001
[epoch 350: 300/307] 	 train loss: 0.053266 	 lr: 0.00001
[epoch 351:   0/307] 	 train loss: 0.005650 	 lr: 0.00001
[epoch 351:  20/307] 	 train loss: 0.113824 	 lr: 0.00001
[epoch 351:  40/307] 	 train loss: 0.143032 	 lr: 0.00001
[epoch 351:  60/307] 	 train loss: 0.130405 	 lr: 0.00001

val loss: 0.353496 	 acc: 0.913695

[epoch 351:  80/307] 	 train loss: 0.036587 	 lr: 0.00001
[epoch 351: 100/307] 	 train loss: 0.058101 	 lr: 0.00001
[epoch 351: 120/307] 	 train loss: 0.002133 	 lr: 0.00001
[epoch 351: 140/307] 	 train loss: 0.055309 	 lr: 0.00001
[epoch 351: 160/307] 	 train loss: 0.072506 	 lr: 0.00001
[epoch 351: 180/307] 	 train loss: 0.048574 	 lr: 0.00001
[epoch 351: 200/307] 	 train loss: 0.116974 	 lr: 0.00001

val loss: 0.353429 	 acc: 0.912075

[epoch 351: 220/307] 	 train loss: 0.263131 	 lr: 0.00001
[epoch 351: 240/307] 	 train loss: 0.095895 	 lr: 0.00001
[epoch 351: 260/307] 	 train loss: 0.027382 	 lr: 0.00001
[epoch 351: 280/307] 	 train loss: 0.040665 	 lr: 0.00001
[epoch 351: 300/307] 	 train loss: 0.053346 	 lr: 0.00001
[epoch 352:   0/307] 	 train loss: 0.092263 	 lr: 0.00001
[epoch 352:  20/307] 	 train loss: 0.068104 	 lr: 0.00001
[epoch 352:  40/307] 	 train loss: 0.052783 	 lr: 0.00001
[epoch 352:  60/307] 	 train loss: 0.226329 	 lr: 0.00001

val loss: 0.352054 	 acc: 0.912885

[epoch 352:  80/307] 	 train loss: 0.109806 	 lr: 0.00001
[epoch 352: 100/307] 	 train loss: 0.025775 	 lr: 0.00001
[epoch 352: 120/307] 	 train loss: 0.112984 	 lr: 0.00001
[epoch 352: 140/307] 	 train loss: 0.129388 	 lr: 0.00001
[epoch 352: 160/307] 	 train loss: 0.208192 	 lr: 0.00001
[epoch 352: 180/307] 	 train loss: 0.152822 	 lr: 0.00001
[epoch 352: 200/307] 	 train loss: 0.045053 	 lr: 0.00001

val loss: 0.352819 	 acc: 0.912075

[epoch 352: 220/307] 	 train loss: 0.057453 	 lr: 0.00001
[epoch 352: 240/307] 	 train loss: 0.016356 	 lr: 0.00001
[epoch 352: 260/307] 	 train loss: 0.038601 	 lr: 0.00001
[epoch 352: 280/307] 	 train loss: 0.045970 	 lr: 0.00001
[epoch 352: 300/307] 	 train loss: 0.105612 	 lr: 0.00001
[epoch 353:   0/307] 	 train loss: 0.169784 	 lr: 0.00001
[epoch 353:  20/307] 	 train loss: 0.071416 	 lr: 0.00001
[epoch 353:  40/307] 	 train loss: 0.053884 	 lr: 0.00001
[epoch 353:  60/307] 	 train loss: 0.178765 	 lr: 0.00001

val loss: 0.353004 	 acc: 0.913290

[epoch 353:  80/307] 	 train loss: 0.044658 	 lr: 0.00001
[epoch 353: 100/307] 	 train loss: 0.017578 	 lr: 0.00001
[epoch 353: 120/307] 	 train loss: 0.152681 	 lr: 0.00001
[epoch 353: 140/307] 	 train loss: 0.153606 	 lr: 0.00001
[epoch 353: 160/307] 	 train loss: 0.014138 	 lr: 0.00001
[epoch 353: 180/307] 	 train loss: 0.036113 	 lr: 0.00001
[epoch 353: 200/307] 	 train loss: 0.258999 	 lr: 0.00001

val loss: 0.353652 	 acc: 0.912885

[epoch 353: 220/307] 	 train loss: 0.089408 	 lr: 0.00001
[epoch 353: 240/307] 	 train loss: 0.035382 	 lr: 0.00001
[epoch 353: 260/307] 	 train loss: 0.024865 	 lr: 0.00001
[epoch 353: 280/307] 	 train loss: 0.139711 	 lr: 0.00001
[epoch 353: 300/307] 	 train loss: 0.017833 	 lr: 0.00001
[epoch 354:   0/307] 	 train loss: 0.143383 	 lr: 0.00001
[epoch 354:  20/307] 	 train loss: 0.190461 	 lr: 0.00001
[epoch 354:  40/307] 	 train loss: 0.196406 	 lr: 0.00001

val loss: 0.353898 	 acc: 0.913290

[epoch 354:  60/307] 	 train loss: 0.204950 	 lr: 0.00001
[epoch 354:  80/307] 	 train loss: 0.141457 	 lr: 0.00001
[epoch 354: 100/307] 	 train loss: 0.066190 	 lr: 0.00001
[epoch 354: 120/307] 	 train loss: 0.227117 	 lr: 0.00001
[epoch 354: 140/307] 	 train loss: 0.023595 	 lr: 0.00001
[epoch 354: 160/307] 	 train loss: 0.059670 	 lr: 0.00001
[epoch 354: 180/307] 	 train loss: 0.018892 	 lr: 0.00001
[epoch 354: 200/307] 	 train loss: 0.064151 	 lr: 0.00001

val loss: 0.354706 	 acc: 0.913290

[epoch 354: 220/307] 	 train loss: 0.108342 	 lr: 0.00001
[epoch 354: 240/307] 	 train loss: 0.106229 	 lr: 0.00001
[epoch 354: 260/307] 	 train loss: 0.122149 	 lr: 0.00001
[epoch 354: 280/307] 	 train loss: 0.231400 	 lr: 0.00001
[epoch 354: 300/307] 	 train loss: 0.106083 	 lr: 0.00001
[epoch 355:   0/307] 	 train loss: 0.058431 	 lr: 0.00001
[epoch 355:  20/307] 	 train loss: 0.038688 	 lr: 0.00001
[epoch 355:  40/307] 	 train loss: 0.150120 	 lr: 0.00001

val loss: 0.353537 	 acc: 0.914506

[epoch 355:  60/307] 	 train loss: 0.076709 	 lr: 0.00001
[epoch 355:  80/307] 	 train loss: 0.202920 	 lr: 0.00001
[epoch 355: 100/307] 	 train loss: 0.059341 	 lr: 0.00001
[epoch 355: 120/307] 	 train loss: 0.089981 	 lr: 0.00001
[epoch 355: 140/307] 	 train loss: 0.209763 	 lr: 0.00001
[epoch 355: 160/307] 	 train loss: 0.108855 	 lr: 0.00001
[epoch 355: 180/307] 	 train loss: 0.037281 	 lr: 0.00001
[epoch 355: 200/307] 	 train loss: 0.212868 	 lr: 0.00001

val loss: 0.354719 	 acc: 0.912885

[epoch 355: 220/307] 	 train loss: 0.200810 	 lr: 0.00001
[epoch 355: 240/307] 	 train loss: 0.091092 	 lr: 0.00001
[epoch 355: 260/307] 	 train loss: 0.176360 	 lr: 0.00001
[epoch 355: 280/307] 	 train loss: 0.034471 	 lr: 0.00001
[epoch 355: 300/307] 	 train loss: 0.128456 	 lr: 0.00001
[epoch 356:   0/307] 	 train loss: 0.114428 	 lr: 0.00001
[epoch 356:  20/307] 	 train loss: 0.144299 	 lr: 0.00001
[epoch 356:  40/307] 	 train loss: 0.059791 	 lr: 0.00001

val loss: 0.358323 	 acc: 0.913290

[epoch 356:  60/307] 	 train loss: 0.109911 	 lr: 0.00001
[epoch 356:  80/307] 	 train loss: 0.227645 	 lr: 0.00001
[epoch 356: 100/307] 	 train loss: 0.061701 	 lr: 0.00001
[epoch 356: 120/307] 	 train loss: 0.094980 	 lr: 0.00001
[epoch 356: 140/307] 	 train loss: 0.034642 	 lr: 0.00001
[epoch 356: 160/307] 	 train loss: 0.198586 	 lr: 0.00001
[epoch 356: 180/307] 	 train loss: 0.027216 	 lr: 0.00001
[epoch 356: 200/307] 	 train loss: 0.035081 	 lr: 0.00001

val loss: 0.354565 	 acc: 0.914100

[epoch 356: 220/307] 	 train loss: 0.024066 	 lr: 0.00001
[epoch 356: 240/307] 	 train loss: 0.098698 	 lr: 0.00001
[epoch 356: 260/307] 	 train loss: 0.090262 	 lr: 0.00001
[epoch 356: 280/307] 	 train loss: 0.118782 	 lr: 0.00001
[epoch 356: 300/307] 	 train loss: 0.010490 	 lr: 0.00001
[epoch 357:   0/307] 	 train loss: 0.100321 	 lr: 0.00001
[epoch 357:  20/307] 	 train loss: 0.049827 	 lr: 0.00001
[epoch 357:  40/307] 	 train loss: 0.011057 	 lr: 0.00001

val loss: 0.356223 	 acc: 0.913290

[epoch 357:  60/307] 	 train loss: 0.067724 	 lr: 0.00001
[epoch 357:  80/307] 	 train loss: 0.138352 	 lr: 0.00001
[epoch 357: 100/307] 	 train loss: 0.109639 	 lr: 0.00001
[epoch 357: 120/307] 	 train loss: 0.123402 	 lr: 0.00001
[epoch 357: 140/307] 	 train loss: 0.249971 	 lr: 0.00001
[epoch 357: 160/307] 	 train loss: 0.054986 	 lr: 0.00001
[epoch 357: 180/307] 	 train loss: 0.118723 	 lr: 0.00001
[epoch 357: 200/307] 	 train loss: 0.004711 	 lr: 0.00001

val loss: 0.355663 	 acc: 0.913290

[epoch 357: 220/307] 	 train loss: 0.019244 	 lr: 0.00001
[epoch 357: 240/307] 	 train loss: 0.147219 	 lr: 0.00001
[epoch 357: 260/307] 	 train loss: 0.127980 	 lr: 0.00001
[epoch 357: 280/307] 	 train loss: 0.097109 	 lr: 0.00001
[epoch 357: 300/307] 	 train loss: 0.043223 	 lr: 0.00001
[epoch 358:   0/307] 	 train loss: 0.157634 	 lr: 0.00001
[epoch 358:  20/307] 	 train loss: 0.063290 	 lr: 0.00001
[epoch 358:  40/307] 	 train loss: 0.261630 	 lr: 0.00001

val loss: 0.356076 	 acc: 0.912480

[epoch 358:  60/307] 	 train loss: 0.190279 	 lr: 0.00001
[epoch 358:  80/307] 	 train loss: 0.105155 	 lr: 0.00001
[epoch 358: 100/307] 	 train loss: 0.143329 	 lr: 0.00001
[epoch 358: 120/307] 	 train loss: 0.233706 	 lr: 0.00001
[epoch 358: 140/307] 	 train loss: 0.129847 	 lr: 0.00001
[epoch 358: 160/307] 	 train loss: 0.142489 	 lr: 0.00001
[epoch 358: 180/307] 	 train loss: 0.304417 	 lr: 0.00001
[epoch 358: 200/307] 	 train loss: 0.100119 	 lr: 0.00001

val loss: 0.354312 	 acc: 0.912075

[epoch 358: 220/307] 	 train loss: 0.126020 	 lr: 0.00001
[epoch 358: 240/307] 	 train loss: 0.040497 	 lr: 0.00001
[epoch 358: 260/307] 	 train loss: 0.054521 	 lr: 0.00001
[epoch 358: 280/307] 	 train loss: 0.121880 	 lr: 0.00001
[epoch 358: 300/307] 	 train loss: 0.026014 	 lr: 0.00001
[epoch 359:   0/307] 	 train loss: 0.042900 	 lr: 0.00001
[epoch 359:  20/307] 	 train loss: 0.096049 	 lr: 0.00001
[epoch 359:  40/307] 	 train loss: 0.023640 	 lr: 0.00001

val loss: 0.353443 	 acc: 0.911669

[epoch 359:  60/307] 	 train loss: 0.028152 	 lr: 0.00001
[epoch 359:  80/307] 	 train loss: 0.080719 	 lr: 0.00001
[epoch 359: 100/307] 	 train loss: 0.024843 	 lr: 0.00001
[epoch 359: 120/307] 	 train loss: 0.129893 	 lr: 0.00001
[epoch 359: 140/307] 	 train loss: 0.117819 	 lr: 0.00001
[epoch 359: 160/307] 	 train loss: 0.050856 	 lr: 0.00001
[epoch 359: 180/307] 	 train loss: 0.087326 	 lr: 0.00001
[epoch 359: 200/307] 	 train loss: 0.083451 	 lr: 0.00001

val loss: 0.356414 	 acc: 0.911669

[epoch 359: 220/307] 	 train loss: 0.146170 	 lr: 0.00001
[epoch 359: 240/307] 	 train loss: 0.138640 	 lr: 0.00001
[epoch 359: 260/307] 	 train loss: 0.090536 	 lr: 0.00001
[epoch 359: 280/307] 	 train loss: 0.062521 	 lr: 0.00001
[epoch 359: 300/307] 	 train loss: 0.121270 	 lr: 0.00001
[epoch 360:   0/307] 	 train loss: 0.108941 	 lr: 0.00001
[epoch 360:  20/307] 	 train loss: 0.167620 	 lr: 0.00001
[epoch 360:  40/307] 	 train loss: 0.197918 	 lr: 0.00001

val loss: 0.356388 	 acc: 0.913290

[epoch 360:  60/307] 	 train loss: 0.063795 	 lr: 0.00001
[epoch 360:  80/307] 	 train loss: 0.034054 	 lr: 0.00001
[epoch 360: 100/307] 	 train loss: 0.058536 	 lr: 0.00001
[epoch 360: 120/307] 	 train loss: 0.150224 	 lr: 0.00001
[epoch 360: 140/307] 	 train loss: 0.196054 	 lr: 0.00001
[epoch 360: 160/307] 	 train loss: 0.153573 	 lr: 0.00001
[epoch 360: 180/307] 	 train loss: 0.024128 	 lr: 0.00001

val loss: 0.354724 	 acc: 0.912480

[epoch 360: 200/307] 	 train loss: 0.019077 	 lr: 0.00001
[epoch 360: 220/307] 	 train loss: 0.021202 	 lr: 0.00001
[epoch 360: 240/307] 	 train loss: 0.120847 	 lr: 0.00001
[epoch 360: 260/307] 	 train loss: 0.056127 	 lr: 0.00001
[epoch 360: 280/307] 	 train loss: 0.170153 	 lr: 0.00001
[epoch 360: 300/307] 	 train loss: 0.080343 	 lr: 0.00001
[epoch 361:   0/307] 	 train loss: 0.047781 	 lr: 0.00001
[epoch 361:  20/307] 	 train loss: 0.247063 	 lr: 0.00001
[epoch 361:  40/307] 	 train loss: 0.140393 	 lr: 0.00001

val loss: 0.357225 	 acc: 0.912075

[epoch 361:  60/307] 	 train loss: 0.024553 	 lr: 0.00001
[epoch 361:  80/307] 	 train loss: 0.188650 	 lr: 0.00001
[epoch 361: 100/307] 	 train loss: 0.149625 	 lr: 0.00001
[epoch 361: 120/307] 	 train loss: 0.018745 	 lr: 0.00001
[epoch 361: 140/307] 	 train loss: 0.027858 	 lr: 0.00001
[epoch 361: 160/307] 	 train loss: 0.257731 	 lr: 0.00001
[epoch 361: 180/307] 	 train loss: 0.102424 	 lr: 0.00001

val loss: 0.356008 	 acc: 0.910859

[epoch 361: 200/307] 	 train loss: 0.167964 	 lr: 0.00001
[epoch 361: 220/307] 	 train loss: 0.017644 	 lr: 0.00001
[epoch 361: 240/307] 	 train loss: 0.166840 	 lr: 0.00001
[epoch 361: 260/307] 	 train loss: 0.198999 	 lr: 0.00001
[epoch 361: 280/307] 	 train loss: 0.038355 	 lr: 0.00001
[epoch 361: 300/307] 	 train loss: 0.110770 	 lr: 0.00001
[epoch 362:   0/307] 	 train loss: 0.043116 	 lr: 0.00001
[epoch 362:  20/307] 	 train loss: 0.101659 	 lr: 0.00001
[epoch 362:  40/307] 	 train loss: 0.177699 	 lr: 0.00001

val loss: 0.353432 	 acc: 0.912480

[epoch 362:  60/307] 	 train loss: 0.170508 	 lr: 0.00001
[epoch 362:  80/307] 	 train loss: 0.048855 	 lr: 0.00001
[epoch 362: 100/307] 	 train loss: 0.065256 	 lr: 0.00001
[epoch 362: 120/307] 	 train loss: 0.028947 	 lr: 0.00001
[epoch 362: 140/307] 	 train loss: 0.068409 	 lr: 0.00001
[epoch 362: 160/307] 	 train loss: 0.087307 	 lr: 0.00001
[epoch 362: 180/307] 	 train loss: 0.065103 	 lr: 0.00001

val loss: 0.354584 	 acc: 0.910859

[epoch 362: 200/307] 	 train loss: 0.085551 	 lr: 0.00001
[epoch 362: 220/307] 	 train loss: 0.070686 	 lr: 0.00001
[epoch 362: 240/307] 	 train loss: 0.177448 	 lr: 0.00001
[epoch 362: 260/307] 	 train loss: 0.060252 	 lr: 0.00001
[epoch 362: 280/307] 	 train loss: 0.064726 	 lr: 0.00001
[epoch 362: 300/307] 	 train loss: 0.042617 	 lr: 0.00001
[epoch 363:   0/307] 	 train loss: 0.047544 	 lr: 0.00001
[epoch 363:  20/307] 	 train loss: 0.323289 	 lr: 0.00001
[epoch 363:  40/307] 	 train loss: 0.008937 	 lr: 0.00001

val loss: 0.353766 	 acc: 0.911669

[epoch 363:  60/307] 	 train loss: 0.218671 	 lr: 0.00001
[epoch 363:  80/307] 	 train loss: 0.042112 	 lr: 0.00001
[epoch 363: 100/307] 	 train loss: 0.158882 	 lr: 0.00001
[epoch 363: 120/307] 	 train loss: 0.022871 	 lr: 0.00001
[epoch 363: 140/307] 	 train loss: 0.085618 	 lr: 0.00001
[epoch 363: 160/307] 	 train loss: 0.098389 	 lr: 0.00001
[epoch 363: 180/307] 	 train loss: 0.119206 	 lr: 0.00001

val loss: 0.352887 	 acc: 0.911264

[epoch 363: 200/307] 	 train loss: 0.043526 	 lr: 0.00001
[epoch 363: 220/307] 	 train loss: 0.023440 	 lr: 0.00001
[epoch 363: 240/307] 	 train loss: 0.177086 	 lr: 0.00001
[epoch 363: 260/307] 	 train loss: 0.078800 	 lr: 0.00001
[epoch 363: 280/307] 	 train loss: 0.042095 	 lr: 0.00001
[epoch 363: 300/307] 	 train loss: 0.052944 	 lr: 0.00001
[epoch 364:   0/307] 	 train loss: 0.107494 	 lr: 0.00001
[epoch 364:  20/307] 	 train loss: 0.117497 	 lr: 0.00001

val loss: 0.352765 	 acc: 0.913290

[epoch 364:  40/307] 	 train loss: 0.134916 	 lr: 0.00001
[epoch 364:  60/307] 	 train loss: 0.220526 	 lr: 0.00001
[epoch 364:  80/307] 	 train loss: 0.134013 	 lr: 0.00001
[epoch 364: 100/307] 	 train loss: 0.049102 	 lr: 0.00001
[epoch 364: 120/307] 	 train loss: 0.042389 	 lr: 0.00001
[epoch 364: 140/307] 	 train loss: 0.136657 	 lr: 0.00001
[epoch 364: 160/307] 	 train loss: 0.324707 	 lr: 0.00001
[epoch 364: 180/307] 	 train loss: 0.018624 	 lr: 0.00001

val loss: 0.352005 	 acc: 0.912480

[epoch 364: 200/307] 	 train loss: 0.018455 	 lr: 0.00001
[epoch 364: 220/307] 	 train loss: 0.096730 	 lr: 0.00001
[epoch 364: 240/307] 	 train loss: 0.038502 	 lr: 0.00001
[epoch 364: 260/307] 	 train loss: 0.040625 	 lr: 0.00001
[epoch 364: 280/307] 	 train loss: 0.122614 	 lr: 0.00001
[epoch 364: 300/307] 	 train loss: 0.095883 	 lr: 0.00001
[epoch 365:   0/307] 	 train loss: 0.084049 	 lr: 0.00001
[epoch 365:  20/307] 	 train loss: 0.020525 	 lr: 0.00001

val loss: 0.351125 	 acc: 0.913695

[epoch 365:  40/307] 	 train loss: 0.217643 	 lr: 0.00001
[epoch 365:  60/307] 	 train loss: 0.179492 	 lr: 0.00001
[epoch 365:  80/307] 	 train loss: 0.096246 	 lr: 0.00001
[epoch 365: 100/307] 	 train loss: 0.077320 	 lr: 0.00001
[epoch 365: 120/307] 	 train loss: 0.140094 	 lr: 0.00001
[epoch 365: 140/307] 	 train loss: 0.122449 	 lr: 0.00001
[epoch 365: 160/307] 	 train loss: 0.153164 	 lr: 0.00001
[epoch 365: 180/307] 	 train loss: 0.240250 	 lr: 0.00001

val loss: 0.353421 	 acc: 0.911669

[epoch 365: 200/307] 	 train loss: 0.192275 	 lr: 0.00001
[epoch 365: 220/307] 	 train loss: 0.376885 	 lr: 0.00001
[epoch 365: 240/307] 	 train loss: 0.090004 	 lr: 0.00001
[epoch 365: 260/307] 	 train loss: 0.010729 	 lr: 0.00001
[epoch 365: 280/307] 	 train loss: 0.078357 	 lr: 0.00001
[epoch 365: 300/307] 	 train loss: 0.086708 	 lr: 0.00001
[epoch 366:   0/307] 	 train loss: 0.075363 	 lr: 0.00001
[epoch 366:  20/307] 	 train loss: 0.153379 	 lr: 0.00001

val loss: 0.352465 	 acc: 0.912480

[epoch 366:  40/307] 	 train loss: 0.078474 	 lr: 0.00001
[epoch 366:  60/307] 	 train loss: 0.170958 	 lr: 0.00001
[epoch 366:  80/307] 	 train loss: 0.129743 	 lr: 0.00001
[epoch 366: 100/307] 	 train loss: 0.112640 	 lr: 0.00001
[epoch 366: 120/307] 	 train loss: 0.097277 	 lr: 0.00001
[epoch 366: 140/307] 	 train loss: 0.200336 	 lr: 0.00001
[epoch 366: 160/307] 	 train loss: 0.113565 	 lr: 0.00001
[epoch 366: 180/307] 	 train loss: 0.075423 	 lr: 0.00001

val loss: 0.353016 	 acc: 0.912075

[epoch 366: 200/307] 	 train loss: 0.103028 	 lr: 0.00001
[epoch 366: 220/307] 	 train loss: 0.047479 	 lr: 0.00001
[epoch 366: 240/307] 	 train loss: 0.200492 	 lr: 0.00001
[epoch 366: 260/307] 	 train loss: 0.034490 	 lr: 0.00001
[epoch 366: 280/307] 	 train loss: 0.181234 	 lr: 0.00001
[epoch 366: 300/307] 	 train loss: 0.067809 	 lr: 0.00001
[epoch 367:   0/307] 	 train loss: 0.052022 	 lr: 0.00001
[epoch 367:  20/307] 	 train loss: 0.048014 	 lr: 0.00001

val loss: 0.353816 	 acc: 0.913290

[epoch 367:  40/307] 	 train loss: 0.062327 	 lr: 0.00001
[epoch 367:  60/307] 	 train loss: 0.055099 	 lr: 0.00001
[epoch 367:  80/307] 	 train loss: 0.101552 	 lr: 0.00001
[epoch 367: 100/307] 	 train loss: 0.026446 	 lr: 0.00001
[epoch 367: 120/307] 	 train loss: 0.137103 	 lr: 0.00001
[epoch 367: 140/307] 	 train loss: 0.126751 	 lr: 0.00001
[epoch 367: 160/307] 	 train loss: 0.026685 	 lr: 0.00001
[epoch 367: 180/307] 	 train loss: 0.030456 	 lr: 0.00001

val loss: 0.354301 	 acc: 0.911264

[epoch 367: 200/307] 	 train loss: 0.093937 	 lr: 0.00001
[epoch 367: 220/307] 	 train loss: 0.022279 	 lr: 0.00001
[epoch 367: 240/307] 	 train loss: 0.073243 	 lr: 0.00001
[epoch 367: 260/307] 	 train loss: 0.285999 	 lr: 0.00001
[epoch 367: 280/307] 	 train loss: 0.028870 	 lr: 0.00001
[epoch 367: 300/307] 	 train loss: 0.077714 	 lr: 0.00001
[epoch 368:   0/307] 	 train loss: 0.156018 	 lr: 0.00001
[epoch 368:  20/307] 	 train loss: 0.087260 	 lr: 0.00001

val loss: 0.353432 	 acc: 0.912885

[epoch 368:  40/307] 	 train loss: 0.047630 	 lr: 0.00001
[epoch 368:  60/307] 	 train loss: 0.011863 	 lr: 0.00001
[epoch 368:  80/307] 	 train loss: 0.171368 	 lr: 0.00001
[epoch 368: 100/307] 	 train loss: 0.040181 	 lr: 0.00001
[epoch 368: 120/307] 	 train loss: 0.105961 	 lr: 0.00001
[epoch 368: 140/307] 	 train loss: 0.093183 	 lr: 0.00001
[epoch 368: 160/307] 	 train loss: 0.031398 	 lr: 0.00001
[epoch 368: 180/307] 	 train loss: 0.035597 	 lr: 0.00001

val loss: 0.354195 	 acc: 0.911669

[epoch 368: 200/307] 	 train loss: 0.141225 	 lr: 0.00001
[epoch 368: 220/307] 	 train loss: 0.024229 	 lr: 0.00001
[epoch 368: 240/307] 	 train loss: 0.131838 	 lr: 0.00001
[epoch 368: 260/307] 	 train loss: 0.026303 	 lr: 0.00001
[epoch 368: 280/307] 	 train loss: 0.152893 	 lr: 0.00001
[epoch 368: 300/307] 	 train loss: 0.060032 	 lr: 0.00001
[epoch 369:   0/307] 	 train loss: 0.286655 	 lr: 0.00001
[epoch 369:  20/307] 	 train loss: 0.036835 	 lr: 0.00001

val loss: 0.352237 	 acc: 0.910049

[epoch 369:  40/307] 	 train loss: 0.013185 	 lr: 0.00001
[epoch 369:  60/307] 	 train loss: 0.049537 	 lr: 0.00001
[epoch 369:  80/307] 	 train loss: 0.130867 	 lr: 0.00001
[epoch 369: 100/307] 	 train loss: 0.101736 	 lr: 0.00001
[epoch 369: 120/307] 	 train loss: 0.091986 	 lr: 0.00001
[epoch 369: 140/307] 	 train loss: 0.023656 	 lr: 0.00001
[epoch 369: 160/307] 	 train loss: 0.091763 	 lr: 0.00001
[epoch 369: 180/307] 	 train loss: 0.043678 	 lr: 0.00001

val loss: 0.352651 	 acc: 0.912075

[epoch 369: 200/307] 	 train loss: 0.271852 	 lr: 0.00001
[epoch 369: 220/307] 	 train loss: 0.212510 	 lr: 0.00001
[epoch 369: 240/307] 	 train loss: 0.214906 	 lr: 0.00001
[epoch 369: 260/307] 	 train loss: 0.298987 	 lr: 0.00001
[epoch 369: 280/307] 	 train loss: 0.134240 	 lr: 0.00001
[epoch 369: 300/307] 	 train loss: 0.137007 	 lr: 0.00001
[epoch 370:   0/307] 	 train loss: 0.033893 	 lr: 0.00001
[epoch 370:  20/307] 	 train loss: 0.260036 	 lr: 0.00001

val loss: 0.353425 	 acc: 0.911264

[epoch 370:  40/307] 	 train loss: 0.027133 	 lr: 0.00001
[epoch 370:  60/307] 	 train loss: 0.126292 	 lr: 0.00001
[epoch 370:  80/307] 	 train loss: 0.235469 	 lr: 0.00001
[epoch 370: 100/307] 	 train loss: 0.059312 	 lr: 0.00001
[epoch 370: 120/307] 	 train loss: 0.050871 	 lr: 0.00001
[epoch 370: 140/307] 	 train loss: 0.037722 	 lr: 0.00001
[epoch 370: 160/307] 	 train loss: 0.120964 	 lr: 0.00001

val loss: 0.351695 	 acc: 0.912885

[epoch 370: 180/307] 	 train loss: 0.319185 	 lr: 0.00001
[epoch 370: 200/307] 	 train loss: 0.035237 	 lr: 0.00001
[epoch 370: 220/307] 	 train loss: 0.212581 	 lr: 0.00001
[epoch 370: 240/307] 	 train loss: 0.124062 	 lr: 0.00001
[epoch 370: 260/307] 	 train loss: 0.114859 	 lr: 0.00001
[epoch 370: 280/307] 	 train loss: 0.138129 	 lr: 0.00001
[epoch 370: 300/307] 	 train loss: 0.153351 	 lr: 0.00001
[epoch 371:   0/307] 	 train loss: 0.075614 	 lr: 0.00001
[epoch 371:  20/307] 	 train loss: 0.086791 	 lr: 0.00001

val loss: 0.353082 	 acc: 0.910859

[epoch 371:  40/307] 	 train loss: 0.043099 	 lr: 0.00001
[epoch 371:  60/307] 	 train loss: 0.094943 	 lr: 0.00001
[epoch 371:  80/307] 	 train loss: 0.159585 	 lr: 0.00001
[epoch 371: 100/307] 	 train loss: 0.079450 	 lr: 0.00001
[epoch 371: 120/307] 	 train loss: 0.134460 	 lr: 0.00001
[epoch 371: 140/307] 	 train loss: 0.070819 	 lr: 0.00001
[epoch 371: 160/307] 	 train loss: 0.012425 	 lr: 0.00001

val loss: 0.352607 	 acc: 0.910454

[epoch 371: 180/307] 	 train loss: 0.043069 	 lr: 0.00001
[epoch 371: 200/307] 	 train loss: 0.339907 	 lr: 0.00001
[epoch 371: 220/307] 	 train loss: 0.057396 	 lr: 0.00001
[epoch 371: 240/307] 	 train loss: 0.057140 	 lr: 0.00001
[epoch 371: 260/307] 	 train loss: 0.046947 	 lr: 0.00001
[epoch 371: 280/307] 	 train loss: 0.208794 	 lr: 0.00001
[epoch 371: 300/307] 	 train loss: 0.049020 	 lr: 0.00001
[epoch 372:   0/307] 	 train loss: 0.051803 	 lr: 0.00001
[epoch 372:  20/307] 	 train loss: 0.124275 	 lr: 0.00001

val loss: 0.353068 	 acc: 0.910049

[epoch 372:  40/307] 	 train loss: 0.072278 	 lr: 0.00001
[epoch 372:  60/307] 	 train loss: 0.028120 	 lr: 0.00001
[epoch 372:  80/307] 	 train loss: 0.273100 	 lr: 0.00001
[epoch 372: 100/307] 	 train loss: 0.197463 	 lr: 0.00001
[epoch 372: 120/307] 	 train loss: 0.162273 	 lr: 0.00001
[epoch 372: 140/307] 	 train loss: 0.046275 	 lr: 0.00001
[epoch 372: 160/307] 	 train loss: 0.008310 	 lr: 0.00001

val loss: 0.353750 	 acc: 0.911264

[epoch 372: 180/307] 	 train loss: 0.009304 	 lr: 0.00001
[epoch 372: 200/307] 	 train loss: 0.080319 	 lr: 0.00001
[epoch 372: 220/307] 	 train loss: 0.062241 	 lr: 0.00001
[epoch 372: 240/307] 	 train loss: 0.108552 	 lr: 0.00001
[epoch 372: 260/307] 	 train loss: 0.083453 	 lr: 0.00001
[epoch 372: 280/307] 	 train loss: 0.056155 	 lr: 0.00001
[epoch 372: 300/307] 	 train loss: 0.076425 	 lr: 0.00001
[epoch 373:   0/307] 	 train loss: 0.021165 	 lr: 0.00001
[epoch 373:  20/307] 	 train loss: 0.025011 	 lr: 0.00001

val loss: 0.354665 	 acc: 0.909238

[epoch 373:  40/307] 	 train loss: 0.090502 	 lr: 0.00001
[epoch 373:  60/307] 	 train loss: 0.034608 	 lr: 0.00001
[epoch 373:  80/307] 	 train loss: 0.168399 	 lr: 0.00001
[epoch 373: 100/307] 	 train loss: 0.228177 	 lr: 0.00001
[epoch 373: 120/307] 	 train loss: 0.188712 	 lr: 0.00001
[epoch 373: 140/307] 	 train loss: 0.069283 	 lr: 0.00001
[epoch 373: 160/307] 	 train loss: 0.033160 	 lr: 0.00001

val loss: 0.353573 	 acc: 0.912075

[epoch 373: 180/307] 	 train loss: 0.040254 	 lr: 0.00001
[epoch 373: 200/307] 	 train loss: 0.063601 	 lr: 0.00001
[epoch 373: 220/307] 	 train loss: 0.097020 	 lr: 0.00001
[epoch 373: 240/307] 	 train loss: 0.043009 	 lr: 0.00001
[epoch 373: 260/307] 	 train loss: 0.117860 	 lr: 0.00001
[epoch 373: 280/307] 	 train loss: 0.251979 	 lr: 0.00001
[epoch 373: 300/307] 	 train loss: 0.100027 	 lr: 0.00001
[epoch 374:   0/307] 	 train loss: 0.181567 	 lr: 0.00001

val loss: 0.354107 	 acc: 0.910859

[epoch 374:  20/307] 	 train loss: 0.041733 	 lr: 0.00001
[epoch 374:  40/307] 	 train loss: 0.141282 	 lr: 0.00001
[epoch 374:  60/307] 	 train loss: 0.100512 	 lr: 0.00001
[epoch 374:  80/307] 	 train loss: 0.015764 	 lr: 0.00001
[epoch 374: 100/307] 	 train loss: 0.209409 	 lr: 0.00001
[epoch 374: 120/307] 	 train loss: 0.158747 	 lr: 0.00001
[epoch 374: 140/307] 	 train loss: 0.224785 	 lr: 0.00001
[epoch 374: 160/307] 	 train loss: 0.031930 	 lr: 0.00001

val loss: 0.354321 	 acc: 0.911669

[epoch 374: 180/307] 	 train loss: 0.215122 	 lr: 0.00001
[epoch 374: 200/307] 	 train loss: 0.235738 	 lr: 0.00001
[epoch 374: 220/307] 	 train loss: 0.399750 	 lr: 0.00001
[epoch 374: 240/307] 	 train loss: 0.211865 	 lr: 0.00001
[epoch 374: 260/307] 	 train loss: 0.143457 	 lr: 0.00001
[epoch 374: 280/307] 	 train loss: 0.231647 	 lr: 0.00001
[epoch 374: 300/307] 	 train loss: 0.125892 	 lr: 0.00001
[epoch 375:   0/307] 	 train loss: 0.037759 	 lr: 0.00001

val loss: 0.354547 	 acc: 0.909238

[epoch 375:  20/307] 	 train loss: 0.169826 	 lr: 0.00001
[epoch 375:  40/307] 	 train loss: 0.326767 	 lr: 0.00001
[epoch 375:  60/307] 	 train loss: 0.028582 	 lr: 0.00001
[epoch 375:  80/307] 	 train loss: 0.156905 	 lr: 0.00001
[epoch 375: 100/307] 	 train loss: 0.020045 	 lr: 0.00001
[epoch 375: 120/307] 	 train loss: 0.240969 	 lr: 0.00001
[epoch 375: 140/307] 	 train loss: 0.011591 	 lr: 0.00001
[epoch 375: 160/307] 	 train loss: 0.024128 	 lr: 0.00001

val loss: 0.355837 	 acc: 0.910859

[epoch 375: 180/307] 	 train loss: 0.028857 	 lr: 0.00001
[epoch 375: 200/307] 	 train loss: 0.087673 	 lr: 0.00001
[epoch 375: 220/307] 	 train loss: 0.105672 	 lr: 0.00001
[epoch 375: 240/307] 	 train loss: 0.293571 	 lr: 0.00001
[epoch 375: 260/307] 	 train loss: 0.123132 	 lr: 0.00001
[epoch 375: 280/307] 	 train loss: 0.037695 	 lr: 0.00001
[epoch 375: 300/307] 	 train loss: 0.116506 	 lr: 0.00001
[epoch 376:   0/307] 	 train loss: 0.114917 	 lr: 0.00001

val loss: 0.356002 	 acc: 0.910859

[epoch 376:  20/307] 	 train loss: 0.066634 	 lr: 0.00001
[epoch 376:  40/307] 	 train loss: 0.067181 	 lr: 0.00001
[epoch 376:  60/307] 	 train loss: 0.045122 	 lr: 0.00001
[epoch 376:  80/307] 	 train loss: 0.050641 	 lr: 0.00001
[epoch 376: 100/307] 	 train loss: 0.069827 	 lr: 0.00001
[epoch 376: 120/307] 	 train loss: 0.089564 	 lr: 0.00001
[epoch 376: 140/307] 	 train loss: 0.195059 	 lr: 0.00001
[epoch 376: 160/307] 	 train loss: 0.405917 	 lr: 0.00001

val loss: 0.356313 	 acc: 0.910859

[epoch 376: 180/307] 	 train loss: 0.044663 	 lr: 0.00001
[epoch 376: 200/307] 	 train loss: 0.270135 	 lr: 0.00001
[epoch 376: 220/307] 	 train loss: 0.079772 	 lr: 0.00001
[epoch 376: 240/307] 	 train loss: 0.075609 	 lr: 0.00001
[epoch 376: 260/307] 	 train loss: 0.041303 	 lr: 0.00001
[epoch 376: 280/307] 	 train loss: 0.141528 	 lr: 0.00001
[epoch 376: 300/307] 	 train loss: 0.076255 	 lr: 0.00001
[epoch 377:   0/307] 	 train loss: 0.248447 	 lr: 0.00001

val loss: 0.354643 	 acc: 0.910859

[epoch 377:  20/307] 	 train loss: 0.074392 	 lr: 0.00001
[epoch 377:  40/307] 	 train loss: 0.085519 	 lr: 0.00001
[epoch 377:  60/307] 	 train loss: 0.138827 	 lr: 0.00001
[epoch 377:  80/307] 	 train loss: 0.202540 	 lr: 0.00001
[epoch 377: 100/307] 	 train loss: 0.104447 	 lr: 0.00001
[epoch 377: 120/307] 	 train loss: 0.069976 	 lr: 0.00001
[epoch 377: 140/307] 	 train loss: 0.082779 	 lr: 0.00001
[epoch 377: 160/307] 	 train loss: 0.185154 	 lr: 0.00001

val loss: 0.354948 	 acc: 0.911264

[epoch 377: 180/307] 	 train loss: 0.168859 	 lr: 0.00001
[epoch 377: 200/307] 	 train loss: 0.300928 	 lr: 0.00001
[epoch 377: 220/307] 	 train loss: 0.099419 	 lr: 0.00001
[epoch 377: 240/307] 	 train loss: 0.149861 	 lr: 0.00001
[epoch 377: 260/307] 	 train loss: 0.235562 	 lr: 0.00001
[epoch 377: 280/307] 	 train loss: 0.205495 	 lr: 0.00001
[epoch 377: 300/307] 	 train loss: 0.061013 	 lr: 0.00001
[epoch 378:   0/307] 	 train loss: 0.203727 	 lr: 0.00001

val loss: 0.356141 	 acc: 0.912480

[epoch 378:  20/307] 	 train loss: 0.017050 	 lr: 0.00001
[epoch 378:  40/307] 	 train loss: 0.064580 	 lr: 0.00001
[epoch 378:  60/307] 	 train loss: 0.107624 	 lr: 0.00001
[epoch 378:  80/307] 	 train loss: 0.103442 	 lr: 0.00001
[epoch 378: 100/307] 	 train loss: 0.156759 	 lr: 0.00001
[epoch 378: 120/307] 	 train loss: 0.121217 	 lr: 0.00001
[epoch 378: 140/307] 	 train loss: 0.052737 	 lr: 0.00001
[epoch 378: 160/307] 	 train loss: 0.071359 	 lr: 0.00001

val loss: 0.355607 	 acc: 0.912480

[epoch 378: 180/307] 	 train loss: 0.036842 	 lr: 0.00001
[epoch 378: 200/307] 	 train loss: 0.025255 	 lr: 0.00001
[epoch 378: 220/307] 	 train loss: 0.053746 	 lr: 0.00001
[epoch 378: 240/307] 	 train loss: 0.114144 	 lr: 0.00001
[epoch 378: 260/307] 	 train loss: 0.044452 	 lr: 0.00001
[epoch 378: 280/307] 	 train loss: 0.129901 	 lr: 0.00001
[epoch 378: 300/307] 	 train loss: 0.062495 	 lr: 0.00001
[epoch 379:   0/307] 	 train loss: 0.088761 	 lr: 0.00001

val loss: 0.356350 	 acc: 0.910859

[epoch 379:  20/307] 	 train loss: 0.181057 	 lr: 0.00001
[epoch 379:  40/307] 	 train loss: 0.062388 	 lr: 0.00001
[epoch 379:  60/307] 	 train loss: 0.056215 	 lr: 0.00001
[epoch 379:  80/307] 	 train loss: 0.107080 	 lr: 0.00001
[epoch 379: 100/307] 	 train loss: 0.152762 	 lr: 0.00001
[epoch 379: 120/307] 	 train loss: 0.070964 	 lr: 0.00001
[epoch 379: 140/307] 	 train loss: 0.100966 	 lr: 0.00001
[epoch 379: 160/307] 	 train loss: 0.064354 	 lr: 0.00001

val loss: 0.354729 	 acc: 0.910049

[epoch 379: 180/307] 	 train loss: 0.149827 	 lr: 0.00001
[epoch 379: 200/307] 	 train loss: 0.196599 	 lr: 0.00001
[epoch 379: 220/307] 	 train loss: 0.064942 	 lr: 0.00001
[epoch 379: 240/307] 	 train loss: 0.054366 	 lr: 0.00001
[epoch 379: 260/307] 	 train loss: 0.133021 	 lr: 0.00001
[epoch 379: 280/307] 	 train loss: 0.039407 	 lr: 0.00001
[epoch 379: 300/307] 	 train loss: 0.098459 	 lr: 0.00001
[epoch 380:   0/307] 	 train loss: 0.172502 	 lr: 0.00001

val loss: 0.353102 	 acc: 0.910049

[epoch 380:  20/307] 	 train loss: 0.023028 	 lr: 0.00001
[epoch 380:  40/307] 	 train loss: 0.145614 	 lr: 0.00001
[epoch 380:  60/307] 	 train loss: 0.073459 	 lr: 0.00001
[epoch 380:  80/307] 	 train loss: 0.120385 	 lr: 0.00001
[epoch 380: 100/307] 	 train loss: 0.039242 	 lr: 0.00001
[epoch 380: 120/307] 	 train loss: 0.006226 	 lr: 0.00001
[epoch 380: 140/307] 	 train loss: 0.141807 	 lr: 0.00001

val loss: 0.353989 	 acc: 0.910859

[epoch 380: 160/307] 	 train loss: 0.025255 	 lr: 0.00001
[epoch 380: 180/307] 	 train loss: 0.054245 	 lr: 0.00001
[epoch 380: 200/307] 	 train loss: 0.083032 	 lr: 0.00001
[epoch 380: 220/307] 	 train loss: 0.214520 	 lr: 0.00001
[epoch 380: 240/307] 	 train loss: 0.138233 	 lr: 0.00001
[epoch 380: 260/307] 	 train loss: 0.163799 	 lr: 0.00001
[epoch 380: 280/307] 	 train loss: 0.070035 	 lr: 0.00001
[epoch 380: 300/307] 	 train loss: 0.178357 	 lr: 0.00001
[epoch 381:   0/307] 	 train loss: 0.172830 	 lr: 0.00001

val loss: 0.355035 	 acc: 0.910454

[epoch 381:  20/307] 	 train loss: 0.031824 	 lr: 0.00001
[epoch 381:  40/307] 	 train loss: 0.136421 	 lr: 0.00001
[epoch 381:  60/307] 	 train loss: 0.005630 	 lr: 0.00001
[epoch 381:  80/307] 	 train loss: 0.135634 	 lr: 0.00001
[epoch 381: 100/307] 	 train loss: 0.005545 	 lr: 0.00001
[epoch 381: 120/307] 	 train loss: 0.043018 	 lr: 0.00001
[epoch 381: 140/307] 	 train loss: 0.103739 	 lr: 0.00001

val loss: 0.354842 	 acc: 0.910859

[epoch 381: 160/307] 	 train loss: 0.115922 	 lr: 0.00001
[epoch 381: 180/307] 	 train loss: 0.010635 	 lr: 0.00001
[epoch 381: 200/307] 	 train loss: 0.124446 	 lr: 0.00001
[epoch 381: 220/307] 	 train loss: 0.098418 	 lr: 0.00001
[epoch 381: 240/307] 	 train loss: 0.208851 	 lr: 0.00001
[epoch 381: 260/307] 	 train loss: 0.131428 	 lr: 0.00001
[epoch 381: 280/307] 	 train loss: 0.096891 	 lr: 0.00001
[epoch 381: 300/307] 	 train loss: 0.035228 	 lr: 0.00001
[epoch 382:   0/307] 	 train loss: 0.282728 	 lr: 0.00001

val loss: 0.356100 	 acc: 0.911264

[epoch 382:  20/307] 	 train loss: 0.600226 	 lr: 0.00001
[epoch 382:  40/307] 	 train loss: 0.368231 	 lr: 0.00001
[epoch 382:  60/307] 	 train loss: 0.145439 	 lr: 0.00001
[epoch 382:  80/307] 	 train loss: 0.072617 	 lr: 0.00001
[epoch 382: 100/307] 	 train loss: 0.152758 	 lr: 0.00001
[epoch 382: 120/307] 	 train loss: 0.059004 	 lr: 0.00001
[epoch 382: 140/307] 	 train loss: 0.163626 	 lr: 0.00001

val loss: 0.358470 	 acc: 0.909238

[epoch 382: 160/307] 	 train loss: 0.142029 	 lr: 0.00001
[epoch 382: 180/307] 	 train loss: 0.405765 	 lr: 0.00001
[epoch 382: 200/307] 	 train loss: 0.192564 	 lr: 0.00001
[epoch 382: 220/307] 	 train loss: 0.129072 	 lr: 0.00001
[epoch 382: 240/307] 	 train loss: 0.220786 	 lr: 0.00001
[epoch 382: 260/307] 	 train loss: 0.333980 	 lr: 0.00001
[epoch 382: 280/307] 	 train loss: 0.116571 	 lr: 0.00001
[epoch 382: 300/307] 	 train loss: 0.054557 	 lr: 0.00001
[epoch 383:   0/307] 	 train loss: 0.161767 	 lr: 0.00001

val loss: 0.357248 	 acc: 0.912885

[epoch 383:  20/307] 	 train loss: 0.061058 	 lr: 0.00001
[epoch 383:  40/307] 	 train loss: 0.079660 	 lr: 0.00001
[epoch 383:  60/307] 	 train loss: 0.016980 	 lr: 0.00001
[epoch 383:  80/307] 	 train loss: 0.036951 	 lr: 0.00001
[epoch 383: 100/307] 	 train loss: 0.086455 	 lr: 0.00001
[epoch 383: 120/307] 	 train loss: 0.120371 	 lr: 0.00001
[epoch 383: 140/307] 	 train loss: 0.298927 	 lr: 0.00001

val loss: 0.356156 	 acc: 0.909643

[epoch 383: 160/307] 	 train loss: 0.077457 	 lr: 0.00001
[epoch 383: 180/307] 	 train loss: 0.043797 	 lr: 0.00001
[epoch 383: 200/307] 	 train loss: 0.083010 	 lr: 0.00001
[epoch 383: 220/307] 	 train loss: 0.065481 	 lr: 0.00001
[epoch 383: 240/307] 	 train loss: 0.059688 	 lr: 0.00001
[epoch 383: 260/307] 	 train loss: 0.056468 	 lr: 0.00001
[epoch 383: 280/307] 	 train loss: 0.081614 	 lr: 0.00001
[epoch 383: 300/307] 	 train loss: 0.073553 	 lr: 0.00001

val loss: 0.356039 	 acc: 0.912075

[epoch 384:   0/307] 	 train loss: 0.079561 	 lr: 0.00001
[epoch 384:  20/307] 	 train loss: 0.063561 	 lr: 0.00001
[epoch 384:  40/307] 	 train loss: 0.052471 	 lr: 0.00001
[epoch 384:  60/307] 	 train loss: 0.046856 	 lr: 0.00001
[epoch 384:  80/307] 	 train loss: 0.179723 	 lr: 0.00001
[epoch 384: 100/307] 	 train loss: 0.101949 	 lr: 0.00001
[epoch 384: 120/307] 	 train loss: 0.117529 	 lr: 0.00001
[epoch 384: 140/307] 	 train loss: 0.128289 	 lr: 0.00001

val loss: 0.354701 	 acc: 0.910454

[epoch 384: 160/307] 	 train loss: 0.020823 	 lr: 0.00001
[epoch 384: 180/307] 	 train loss: 0.078709 	 lr: 0.00001
[epoch 384: 200/307] 	 train loss: 0.118204 	 lr: 0.00001
[epoch 384: 220/307] 	 train loss: 0.164474 	 lr: 0.00001
[epoch 384: 240/307] 	 train loss: 0.180143 	 lr: 0.00001
[epoch 384: 260/307] 	 train loss: 0.095082 	 lr: 0.00001
[epoch 384: 280/307] 	 train loss: 0.083343 	 lr: 0.00001
[epoch 384: 300/307] 	 train loss: 0.078591 	 lr: 0.00001

val loss: 0.354869 	 acc: 0.912075

[epoch 385:   0/307] 	 train loss: 0.189687 	 lr: 0.00001
[epoch 385:  20/307] 	 train loss: 0.029123 	 lr: 0.00001
[epoch 385:  40/307] 	 train loss: 0.175596 	 lr: 0.00001
[epoch 385:  60/307] 	 train loss: 0.086977 	 lr: 0.00001
[epoch 385:  80/307] 	 train loss: 0.223334 	 lr: 0.00001
[epoch 385: 100/307] 	 train loss: 0.018645 	 lr: 0.00001
[epoch 385: 120/307] 	 train loss: 0.075486 	 lr: 0.00001
[epoch 385: 140/307] 	 train loss: 0.046726 	 lr: 0.00001

val loss: 0.355884 	 acc: 0.911264

[epoch 385: 160/307] 	 train loss: 0.100317 	 lr: 0.00001
[epoch 385: 180/307] 	 train loss: 0.083811 	 lr: 0.00001
[epoch 385: 200/307] 	 train loss: 0.058462 	 lr: 0.00001
[epoch 385: 220/307] 	 train loss: 0.046777 	 lr: 0.00001
[epoch 385: 240/307] 	 train loss: 0.030405 	 lr: 0.00001
[epoch 385: 260/307] 	 train loss: 0.210952 	 lr: 0.00001
[epoch 385: 280/307] 	 train loss: 0.025194 	 lr: 0.00001
[epoch 385: 300/307] 	 train loss: 0.143687 	 lr: 0.00001

val loss: 0.355066 	 acc: 0.911669

[epoch 386:   0/307] 	 train loss: 0.112275 	 lr: 0.00001
[epoch 386:  20/307] 	 train loss: 0.074808 	 lr: 0.00001
[epoch 386:  40/307] 	 train loss: 0.073408 	 lr: 0.00001
[epoch 386:  60/307] 	 train loss: 0.111699 	 lr: 0.00001
[epoch 386:  80/307] 	 train loss: 0.032995 	 lr: 0.00001
[epoch 386: 100/307] 	 train loss: 0.029433 	 lr: 0.00001
[epoch 386: 120/307] 	 train loss: 0.192874 	 lr: 0.00001
[epoch 386: 140/307] 	 train loss: 0.052963 	 lr: 0.00001

val loss: 0.358002 	 acc: 0.912075

[epoch 386: 160/307] 	 train loss: 0.162465 	 lr: 0.00001
[epoch 386: 180/307] 	 train loss: 0.078897 	 lr: 0.00001
[epoch 386: 200/307] 	 train loss: 0.045428 	 lr: 0.00001
[epoch 386: 220/307] 	 train loss: 0.017982 	 lr: 0.00001
[epoch 386: 240/307] 	 train loss: 0.076698 	 lr: 0.00001
[epoch 386: 260/307] 	 train loss: 0.234587 	 lr: 0.00001
[epoch 386: 280/307] 	 train loss: 0.107094 	 lr: 0.00001
[epoch 386: 300/307] 	 train loss: 0.043168 	 lr: 0.00001

val loss: 0.357976 	 acc: 0.910454

[epoch 387:   0/307] 	 train loss: 0.143592 	 lr: 0.00001
[epoch 387:  20/307] 	 train loss: 0.140840 	 lr: 0.00001
[epoch 387:  40/307] 	 train loss: 0.036085 	 lr: 0.00001
[epoch 387:  60/307] 	 train loss: 0.087192 	 lr: 0.00001
[epoch 387:  80/307] 	 train loss: 0.031509 	 lr: 0.00001
[epoch 387: 100/307] 	 train loss: 0.029795 	 lr: 0.00001
[epoch 387: 120/307] 	 train loss: 0.219517 	 lr: 0.00001
[epoch 387: 140/307] 	 train loss: 0.102214 	 lr: 0.00001

val loss: 0.356896 	 acc: 0.910454

[epoch 387: 160/307] 	 train loss: 0.051090 	 lr: 0.00001
[epoch 387: 180/307] 	 train loss: 0.034445 	 lr: 0.00001
[epoch 387: 200/307] 	 train loss: 0.043179 	 lr: 0.00001
[epoch 387: 220/307] 	 train loss: 0.083245 	 lr: 0.00001
[epoch 387: 240/307] 	 train loss: 0.054915 	 lr: 0.00001
[epoch 387: 260/307] 	 train loss: 0.220864 	 lr: 0.00001
[epoch 387: 280/307] 	 train loss: 0.109455 	 lr: 0.00001

val loss: 0.354669 	 acc: 0.910859

[epoch 387: 300/307] 	 train loss: 0.371113 	 lr: 0.00001
[epoch 388:   0/307] 	 train loss: 0.115795 	 lr: 0.00001
[epoch 388:  20/307] 	 train loss: 0.102119 	 lr: 0.00001
[epoch 388:  40/307] 	 train loss: 0.062798 	 lr: 0.00001
[epoch 388:  60/307] 	 train loss: 0.024873 	 lr: 0.00001
[epoch 388:  80/307] 	 train loss: 0.139305 	 lr: 0.00001
[epoch 388: 100/307] 	 train loss: 0.114578 	 lr: 0.00001
[epoch 388: 120/307] 	 train loss: 0.119951 	 lr: 0.00001
[epoch 388: 140/307] 	 train loss: 0.052749 	 lr: 0.00001

val loss: 0.353993 	 acc: 0.909643

[epoch 388: 160/307] 	 train loss: 0.123830 	 lr: 0.00001
[epoch 388: 180/307] 	 train loss: 0.085374 	 lr: 0.00001
[epoch 388: 200/307] 	 train loss: 0.183206 	 lr: 0.00001
[epoch 388: 220/307] 	 train loss: 0.039613 	 lr: 0.00001
[epoch 388: 240/307] 	 train loss: 0.021994 	 lr: 0.00001
[epoch 388: 260/307] 	 train loss: 0.019632 	 lr: 0.00001
[epoch 388: 280/307] 	 train loss: 0.114109 	 lr: 0.00001

val loss: 0.356158 	 acc: 0.909238

[epoch 388: 300/307] 	 train loss: 0.170965 	 lr: 0.00001
[epoch 389:   0/307] 	 train loss: 0.325241 	 lr: 0.00001
[epoch 389:  20/307] 	 train loss: 0.118083 	 lr: 0.00001
[epoch 389:  40/307] 	 train loss: 0.132194 	 lr: 0.00001
[epoch 389:  60/307] 	 train loss: 0.004817 	 lr: 0.00001
[epoch 389:  80/307] 	 train loss: 0.311996 	 lr: 0.00001
[epoch 389: 100/307] 	 train loss: 0.068068 	 lr: 0.00001
[epoch 389: 120/307] 	 train loss: 0.147031 	 lr: 0.00001
[epoch 389: 140/307] 	 train loss: 0.105763 	 lr: 0.00001

val loss: 0.356352 	 acc: 0.909643

[epoch 389: 160/307] 	 train loss: 0.052631 	 lr: 0.00001
[epoch 389: 180/307] 	 train loss: 0.024249 	 lr: 0.00001
[epoch 389: 200/307] 	 train loss: 0.104811 	 lr: 0.00001
[epoch 389: 220/307] 	 train loss: 0.078147 	 lr: 0.00001
[epoch 389: 240/307] 	 train loss: 0.103595 	 lr: 0.00001
[epoch 389: 260/307] 	 train loss: 0.141261 	 lr: 0.00001
[epoch 389: 280/307] 	 train loss: 0.014815 	 lr: 0.00001

val loss: 0.355973 	 acc: 0.911669

[epoch 389: 300/307] 	 train loss: 0.075739 	 lr: 0.00001
[epoch 390:   0/307] 	 train loss: 0.085399 	 lr: 0.00001
[epoch 390:  20/307] 	 train loss: 0.236957 	 lr: 0.00001
[epoch 390:  40/307] 	 train loss: 0.061962 	 lr: 0.00001
[epoch 390:  60/307] 	 train loss: 0.119843 	 lr: 0.00001
[epoch 390:  80/307] 	 train loss: 0.146583 	 lr: 0.00001
[epoch 390: 100/307] 	 train loss: 0.069553 	 lr: 0.00001
[epoch 390: 120/307] 	 train loss: 0.062366 	 lr: 0.00001

val loss: 0.354863 	 acc: 0.909643

[epoch 390: 140/307] 	 train loss: 0.030838 	 lr: 0.00001
[epoch 390: 160/307] 	 train loss: 0.070338 	 lr: 0.00001
[epoch 390: 180/307] 	 train loss: 0.108072 	 lr: 0.00001
[epoch 390: 200/307] 	 train loss: 0.161778 	 lr: 0.00001
[epoch 390: 220/307] 	 train loss: 0.289314 	 lr: 0.00001
[epoch 390: 240/307] 	 train loss: 0.126293 	 lr: 0.00001
[epoch 390: 260/307] 	 train loss: 0.130709 	 lr: 0.00001
[epoch 390: 280/307] 	 train loss: 0.020424 	 lr: 0.00001

val loss: 0.352926 	 acc: 0.910454

[epoch 390: 300/307] 	 train loss: 0.007530 	 lr: 0.00001
[epoch 391:   0/307] 	 train loss: 0.074235 	 lr: 0.00001
[epoch 391:  20/307] 	 train loss: 0.234751 	 lr: 0.00001
[epoch 391:  40/307] 	 train loss: 0.031209 	 lr: 0.00001
[epoch 391:  60/307] 	 train loss: 0.143816 	 lr: 0.00001
[epoch 391:  80/307] 	 train loss: 0.139272 	 lr: 0.00001
[epoch 391: 100/307] 	 train loss: 0.022428 	 lr: 0.00001
[epoch 391: 120/307] 	 train loss: 0.086880 	 lr: 0.00001

val loss: 0.354619 	 acc: 0.910859

[epoch 391: 140/307] 	 train loss: 0.221781 	 lr: 0.00001
[epoch 391: 160/307] 	 train loss: 0.151156 	 lr: 0.00001
[epoch 391: 180/307] 	 train loss: 0.106835 	 lr: 0.00001
[epoch 391: 200/307] 	 train loss: 0.302299 	 lr: 0.00001
[epoch 391: 220/307] 	 train loss: 0.097964 	 lr: 0.00001
[epoch 391: 240/307] 	 train loss: 0.077243 	 lr: 0.00001
[epoch 391: 260/307] 	 train loss: 0.066039 	 lr: 0.00001
[epoch 391: 280/307] 	 train loss: 0.014120 	 lr: 0.00001

val loss: 0.356182 	 acc: 0.910454

[epoch 391: 300/307] 	 train loss: 0.078039 	 lr: 0.00001
[epoch 392:   0/307] 	 train loss: 0.097506 	 lr: 0.00001
[epoch 392:  20/307] 	 train loss: 0.067896 	 lr: 0.00001
[epoch 392:  40/307] 	 train loss: 0.120833 	 lr: 0.00001
[epoch 392:  60/307] 	 train loss: 0.076621 	 lr: 0.00001
[epoch 392:  80/307] 	 train loss: 0.050331 	 lr: 0.00001
[epoch 392: 100/307] 	 train loss: 0.090475 	 lr: 0.00001
[epoch 392: 120/307] 	 train loss: 0.052072 	 lr: 0.00001

val loss: 0.354841 	 acc: 0.909643

[epoch 392: 140/307] 	 train loss: 0.122481 	 lr: 0.00001
[epoch 392: 160/307] 	 train loss: 0.014285 	 lr: 0.00001
[epoch 392: 180/307] 	 train loss: 0.228069 	 lr: 0.00001
[epoch 392: 200/307] 	 train loss: 0.059382 	 lr: 0.00001
[epoch 392: 220/307] 	 train loss: 0.091926 	 lr: 0.00001
[epoch 392: 240/307] 	 train loss: 0.204456 	 lr: 0.00001
[epoch 392: 260/307] 	 train loss: 0.074932 	 lr: 0.00001
[epoch 392: 280/307] 	 train loss: 0.182434 	 lr: 0.00001

val loss: 0.355047 	 acc: 0.911264

[epoch 392: 300/307] 	 train loss: 0.087914 	 lr: 0.00001
[epoch 393:   0/307] 	 train loss: 0.155957 	 lr: 0.00001
[epoch 393:  20/307] 	 train loss: 0.150860 	 lr: 0.00001
[epoch 393:  40/307] 	 train loss: 0.050327 	 lr: 0.00001
[epoch 393:  60/307] 	 train loss: 0.030995 	 lr: 0.00001
[epoch 393:  80/307] 	 train loss: 0.057343 	 lr: 0.00001
[epoch 393: 100/307] 	 train loss: 0.007162 	 lr: 0.00001
[epoch 393: 120/307] 	 train loss: 0.177067 	 lr: 0.00001

val loss: 0.358211 	 acc: 0.910454

[epoch 393: 140/307] 	 train loss: 0.133682 	 lr: 0.00001
[epoch 393: 160/307] 	 train loss: 0.326716 	 lr: 0.00001
[epoch 393: 180/307] 	 train loss: 0.172531 	 lr: 0.00001
[epoch 393: 200/307] 	 train loss: 0.045581 	 lr: 0.00001
[epoch 393: 220/307] 	 train loss: 0.061877 	 lr: 0.00001
[epoch 393: 240/307] 	 train loss: 0.126672 	 lr: 0.00001
[epoch 393: 260/307] 	 train loss: 0.117654 	 lr: 0.00001
[epoch 393: 280/307] 	 train loss: 0.028515 	 lr: 0.00001

val loss: 0.354818 	 acc: 0.911264

[epoch 393: 300/307] 	 train loss: 0.230466 	 lr: 0.00001
[epoch 394:   0/307] 	 train loss: 0.055308 	 lr: 0.00001
[epoch 394:  20/307] 	 train loss: 0.076258 	 lr: 0.00001
[epoch 394:  40/307] 	 train loss: 0.014891 	 lr: 0.00001
[epoch 394:  60/307] 	 train loss: 0.190982 	 lr: 0.00001
[epoch 394:  80/307] 	 train loss: 0.149212 	 lr: 0.00001
[epoch 394: 100/307] 	 train loss: 0.161520 	 lr: 0.00001
[epoch 394: 120/307] 	 train loss: 0.039234 	 lr: 0.00001

val loss: 0.355329 	 acc: 0.910859

[epoch 394: 140/307] 	 train loss: 0.014683 	 lr: 0.00001
[epoch 394: 160/307] 	 train loss: 0.084741 	 lr: 0.00001
[epoch 394: 180/307] 	 train loss: 0.117389 	 lr: 0.00001
[epoch 394: 200/307] 	 train loss: 0.046969 	 lr: 0.00001
[epoch 394: 220/307] 	 train loss: 0.109697 	 lr: 0.00001
[epoch 394: 240/307] 	 train loss: 0.042779 	 lr: 0.00001
[epoch 394: 260/307] 	 train loss: 0.230258 	 lr: 0.00001
[epoch 394: 280/307] 	 train loss: 0.060309 	 lr: 0.00001

val loss: 0.355825 	 acc: 0.910859

[epoch 394: 300/307] 	 train loss: 0.170516 	 lr: 0.00001
[epoch 395:   0/307] 	 train loss: 0.084446 	 lr: 0.00001
[epoch 395:  20/307] 	 train loss: 0.059154 	 lr: 0.00001
[epoch 395:  40/307] 	 train loss: 0.054548 	 lr: 0.00001
[epoch 395:  60/307] 	 train loss: 0.014471 	 lr: 0.00001
[epoch 395:  80/307] 	 train loss: 0.119682 	 lr: 0.00001
[epoch 395: 100/307] 	 train loss: 0.067211 	 lr: 0.00001
[epoch 395: 120/307] 	 train loss: 0.194353 	 lr: 0.00001

val loss: 0.354855 	 acc: 0.911264

[epoch 395: 140/307] 	 train loss: 0.205288 	 lr: 0.00001
[epoch 395: 160/307] 	 train loss: 0.107833 	 lr: 0.00001
[epoch 395: 180/307] 	 train loss: 0.027731 	 lr: 0.00001
[epoch 395: 200/307] 	 train loss: 0.049231 	 lr: 0.00001
[epoch 395: 220/307] 	 train loss: 0.045419 	 lr: 0.00001
[epoch 395: 240/307] 	 train loss: 0.156108 	 lr: 0.00001
[epoch 395: 260/307] 	 train loss: 0.399913 	 lr: 0.00001
[epoch 395: 280/307] 	 train loss: 0.091333 	 lr: 0.00001

val loss: 0.356465 	 acc: 0.911264

[epoch 395: 300/307] 	 train loss: 0.053959 	 lr: 0.00001
[epoch 396:   0/307] 	 train loss: 0.073834 	 lr: 0.00001
[epoch 396:  20/307] 	 train loss: 0.042568 	 lr: 0.00001
[epoch 396:  40/307] 	 train loss: 0.087372 	 lr: 0.00001
[epoch 396:  60/307] 	 train loss: 0.044543 	 lr: 0.00001
[epoch 396:  80/307] 	 train loss: 0.073003 	 lr: 0.00001
[epoch 396: 100/307] 	 train loss: 0.015187 	 lr: 0.00001
[epoch 396: 120/307] 	 train loss: 0.245586 	 lr: 0.00001

val loss: 0.354174 	 acc: 0.912480

[epoch 396: 140/307] 	 train loss: 0.044874 	 lr: 0.00001
[epoch 396: 160/307] 	 train loss: 0.058105 	 lr: 0.00001
[epoch 396: 180/307] 	 train loss: 0.301982 	 lr: 0.00001
[epoch 396: 200/307] 	 train loss: 0.287644 	 lr: 0.00001
[epoch 396: 220/307] 	 train loss: 0.017244 	 lr: 0.00001
[epoch 396: 240/307] 	 train loss: 0.174251 	 lr: 0.00001
[epoch 396: 260/307] 	 train loss: 0.209803 	 lr: 0.00001
[epoch 396: 280/307] 	 train loss: 0.056969 	 lr: 0.00001

val loss: 0.355509 	 acc: 0.912885

[epoch 396: 300/307] 	 train loss: 0.180430 	 lr: 0.00001
[epoch 397:   0/307] 	 train loss: 0.177453 	 lr: 0.00001
[epoch 397:  20/307] 	 train loss: 0.034806 	 lr: 0.00001
[epoch 397:  40/307] 	 train loss: 0.097702 	 lr: 0.00001
[epoch 397:  60/307] 	 train loss: 0.054643 	 lr: 0.00001
[epoch 397:  80/307] 	 train loss: 0.060086 	 lr: 0.00001
[epoch 397: 100/307] 	 train loss: 0.141303 	 lr: 0.00001
[epoch 397: 120/307] 	 train loss: 0.086482 	 lr: 0.00001

val loss: 0.355287 	 acc: 0.912885

[epoch 397: 140/307] 	 train loss: 0.177676 	 lr: 0.00001
[epoch 397: 160/307] 	 train loss: 0.050970 	 lr: 0.00001
[epoch 397: 180/307] 	 train loss: 0.036729 	 lr: 0.00001
[epoch 397: 200/307] 	 train loss: 0.135717 	 lr: 0.00001
[epoch 397: 220/307] 	 train loss: 0.012939 	 lr: 0.00001
[epoch 397: 240/307] 	 train loss: 0.088252 	 lr: 0.00001
[epoch 397: 260/307] 	 train loss: 0.079591 	 lr: 0.00001

val loss: 0.356379 	 acc: 0.913290

[epoch 397: 280/307] 	 train loss: 0.108241 	 lr: 0.00001
[epoch 397: 300/307] 	 train loss: 0.111455 	 lr: 0.00001
[epoch 398:   0/307] 	 train loss: 0.103441 	 lr: 0.00001
[epoch 398:  20/307] 	 train loss: 0.141118 	 lr: 0.00001
[epoch 398:  40/307] 	 train loss: 0.054896 	 lr: 0.00001
[epoch 398:  60/307] 	 train loss: 0.104569 	 lr: 0.00001
[epoch 398:  80/307] 	 train loss: 0.099463 	 lr: 0.00001
[epoch 398: 100/307] 	 train loss: 0.102765 	 lr: 0.00001
[epoch 398: 120/307] 	 train loss: 0.345776 	 lr: 0.00001

val loss: 0.355292 	 acc: 0.911669

[epoch 398: 140/307] 	 train loss: 0.105279 	 lr: 0.00001
[epoch 398: 160/307] 	 train loss: 0.029814 	 lr: 0.00001
[epoch 398: 180/307] 	 train loss: 0.013259 	 lr: 0.00001
[epoch 398: 200/307] 	 train loss: 0.031207 	 lr: 0.00001
[epoch 398: 220/307] 	 train loss: 0.426828 	 lr: 0.00001
[epoch 398: 240/307] 	 train loss: 0.080790 	 lr: 0.00001
[epoch 398: 260/307] 	 train loss: 0.075136 	 lr: 0.00001

val loss: 0.356396 	 acc: 0.911669

[epoch 398: 280/307] 	 train loss: 0.129108 	 lr: 0.00001
[epoch 398: 300/307] 	 train loss: 0.049308 	 lr: 0.00001
[epoch 399:   0/307] 	 train loss: 0.077908 	 lr: 0.00001
[epoch 399:  20/307] 	 train loss: 0.102882 	 lr: 0.00001
[epoch 399:  40/307] 	 train loss: 0.177909 	 lr: 0.00001
[epoch 399:  60/307] 	 train loss: 0.155264 	 lr: 0.00001
[epoch 399:  80/307] 	 train loss: 0.082405 	 lr: 0.00001
[epoch 399: 100/307] 	 train loss: 0.036430 	 lr: 0.00001
[epoch 399: 120/307] 	 train loss: 0.117097 	 lr: 0.00001

val loss: 0.355864 	 acc: 0.912480

[epoch 399: 140/307] 	 train loss: 0.090904 	 lr: 0.00001
[epoch 399: 160/307] 	 train loss: 0.089005 	 lr: 0.00001
[epoch 399: 180/307] 	 train loss: 0.055599 	 lr: 0.00001
[epoch 399: 200/307] 	 train loss: 0.033813 	 lr: 0.00001
[epoch 399: 220/307] 	 train loss: 0.101364 	 lr: 0.00001
[epoch 399: 240/307] 	 train loss: 0.139737 	 lr: 0.00001
[epoch 399: 260/307] 	 train loss: 0.057921 	 lr: 0.00001

val loss: 0.358926 	 acc: 0.911264

[epoch 399: 280/307] 	 train loss: 0.026805 	 lr: 0.00001
[epoch 399: 300/307] 	 train loss: 0.105836 	 lr: 0.00001
[epoch 400:   0/307] 	 train loss: 0.045724 	 lr: 0.00001
[epoch 400:  20/307] 	 train loss: 0.052221 	 lr: 0.00001
[epoch 400:  40/307] 	 train loss: 0.117436 	 lr: 0.00001
[epoch 400:  60/307] 	 train loss: 0.048384 	 lr: 0.00001
[epoch 400:  80/307] 	 train loss: 0.208430 	 lr: 0.00001
[epoch 400: 100/307] 	 train loss: 0.045781 	 lr: 0.00001

val loss: 0.355129 	 acc: 0.912075

[epoch 400: 120/307] 	 train loss: 0.086093 	 lr: 0.00001
[epoch 400: 140/307] 	 train loss: 0.200032 	 lr: 0.00001
[epoch 400: 160/307] 	 train loss: 0.015173 	 lr: 0.00001
[epoch 400: 180/307] 	 train loss: 0.076513 	 lr: 0.00001
[epoch 400: 200/307] 	 train loss: 0.255596 	 lr: 0.00001
[epoch 400: 220/307] 	 train loss: 0.117630 	 lr: 0.00001
[epoch 400: 240/307] 	 train loss: 0.105476 	 lr: 0.00001
[epoch 400: 260/307] 	 train loss: 0.132848 	 lr: 0.00001

val loss: 0.354839 	 acc: 0.912885

[epoch 400: 280/307] 	 train loss: 0.073583 	 lr: 0.00001
[epoch 400: 300/307] 	 train loss: 0.021129 	 lr: 0.00001
