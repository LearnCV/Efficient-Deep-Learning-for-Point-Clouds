
**************************

[epochs]: 200

[num_points]: 1024

[batch_size]: 32

[decay_step]: 21

[lr_clip]: 1e-05

[lr_decay]: 0.8

[num_classes]: 40

[weight_decay]: 0

[save_path]: log

[data_root]: ../../Datasets

[bn_momentum]: 0.9

[workers]: 4

[evaluate]: 1

[bn_decay]: 0.5

[checkpoint]: 

[base_lr]: 0.001

[print_freq_iter]: 20

[val_freq_epoch]: 0.5

[input_channels]: 0

[bnm_clip]: 0.01

**************************

[epoch   1:   0/307] 	 train loss: 3.786818 	 lr: 0.00100
[epoch   1:  20/307] 	 train loss: 2.787151 	 lr: 0.00100
[epoch   1:  40/307] 	 train loss: 2.284858 	 lr: 0.00100
[epoch   1:  60/307] 	 train loss: 1.891215 	 lr: 0.00100
[epoch   1:  80/307] 	 train loss: 2.034930 	 lr: 0.00100
[epoch   1: 100/307] 	 train loss: 1.462138 	 lr: 0.00100
[epoch   1: 120/307] 	 train loss: 1.822111 	 lr: 0.00100
[epoch   1: 140/307] 	 train loss: 1.335842 	 lr: 0.00100

val loss: 2.758823 	 acc: 0.364263

[epoch   1: 160/307] 	 train loss: 1.218367 	 lr: 0.00100
[epoch   1: 180/307] 	 train loss: 1.618473 	 lr: 0.00100
[epoch   1: 200/307] 	 train loss: 1.587398 	 lr: 0.00100
[epoch   1: 220/307] 	 train loss: 1.181963 	 lr: 0.00100
[epoch   1: 240/307] 	 train loss: 1.377996 	 lr: 0.00100
[epoch   1: 260/307] 	 train loss: 1.772778 	 lr: 0.00100
[epoch   1: 280/307] 	 train loss: 1.533504 	 lr: 0.00100
[epoch   1: 300/307] 	 train loss: 1.629560 	 lr: 0.00100

val loss: 1.570097 	 acc: 0.534846

[epoch   2:   0/307] 	 train loss: 1.197762 	 lr: 0.00100
[epoch   2:  20/307] 	 train loss: 1.363223 	 lr: 0.00100
[epoch   2:  40/307] 	 train loss: 0.755293 	 lr: 0.00100
[epoch   2:  60/307] 	 train loss: 1.200629 	 lr: 0.00100
[epoch   2:  80/307] 	 train loss: 1.376105 	 lr: 0.00100
[epoch   2: 100/307] 	 train loss: 0.866495 	 lr: 0.00100
[epoch   2: 120/307] 	 train loss: 1.081151 	 lr: 0.00100
[epoch   2: 140/307] 	 train loss: 1.209136 	 lr: 0.00100

val loss: 0.940723 	 acc: 0.725689

[epoch   2: 160/307] 	 train loss: 1.223912 	 lr: 0.00100
[epoch   2: 180/307] 	 train loss: 1.214731 	 lr: 0.00100
[epoch   2: 200/307] 	 train loss: 1.447782 	 lr: 0.00100
[epoch   2: 220/307] 	 train loss: 1.191482 	 lr: 0.00100
[epoch   2: 240/307] 	 train loss: 1.427590 	 lr: 0.00100
[epoch   2: 260/307] 	 train loss: 0.922348 	 lr: 0.00100
[epoch   2: 280/307] 	 train loss: 0.903095 	 lr: 0.00100
[epoch   2: 300/307] 	 train loss: 0.879165 	 lr: 0.00100

val loss: 0.834772 	 acc: 0.741491

[epoch   3:   0/307] 	 train loss: 0.771862 	 lr: 0.00100
[epoch   3:  20/307] 	 train loss: 0.790646 	 lr: 0.00100
[epoch   3:  40/307] 	 train loss: 0.781540 	 lr: 0.00100
[epoch   3:  60/307] 	 train loss: 0.733648 	 lr: 0.00100
[epoch   3:  80/307] 	 train loss: 0.801529 	 lr: 0.00100
[epoch   3: 100/307] 	 train loss: 0.880524 	 lr: 0.00100
[epoch   3: 120/307] 	 train loss: 0.933843 	 lr: 0.00100
[epoch   3: 140/307] 	 train loss: 0.794157 	 lr: 0.00100

val loss: 0.768311 	 acc: 0.776337

[epoch   3: 160/307] 	 train loss: 0.632761 	 lr: 0.00100
[epoch   3: 180/307] 	 train loss: 0.918717 	 lr: 0.00100
[epoch   3: 200/307] 	 train loss: 0.651745 	 lr: 0.00100
[epoch   3: 220/307] 	 train loss: 0.638549 	 lr: 0.00100
[epoch   3: 240/307] 	 train loss: 0.958337 	 lr: 0.00100
[epoch   3: 260/307] 	 train loss: 0.766951 	 lr: 0.00100
[epoch   3: 280/307] 	 train loss: 1.009114 	 lr: 0.00100
[epoch   3: 300/307] 	 train loss: 0.753329 	 lr: 0.00100

val loss: 0.744690 	 acc: 0.775527

[epoch   4:   0/307] 	 train loss: 0.849392 	 lr: 0.00100
[epoch   4:  20/307] 	 train loss: 0.551642 	 lr: 0.00100
[epoch   4:  40/307] 	 train loss: 0.704533 	 lr: 0.00100
[epoch   4:  60/307] 	 train loss: 0.905159 	 lr: 0.00100
[epoch   4:  80/307] 	 train loss: 0.700826 	 lr: 0.00100
[epoch   4: 100/307] 	 train loss: 0.959186 	 lr: 0.00100
[epoch   4: 120/307] 	 train loss: 0.722463 	 lr: 0.00100
[epoch   4: 140/307] 	 train loss: 1.102636 	 lr: 0.00100

val loss: 0.682359 	 acc: 0.799433

[epoch   4: 160/307] 	 train loss: 0.872313 	 lr: 0.00100
[epoch   4: 180/307] 	 train loss: 0.511605 	 lr: 0.00100
[epoch   4: 200/307] 	 train loss: 1.018349 	 lr: 0.00100
[epoch   4: 220/307] 	 train loss: 0.490050 	 lr: 0.00100
[epoch   4: 240/307] 	 train loss: 0.706908 	 lr: 0.00100
[epoch   4: 260/307] 	 train loss: 0.641531 	 lr: 0.00100
[epoch   4: 280/307] 	 train loss: 0.731932 	 lr: 0.00100

val loss: 0.600406 	 acc: 0.816451

[epoch   4: 300/307] 	 train loss: 1.137092 	 lr: 0.00100
[epoch   5:   0/307] 	 train loss: 0.507146 	 lr: 0.00100
[epoch   5:  20/307] 	 train loss: 0.728539 	 lr: 0.00100
[epoch   5:  40/307] 	 train loss: 0.579887 	 lr: 0.00100
[epoch   5:  60/307] 	 train loss: 0.673227 	 lr: 0.00100
[epoch   5:  80/307] 	 train loss: 1.039111 	 lr: 0.00100
[epoch   5: 100/307] 	 train loss: 0.584983 	 lr: 0.00100
[epoch   5: 120/307] 	 train loss: 0.674343 	 lr: 0.00100
[epoch   5: 140/307] 	 train loss: 0.830252 	 lr: 0.00100

val loss: 0.619790 	 acc: 0.811588

[epoch   5: 160/307] 	 train loss: 0.462474 	 lr: 0.00100
[epoch   5: 180/307] 	 train loss: 0.700955 	 lr: 0.00100
[epoch   5: 200/307] 	 train loss: 0.444279 	 lr: 0.00100
[epoch   5: 220/307] 	 train loss: 0.770874 	 lr: 0.00100
[epoch   5: 240/307] 	 train loss: 0.819692 	 lr: 0.00100
[epoch   5: 260/307] 	 train loss: 0.680764 	 lr: 0.00100
[epoch   5: 280/307] 	 train loss: 0.446708 	 lr: 0.00100

val loss: 0.564804 	 acc: 0.809968

[epoch   5: 300/307] 	 train loss: 0.847098 	 lr: 0.00100
[epoch   6:   0/307] 	 train loss: 0.547565 	 lr: 0.00100
[epoch   6:  20/307] 	 train loss: 0.679404 	 lr: 0.00100
[epoch   6:  40/307] 	 train loss: 0.499954 	 lr: 0.00100
[epoch   6:  60/307] 	 train loss: 0.606184 	 lr: 0.00100
[epoch   6:  80/307] 	 train loss: 0.780468 	 lr: 0.00100
[epoch   6: 100/307] 	 train loss: 0.493278 	 lr: 0.00100
[epoch   6: 120/307] 	 train loss: 1.013829 	 lr: 0.00100
[epoch   6: 140/307] 	 train loss: 0.748186 	 lr: 0.00100

val loss: 0.526464 	 acc: 0.835494

[epoch   6: 160/307] 	 train loss: 0.512891 	 lr: 0.00100
[epoch   6: 180/307] 	 train loss: 0.874784 	 lr: 0.00100
[epoch   6: 200/307] 	 train loss: 0.592914 	 lr: 0.00100
[epoch   6: 220/307] 	 train loss: 0.674781 	 lr: 0.00100
[epoch   6: 240/307] 	 train loss: 0.739063 	 lr: 0.00100
[epoch   6: 260/307] 	 train loss: 0.671146 	 lr: 0.00100
[epoch   6: 280/307] 	 train loss: 0.720993 	 lr: 0.00100

val loss: 0.614741 	 acc: 0.807131

[epoch   6: 300/307] 	 train loss: 0.347565 	 lr: 0.00100
[epoch   7:   0/307] 	 train loss: 0.341527 	 lr: 0.00100
[epoch   7:  20/307] 	 train loss: 0.319210 	 lr: 0.00100
[epoch   7:  40/307] 	 train loss: 0.852260 	 lr: 0.00100
[epoch   7:  60/307] 	 train loss: 0.707416 	 lr: 0.00100
[epoch   7:  80/307] 	 train loss: 0.528728 	 lr: 0.00100
[epoch   7: 100/307] 	 train loss: 0.365186 	 lr: 0.00100
[epoch   7: 120/307] 	 train loss: 0.358722 	 lr: 0.00100
[epoch   7: 140/307] 	 train loss: 0.498528 	 lr: 0.00100

val loss: 0.496163 	 acc: 0.845219

[epoch   7: 160/307] 	 train loss: 0.912347 	 lr: 0.00100
[epoch   7: 180/307] 	 train loss: 0.706338 	 lr: 0.00100
[epoch   7: 200/307] 	 train loss: 0.403432 	 lr: 0.00100
[epoch   7: 220/307] 	 train loss: 0.765515 	 lr: 0.00100
[epoch   7: 240/307] 	 train loss: 0.326479 	 lr: 0.00100
[epoch   7: 260/307] 	 train loss: 1.130482 	 lr: 0.00100
[epoch   7: 280/307] 	 train loss: 0.378918 	 lr: 0.00100

val loss: 0.491981 	 acc: 0.841977

[epoch   7: 300/307] 	 train loss: 0.701404 	 lr: 0.00100
[epoch   8:   0/307] 	 train loss: 0.443698 	 lr: 0.00100
[epoch   8:  20/307] 	 train loss: 0.527797 	 lr: 0.00100
[epoch   8:  40/307] 	 train loss: 0.470140 	 lr: 0.00100
[epoch   8:  60/307] 	 train loss: 0.604294 	 lr: 0.00100
[epoch   8:  80/307] 	 train loss: 1.094703 	 lr: 0.00100
[epoch   8: 100/307] 	 train loss: 0.991006 	 lr: 0.00100
[epoch   8: 120/307] 	 train loss: 0.709786 	 lr: 0.00100

val loss: 0.461033 	 acc: 0.859400

[epoch   8: 140/307] 	 train loss: 0.516343 	 lr: 0.00100
[epoch   8: 160/307] 	 train loss: 0.577180 	 lr: 0.00100
[epoch   8: 180/307] 	 train loss: 0.704462 	 lr: 0.00100
[epoch   8: 200/307] 	 train loss: 0.849523 	 lr: 0.00100
[epoch   8: 220/307] 	 train loss: 0.449845 	 lr: 0.00100
[epoch   8: 240/307] 	 train loss: 0.733343 	 lr: 0.00100
[epoch   8: 260/307] 	 train loss: 0.494474 	 lr: 0.00100
[epoch   8: 280/307] 	 train loss: 0.890648 	 lr: 0.00100

val loss: 0.514002 	 acc: 0.838736

[epoch   8: 300/307] 	 train loss: 0.381389 	 lr: 0.00100
[epoch   9:   0/307] 	 train loss: 0.496510 	 lr: 0.00100
[epoch   9:  20/307] 	 train loss: 1.261063 	 lr: 0.00100
[epoch   9:  40/307] 	 train loss: 0.419145 	 lr: 0.00100
[epoch   9:  60/307] 	 train loss: 0.389261 	 lr: 0.00100
[epoch   9:  80/307] 	 train loss: 0.645311 	 lr: 0.00100
[epoch   9: 100/307] 	 train loss: 0.414825 	 lr: 0.00100
[epoch   9: 120/307] 	 train loss: 0.734686 	 lr: 0.00100

val loss: 0.447262 	 acc: 0.863452

[epoch   9: 140/307] 	 train loss: 0.434328 	 lr: 0.00100
[epoch   9: 160/307] 	 train loss: 0.589983 	 lr: 0.00100
[epoch   9: 180/307] 	 train loss: 0.632574 	 lr: 0.00100
[epoch   9: 200/307] 	 train loss: 1.096277 	 lr: 0.00100
[epoch   9: 220/307] 	 train loss: 0.385266 	 lr: 0.00100
[epoch   9: 240/307] 	 train loss: 0.522194 	 lr: 0.00100
[epoch   9: 260/307] 	 train loss: 0.554258 	 lr: 0.00100
[epoch   9: 280/307] 	 train loss: 0.454856 	 lr: 0.00100

val loss: 0.449031 	 acc: 0.856159

[epoch   9: 300/307] 	 train loss: 0.709940 	 lr: 0.00100
[epoch  10:   0/307] 	 train loss: 0.634849 	 lr: 0.00100
[epoch  10:  20/307] 	 train loss: 0.352174 	 lr: 0.00100
[epoch  10:  40/307] 	 train loss: 0.290328 	 lr: 0.00100
[epoch  10:  60/307] 	 train loss: 0.332670 	 lr: 0.00100
[epoch  10:  80/307] 	 train loss: 0.535275 	 lr: 0.00100
[epoch  10: 100/307] 	 train loss: 0.331851 	 lr: 0.00100
[epoch  10: 120/307] 	 train loss: 0.310110 	 lr: 0.00100

val loss: 0.515503 	 acc: 0.834279

[epoch  10: 140/307] 	 train loss: 0.479245 	 lr: 0.00100
[epoch  10: 160/307] 	 train loss: 0.630479 	 lr: 0.00100
[epoch  10: 180/307] 	 train loss: 0.306704 	 lr: 0.00100
[epoch  10: 200/307] 	 train loss: 0.947465 	 lr: 0.00100
[epoch  10: 220/307] 	 train loss: 0.618278 	 lr: 0.00100
[epoch  10: 240/307] 	 train loss: 0.727015 	 lr: 0.00100
[epoch  10: 260/307] 	 train loss: 0.582962 	 lr: 0.00100
[epoch  10: 280/307] 	 train loss: 0.558454 	 lr: 0.00100

val loss: 0.481977 	 acc: 0.850081

[epoch  10: 300/307] 	 train loss: 0.720082 	 lr: 0.00100
[epoch  11:   0/307] 	 train loss: 0.276077 	 lr: 0.00100
[epoch  11:  20/307] 	 train loss: 0.463092 	 lr: 0.00100
[epoch  11:  40/307] 	 train loss: 0.367442 	 lr: 0.00100
[epoch  11:  60/307] 	 train loss: 0.546096 	 lr: 0.00100
[epoch  11:  80/307] 	 train loss: 0.444755 	 lr: 0.00100
[epoch  11: 100/307] 	 train loss: 0.544232 	 lr: 0.00100
[epoch  11: 120/307] 	 train loss: 0.266151 	 lr: 0.00100

val loss: 0.432454 	 acc: 0.861426

[epoch  11: 140/307] 	 train loss: 0.246330 	 lr: 0.00100
[epoch  11: 160/307] 	 train loss: 0.668807 	 lr: 0.00100
[epoch  11: 180/307] 	 train loss: 0.436441 	 lr: 0.00100
[epoch  11: 200/307] 	 train loss: 0.556849 	 lr: 0.00100
[epoch  11: 220/307] 	 train loss: 0.364670 	 lr: 0.00100
[epoch  11: 240/307] 	 train loss: 0.533167 	 lr: 0.00100
[epoch  11: 260/307] 	 train loss: 0.327157 	 lr: 0.00100
[epoch  11: 280/307] 	 train loss: 0.597671 	 lr: 0.00100

val loss: 0.451073 	 acc: 0.861426

[epoch  11: 300/307] 	 train loss: 0.587735 	 lr: 0.00100
[epoch  12:   0/307] 	 train loss: 0.532551 	 lr: 0.00100
[epoch  12:  20/307] 	 train loss: 0.390254 	 lr: 0.00100
[epoch  12:  40/307] 	 train loss: 0.686240 	 lr: 0.00100
[epoch  12:  60/307] 	 train loss: 0.494819 	 lr: 0.00100
[epoch  12:  80/307] 	 train loss: 0.759296 	 lr: 0.00100
[epoch  12: 100/307] 	 train loss: 0.538340 	 lr: 0.00100
[epoch  12: 120/307] 	 train loss: 0.554105 	 lr: 0.00100

val loss: 0.412789 	 acc: 0.869125

[epoch  12: 140/307] 	 train loss: 0.383551 	 lr: 0.00100
[epoch  12: 160/307] 	 train loss: 0.862560 	 lr: 0.00100
[epoch  12: 180/307] 	 train loss: 0.720992 	 lr: 0.00100
[epoch  12: 200/307] 	 train loss: 0.733507 	 lr: 0.00100
[epoch  12: 220/307] 	 train loss: 0.553292 	 lr: 0.00100
[epoch  12: 240/307] 	 train loss: 0.619728 	 lr: 0.00100
[epoch  12: 260/307] 	 train loss: 0.479780 	 lr: 0.00100
[epoch  12: 280/307] 	 train loss: 0.305198 	 lr: 0.00100

val loss: 0.447074 	 acc: 0.863047

[epoch  12: 300/307] 	 train loss: 0.914263 	 lr: 0.00100
[epoch  13:   0/307] 	 train loss: 0.417494 	 lr: 0.00100
[epoch  13:  20/307] 	 train loss: 0.552292 	 lr: 0.00100
[epoch  13:  40/307] 	 train loss: 0.395251 	 lr: 0.00100
[epoch  13:  60/307] 	 train loss: 0.693660 	 lr: 0.00100
[epoch  13:  80/307] 	 train loss: 0.374328 	 lr: 0.00100
[epoch  13: 100/307] 	 train loss: 0.805602 	 lr: 0.00100
[epoch  13: 120/307] 	 train loss: 0.625155 	 lr: 0.00100

val loss: 0.427994 	 acc: 0.868720

[epoch  13: 140/307] 	 train loss: 0.321895 	 lr: 0.00100
[epoch  13: 160/307] 	 train loss: 0.971389 	 lr: 0.00100
[epoch  13: 180/307] 	 train loss: 0.716361 	 lr: 0.00100
[epoch  13: 200/307] 	 train loss: 0.515481 	 lr: 0.00100
[epoch  13: 220/307] 	 train loss: 0.674883 	 lr: 0.00100
[epoch  13: 240/307] 	 train loss: 0.333360 	 lr: 0.00100
[epoch  13: 260/307] 	 train loss: 0.289840 	 lr: 0.00100
[epoch  13: 280/307] 	 train loss: 0.627673 	 lr: 0.00100

val loss: 0.434204 	 acc: 0.864668

[epoch  13: 300/307] 	 train loss: 0.334796 	 lr: 0.00100
[epoch  14:   0/307] 	 train loss: 1.189201 	 lr: 0.00100
[epoch  14:  20/307] 	 train loss: 0.297604 	 lr: 0.00100
[epoch  14:  40/307] 	 train loss: 0.679791 	 lr: 0.00100
[epoch  14:  60/307] 	 train loss: 0.554148 	 lr: 0.00100
[epoch  14:  80/307] 	 train loss: 0.531506 	 lr: 0.00100
[epoch  14: 100/307] 	 train loss: 0.255816 	 lr: 0.00100
[epoch  14: 120/307] 	 train loss: 0.203800 	 lr: 0.00100

val loss: 0.419397 	 acc: 0.868720

[epoch  14: 140/307] 	 train loss: 0.673954 	 lr: 0.00100
[epoch  14: 160/307] 	 train loss: 0.545031 	 lr: 0.00100
[epoch  14: 180/307] 	 train loss: 0.341629 	 lr: 0.00100
[epoch  14: 200/307] 	 train loss: 0.304405 	 lr: 0.00100
[epoch  14: 220/307] 	 train loss: 0.538894 	 lr: 0.00100
[epoch  14: 240/307] 	 train loss: 0.850164 	 lr: 0.00100
[epoch  14: 260/307] 	 train loss: 0.471241 	 lr: 0.00100

val loss: 0.429575 	 acc: 0.868314

[epoch  14: 280/307] 	 train loss: 0.388174 	 lr: 0.00100
[epoch  14: 300/307] 	 train loss: 0.397172 	 lr: 0.00100
[epoch  15:   0/307] 	 train loss: 0.717168 	 lr: 0.00100
[epoch  15:  20/307] 	 train loss: 0.338932 	 lr: 0.00100
[epoch  15:  40/307] 	 train loss: 0.349310 	 lr: 0.00100
[epoch  15:  60/307] 	 train loss: 0.464722 	 lr: 0.00100
[epoch  15:  80/307] 	 train loss: 0.217719 	 lr: 0.00100
[epoch  15: 100/307] 	 train loss: 0.325940 	 lr: 0.00100
[epoch  15: 120/307] 	 train loss: 0.401643 	 lr: 0.00100

val loss: 0.433044 	 acc: 0.872771

[epoch  15: 140/307] 	 train loss: 0.441085 	 lr: 0.00100
[epoch  15: 160/307] 	 train loss: 0.778466 	 lr: 0.00100
[epoch  15: 180/307] 	 train loss: 0.501643 	 lr: 0.00100
[epoch  15: 200/307] 	 train loss: 0.409838 	 lr: 0.00100
[epoch  15: 220/307] 	 train loss: 0.795424 	 lr: 0.00100
[epoch  15: 240/307] 	 train loss: 0.550391 	 lr: 0.00100
[epoch  15: 260/307] 	 train loss: 0.326450 	 lr: 0.00100

val loss: 0.454065 	 acc: 0.859400

[epoch  15: 280/307] 	 train loss: 0.564523 	 lr: 0.00100
[epoch  15: 300/307] 	 train loss: 0.581061 	 lr: 0.00100
[epoch  16:   0/307] 	 train loss: 0.103556 	 lr: 0.00100
[epoch  16:  20/307] 	 train loss: 0.383534 	 lr: 0.00100
[epoch  16:  40/307] 	 train loss: 0.259073 	 lr: 0.00100
[epoch  16:  60/307] 	 train loss: 0.510091 	 lr: 0.00100
[epoch  16:  80/307] 	 train loss: 0.680667 	 lr: 0.00100
[epoch  16: 100/307] 	 train loss: 0.394779 	 lr: 0.00100
[epoch  16: 120/307] 	 train loss: 0.219623 	 lr: 0.00100

val loss: 0.401838 	 acc: 0.873177

[epoch  16: 140/307] 	 train loss: 0.802566 	 lr: 0.00100
[epoch  16: 160/307] 	 train loss: 0.545819 	 lr: 0.00100
[epoch  16: 180/307] 	 train loss: 0.811253 	 lr: 0.00100
[epoch  16: 200/307] 	 train loss: 0.401314 	 lr: 0.00100
[epoch  16: 220/307] 	 train loss: 0.592012 	 lr: 0.00100
[epoch  16: 240/307] 	 train loss: 0.366909 	 lr: 0.00100
[epoch  16: 260/307] 	 train loss: 0.745480 	 lr: 0.00100

val loss: 0.425532 	 acc: 0.865883

[epoch  16: 280/307] 	 train loss: 0.757550 	 lr: 0.00100
[epoch  16: 300/307] 	 train loss: 0.737501 	 lr: 0.00100
[epoch  17:   0/307] 	 train loss: 0.900497 	 lr: 0.00100
[epoch  17:  20/307] 	 train loss: 0.477123 	 lr: 0.00100
[epoch  17:  40/307] 	 train loss: 0.312892 	 lr: 0.00100
[epoch  17:  60/307] 	 train loss: 0.636038 	 lr: 0.00100
[epoch  17:  80/307] 	 train loss: 0.539601 	 lr: 0.00100
[epoch  17: 100/307] 	 train loss: 0.938263 	 lr: 0.00100
[epoch  17: 120/307] 	 train loss: 0.449455 	 lr: 0.00100

val loss: 0.456326 	 acc: 0.865073

[epoch  17: 140/307] 	 train loss: 0.423087 	 lr: 0.00100
[epoch  17: 160/307] 	 train loss: 0.923567 	 lr: 0.00100
[epoch  17: 180/307] 	 train loss: 0.470996 	 lr: 0.00100
[epoch  17: 200/307] 	 train loss: 0.521630 	 lr: 0.00100
[epoch  17: 220/307] 	 train loss: 0.895512 	 lr: 0.00100
[epoch  17: 240/307] 	 train loss: 0.341431 	 lr: 0.00100
[epoch  17: 260/307] 	 train loss: 0.440939 	 lr: 0.00100

val loss: 0.387829 	 acc: 0.875608

[epoch  17: 280/307] 	 train loss: 0.660850 	 lr: 0.00100
[epoch  17: 300/307] 	 train loss: 0.582748 	 lr: 0.00100
[epoch  18:   0/307] 	 train loss: 0.229615 	 lr: 0.00100
[epoch  18:  20/307] 	 train loss: 0.397067 	 lr: 0.00100
[epoch  18:  40/307] 	 train loss: 0.924504 	 lr: 0.00100
[epoch  18:  60/307] 	 train loss: 0.373915 	 lr: 0.00100
[epoch  18:  80/307] 	 train loss: 0.279684 	 lr: 0.00100
[epoch  18: 100/307] 	 train loss: 0.292484 	 lr: 0.00100

val loss: 0.435868 	 acc: 0.861021

[epoch  18: 120/307] 	 train loss: 0.327323 	 lr: 0.00100
[epoch  18: 140/307] 	 train loss: 0.340073 	 lr: 0.00100
[epoch  18: 160/307] 	 train loss: 0.403151 	 lr: 0.00100
[epoch  18: 180/307] 	 train loss: 0.319228 	 lr: 0.00100
[epoch  18: 200/307] 	 train loss: 0.369844 	 lr: 0.00100
[epoch  18: 220/307] 	 train loss: 0.397860 	 lr: 0.00100
[epoch  18: 240/307] 	 train loss: 0.190776 	 lr: 0.00100
[epoch  18: 260/307] 	 train loss: 0.495202 	 lr: 0.00100

val loss: 0.399134 	 acc: 0.867504

[epoch  18: 280/307] 	 train loss: 0.391559 	 lr: 0.00100
[epoch  18: 300/307] 	 train loss: 0.473979 	 lr: 0.00100
[epoch  19:   0/307] 	 train loss: 0.480400 	 lr: 0.00100
[epoch  19:  20/307] 	 train loss: 0.653001 	 lr: 0.00100
[epoch  19:  40/307] 	 train loss: 0.380958 	 lr: 0.00100
[epoch  19:  60/307] 	 train loss: 0.368176 	 lr: 0.00100
[epoch  19:  80/307] 	 train loss: 0.408431 	 lr: 0.00100
[epoch  19: 100/307] 	 train loss: 0.547466 	 lr: 0.00100

val loss: 0.416381 	 acc: 0.873582

[epoch  19: 120/307] 	 train loss: 0.328484 	 lr: 0.00100
[epoch  19: 140/307] 	 train loss: 0.365389 	 lr: 0.00100
[epoch  19: 160/307] 	 train loss: 0.263737 	 lr: 0.00100
[epoch  19: 180/307] 	 train loss: 0.360120 	 lr: 0.00100
[epoch  19: 200/307] 	 train loss: 0.333044 	 lr: 0.00100
[epoch  19: 220/307] 	 train loss: 0.484510 	 lr: 0.00100
[epoch  19: 240/307] 	 train loss: 0.751012 	 lr: 0.00100
[epoch  19: 260/307] 	 train loss: 0.596939 	 lr: 0.00100

val loss: 0.385343 	 acc: 0.872771

[epoch  19: 280/307] 	 train loss: 0.310728 	 lr: 0.00100
[epoch  19: 300/307] 	 train loss: 0.223027 	 lr: 0.00100
[epoch  20:   0/307] 	 train loss: 0.369355 	 lr: 0.00100
[epoch  20:  20/307] 	 train loss: 0.200791 	 lr: 0.00100
[epoch  20:  40/307] 	 train loss: 0.156958 	 lr: 0.00100
[epoch  20:  60/307] 	 train loss: 0.227399 	 lr: 0.00100
[epoch  20:  80/307] 	 train loss: 0.552901 	 lr: 0.00100
[epoch  20: 100/307] 	 train loss: 0.235425 	 lr: 0.00100

val loss: 0.434874 	 acc: 0.859806

[epoch  20: 120/307] 	 train loss: 0.327257 	 lr: 0.00100
[epoch  20: 140/307] 	 train loss: 0.264665 	 lr: 0.00100
[epoch  20: 160/307] 	 train loss: 0.441871 	 lr: 0.00100
[epoch  20: 180/307] 	 train loss: 0.275673 	 lr: 0.00100
[epoch  20: 200/307] 	 train loss: 0.408930 	 lr: 0.00100
[epoch  20: 220/307] 	 train loss: 0.571549 	 lr: 0.00100
[epoch  20: 240/307] 	 train loss: 0.537117 	 lr: 0.00100
[epoch  20: 260/307] 	 train loss: 0.519787 	 lr: 0.00100

val loss: 0.400447 	 acc: 0.882091

[epoch  20: 280/307] 	 train loss: 0.428314 	 lr: 0.00100
[epoch  20: 300/307] 	 train loss: 0.658600 	 lr: 0.00100
[epoch  21:   0/307] 	 train loss: 0.281465 	 lr: 0.00100
[epoch  21:  20/307] 	 train loss: 0.577726 	 lr: 0.00100
[epoch  21:  40/307] 	 train loss: 0.395832 	 lr: 0.00100
[epoch  21:  60/307] 	 train loss: 0.380324 	 lr: 0.00100
[epoch  21:  80/307] 	 train loss: 0.406970 	 lr: 0.00100
[epoch  21: 100/307] 	 train loss: 0.408473 	 lr: 0.00100

val loss: 0.381325 	 acc: 0.876418

[epoch  21: 120/307] 	 train loss: 0.342447 	 lr: 0.00100
[epoch  21: 140/307] 	 train loss: 0.351996 	 lr: 0.00100
[epoch  21: 160/307] 	 train loss: 0.552127 	 lr: 0.00100
[epoch  21: 180/307] 	 train loss: 0.490081 	 lr: 0.00100
[epoch  21: 200/307] 	 train loss: 0.492176 	 lr: 0.00100
[epoch  21: 220/307] 	 train loss: 0.798702 	 lr: 0.00100
[epoch  21: 240/307] 	 train loss: 0.712231 	 lr: 0.00100
[epoch  21: 260/307] 	 train loss: 0.521895 	 lr: 0.00100

val loss: 0.409579 	 acc: 0.861831

[epoch  21: 280/307] 	 train loss: 0.528368 	 lr: 0.00100
[epoch  21: 300/307] 	 train loss: 0.303070 	 lr: 0.00100
[epoch  22:   0/307] 	 train loss: 0.247385 	 lr: 0.00080
[epoch  22:  20/307] 	 train loss: 0.173521 	 lr: 0.00080
[epoch  22:  40/307] 	 train loss: 0.451435 	 lr: 0.00080
[epoch  22:  60/307] 	 train loss: 0.508459 	 lr: 0.00080
[epoch  22:  80/307] 	 train loss: 0.428344 	 lr: 0.00080
[epoch  22: 100/307] 	 train loss: 0.905418 	 lr: 0.00080

val loss: 0.364947 	 acc: 0.883306

[epoch  22: 120/307] 	 train loss: 0.425658 	 lr: 0.00080
[epoch  22: 140/307] 	 train loss: 0.840603 	 lr: 0.00080
[epoch  22: 160/307] 	 train loss: 0.282027 	 lr: 0.00080
[epoch  22: 180/307] 	 train loss: 0.443158 	 lr: 0.00080
[epoch  22: 200/307] 	 train loss: 0.394976 	 lr: 0.00080
[epoch  22: 220/307] 	 train loss: 0.758886 	 lr: 0.00080
[epoch  22: 240/307] 	 train loss: 0.847703 	 lr: 0.00080
[epoch  22: 260/307] 	 train loss: 0.403243 	 lr: 0.00080

val loss: 0.380394 	 acc: 0.880065

[epoch  22: 280/307] 	 train loss: 0.213442 	 lr: 0.00080
[epoch  22: 300/307] 	 train loss: 0.472461 	 lr: 0.00080
[epoch  23:   0/307] 	 train loss: 0.273688 	 lr: 0.00080
[epoch  23:  20/307] 	 train loss: 0.573459 	 lr: 0.00080
[epoch  23:  40/307] 	 train loss: 0.439857 	 lr: 0.00080
[epoch  23:  60/307] 	 train loss: 0.385054 	 lr: 0.00080
[epoch  23:  80/307] 	 train loss: 0.709755 	 lr: 0.00080
[epoch  23: 100/307] 	 train loss: 0.430512 	 lr: 0.00080

val loss: 0.341721 	 acc: 0.886143

[epoch  23: 120/307] 	 train loss: 0.422212 	 lr: 0.00080
[epoch  23: 140/307] 	 train loss: 0.246707 	 lr: 0.00080
[epoch  23: 160/307] 	 train loss: 0.163928 	 lr: 0.00080
[epoch  23: 180/307] 	 train loss: 0.529592 	 lr: 0.00080
[epoch  23: 200/307] 	 train loss: 0.491476 	 lr: 0.00080
[epoch  23: 220/307] 	 train loss: 0.606558 	 lr: 0.00080
[epoch  23: 240/307] 	 train loss: 0.368716 	 lr: 0.00080
[epoch  23: 260/307] 	 train loss: 0.217177 	 lr: 0.00080

val loss: 0.387422 	 acc: 0.882496

[epoch  23: 280/307] 	 train loss: 0.282697 	 lr: 0.00080
[epoch  23: 300/307] 	 train loss: 0.666790 	 lr: 0.00080
[epoch  24:   0/307] 	 train loss: 0.307775 	 lr: 0.00080
[epoch  24:  20/307] 	 train loss: 0.654405 	 lr: 0.00080
[epoch  24:  40/307] 	 train loss: 0.311569 	 lr: 0.00080
[epoch  24:  60/307] 	 train loss: 0.296937 	 lr: 0.00080
[epoch  24:  80/307] 	 train loss: 0.545757 	 lr: 0.00080
[epoch  24: 100/307] 	 train loss: 0.401338 	 lr: 0.00080

val loss: 0.370783 	 acc: 0.882091

[epoch  24: 120/307] 	 train loss: 0.481518 	 lr: 0.00080
[epoch  24: 140/307] 	 train loss: 0.345617 	 lr: 0.00080
[epoch  24: 160/307] 	 train loss: 0.200790 	 lr: 0.00080
[epoch  24: 180/307] 	 train loss: 0.471693 	 lr: 0.00080
[epoch  24: 200/307] 	 train loss: 0.178157 	 lr: 0.00080
[epoch  24: 220/307] 	 train loss: 0.473700 	 lr: 0.00080
[epoch  24: 240/307] 	 train loss: 0.433072 	 lr: 0.00080

val loss: 0.389195 	 acc: 0.869935

[epoch  24: 260/307] 	 train loss: 0.769338 	 lr: 0.00080
[epoch  24: 280/307] 	 train loss: 0.515642 	 lr: 0.00080
[epoch  24: 300/307] 	 train loss: 0.198638 	 lr: 0.00080
[epoch  25:   0/307] 	 train loss: 0.564637 	 lr: 0.00080
[epoch  25:  20/307] 	 train loss: 0.158717 	 lr: 0.00080
[epoch  25:  40/307] 	 train loss: 0.498102 	 lr: 0.00080
[epoch  25:  60/307] 	 train loss: 0.198540 	 lr: 0.00080
[epoch  25:  80/307] 	 train loss: 0.146063 	 lr: 0.00080
[epoch  25: 100/307] 	 train loss: 0.403681 	 lr: 0.00080

val loss: 0.353652 	 acc: 0.894652

[epoch  25: 120/307] 	 train loss: 0.263180 	 lr: 0.00080
[epoch  25: 140/307] 	 train loss: 0.367397 	 lr: 0.00080
[epoch  25: 160/307] 	 train loss: 0.263663 	 lr: 0.00080
[epoch  25: 180/307] 	 train loss: 0.290143 	 lr: 0.00080
[epoch  25: 200/307] 	 train loss: 0.773481 	 lr: 0.00080
[epoch  25: 220/307] 	 train loss: 0.143617 	 lr: 0.00080
[epoch  25: 240/307] 	 train loss: 0.437687 	 lr: 0.00080

val loss: 0.362821 	 acc: 0.883306

[epoch  25: 260/307] 	 train loss: 0.413113 	 lr: 0.00080
[epoch  25: 280/307] 	 train loss: 0.171562 	 lr: 0.00080
[epoch  25: 300/307] 	 train loss: 0.289358 	 lr: 0.00080
[epoch  26:   0/307] 	 train loss: 0.665702 	 lr: 0.00080
[epoch  26:  20/307] 	 train loss: 0.243413 	 lr: 0.00080
[epoch  26:  40/307] 	 train loss: 0.289780 	 lr: 0.00080
[epoch  26:  60/307] 	 train loss: 0.589410 	 lr: 0.00080
[epoch  26:  80/307] 	 train loss: 0.410894 	 lr: 0.00080
[epoch  26: 100/307] 	 train loss: 0.431993 	 lr: 0.00080

val loss: 0.345538 	 acc: 0.897488

[epoch  26: 120/307] 	 train loss: 0.666574 	 lr: 0.00080
[epoch  26: 140/307] 	 train loss: 0.232943 	 lr: 0.00080
[epoch  26: 160/307] 	 train loss: 0.237944 	 lr: 0.00080
[epoch  26: 180/307] 	 train loss: 0.756084 	 lr: 0.00080
[epoch  26: 200/307] 	 train loss: 0.299586 	 lr: 0.00080
[epoch  26: 220/307] 	 train loss: 0.349280 	 lr: 0.00080
[epoch  26: 240/307] 	 train loss: 0.668960 	 lr: 0.00080

val loss: 0.358441 	 acc: 0.886548

[epoch  26: 260/307] 	 train loss: 0.402791 	 lr: 0.00080
[epoch  26: 280/307] 	 train loss: 0.366355 	 lr: 0.00080
[epoch  26: 300/307] 	 train loss: 0.555679 	 lr: 0.00080
[epoch  27:   0/307] 	 train loss: 0.575207 	 lr: 0.00080
[epoch  27:  20/307] 	 train loss: 0.273417 	 lr: 0.00080
[epoch  27:  40/307] 	 train loss: 0.441297 	 lr: 0.00080
[epoch  27:  60/307] 	 train loss: 0.397575 	 lr: 0.00080
[epoch  27:  80/307] 	 train loss: 0.393943 	 lr: 0.00080
[epoch  27: 100/307] 	 train loss: 0.146422 	 lr: 0.00080

val loss: 0.372619 	 acc: 0.884117

[epoch  27: 120/307] 	 train loss: 0.385150 	 lr: 0.00080
[epoch  27: 140/307] 	 train loss: 0.549218 	 lr: 0.00080
[epoch  27: 160/307] 	 train loss: 0.470253 	 lr: 0.00080
[epoch  27: 180/307] 	 train loss: 0.321858 	 lr: 0.00080
[epoch  27: 200/307] 	 train loss: 0.550037 	 lr: 0.00080
[epoch  27: 220/307] 	 train loss: 0.182872 	 lr: 0.00080
[epoch  27: 240/307] 	 train loss: 0.511761 	 lr: 0.00080

val loss: 0.324441 	 acc: 0.891410

[epoch  27: 260/307] 	 train loss: 0.277938 	 lr: 0.00080
[epoch  27: 280/307] 	 train loss: 0.431159 	 lr: 0.00080
[epoch  27: 300/307] 	 train loss: 0.269062 	 lr: 0.00080
[epoch  28:   0/307] 	 train loss: 0.256351 	 lr: 0.00080
[epoch  28:  20/307] 	 train loss: 0.292396 	 lr: 0.00080
[epoch  28:  40/307] 	 train loss: 0.226333 	 lr: 0.00080
[epoch  28:  60/307] 	 train loss: 0.171549 	 lr: 0.00080
[epoch  28:  80/307] 	 train loss: 0.459323 	 lr: 0.00080

val loss: 0.342462 	 acc: 0.892626

[epoch  28: 100/307] 	 train loss: 0.667543 	 lr: 0.00080
[epoch  28: 120/307] 	 train loss: 0.201033 	 lr: 0.00080
[epoch  28: 140/307] 	 train loss: 0.797204 	 lr: 0.00080
[epoch  28: 160/307] 	 train loss: 0.750843 	 lr: 0.00080
[epoch  28: 180/307] 	 train loss: 0.706856 	 lr: 0.00080
[epoch  28: 200/307] 	 train loss: 0.619264 	 lr: 0.00080
[epoch  28: 220/307] 	 train loss: 0.837326 	 lr: 0.00080
[epoch  28: 240/307] 	 train loss: 0.175699 	 lr: 0.00080

val loss: 0.388595 	 acc: 0.876823

[epoch  28: 260/307] 	 train loss: 0.151899 	 lr: 0.00080
[epoch  28: 280/307] 	 train loss: 0.245916 	 lr: 0.00080
[epoch  28: 300/307] 	 train loss: 0.155274 	 lr: 0.00080
[epoch  29:   0/307] 	 train loss: 0.284388 	 lr: 0.00080
[epoch  29:  20/307] 	 train loss: 0.704372 	 lr: 0.00080
[epoch  29:  40/307] 	 train loss: 0.550365 	 lr: 0.00080
[epoch  29:  60/307] 	 train loss: 0.231092 	 lr: 0.00080
[epoch  29:  80/307] 	 train loss: 0.369974 	 lr: 0.00080

val loss: 0.365083 	 acc: 0.886953

[epoch  29: 100/307] 	 train loss: 0.524973 	 lr: 0.00080
[epoch  29: 120/307] 	 train loss: 0.321866 	 lr: 0.00080
[epoch  29: 140/307] 	 train loss: 0.363525 	 lr: 0.00080
[epoch  29: 160/307] 	 train loss: 0.185850 	 lr: 0.00080
[epoch  29: 180/307] 	 train loss: 0.354567 	 lr: 0.00080
[epoch  29: 200/307] 	 train loss: 0.206601 	 lr: 0.00080
[epoch  29: 220/307] 	 train loss: 0.811322 	 lr: 0.00080
[epoch  29: 240/307] 	 train loss: 0.332497 	 lr: 0.00080

val loss: 0.367615 	 acc: 0.889789

[epoch  29: 260/307] 	 train loss: 0.543766 	 lr: 0.00080
[epoch  29: 280/307] 	 train loss: 0.510597 	 lr: 0.00080
[epoch  29: 300/307] 	 train loss: 0.297530 	 lr: 0.00080
[epoch  30:   0/307] 	 train loss: 0.522297 	 lr: 0.00080
[epoch  30:  20/307] 	 train loss: 0.346146 	 lr: 0.00080
[epoch  30:  40/307] 	 train loss: 0.578603 	 lr: 0.00080
[epoch  30:  60/307] 	 train loss: 0.121154 	 lr: 0.00080
[epoch  30:  80/307] 	 train loss: 0.498354 	 lr: 0.00080

val loss: 0.342104 	 acc: 0.891005

[epoch  30: 100/307] 	 train loss: 0.384180 	 lr: 0.00080
[epoch  30: 120/307] 	 train loss: 0.370443 	 lr: 0.00080
[epoch  30: 140/307] 	 train loss: 0.345612 	 lr: 0.00080
[epoch  30: 160/307] 	 train loss: 0.349136 	 lr: 0.00080
[epoch  30: 180/307] 	 train loss: 0.520694 	 lr: 0.00080
[epoch  30: 200/307] 	 train loss: 0.462726 	 lr: 0.00080
[epoch  30: 220/307] 	 train loss: 0.313403 	 lr: 0.00080
[epoch  30: 240/307] 	 train loss: 0.255538 	 lr: 0.00080

val loss: 0.376251 	 acc: 0.881686

[epoch  30: 260/307] 	 train loss: 0.275394 	 lr: 0.00080
[epoch  30: 280/307] 	 train loss: 0.473908 	 lr: 0.00080
[epoch  30: 300/307] 	 train loss: 0.488532 	 lr: 0.00080
[epoch  31:   0/307] 	 train loss: 0.315198 	 lr: 0.00080
[epoch  31:  20/307] 	 train loss: 0.464813 	 lr: 0.00080
[epoch  31:  40/307] 	 train loss: 0.454554 	 lr: 0.00080
[epoch  31:  60/307] 	 train loss: 0.375352 	 lr: 0.00080
[epoch  31:  80/307] 	 train loss: 0.355258 	 lr: 0.00080

val loss: 0.356970 	 acc: 0.896677

[epoch  31: 100/307] 	 train loss: 0.202396 	 lr: 0.00080
[epoch  31: 120/307] 	 train loss: 0.355909 	 lr: 0.00080
[epoch  31: 140/307] 	 train loss: 0.430824 	 lr: 0.00080
[epoch  31: 160/307] 	 train loss: 0.805027 	 lr: 0.00080
[epoch  31: 180/307] 	 train loss: 0.259589 	 lr: 0.00080
[epoch  31: 200/307] 	 train loss: 0.270281 	 lr: 0.00080
[epoch  31: 220/307] 	 train loss: 0.262515 	 lr: 0.00080
[epoch  31: 240/307] 	 train loss: 0.239336 	 lr: 0.00080

val loss: 0.348198 	 acc: 0.891005

[epoch  31: 260/307] 	 train loss: 0.550371 	 lr: 0.00080
[epoch  31: 280/307] 	 train loss: 0.191421 	 lr: 0.00080
[epoch  31: 300/307] 	 train loss: 0.099443 	 lr: 0.00080
[epoch  32:   0/307] 	 train loss: 0.596984 	 lr: 0.00080
[epoch  32:  20/307] 	 train loss: 0.290917 	 lr: 0.00080
[epoch  32:  40/307] 	 train loss: 0.428208 	 lr: 0.00080
[epoch  32:  60/307] 	 train loss: 0.434925 	 lr: 0.00080
[epoch  32:  80/307] 	 train loss: 0.246989 	 lr: 0.00080

val loss: 0.357527 	 acc: 0.891005

[epoch  32: 100/307] 	 train loss: 0.239119 	 lr: 0.00080
[epoch  32: 120/307] 	 train loss: 0.298141 	 lr: 0.00080
[epoch  32: 140/307] 	 train loss: 0.325292 	 lr: 0.00080
[epoch  32: 160/307] 	 train loss: 0.508523 	 lr: 0.00080
[epoch  32: 180/307] 	 train loss: 0.421684 	 lr: 0.00080
[epoch  32: 200/307] 	 train loss: 0.163722 	 lr: 0.00080
[epoch  32: 220/307] 	 train loss: 0.388284 	 lr: 0.00080
[epoch  32: 240/307] 	 train loss: 0.310887 	 lr: 0.00080

val loss: 0.347649 	 acc: 0.884117

[epoch  32: 260/307] 	 train loss: 0.391438 	 lr: 0.00080
[epoch  32: 280/307] 	 train loss: 0.373943 	 lr: 0.00080
[epoch  32: 300/307] 	 train loss: 0.341036 	 lr: 0.00080
[epoch  33:   0/307] 	 train loss: 0.539784 	 lr: 0.00080
[epoch  33:  20/307] 	 train loss: 0.272950 	 lr: 0.00080
[epoch  33:  40/307] 	 train loss: 0.344840 	 lr: 0.00080
[epoch  33:  60/307] 	 train loss: 0.302646 	 lr: 0.00080
[epoch  33:  80/307] 	 train loss: 0.245864 	 lr: 0.00080

val loss: 0.366966 	 acc: 0.887763

[epoch  33: 100/307] 	 train loss: 0.697929 	 lr: 0.00080
[epoch  33: 120/307] 	 train loss: 0.563205 	 lr: 0.00080
[epoch  33: 140/307] 	 train loss: 0.996127 	 lr: 0.00080
[epoch  33: 160/307] 	 train loss: 0.619806 	 lr: 0.00080
[epoch  33: 180/307] 	 train loss: 0.257339 	 lr: 0.00080
[epoch  33: 200/307] 	 train loss: 0.306953 	 lr: 0.00080
[epoch  33: 220/307] 	 train loss: 0.211515 	 lr: 0.00080
[epoch  33: 240/307] 	 train loss: 0.524588 	 lr: 0.00080

val loss: 0.359022 	 acc: 0.882091

[epoch  33: 260/307] 	 train loss: 0.271324 	 lr: 0.00080
[epoch  33: 280/307] 	 train loss: 0.289236 	 lr: 0.00080
[epoch  33: 300/307] 	 train loss: 0.194280 	 lr: 0.00080
[epoch  34:   0/307] 	 train loss: 0.159373 	 lr: 0.00080
[epoch  34:  20/307] 	 train loss: 0.472165 	 lr: 0.00080
[epoch  34:  40/307] 	 train loss: 0.337485 	 lr: 0.00080
[epoch  34:  60/307] 	 train loss: 0.363162 	 lr: 0.00080
[epoch  34:  80/307] 	 train loss: 0.373621 	 lr: 0.00080

val loss: 0.350912 	 acc: 0.891410

[epoch  34: 100/307] 	 train loss: 0.468855 	 lr: 0.00080
[epoch  34: 120/307] 	 train loss: 0.268116 	 lr: 0.00080
[epoch  34: 140/307] 	 train loss: 0.217944 	 lr: 0.00080
[epoch  34: 160/307] 	 train loss: 0.379210 	 lr: 0.00080
[epoch  34: 180/307] 	 train loss: 0.724965 	 lr: 0.00080
[epoch  34: 200/307] 	 train loss: 0.092480 	 lr: 0.00080
[epoch  34: 220/307] 	 train loss: 0.639365 	 lr: 0.00080

val loss: 0.330199 	 acc: 0.899919

[epoch  34: 240/307] 	 train loss: 0.562613 	 lr: 0.00080
[epoch  34: 260/307] 	 train loss: 0.243413 	 lr: 0.00080
[epoch  34: 280/307] 	 train loss: 0.598235 	 lr: 0.00080
[epoch  34: 300/307] 	 train loss: 0.481493 	 lr: 0.00080
[epoch  35:   0/307] 	 train loss: 0.622612 	 lr: 0.00080
[epoch  35:  20/307] 	 train loss: 0.223099 	 lr: 0.00080
[epoch  35:  40/307] 	 train loss: 0.310985 	 lr: 0.00080
[epoch  35:  60/307] 	 train loss: 0.548976 	 lr: 0.00080
[epoch  35:  80/307] 	 train loss: 0.161176 	 lr: 0.00080

val loss: 0.383228 	 acc: 0.883306

[epoch  35: 100/307] 	 train loss: 0.288802 	 lr: 0.00080
[epoch  35: 120/307] 	 train loss: 0.287797 	 lr: 0.00080
[epoch  35: 140/307] 	 train loss: 0.307484 	 lr: 0.00080
[epoch  35: 160/307] 	 train loss: 0.364625 	 lr: 0.00080
[epoch  35: 180/307] 	 train loss: 0.212305 	 lr: 0.00080
[epoch  35: 200/307] 	 train loss: 0.278850 	 lr: 0.00080
[epoch  35: 220/307] 	 train loss: 0.156630 	 lr: 0.00080

val loss: 0.336885 	 acc: 0.896677

[epoch  35: 240/307] 	 train loss: 0.251893 	 lr: 0.00080
[epoch  35: 260/307] 	 train loss: 0.139821 	 lr: 0.00080
[epoch  35: 280/307] 	 train loss: 0.341723 	 lr: 0.00080
[epoch  35: 300/307] 	 train loss: 0.124245 	 lr: 0.00080
[epoch  36:   0/307] 	 train loss: 0.162125 	 lr: 0.00080
[epoch  36:  20/307] 	 train loss: 0.436826 	 lr: 0.00080
[epoch  36:  40/307] 	 train loss: 0.482020 	 lr: 0.00080
[epoch  36:  60/307] 	 train loss: 0.561425 	 lr: 0.00080
[epoch  36:  80/307] 	 train loss: 0.282317 	 lr: 0.00080

val loss: 0.337612 	 acc: 0.899109

[epoch  36: 100/307] 	 train loss: 0.264913 	 lr: 0.00080
[epoch  36: 120/307] 	 train loss: 0.327046 	 lr: 0.00080
[epoch  36: 140/307] 	 train loss: 0.228928 	 lr: 0.00080
[epoch  36: 160/307] 	 train loss: 0.383957 	 lr: 0.00080
[epoch  36: 180/307] 	 train loss: 0.432908 	 lr: 0.00080
[epoch  36: 200/307] 	 train loss: 0.572372 	 lr: 0.00080
[epoch  36: 220/307] 	 train loss: 0.292271 	 lr: 0.00080

val loss: 0.336598 	 acc: 0.901540

[epoch  36: 240/307] 	 train loss: 0.353522 	 lr: 0.00080
[epoch  36: 260/307] 	 train loss: 0.529153 	 lr: 0.00080
[epoch  36: 280/307] 	 train loss: 0.601209 	 lr: 0.00080
[epoch  36: 300/307] 	 train loss: 0.274388 	 lr: 0.00080
[epoch  37:   0/307] 	 train loss: 0.168569 	 lr: 0.00080
[epoch  37:  20/307] 	 train loss: 0.213102 	 lr: 0.00080
[epoch  37:  40/307] 	 train loss: 0.443846 	 lr: 0.00080
[epoch  37:  60/307] 	 train loss: 0.730410 	 lr: 0.00080
[epoch  37:  80/307] 	 train loss: 0.511091 	 lr: 0.00080

val loss: 0.362503 	 acc: 0.892626

[epoch  37: 100/307] 	 train loss: 0.450355 	 lr: 0.00080
[epoch  37: 120/307] 	 train loss: 0.235360 	 lr: 0.00080
[epoch  37: 140/307] 	 train loss: 0.290002 	 lr: 0.00080
[epoch  37: 160/307] 	 train loss: 0.479707 	 lr: 0.00080
[epoch  37: 180/307] 	 train loss: 0.279441 	 lr: 0.00080
[epoch  37: 200/307] 	 train loss: 0.529243 	 lr: 0.00080
[epoch  37: 220/307] 	 train loss: 0.382472 	 lr: 0.00080

val loss: 0.336309 	 acc: 0.896677

[epoch  37: 240/307] 	 train loss: 0.168782 	 lr: 0.00080
[epoch  37: 260/307] 	 train loss: 0.115142 	 lr: 0.00080
[epoch  37: 280/307] 	 train loss: 0.425451 	 lr: 0.00080
[epoch  37: 300/307] 	 train loss: 0.241682 	 lr: 0.00080
[epoch  38:   0/307] 	 train loss: 0.389171 	 lr: 0.00080
[epoch  38:  20/307] 	 train loss: 0.395266 	 lr: 0.00080
[epoch  38:  40/307] 	 train loss: 0.162590 	 lr: 0.00080
[epoch  38:  60/307] 	 train loss: 0.273752 	 lr: 0.00080

val loss: 0.343661 	 acc: 0.898298

[epoch  38:  80/307] 	 train loss: 0.426564 	 lr: 0.00080
[epoch  38: 100/307] 	 train loss: 0.157423 	 lr: 0.00080
[epoch  38: 120/307] 	 train loss: 0.264397 	 lr: 0.00080
[epoch  38: 140/307] 	 train loss: 0.358034 	 lr: 0.00080
[epoch  38: 160/307] 	 train loss: 0.225702 	 lr: 0.00080
[epoch  38: 180/307] 	 train loss: 0.489234 	 lr: 0.00080
[epoch  38: 200/307] 	 train loss: 0.237218 	 lr: 0.00080
[epoch  38: 220/307] 	 train loss: 0.178615 	 lr: 0.00080

val loss: 0.343677 	 acc: 0.891815

[epoch  38: 240/307] 	 train loss: 0.423670 	 lr: 0.00080
[epoch  38: 260/307] 	 train loss: 0.277951 	 lr: 0.00080
[epoch  38: 280/307] 	 train loss: 0.104957 	 lr: 0.00080
[epoch  38: 300/307] 	 train loss: 0.237046 	 lr: 0.00080
[epoch  39:   0/307] 	 train loss: 0.449978 	 lr: 0.00080
[epoch  39:  20/307] 	 train loss: 0.199956 	 lr: 0.00080
[epoch  39:  40/307] 	 train loss: 0.444131 	 lr: 0.00080
[epoch  39:  60/307] 	 train loss: 0.445251 	 lr: 0.00080

val loss: 0.338008 	 acc: 0.889789

[epoch  39:  80/307] 	 train loss: 0.319237 	 lr: 0.00080
[epoch  39: 100/307] 	 train loss: 0.294799 	 lr: 0.00080
[epoch  39: 120/307] 	 train loss: 0.199447 	 lr: 0.00080
[epoch  39: 140/307] 	 train loss: 0.371407 	 lr: 0.00080
[epoch  39: 160/307] 	 train loss: 0.538131 	 lr: 0.00080
[epoch  39: 180/307] 	 train loss: 0.670129 	 lr: 0.00080
[epoch  39: 200/307] 	 train loss: 0.385308 	 lr: 0.00080
[epoch  39: 220/307] 	 train loss: 0.301293 	 lr: 0.00080

val loss: 0.338251 	 acc: 0.893031

[epoch  39: 240/307] 	 train loss: 0.461782 	 lr: 0.00080
[epoch  39: 260/307] 	 train loss: 0.215242 	 lr: 0.00080
[epoch  39: 280/307] 	 train loss: 0.248490 	 lr: 0.00080
[epoch  39: 300/307] 	 train loss: 0.519376 	 lr: 0.00080
[epoch  40:   0/307] 	 train loss: 0.094765 	 lr: 0.00080
[epoch  40:  20/307] 	 train loss: 0.148019 	 lr: 0.00080
[epoch  40:  40/307] 	 train loss: 0.283341 	 lr: 0.00080
[epoch  40:  60/307] 	 train loss: 0.211593 	 lr: 0.00080

val loss: 0.328815 	 acc: 0.903160

[epoch  40:  80/307] 	 train loss: 0.661386 	 lr: 0.00080
[epoch  40: 100/307] 	 train loss: 0.136718 	 lr: 0.00080
[epoch  40: 120/307] 	 train loss: 0.470592 	 lr: 0.00080
[epoch  40: 140/307] 	 train loss: 0.325244 	 lr: 0.00080
[epoch  40: 160/307] 	 train loss: 0.462240 	 lr: 0.00080
[epoch  40: 180/307] 	 train loss: 0.597527 	 lr: 0.00080
[epoch  40: 200/307] 	 train loss: 0.223695 	 lr: 0.00080
[epoch  40: 220/307] 	 train loss: 0.144185 	 lr: 0.00080

val loss: 0.334863 	 acc: 0.891815

[epoch  40: 240/307] 	 train loss: 0.175174 	 lr: 0.00080
[epoch  40: 260/307] 	 train loss: 0.234520 	 lr: 0.00080
[epoch  40: 280/307] 	 train loss: 0.377010 	 lr: 0.00080
[epoch  40: 300/307] 	 train loss: 0.321000 	 lr: 0.00080
[epoch  41:   0/307] 	 train loss: 0.530526 	 lr: 0.00080
[epoch  41:  20/307] 	 train loss: 0.354992 	 lr: 0.00080
[epoch  41:  40/307] 	 train loss: 0.366786 	 lr: 0.00080
[epoch  41:  60/307] 	 train loss: 0.252665 	 lr: 0.00080

val loss: 0.317688 	 acc: 0.906402

[epoch  41:  80/307] 	 train loss: 0.321198 	 lr: 0.00080
[epoch  41: 100/307] 	 train loss: 0.137952 	 lr: 0.00080
[epoch  41: 120/307] 	 train loss: 0.318046 	 lr: 0.00080
[epoch  41: 140/307] 	 train loss: 0.388364 	 lr: 0.00080
[epoch  41: 160/307] 	 train loss: 0.205666 	 lr: 0.00080
[epoch  41: 180/307] 	 train loss: 0.258635 	 lr: 0.00080
[epoch  41: 200/307] 	 train loss: 0.552106 	 lr: 0.00080
[epoch  41: 220/307] 	 train loss: 0.468363 	 lr: 0.00080

val loss: 0.356105 	 acc: 0.884117

[epoch  41: 240/307] 	 train loss: 0.405930 	 lr: 0.00080
[epoch  41: 260/307] 	 train loss: 0.419020 	 lr: 0.00080
[epoch  41: 280/307] 	 train loss: 0.213639 	 lr: 0.00080
[epoch  41: 300/307] 	 train loss: 0.655803 	 lr: 0.00080
[epoch  42:   0/307] 	 train loss: 0.410342 	 lr: 0.00080
[epoch  42:  20/307] 	 train loss: 0.237299 	 lr: 0.00080
[epoch  42:  40/307] 	 train loss: 0.304131 	 lr: 0.00080
[epoch  42:  60/307] 	 train loss: 0.305631 	 lr: 0.00080

val loss: 0.342137 	 acc: 0.893031

[epoch  42:  80/307] 	 train loss: 0.307104 	 lr: 0.00080
[epoch  42: 100/307] 	 train loss: 0.517907 	 lr: 0.00080
[epoch  42: 120/307] 	 train loss: 0.117271 	 lr: 0.00080
[epoch  42: 140/307] 	 train loss: 0.181420 	 lr: 0.00080
[epoch  42: 160/307] 	 train loss: 0.214786 	 lr: 0.00080
[epoch  42: 180/307] 	 train loss: 0.185165 	 lr: 0.00080
[epoch  42: 200/307] 	 train loss: 0.421679 	 lr: 0.00080
[epoch  42: 220/307] 	 train loss: 0.235800 	 lr: 0.00080

val loss: 0.339625 	 acc: 0.890600

[epoch  42: 240/307] 	 train loss: 0.184048 	 lr: 0.00080
[epoch  42: 260/307] 	 train loss: 0.336299 	 lr: 0.00080
[epoch  42: 280/307] 	 train loss: 0.337128 	 lr: 0.00080
[epoch  42: 300/307] 	 train loss: 0.724286 	 lr: 0.00080
[epoch  43:   0/307] 	 train loss: 0.241765 	 lr: 0.00064
[epoch  43:  20/307] 	 train loss: 0.129170 	 lr: 0.00064
[epoch  43:  40/307] 	 train loss: 0.239257 	 lr: 0.00064
[epoch  43:  60/307] 	 train loss: 0.272432 	 lr: 0.00064

val loss: 0.328725 	 acc: 0.892626

[epoch  43:  80/307] 	 train loss: 0.303221 	 lr: 0.00064
[epoch  43: 100/307] 	 train loss: 0.285072 	 lr: 0.00064
[epoch  43: 120/307] 	 train loss: 0.480068 	 lr: 0.00064
[epoch  43: 140/307] 	 train loss: 0.386043 	 lr: 0.00064
[epoch  43: 160/307] 	 train loss: 0.482146 	 lr: 0.00064
[epoch  43: 180/307] 	 train loss: 0.228031 	 lr: 0.00064
[epoch  43: 200/307] 	 train loss: 0.239262 	 lr: 0.00064
[epoch  43: 220/307] 	 train loss: 0.553085 	 lr: 0.00064

val loss: 0.337448 	 acc: 0.899919

[epoch  43: 240/307] 	 train loss: 0.534217 	 lr: 0.00064
[epoch  43: 260/307] 	 train loss: 0.355281 	 lr: 0.00064
[epoch  43: 280/307] 	 train loss: 0.300614 	 lr: 0.00064
[epoch  43: 300/307] 	 train loss: 0.162879 	 lr: 0.00064
[epoch  44:   0/307] 	 train loss: 0.576782 	 lr: 0.00064
[epoch  44:  20/307] 	 train loss: 0.342969 	 lr: 0.00064
[epoch  44:  40/307] 	 train loss: 0.245394 	 lr: 0.00064
[epoch  44:  60/307] 	 train loss: 0.316283 	 lr: 0.00064

val loss: 0.302800 	 acc: 0.903160

[epoch  44:  80/307] 	 train loss: 0.309830 	 lr: 0.00064
[epoch  44: 100/307] 	 train loss: 0.367438 	 lr: 0.00064
[epoch  44: 120/307] 	 train loss: 0.211549 	 lr: 0.00064
[epoch  44: 140/307] 	 train loss: 0.211451 	 lr: 0.00064
[epoch  44: 160/307] 	 train loss: 0.473808 	 lr: 0.00064
[epoch  44: 180/307] 	 train loss: 0.349140 	 lr: 0.00064
[epoch  44: 200/307] 	 train loss: 0.362273 	 lr: 0.00064

val loss: 0.323437 	 acc: 0.897893

[epoch  44: 220/307] 	 train loss: 0.409560 	 lr: 0.00064
[epoch  44: 240/307] 	 train loss: 0.287176 	 lr: 0.00064
[epoch  44: 260/307] 	 train loss: 0.478573 	 lr: 0.00064
[epoch  44: 280/307] 	 train loss: 0.287161 	 lr: 0.00064
[epoch  44: 300/307] 	 train loss: 0.563014 	 lr: 0.00064
[epoch  45:   0/307] 	 train loss: 0.270146 	 lr: 0.00064
[epoch  45:  20/307] 	 train loss: 0.241326 	 lr: 0.00064
[epoch  45:  40/307] 	 train loss: 0.266335 	 lr: 0.00064
[epoch  45:  60/307] 	 train loss: 0.422578 	 lr: 0.00064

val loss: 0.325133 	 acc: 0.895867

[epoch  45:  80/307] 	 train loss: 0.617548 	 lr: 0.00064
[epoch  45: 100/307] 	 train loss: 0.257033 	 lr: 0.00064
[epoch  45: 120/307] 	 train loss: 0.408055 	 lr: 0.00064
[epoch  45: 140/307] 	 train loss: 0.285859 	 lr: 0.00064
[epoch  45: 160/307] 	 train loss: 0.336728 	 lr: 0.00064
[epoch  45: 180/307] 	 train loss: 0.335390 	 lr: 0.00064
[epoch  45: 200/307] 	 train loss: 0.666185 	 lr: 0.00064

val loss: 0.338711 	 acc: 0.898298

[epoch  45: 220/307] 	 train loss: 0.343429 	 lr: 0.00064
[epoch  45: 240/307] 	 train loss: 0.344402 	 lr: 0.00064
[epoch  45: 260/307] 	 train loss: 0.420854 	 lr: 0.00064
[epoch  45: 280/307] 	 train loss: 0.112613 	 lr: 0.00064
[epoch  45: 300/307] 	 train loss: 0.614258 	 lr: 0.00064
[epoch  46:   0/307] 	 train loss: 0.093716 	 lr: 0.00064
[epoch  46:  20/307] 	 train loss: 0.463313 	 lr: 0.00064
[epoch  46:  40/307] 	 train loss: 0.488774 	 lr: 0.00064
[epoch  46:  60/307] 	 train loss: 0.281722 	 lr: 0.00064

val loss: 0.322989 	 acc: 0.899109

[epoch  46:  80/307] 	 train loss: 0.382412 	 lr: 0.00064
[epoch  46: 100/307] 	 train loss: 0.341536 	 lr: 0.00064
[epoch  46: 120/307] 	 train loss: 0.362626 	 lr: 0.00064
[epoch  46: 140/307] 	 train loss: 0.275469 	 lr: 0.00064
[epoch  46: 160/307] 	 train loss: 0.353147 	 lr: 0.00064
[epoch  46: 180/307] 	 train loss: 0.137130 	 lr: 0.00064
[epoch  46: 200/307] 	 train loss: 0.350987 	 lr: 0.00064

val loss: 0.323884 	 acc: 0.901135

[epoch  46: 220/307] 	 train loss: 0.283484 	 lr: 0.00064
[epoch  46: 240/307] 	 train loss: 0.192633 	 lr: 0.00064
[epoch  46: 260/307] 	 train loss: 0.256248 	 lr: 0.00064
[epoch  46: 280/307] 	 train loss: 0.330274 	 lr: 0.00064
[epoch  46: 300/307] 	 train loss: 0.295873 	 lr: 0.00064
[epoch  47:   0/307] 	 train loss: 0.187654 	 lr: 0.00064
[epoch  47:  20/307] 	 train loss: 0.172363 	 lr: 0.00064
[epoch  47:  40/307] 	 train loss: 0.086934 	 lr: 0.00064
[epoch  47:  60/307] 	 train loss: 0.381102 	 lr: 0.00064

val loss: 0.326454 	 acc: 0.893841

[epoch  47:  80/307] 	 train loss: 0.384181 	 lr: 0.00064
[epoch  47: 100/307] 	 train loss: 0.273148 	 lr: 0.00064
[epoch  47: 120/307] 	 train loss: 0.420728 	 lr: 0.00064
[epoch  47: 140/307] 	 train loss: 0.490074 	 lr: 0.00064
[epoch  47: 160/307] 	 train loss: 0.189389 	 lr: 0.00064
[epoch  47: 180/307] 	 train loss: 0.696810 	 lr: 0.00064
[epoch  47: 200/307] 	 train loss: 0.221979 	 lr: 0.00064

val loss: 0.345731 	 acc: 0.899109

[epoch  47: 220/307] 	 train loss: 0.398926 	 lr: 0.00064
[epoch  47: 240/307] 	 train loss: 0.085326 	 lr: 0.00064
[epoch  47: 260/307] 	 train loss: 0.139775 	 lr: 0.00064
[epoch  47: 280/307] 	 train loss: 0.607393 	 lr: 0.00064
[epoch  47: 300/307] 	 train loss: 0.674577 	 lr: 0.00064
[epoch  48:   0/307] 	 train loss: 0.457636 	 lr: 0.00064
[epoch  48:  20/307] 	 train loss: 0.246073 	 lr: 0.00064
[epoch  48:  40/307] 	 train loss: 0.838068 	 lr: 0.00064

val loss: 0.331024 	 acc: 0.903566

[epoch  48:  60/307] 	 train loss: 0.467451 	 lr: 0.00064
[epoch  48:  80/307] 	 train loss: 0.244560 	 lr: 0.00064
[epoch  48: 100/307] 	 train loss: 0.225316 	 lr: 0.00064
[epoch  48: 120/307] 	 train loss: 0.170660 	 lr: 0.00064
[epoch  48: 140/307] 	 train loss: 0.121148 	 lr: 0.00064
[epoch  48: 160/307] 	 train loss: 0.310227 	 lr: 0.00064
[epoch  48: 180/307] 	 train loss: 0.461351 	 lr: 0.00064
[epoch  48: 200/307] 	 train loss: 0.338111 	 lr: 0.00064

val loss: 0.324724 	 acc: 0.903566

[epoch  48: 220/307] 	 train loss: 0.384496 	 lr: 0.00064
[epoch  48: 240/307] 	 train loss: 0.363838 	 lr: 0.00064
[epoch  48: 260/307] 	 train loss: 0.488081 	 lr: 0.00064
[epoch  48: 280/307] 	 train loss: 0.059602 	 lr: 0.00064
[epoch  48: 300/307] 	 train loss: 0.358053 	 lr: 0.00064
[epoch  49:   0/307] 	 train loss: 0.313153 	 lr: 0.00064
[epoch  49:  20/307] 	 train loss: 0.491083 	 lr: 0.00064
[epoch  49:  40/307] 	 train loss: 0.439227 	 lr: 0.00064

val loss: 0.309638 	 acc: 0.900729

[epoch  49:  60/307] 	 train loss: 0.285719 	 lr: 0.00064
[epoch  49:  80/307] 	 train loss: 0.213176 	 lr: 0.00064
[epoch  49: 100/307] 	 train loss: 0.190330 	 lr: 0.00064
[epoch  49: 120/307] 	 train loss: 0.197203 	 lr: 0.00064
[epoch  49: 140/307] 	 train loss: 0.496367 	 lr: 0.00064
[epoch  49: 160/307] 	 train loss: 0.122919 	 lr: 0.00064
[epoch  49: 180/307] 	 train loss: 0.228849 	 lr: 0.00064
[epoch  49: 200/307] 	 train loss: 0.273177 	 lr: 0.00064

val loss: 0.334600 	 acc: 0.895462

[epoch  49: 220/307] 	 train loss: 0.222945 	 lr: 0.00064
[epoch  49: 240/307] 	 train loss: 0.483574 	 lr: 0.00064
[epoch  49: 260/307] 	 train loss: 0.385940 	 lr: 0.00064
[epoch  49: 280/307] 	 train loss: 0.257123 	 lr: 0.00064
[epoch  49: 300/307] 	 train loss: 0.120752 	 lr: 0.00064
[epoch  50:   0/307] 	 train loss: 0.289388 	 lr: 0.00064
[epoch  50:  20/307] 	 train loss: 0.439403 	 lr: 0.00064
[epoch  50:  40/307] 	 train loss: 0.153649 	 lr: 0.00064

val loss: 0.346339 	 acc: 0.897083

[epoch  50:  60/307] 	 train loss: 0.263623 	 lr: 0.00064
[epoch  50:  80/307] 	 train loss: 0.135377 	 lr: 0.00064
[epoch  50: 100/307] 	 train loss: 0.176912 	 lr: 0.00064
[epoch  50: 120/307] 	 train loss: 0.545359 	 lr: 0.00064
[epoch  50: 140/307] 	 train loss: 0.243127 	 lr: 0.00064
[epoch  50: 160/307] 	 train loss: 0.195545 	 lr: 0.00064
[epoch  50: 180/307] 	 train loss: 0.226906 	 lr: 0.00064
[epoch  50: 200/307] 	 train loss: 0.609443 	 lr: 0.00064

val loss: 0.313672 	 acc: 0.898298

[epoch  50: 220/307] 	 train loss: 0.494236 	 lr: 0.00064
[epoch  50: 240/307] 	 train loss: 0.498873 	 lr: 0.00064
[epoch  50: 260/307] 	 train loss: 0.418564 	 lr: 0.00064
[epoch  50: 280/307] 	 train loss: 0.156948 	 lr: 0.00064
[epoch  50: 300/307] 	 train loss: 0.183006 	 lr: 0.00064
[epoch  51:   0/307] 	 train loss: 0.167060 	 lr: 0.00064
[epoch  51:  20/307] 	 train loss: 0.139007 	 lr: 0.00064
[epoch  51:  40/307] 	 train loss: 0.217488 	 lr: 0.00064

val loss: 0.348254 	 acc: 0.893031

[epoch  51:  60/307] 	 train loss: 0.162837 	 lr: 0.00064
[epoch  51:  80/307] 	 train loss: 0.293950 	 lr: 0.00064
[epoch  51: 100/307] 	 train loss: 0.419554 	 lr: 0.00064
[epoch  51: 120/307] 	 train loss: 0.498551 	 lr: 0.00064
[epoch  51: 140/307] 	 train loss: 0.548765 	 lr: 0.00064
[epoch  51: 160/307] 	 train loss: 0.200387 	 lr: 0.00064
[epoch  51: 180/307] 	 train loss: 0.293708 	 lr: 0.00064
[epoch  51: 200/307] 	 train loss: 0.418177 	 lr: 0.00064

val loss: 0.349447 	 acc: 0.890194

[epoch  51: 220/307] 	 train loss: 0.472087 	 lr: 0.00064
[epoch  51: 240/307] 	 train loss: 0.255658 	 lr: 0.00064
[epoch  51: 260/307] 	 train loss: 0.441221 	 lr: 0.00064
[epoch  51: 280/307] 	 train loss: 0.281704 	 lr: 0.00064
[epoch  51: 300/307] 	 train loss: 0.194112 	 lr: 0.00064
[epoch  52:   0/307] 	 train loss: 0.175546 	 lr: 0.00064
[epoch  52:  20/307] 	 train loss: 0.378821 	 lr: 0.00064
[epoch  52:  40/307] 	 train loss: 0.185009 	 lr: 0.00064

val loss: 0.327791 	 acc: 0.902755

[epoch  52:  60/307] 	 train loss: 0.496902 	 lr: 0.00064
[epoch  52:  80/307] 	 train loss: 0.253634 	 lr: 0.00064
[epoch  52: 100/307] 	 train loss: 0.160494 	 lr: 0.00064
[epoch  52: 120/307] 	 train loss: 0.131909 	 lr: 0.00064
[epoch  52: 140/307] 	 train loss: 0.283377 	 lr: 0.00064
[epoch  52: 160/307] 	 train loss: 0.184055 	 lr: 0.00064
[epoch  52: 180/307] 	 train loss: 0.229850 	 lr: 0.00064
[epoch  52: 200/307] 	 train loss: 0.153042 	 lr: 0.00064

val loss: 0.330449 	 acc: 0.903160

[epoch  52: 220/307] 	 train loss: 0.214260 	 lr: 0.00064
[epoch  52: 240/307] 	 train loss: 0.309298 	 lr: 0.00064
[epoch  52: 260/307] 	 train loss: 0.321711 	 lr: 0.00064
[epoch  52: 280/307] 	 train loss: 0.256082 	 lr: 0.00064
[epoch  52: 300/307] 	 train loss: 0.186054 	 lr: 0.00064
[epoch  53:   0/307] 	 train loss: 0.376988 	 lr: 0.00064
[epoch  53:  20/307] 	 train loss: 0.491915 	 lr: 0.00064
[epoch  53:  40/307] 	 train loss: 0.350179 	 lr: 0.00064

val loss: 0.332038 	 acc: 0.900324

[epoch  53:  60/307] 	 train loss: 0.230661 	 lr: 0.00064
[epoch  53:  80/307] 	 train loss: 0.130417 	 lr: 0.00064
[epoch  53: 100/307] 	 train loss: 0.249446 	 lr: 0.00064
[epoch  53: 120/307] 	 train loss: 0.463780 	 lr: 0.00064
[epoch  53: 140/307] 	 train loss: 0.136201 	 lr: 0.00064
[epoch  53: 160/307] 	 train loss: 0.397899 	 lr: 0.00064
[epoch  53: 180/307] 	 train loss: 0.147983 	 lr: 0.00064
[epoch  53: 200/307] 	 train loss: 0.186810 	 lr: 0.00064

val loss: 0.336739 	 acc: 0.894246

[epoch  53: 220/307] 	 train loss: 0.442678 	 lr: 0.00064
[epoch  53: 240/307] 	 train loss: 0.276879 	 lr: 0.00064
[epoch  53: 260/307] 	 train loss: 0.271955 	 lr: 0.00064
[epoch  53: 280/307] 	 train loss: 0.138372 	 lr: 0.00064
[epoch  53: 300/307] 	 train loss: 0.085270 	 lr: 0.00064
[epoch  54:   0/307] 	 train loss: 0.465147 	 lr: 0.00064
[epoch  54:  20/307] 	 train loss: 0.133847 	 lr: 0.00064
[epoch  54:  40/307] 	 train loss: 0.421843 	 lr: 0.00064

val loss: 0.330408 	 acc: 0.907212

[epoch  54:  60/307] 	 train loss: 0.339482 	 lr: 0.00064
[epoch  54:  80/307] 	 train loss: 0.069008 	 lr: 0.00064
[epoch  54: 100/307] 	 train loss: 0.166261 	 lr: 0.00064
[epoch  54: 120/307] 	 train loss: 0.396850 	 lr: 0.00064
[epoch  54: 140/307] 	 train loss: 0.190005 	 lr: 0.00064
[epoch  54: 160/307] 	 train loss: 0.508714 	 lr: 0.00064
[epoch  54: 180/307] 	 train loss: 0.249660 	 lr: 0.00064

val loss: 0.320704 	 acc: 0.897488

[epoch  54: 200/307] 	 train loss: 0.114701 	 lr: 0.00064
[epoch  54: 220/307] 	 train loss: 0.252392 	 lr: 0.00064
[epoch  54: 240/307] 	 train loss: 0.163885 	 lr: 0.00064
[epoch  54: 260/307] 	 train loss: 0.321450 	 lr: 0.00064
[epoch  54: 280/307] 	 train loss: 0.220947 	 lr: 0.00064
[epoch  54: 300/307] 	 train loss: 0.313704 	 lr: 0.00064
[epoch  55:   0/307] 	 train loss: 0.350912 	 lr: 0.00064
[epoch  55:  20/307] 	 train loss: 0.236276 	 lr: 0.00064
[epoch  55:  40/307] 	 train loss: 0.276997 	 lr: 0.00064

val loss: 0.312318 	 acc: 0.896677

[epoch  55:  60/307] 	 train loss: 0.337843 	 lr: 0.00064
[epoch  55:  80/307] 	 train loss: 0.344221 	 lr: 0.00064
[epoch  55: 100/307] 	 train loss: 0.285239 	 lr: 0.00064
[epoch  55: 120/307] 	 train loss: 0.230886 	 lr: 0.00064
[epoch  55: 140/307] 	 train loss: 0.216126 	 lr: 0.00064
[epoch  55: 160/307] 	 train loss: 0.186464 	 lr: 0.00064
[epoch  55: 180/307] 	 train loss: 0.180397 	 lr: 0.00064

val loss: 0.317755 	 acc: 0.903160

[epoch  55: 200/307] 	 train loss: 0.220569 	 lr: 0.00064
[epoch  55: 220/307] 	 train loss: 0.336376 	 lr: 0.00064
[epoch  55: 240/307] 	 train loss: 0.183887 	 lr: 0.00064
[epoch  55: 260/307] 	 train loss: 0.131990 	 lr: 0.00064
[epoch  55: 280/307] 	 train loss: 0.441657 	 lr: 0.00064
[epoch  55: 300/307] 	 train loss: 0.270292 	 lr: 0.00064
[epoch  56:   0/307] 	 train loss: 0.276391 	 lr: 0.00064
[epoch  56:  20/307] 	 train loss: 0.238917 	 lr: 0.00064
[epoch  56:  40/307] 	 train loss: 0.104641 	 lr: 0.00064

val loss: 0.338072 	 acc: 0.901540

[epoch  56:  60/307] 	 train loss: 0.137128 	 lr: 0.00064
[epoch  56:  80/307] 	 train loss: 0.365965 	 lr: 0.00064
[epoch  56: 100/307] 	 train loss: 0.236894 	 lr: 0.00064
[epoch  56: 120/307] 	 train loss: 0.563420 	 lr: 0.00064
[epoch  56: 140/307] 	 train loss: 0.476092 	 lr: 0.00064
[epoch  56: 160/307] 	 train loss: 0.065673 	 lr: 0.00064
[epoch  56: 180/307] 	 train loss: 0.521999 	 lr: 0.00064

val loss: 0.325197 	 acc: 0.900324

[epoch  56: 200/307] 	 train loss: 0.076074 	 lr: 0.00064
[epoch  56: 220/307] 	 train loss: 0.221834 	 lr: 0.00064
[epoch  56: 240/307] 	 train loss: 0.354296 	 lr: 0.00064
[epoch  56: 260/307] 	 train loss: 0.390729 	 lr: 0.00064
[epoch  56: 280/307] 	 train loss: 0.191062 	 lr: 0.00064
[epoch  56: 300/307] 	 train loss: 0.200433 	 lr: 0.00064
[epoch  57:   0/307] 	 train loss: 0.271749 	 lr: 0.00064
[epoch  57:  20/307] 	 train loss: 0.145425 	 lr: 0.00064
[epoch  57:  40/307] 	 train loss: 0.350858 	 lr: 0.00064

val loss: 0.335227 	 acc: 0.900324

[epoch  57:  60/307] 	 train loss: 0.267679 	 lr: 0.00064
[epoch  57:  80/307] 	 train loss: 0.535319 	 lr: 0.00064
[epoch  57: 100/307] 	 train loss: 0.248146 	 lr: 0.00064
[epoch  57: 120/307] 	 train loss: 0.311150 	 lr: 0.00064
[epoch  57: 140/307] 	 train loss: 0.388220 	 lr: 0.00064
[epoch  57: 160/307] 	 train loss: 0.115181 	 lr: 0.00064
[epoch  57: 180/307] 	 train loss: 0.198256 	 lr: 0.00064

val loss: 0.315112 	 acc: 0.902755

[epoch  57: 200/307] 	 train loss: 0.428407 	 lr: 0.00064
[epoch  57: 220/307] 	 train loss: 0.254076 	 lr: 0.00064
[epoch  57: 240/307] 	 train loss: 0.271789 	 lr: 0.00064
[epoch  57: 260/307] 	 train loss: 0.348798 	 lr: 0.00064
[epoch  57: 280/307] 	 train loss: 0.650255 	 lr: 0.00064
[epoch  57: 300/307] 	 train loss: 0.315804 	 lr: 0.00064
[epoch  58:   0/307] 	 train loss: 0.326775 	 lr: 0.00064
[epoch  58:  20/307] 	 train loss: 0.519713 	 lr: 0.00064

val loss: 0.329781 	 acc: 0.897893

[epoch  58:  40/307] 	 train loss: 0.129698 	 lr: 0.00064
[epoch  58:  60/307] 	 train loss: 0.374521 	 lr: 0.00064
[epoch  58:  80/307] 	 train loss: 0.441733 	 lr: 0.00064
[epoch  58: 100/307] 	 train loss: 0.232458 	 lr: 0.00064
[epoch  58: 120/307] 	 train loss: 0.136951 	 lr: 0.00064
[epoch  58: 140/307] 	 train loss: 0.375069 	 lr: 0.00064
[epoch  58: 160/307] 	 train loss: 0.527066 	 lr: 0.00064
[epoch  58: 180/307] 	 train loss: 0.079152 	 lr: 0.00064

val loss: 0.329221 	 acc: 0.898298

[epoch  58: 200/307] 	 train loss: 0.294609 	 lr: 0.00064
[epoch  58: 220/307] 	 train loss: 0.313274 	 lr: 0.00064
[epoch  58: 240/307] 	 train loss: 0.445378 	 lr: 0.00064
[epoch  58: 260/307] 	 train loss: 0.169967 	 lr: 0.00064
[epoch  58: 280/307] 	 train loss: 0.408100 	 lr: 0.00064
[epoch  58: 300/307] 	 train loss: 0.434232 	 lr: 0.00064
[epoch  59:   0/307] 	 train loss: 0.141913 	 lr: 0.00064
[epoch  59:  20/307] 	 train loss: 0.510912 	 lr: 0.00064

val loss: 0.326227 	 acc: 0.900324

[epoch  59:  40/307] 	 train loss: 0.185176 	 lr: 0.00064
[epoch  59:  60/307] 	 train loss: 0.284501 	 lr: 0.00064
[epoch  59:  80/307] 	 train loss: 0.420575 	 lr: 0.00064
[epoch  59: 100/307] 	 train loss: 0.572248 	 lr: 0.00064
[epoch  59: 120/307] 	 train loss: 0.452298 	 lr: 0.00064
[epoch  59: 140/307] 	 train loss: 0.179147 	 lr: 0.00064
[epoch  59: 160/307] 	 train loss: 0.347917 	 lr: 0.00064
[epoch  59: 180/307] 	 train loss: 0.347779 	 lr: 0.00064

val loss: 0.315982 	 acc: 0.900729

[epoch  59: 200/307] 	 train loss: 0.305886 	 lr: 0.00064
[epoch  59: 220/307] 	 train loss: 0.288421 	 lr: 0.00064
[epoch  59: 240/307] 	 train loss: 0.285696 	 lr: 0.00064
[epoch  59: 260/307] 	 train loss: 0.208360 	 lr: 0.00064
[epoch  59: 280/307] 	 train loss: 0.091625 	 lr: 0.00064
[epoch  59: 300/307] 	 train loss: 0.464188 	 lr: 0.00064
[epoch  60:   0/307] 	 train loss: 0.130347 	 lr: 0.00064
[epoch  60:  20/307] 	 train loss: 0.311825 	 lr: 0.00064

val loss: 0.336677 	 acc: 0.899109

[epoch  60:  40/307] 	 train loss: 0.305072 	 lr: 0.00064
[epoch  60:  60/307] 	 train loss: 0.154032 	 lr: 0.00064
[epoch  60:  80/307] 	 train loss: 0.237476 	 lr: 0.00064
[epoch  60: 100/307] 	 train loss: 0.183970 	 lr: 0.00064
[epoch  60: 120/307] 	 train loss: 0.467883 	 lr: 0.00064
[epoch  60: 140/307] 	 train loss: 0.477739 	 lr: 0.00064
[epoch  60: 160/307] 	 train loss: 0.185318 	 lr: 0.00064
[epoch  60: 180/307] 	 train loss: 0.395487 	 lr: 0.00064

val loss: 0.339740 	 acc: 0.896272

[epoch  60: 200/307] 	 train loss: 0.234018 	 lr: 0.00064
[epoch  60: 220/307] 	 train loss: 0.248720 	 lr: 0.00064
[epoch  60: 240/307] 	 train loss: 0.284203 	 lr: 0.00064
[epoch  60: 260/307] 	 train loss: 0.390032 	 lr: 0.00064
[epoch  60: 280/307] 	 train loss: 0.204131 	 lr: 0.00064
[epoch  60: 300/307] 	 train loss: 0.104496 	 lr: 0.00064
[epoch  61:   0/307] 	 train loss: 0.370403 	 lr: 0.00064
[epoch  61:  20/307] 	 train loss: 0.266770 	 lr: 0.00064

val loss: 0.334036 	 acc: 0.900729

[epoch  61:  40/307] 	 train loss: 0.417133 	 lr: 0.00064
[epoch  61:  60/307] 	 train loss: 0.171407 	 lr: 0.00064
[epoch  61:  80/307] 	 train loss: 0.154141 	 lr: 0.00064
[epoch  61: 100/307] 	 train loss: 0.150573 	 lr: 0.00064
[epoch  61: 120/307] 	 train loss: 0.639351 	 lr: 0.00064
[epoch  61: 140/307] 	 train loss: 0.603646 	 lr: 0.00064
[epoch  61: 160/307] 	 train loss: 0.469729 	 lr: 0.00064
[epoch  61: 180/307] 	 train loss: 0.269097 	 lr: 0.00064

val loss: 0.343944 	 acc: 0.900729

[epoch  61: 200/307] 	 train loss: 0.292076 	 lr: 0.00064
[epoch  61: 220/307] 	 train loss: 0.291310 	 lr: 0.00064
[epoch  61: 240/307] 	 train loss: 0.239293 	 lr: 0.00064
[epoch  61: 260/307] 	 train loss: 0.228227 	 lr: 0.00064
[epoch  61: 280/307] 	 train loss: 0.390560 	 lr: 0.00064
[epoch  61: 300/307] 	 train loss: 0.216859 	 lr: 0.00064
[epoch  62:   0/307] 	 train loss: 0.090846 	 lr: 0.00064
[epoch  62:  20/307] 	 train loss: 0.561848 	 lr: 0.00064

val loss: 0.355237 	 acc: 0.894246

[epoch  62:  40/307] 	 train loss: 0.300740 	 lr: 0.00064
[epoch  62:  60/307] 	 train loss: 0.545708 	 lr: 0.00064
[epoch  62:  80/307] 	 train loss: 0.197201 	 lr: 0.00064
[epoch  62: 100/307] 	 train loss: 0.325652 	 lr: 0.00064
[epoch  62: 120/307] 	 train loss: 0.350611 	 lr: 0.00064
[epoch  62: 140/307] 	 train loss: 0.259110 	 lr: 0.00064
[epoch  62: 160/307] 	 train loss: 0.123465 	 lr: 0.00064
[epoch  62: 180/307] 	 train loss: 0.174850 	 lr: 0.00064

val loss: 0.348913 	 acc: 0.899109

[epoch  62: 200/307] 	 train loss: 0.229487 	 lr: 0.00064
[epoch  62: 220/307] 	 train loss: 0.298398 	 lr: 0.00064
[epoch  62: 240/307] 	 train loss: 0.283525 	 lr: 0.00064
[epoch  62: 260/307] 	 train loss: 0.174977 	 lr: 0.00064
[epoch  62: 280/307] 	 train loss: 0.617591 	 lr: 0.00064
[epoch  62: 300/307] 	 train loss: 0.273306 	 lr: 0.00064
[epoch  63:   0/307] 	 train loss: 0.184461 	 lr: 0.00064
[epoch  63:  20/307] 	 train loss: 0.252599 	 lr: 0.00064

val loss: 0.335576 	 acc: 0.903160

[epoch  63:  40/307] 	 train loss: 0.079245 	 lr: 0.00064
[epoch  63:  60/307] 	 train loss: 0.340374 	 lr: 0.00064
[epoch  63:  80/307] 	 train loss: 0.232600 	 lr: 0.00064
[epoch  63: 100/307] 	 train loss: 0.336682 	 lr: 0.00064
[epoch  63: 120/307] 	 train loss: 0.237032 	 lr: 0.00064
[epoch  63: 140/307] 	 train loss: 0.319516 	 lr: 0.00064
[epoch  63: 160/307] 	 train loss: 0.281978 	 lr: 0.00064
[epoch  63: 180/307] 	 train loss: 0.700504 	 lr: 0.00064

val loss: 0.354960 	 acc: 0.885737

[epoch  63: 200/307] 	 train loss: 0.179446 	 lr: 0.00064
[epoch  63: 220/307] 	 train loss: 0.404090 	 lr: 0.00064
[epoch  63: 240/307] 	 train loss: 0.276385 	 lr: 0.00064
[epoch  63: 260/307] 	 train loss: 0.427215 	 lr: 0.00064
[epoch  63: 280/307] 	 train loss: 0.360627 	 lr: 0.00064
[epoch  63: 300/307] 	 train loss: 0.230782 	 lr: 0.00064
[epoch  64:   0/307] 	 train loss: 0.411206 	 lr: 0.00051
[epoch  64:  20/307] 	 train loss: 0.258759 	 lr: 0.00051

val loss: 0.305255 	 acc: 0.905186

[epoch  64:  40/307] 	 train loss: 0.292609 	 lr: 0.00051
[epoch  64:  60/307] 	 train loss: 0.247721 	 lr: 0.00051
[epoch  64:  80/307] 	 train loss: 0.320262 	 lr: 0.00051
[epoch  64: 100/307] 	 train loss: 0.630381 	 lr: 0.00051
[epoch  64: 120/307] 	 train loss: 0.242148 	 lr: 0.00051
[epoch  64: 140/307] 	 train loss: 0.386349 	 lr: 0.00051
[epoch  64: 160/307] 	 train loss: 0.174241 	 lr: 0.00051

val loss: 0.323995 	 acc: 0.902350

[epoch  64: 180/307] 	 train loss: 0.292123 	 lr: 0.00051
[epoch  64: 200/307] 	 train loss: 0.031066 	 lr: 0.00051
[epoch  64: 220/307] 	 train loss: 0.329089 	 lr: 0.00051
[epoch  64: 240/307] 	 train loss: 0.311154 	 lr: 0.00051
[epoch  64: 260/307] 	 train loss: 0.263852 	 lr: 0.00051
[epoch  64: 280/307] 	 train loss: 0.470091 	 lr: 0.00051
[epoch  64: 300/307] 	 train loss: 0.311864 	 lr: 0.00051
[epoch  65:   0/307] 	 train loss: 0.163448 	 lr: 0.00051
[epoch  65:  20/307] 	 train loss: 0.249440 	 lr: 0.00051

val loss: 0.328542 	 acc: 0.900324

[epoch  65:  40/307] 	 train loss: 0.152630 	 lr: 0.00051
[epoch  65:  60/307] 	 train loss: 0.534756 	 lr: 0.00051
[epoch  65:  80/307] 	 train loss: 0.232545 	 lr: 0.00051
[epoch  65: 100/307] 	 train loss: 0.308244 	 lr: 0.00051
[epoch  65: 120/307] 	 train loss: 0.284826 	 lr: 0.00051
[epoch  65: 140/307] 	 train loss: 0.185445 	 lr: 0.00051
[epoch  65: 160/307] 	 train loss: 0.221789 	 lr: 0.00051

val loss: 0.321830 	 acc: 0.901945

[epoch  65: 180/307] 	 train loss: 0.172568 	 lr: 0.00051
[epoch  65: 200/307] 	 train loss: 0.258167 	 lr: 0.00051
[epoch  65: 220/307] 	 train loss: 0.380307 	 lr: 0.00051
[epoch  65: 240/307] 	 train loss: 0.282916 	 lr: 0.00051
[epoch  65: 260/307] 	 train loss: 0.286249 	 lr: 0.00051
[epoch  65: 280/307] 	 train loss: 0.380949 	 lr: 0.00051
[epoch  65: 300/307] 	 train loss: 0.229129 	 lr: 0.00051
[epoch  66:   0/307] 	 train loss: 0.464211 	 lr: 0.00051
[epoch  66:  20/307] 	 train loss: 0.483694 	 lr: 0.00051

val loss: 0.317819 	 acc: 0.901540

[epoch  66:  40/307] 	 train loss: 0.174010 	 lr: 0.00051
[epoch  66:  60/307] 	 train loss: 0.137447 	 lr: 0.00051
[epoch  66:  80/307] 	 train loss: 0.193017 	 lr: 0.00051
[epoch  66: 100/307] 	 train loss: 0.056761 	 lr: 0.00051
[epoch  66: 120/307] 	 train loss: 0.175409 	 lr: 0.00051
[epoch  66: 140/307] 	 train loss: 0.105605 	 lr: 0.00051
[epoch  66: 160/307] 	 train loss: 0.246068 	 lr: 0.00051

val loss: 0.321168 	 acc: 0.904781

[epoch  66: 180/307] 	 train loss: 0.043901 	 lr: 0.00051
[epoch  66: 200/307] 	 train loss: 0.221173 	 lr: 0.00051
[epoch  66: 220/307] 	 train loss: 0.269294 	 lr: 0.00051
[epoch  66: 240/307] 	 train loss: 0.252245 	 lr: 0.00051
[epoch  66: 260/307] 	 train loss: 0.187546 	 lr: 0.00051
[epoch  66: 280/307] 	 train loss: 0.475022 	 lr: 0.00051
[epoch  66: 300/307] 	 train loss: 0.306355 	 lr: 0.00051
[epoch  67:   0/307] 	 train loss: 0.332141 	 lr: 0.00051
[epoch  67:  20/307] 	 train loss: 0.314677 	 lr: 0.00051

val loss: 0.317389 	 acc: 0.905997

[epoch  67:  40/307] 	 train loss: 0.097000 	 lr: 0.00051
[epoch  67:  60/307] 	 train loss: 0.096138 	 lr: 0.00051
[epoch  67:  80/307] 	 train loss: 0.389993 	 lr: 0.00051
[epoch  67: 100/307] 	 train loss: 0.163934 	 lr: 0.00051
[epoch  67: 120/307] 	 train loss: 0.222148 	 lr: 0.00051
[epoch  67: 140/307] 	 train loss: 0.309180 	 lr: 0.00051
[epoch  67: 160/307] 	 train loss: 0.292023 	 lr: 0.00051

val loss: 0.341897 	 acc: 0.903566

[epoch  67: 180/307] 	 train loss: 0.204405 	 lr: 0.00051
[epoch  67: 200/307] 	 train loss: 0.204674 	 lr: 0.00051
[epoch  67: 220/307] 	 train loss: 0.192725 	 lr: 0.00051
[epoch  67: 240/307] 	 train loss: 0.280343 	 lr: 0.00051
[epoch  67: 260/307] 	 train loss: 0.453397 	 lr: 0.00051
[epoch  67: 280/307] 	 train loss: 0.184450 	 lr: 0.00051
[epoch  67: 300/307] 	 train loss: 0.195069 	 lr: 0.00051
[epoch  68:   0/307] 	 train loss: 0.277612 	 lr: 0.00051

val loss: 0.329171 	 acc: 0.902350

[epoch  68:  20/307] 	 train loss: 0.529804 	 lr: 0.00051
[epoch  68:  40/307] 	 train loss: 0.453665 	 lr: 0.00051
[epoch  68:  60/307] 	 train loss: 0.210497 	 lr: 0.00051
[epoch  68:  80/307] 	 train loss: 0.162989 	 lr: 0.00051
[epoch  68: 100/307] 	 train loss: 0.175142 	 lr: 0.00051
[epoch  68: 120/307] 	 train loss: 0.235816 	 lr: 0.00051
[epoch  68: 140/307] 	 train loss: 0.251892 	 lr: 0.00051
[epoch  68: 160/307] 	 train loss: 0.224852 	 lr: 0.00051

val loss: 0.309697 	 acc: 0.907618

[epoch  68: 180/307] 	 train loss: 0.368493 	 lr: 0.00051
[epoch  68: 200/307] 	 train loss: 0.176954 	 lr: 0.00051
[epoch  68: 220/307] 	 train loss: 0.327100 	 lr: 0.00051
[epoch  68: 240/307] 	 train loss: 0.326971 	 lr: 0.00051
[epoch  68: 260/307] 	 train loss: 0.283603 	 lr: 0.00051
[epoch  68: 280/307] 	 train loss: 0.273612 	 lr: 0.00051
[epoch  68: 300/307] 	 train loss: 0.068475 	 lr: 0.00051
[epoch  69:   0/307] 	 train loss: 0.195107 	 lr: 0.00051

val loss: 0.317529 	 acc: 0.905186

[epoch  69:  20/307] 	 train loss: 0.199793 	 lr: 0.00051
[epoch  69:  40/307] 	 train loss: 0.320518 	 lr: 0.00051
[epoch  69:  60/307] 	 train loss: 0.267595 	 lr: 0.00051
[epoch  69:  80/307] 	 train loss: 0.195171 	 lr: 0.00051
[epoch  69: 100/307] 	 train loss: 0.257773 	 lr: 0.00051
[epoch  69: 120/307] 	 train loss: 0.252463 	 lr: 0.00051
[epoch  69: 140/307] 	 train loss: 0.281228 	 lr: 0.00051
[epoch  69: 160/307] 	 train loss: 0.222128 	 lr: 0.00051

val loss: 0.328457 	 acc: 0.903971

[epoch  69: 180/307] 	 train loss: 0.274996 	 lr: 0.00051
[epoch  69: 200/307] 	 train loss: 0.425446 	 lr: 0.00051
[epoch  69: 220/307] 	 train loss: 0.226140 	 lr: 0.00051
[epoch  69: 240/307] 	 train loss: 0.478573 	 lr: 0.00051
[epoch  69: 260/307] 	 train loss: 0.206019 	 lr: 0.00051
[epoch  69: 280/307] 	 train loss: 0.274315 	 lr: 0.00051
[epoch  69: 300/307] 	 train loss: 0.352493 	 lr: 0.00051
[epoch  70:   0/307] 	 train loss: 0.442321 	 lr: 0.00051

val loss: 0.334782 	 acc: 0.902350

[epoch  70:  20/307] 	 train loss: 0.217227 	 lr: 0.00051
[epoch  70:  40/307] 	 train loss: 0.110967 	 lr: 0.00051
[epoch  70:  60/307] 	 train loss: 0.194010 	 lr: 0.00051
[epoch  70:  80/307] 	 train loss: 0.510798 	 lr: 0.00051
[epoch  70: 100/307] 	 train loss: 0.142525 	 lr: 0.00051
[epoch  70: 120/307] 	 train loss: 0.384011 	 lr: 0.00051
[epoch  70: 140/307] 	 train loss: 0.615205 	 lr: 0.00051
[epoch  70: 160/307] 	 train loss: 0.182795 	 lr: 0.00051

val loss: 0.321579 	 acc: 0.902755

[epoch  70: 180/307] 	 train loss: 0.384588 	 lr: 0.00051
[epoch  70: 200/307] 	 train loss: 0.267757 	 lr: 0.00051
[epoch  70: 220/307] 	 train loss: 0.215335 	 lr: 0.00051
[epoch  70: 240/307] 	 train loss: 0.576126 	 lr: 0.00051
[epoch  70: 260/307] 	 train loss: 0.299911 	 lr: 0.00051
[epoch  70: 280/307] 	 train loss: 0.047517 	 lr: 0.00051
[epoch  70: 300/307] 	 train loss: 0.243281 	 lr: 0.00051
[epoch  71:   0/307] 	 train loss: 0.238107 	 lr: 0.00051

val loss: 0.316623 	 acc: 0.903971

[epoch  71:  20/307] 	 train loss: 0.318650 	 lr: 0.00051
[epoch  71:  40/307] 	 train loss: 0.487426 	 lr: 0.00051
[epoch  71:  60/307] 	 train loss: 0.333611 	 lr: 0.00051
[epoch  71:  80/307] 	 train loss: 0.129153 	 lr: 0.00051
[epoch  71: 100/307] 	 train loss: 0.134726 	 lr: 0.00051
[epoch  71: 120/307] 	 train loss: 0.130483 	 lr: 0.00051
[epoch  71: 140/307] 	 train loss: 0.295661 	 lr: 0.00051
[epoch  71: 160/307] 	 train loss: 0.104247 	 lr: 0.00051

val loss: 0.318362 	 acc: 0.911669

saved model with accuracy  0.9116693679092382
[epoch  71: 180/307] 	 train loss: 0.176141 	 lr: 0.00051
[epoch  71: 200/307] 	 train loss: 0.349803 	 lr: 0.00051
[epoch  71: 220/307] 	 train loss: 0.188204 	 lr: 0.00051
[epoch  71: 240/307] 	 train loss: 0.360793 	 lr: 0.00051
[epoch  71: 260/307] 	 train loss: 0.161235 	 lr: 0.00051
[epoch  71: 280/307] 	 train loss: 0.228909 	 lr: 0.00051
[epoch  71: 300/307] 	 train loss: 0.319456 	 lr: 0.00051
[epoch  72:   0/307] 	 train loss: 0.316001 	 lr: 0.00051

val loss: 0.329313 	 acc: 0.901945

[epoch  72:  20/307] 	 train loss: 0.225870 	 lr: 0.00051
[epoch  72:  40/307] 	 train loss: 0.153112 	 lr: 0.00051
[epoch  72:  60/307] 	 train loss: 0.308720 	 lr: 0.00051
[epoch  72:  80/307] 	 train loss: 0.235893 	 lr: 0.00051
[epoch  72: 100/307] 	 train loss: 0.753544 	 lr: 0.00051
[epoch  72: 120/307] 	 train loss: 0.591635 	 lr: 0.00051
[epoch  72: 140/307] 	 train loss: 0.550085 	 lr: 0.00051
[epoch  72: 160/307] 	 train loss: 0.141074 	 lr: 0.00051

val loss: 0.336762 	 acc: 0.901945

[epoch  72: 180/307] 	 train loss: 0.248183 	 lr: 0.00051
[epoch  72: 200/307] 	 train loss: 0.131483 	 lr: 0.00051
[epoch  72: 220/307] 	 train loss: 0.160615 	 lr: 0.00051
[epoch  72: 240/307] 	 train loss: 0.108068 	 lr: 0.00051
[epoch  72: 260/307] 	 train loss: 0.184031 	 lr: 0.00051
[epoch  72: 280/307] 	 train loss: 0.142369 	 lr: 0.00051
[epoch  72: 300/307] 	 train loss: 0.255906 	 lr: 0.00051
[epoch  73:   0/307] 	 train loss: 0.315983 	 lr: 0.00051

val loss: 0.307007 	 acc: 0.902350

[epoch  73:  20/307] 	 train loss: 0.198707 	 lr: 0.00051
[epoch  73:  40/307] 	 train loss: 0.255648 	 lr: 0.00051
[epoch  73:  60/307] 	 train loss: 0.410046 	 lr: 0.00051
[epoch  73:  80/307] 	 train loss: 0.271268 	 lr: 0.00051
[epoch  73: 100/307] 	 train loss: 0.169051 	 lr: 0.00051
[epoch  73: 120/307] 	 train loss: 0.144637 	 lr: 0.00051
[epoch  73: 140/307] 	 train loss: 0.334365 	 lr: 0.00051
[epoch  73: 160/307] 	 train loss: 0.326972 	 lr: 0.00051

val loss: 0.326092 	 acc: 0.909238

[epoch  73: 180/307] 	 train loss: 0.115090 	 lr: 0.00051
[epoch  73: 200/307] 	 train loss: 0.234125 	 lr: 0.00051
[epoch  73: 220/307] 	 train loss: 0.118504 	 lr: 0.00051
[epoch  73: 240/307] 	 train loss: 0.185423 	 lr: 0.00051
[epoch  73: 260/307] 	 train loss: 0.324726 	 lr: 0.00051
[epoch  73: 280/307] 	 train loss: 0.327855 	 lr: 0.00051
[epoch  73: 300/307] 	 train loss: 0.493693 	 lr: 0.00051
[epoch  74:   0/307] 	 train loss: 0.368908 	 lr: 0.00051

val loss: 0.308449 	 acc: 0.902755

[epoch  74:  20/307] 	 train loss: 0.215753 	 lr: 0.00051
[epoch  74:  40/307] 	 train loss: 0.047792 	 lr: 0.00051
[epoch  74:  60/307] 	 train loss: 0.238845 	 lr: 0.00051
[epoch  74:  80/307] 	 train loss: 0.263721 	 lr: 0.00051
[epoch  74: 100/307] 	 train loss: 0.246360 	 lr: 0.00051
[epoch  74: 120/307] 	 train loss: 0.293216 	 lr: 0.00051
[epoch  74: 140/307] 	 train loss: 0.258163 	 lr: 0.00051

val loss: 0.346047 	 acc: 0.897083

[epoch  74: 160/307] 	 train loss: 0.358732 	 lr: 0.00051
[epoch  74: 180/307] 	 train loss: 0.177527 	 lr: 0.00051
[epoch  74: 200/307] 	 train loss: 0.286737 	 lr: 0.00051
[epoch  74: 220/307] 	 train loss: 0.051521 	 lr: 0.00051
[epoch  74: 240/307] 	 train loss: 0.181314 	 lr: 0.00051
[epoch  74: 260/307] 	 train loss: 0.290525 	 lr: 0.00051
[epoch  74: 280/307] 	 train loss: 0.354090 	 lr: 0.00051
[epoch  74: 300/307] 	 train loss: 0.134497 	 lr: 0.00051
[epoch  75:   0/307] 	 train loss: 0.105051 	 lr: 0.00051

val loss: 0.332592 	 acc: 0.901945

[epoch  75:  20/307] 	 train loss: 0.277655 	 lr: 0.00051
[epoch  75:  40/307] 	 train loss: 0.524641 	 lr: 0.00051
[epoch  75:  60/307] 	 train loss: 0.316649 	 lr: 0.00051
[epoch  75:  80/307] 	 train loss: 0.138041 	 lr: 0.00051
[epoch  75: 100/307] 	 train loss: 0.181206 	 lr: 0.00051
[epoch  75: 120/307] 	 train loss: 0.336973 	 lr: 0.00051
[epoch  75: 140/307] 	 train loss: 0.222892 	 lr: 0.00051

val loss: 0.343565 	 acc: 0.901135

[epoch  75: 160/307] 	 train loss: 0.145542 	 lr: 0.00051
[epoch  75: 180/307] 	 train loss: 0.414707 	 lr: 0.00051
[epoch  75: 200/307] 	 train loss: 0.059701 	 lr: 0.00051
[epoch  75: 220/307] 	 train loss: 0.406523 	 lr: 0.00051
[epoch  75: 240/307] 	 train loss: 0.286729 	 lr: 0.00051
[epoch  75: 260/307] 	 train loss: 0.325931 	 lr: 0.00051
[epoch  75: 280/307] 	 train loss: 0.145531 	 lr: 0.00051
[epoch  75: 300/307] 	 train loss: 0.348584 	 lr: 0.00051
[epoch  76:   0/307] 	 train loss: 0.206799 	 lr: 0.00051

val loss: 0.331773 	 acc: 0.909238

[epoch  76:  20/307] 	 train loss: 0.376205 	 lr: 0.00051
[epoch  76:  40/307] 	 train loss: 0.099696 	 lr: 0.00051
[epoch  76:  60/307] 	 train loss: 0.102224 	 lr: 0.00051
[epoch  76:  80/307] 	 train loss: 0.482167 	 lr: 0.00051
[epoch  76: 100/307] 	 train loss: 0.161313 	 lr: 0.00051
[epoch  76: 120/307] 	 train loss: 0.235650 	 lr: 0.00051
[epoch  76: 140/307] 	 train loss: 0.295186 	 lr: 0.00051

val loss: 0.331238 	 acc: 0.899109

[epoch  76: 160/307] 	 train loss: 0.277000 	 lr: 0.00051
[epoch  76: 180/307] 	 train loss: 0.202628 	 lr: 0.00051
[epoch  76: 200/307] 	 train loss: 0.519785 	 lr: 0.00051
[epoch  76: 220/307] 	 train loss: 0.288758 	 lr: 0.00051
[epoch  76: 240/307] 	 train loss: 0.112965 	 lr: 0.00051
[epoch  76: 260/307] 	 train loss: 0.369832 	 lr: 0.00051
[epoch  76: 280/307] 	 train loss: 0.408951 	 lr: 0.00051
[epoch  76: 300/307] 	 train loss: 0.128684 	 lr: 0.00051
[epoch  77:   0/307] 	 train loss: 0.186495 	 lr: 0.00051

val loss: 0.350457 	 acc: 0.901135

[epoch  77:  20/307] 	 train loss: 0.129440 	 lr: 0.00051
[epoch  77:  40/307] 	 train loss: 0.437394 	 lr: 0.00051
[epoch  77:  60/307] 	 train loss: 0.307033 	 lr: 0.00051
[epoch  77:  80/307] 	 train loss: 0.347251 	 lr: 0.00051
[epoch  77: 100/307] 	 train loss: 0.223854 	 lr: 0.00051
[epoch  77: 120/307] 	 train loss: 0.406934 	 lr: 0.00051
[epoch  77: 140/307] 	 train loss: 0.166870 	 lr: 0.00051

val loss: 0.320924 	 acc: 0.909238

[epoch  77: 160/307] 	 train loss: 0.062212 	 lr: 0.00051
[epoch  77: 180/307] 	 train loss: 0.197878 	 lr: 0.00051
[epoch  77: 200/307] 	 train loss: 0.166965 	 lr: 0.00051
[epoch  77: 220/307] 	 train loss: 0.292477 	 lr: 0.00051
[epoch  77: 240/307] 	 train loss: 0.168939 	 lr: 0.00051
[epoch  77: 260/307] 	 train loss: 0.773058 	 lr: 0.00051
[epoch  77: 280/307] 	 train loss: 0.369321 	 lr: 0.00051
[epoch  77: 300/307] 	 train loss: 0.113180 	 lr: 0.00051

val loss: 0.331716 	 acc: 0.902350

[epoch  78:   0/307] 	 train loss: 0.709648 	 lr: 0.00051
[epoch  78:  20/307] 	 train loss: 0.368302 	 lr: 0.00051
[epoch  78:  40/307] 	 train loss: 0.458769 	 lr: 0.00051
[epoch  78:  60/307] 	 train loss: 0.457941 	 lr: 0.00051
[epoch  78:  80/307] 	 train loss: 0.144789 	 lr: 0.00051
[epoch  78: 100/307] 	 train loss: 0.095352 	 lr: 0.00051
[epoch  78: 120/307] 	 train loss: 0.088590 	 lr: 0.00051
[epoch  78: 140/307] 	 train loss: 0.087231 	 lr: 0.00051

val loss: 0.317082 	 acc: 0.908833

[epoch  78: 160/307] 	 train loss: 0.320194 	 lr: 0.00051
[epoch  78: 180/307] 	 train loss: 0.192207 	 lr: 0.00051
[epoch  78: 200/307] 	 train loss: 0.081633 	 lr: 0.00051
[epoch  78: 220/307] 	 train loss: 0.215098 	 lr: 0.00051
[epoch  78: 240/307] 	 train loss: 0.201370 	 lr: 0.00051
[epoch  78: 260/307] 	 train loss: 0.215573 	 lr: 0.00051
[epoch  78: 280/307] 	 train loss: 0.111821 	 lr: 0.00051
[epoch  78: 300/307] 	 train loss: 0.069139 	 lr: 0.00051

val loss: 0.330648 	 acc: 0.896272

[epoch  79:   0/307] 	 train loss: 0.431743 	 lr: 0.00051
[epoch  79:  20/307] 	 train loss: 0.053823 	 lr: 0.00051
[epoch  79:  40/307] 	 train loss: 0.190167 	 lr: 0.00051
[epoch  79:  60/307] 	 train loss: 0.139994 	 lr: 0.00051
[epoch  79:  80/307] 	 train loss: 0.235381 	 lr: 0.00051
[epoch  79: 100/307] 	 train loss: 0.143896 	 lr: 0.00051
[epoch  79: 120/307] 	 train loss: 0.436995 	 lr: 0.00051
[epoch  79: 140/307] 	 train loss: 0.126659 	 lr: 0.00051

val loss: 0.318456 	 acc: 0.898298

[epoch  79: 160/307] 	 train loss: 0.151356 	 lr: 0.00051
[epoch  79: 180/307] 	 train loss: 0.347982 	 lr: 0.00051
[epoch  79: 200/307] 	 train loss: 0.433707 	 lr: 0.00051
[epoch  79: 220/307] 	 train loss: 0.101150 	 lr: 0.00051
[epoch  79: 240/307] 	 train loss: 0.242394 	 lr: 0.00051
[epoch  79: 260/307] 	 train loss: 0.345307 	 lr: 0.00051
[epoch  79: 280/307] 	 train loss: 0.024381 	 lr: 0.00051
[epoch  79: 300/307] 	 train loss: 0.123189 	 lr: 0.00051

val loss: 0.312971 	 acc: 0.903160

[epoch  80:   0/307] 	 train loss: 0.207363 	 lr: 0.00051
[epoch  80:  20/307] 	 train loss: 0.154130 	 lr: 0.00051
[epoch  80:  40/307] 	 train loss: 0.253815 	 lr: 0.00051
[epoch  80:  60/307] 	 train loss: 0.571914 	 lr: 0.00051
[epoch  80:  80/307] 	 train loss: 0.144937 	 lr: 0.00051
[epoch  80: 100/307] 	 train loss: 0.135235 	 lr: 0.00051
[epoch  80: 120/307] 	 train loss: 0.265768 	 lr: 0.00051
[epoch  80: 140/307] 	 train loss: 0.221430 	 lr: 0.00051

val loss: 0.321313 	 acc: 0.903160

[epoch  80: 160/307] 	 train loss: 0.552725 	 lr: 0.00051
[epoch  80: 180/307] 	 train loss: 0.359066 	 lr: 0.00051
[epoch  80: 200/307] 	 train loss: 0.689064 	 lr: 0.00051
[epoch  80: 220/307] 	 train loss: 0.295277 	 lr: 0.00051
[epoch  80: 240/307] 	 train loss: 0.132279 	 lr: 0.00051
[epoch  80: 260/307] 	 train loss: 0.147628 	 lr: 0.00051
[epoch  80: 280/307] 	 train loss: 0.157598 	 lr: 0.00051
[epoch  80: 300/307] 	 train loss: 0.336192 	 lr: 0.00051

val loss: 0.350760 	 acc: 0.888169

[epoch  81:   0/307] 	 train loss: 0.100033 	 lr: 0.00051
[epoch  81:  20/307] 	 train loss: 0.177668 	 lr: 0.00051
[epoch  81:  40/307] 	 train loss: 0.280911 	 lr: 0.00051
[epoch  81:  60/307] 	 train loss: 0.280784 	 lr: 0.00051
[epoch  81:  80/307] 	 train loss: 0.151018 	 lr: 0.00051
[epoch  81: 100/307] 	 train loss: 0.307107 	 lr: 0.00051
[epoch  81: 120/307] 	 train loss: 0.127467 	 lr: 0.00051
[epoch  81: 140/307] 	 train loss: 0.173792 	 lr: 0.00051

val loss: 0.330348 	 acc: 0.894246

[epoch  81: 160/307] 	 train loss: 0.285848 	 lr: 0.00051
[epoch  81: 180/307] 	 train loss: 0.204453 	 lr: 0.00051
[epoch  81: 200/307] 	 train loss: 0.170425 	 lr: 0.00051
[epoch  81: 220/307] 	 train loss: 0.682723 	 lr: 0.00051
[epoch  81: 240/307] 	 train loss: 0.171329 	 lr: 0.00051
[epoch  81: 260/307] 	 train loss: 0.087229 	 lr: 0.00051
[epoch  81: 280/307] 	 train loss: 0.204523 	 lr: 0.00051

val loss: 0.306998 	 acc: 0.910859

[epoch  81: 300/307] 	 train loss: 0.176349 	 lr: 0.00051
[epoch  82:   0/307] 	 train loss: 0.167708 	 lr: 0.00051
[epoch  82:  20/307] 	 train loss: 0.412069 	 lr: 0.00051
[epoch  82:  40/307] 	 train loss: 0.338426 	 lr: 0.00051
[epoch  82:  60/307] 	 train loss: 0.437032 	 lr: 0.00051
[epoch  82:  80/307] 	 train loss: 0.292475 	 lr: 0.00051
[epoch  82: 100/307] 	 train loss: 0.273246 	 lr: 0.00051
[epoch  82: 120/307] 	 train loss: 0.190307 	 lr: 0.00051
[epoch  82: 140/307] 	 train loss: 0.126408 	 lr: 0.00051

val loss: 0.334383 	 acc: 0.898703

[epoch  82: 160/307] 	 train loss: 0.246467 	 lr: 0.00051
[epoch  82: 180/307] 	 train loss: 0.363724 	 lr: 0.00051
[epoch  82: 200/307] 	 train loss: 0.464648 	 lr: 0.00051
[epoch  82: 220/307] 	 train loss: 0.212930 	 lr: 0.00051
[epoch  82: 240/307] 	 train loss: 0.139360 	 lr: 0.00051
[epoch  82: 260/307] 	 train loss: 0.247436 	 lr: 0.00051
[epoch  82: 280/307] 	 train loss: 0.305868 	 lr: 0.00051

val loss: 0.311221 	 acc: 0.903160

[epoch  82: 300/307] 	 train loss: 0.147427 	 lr: 0.00051
[epoch  83:   0/307] 	 train loss: 0.265068 	 lr: 0.00051
[epoch  83:  20/307] 	 train loss: 0.151866 	 lr: 0.00051
[epoch  83:  40/307] 	 train loss: 0.425938 	 lr: 0.00051
[epoch  83:  60/307] 	 train loss: 0.039731 	 lr: 0.00051
[epoch  83:  80/307] 	 train loss: 0.154857 	 lr: 0.00051
[epoch  83: 100/307] 	 train loss: 0.260639 	 lr: 0.00051
[epoch  83: 120/307] 	 train loss: 0.370981 	 lr: 0.00051
[epoch  83: 140/307] 	 train loss: 0.359188 	 lr: 0.00051

val loss: 0.340020 	 acc: 0.898703

[epoch  83: 160/307] 	 train loss: 0.409601 	 lr: 0.00051
[epoch  83: 180/307] 	 train loss: 0.260157 	 lr: 0.00051
[epoch  83: 200/307] 	 train loss: 0.292224 	 lr: 0.00051
[epoch  83: 220/307] 	 train loss: 0.196412 	 lr: 0.00051
[epoch  83: 240/307] 	 train loss: 0.261252 	 lr: 0.00051
[epoch  83: 260/307] 	 train loss: 0.063411 	 lr: 0.00051
[epoch  83: 280/307] 	 train loss: 0.320047 	 lr: 0.00051

val loss: 0.313781 	 acc: 0.903566

[epoch  83: 300/307] 	 train loss: 1.091980 	 lr: 0.00051
[epoch  84:   0/307] 	 train loss: 0.167820 	 lr: 0.00051
[epoch  84:  20/307] 	 train loss: 0.070519 	 lr: 0.00051
[epoch  84:  40/307] 	 train loss: 0.196080 	 lr: 0.00051
[epoch  84:  60/307] 	 train loss: 0.273381 	 lr: 0.00051
[epoch  84:  80/307] 	 train loss: 0.182350 	 lr: 0.00051
[epoch  84: 100/307] 	 train loss: 0.272297 	 lr: 0.00051
[epoch  84: 120/307] 	 train loss: 0.216902 	 lr: 0.00051

val loss: 0.311256 	 acc: 0.907618

[epoch  84: 140/307] 	 train loss: 0.197879 	 lr: 0.00051
[epoch  84: 160/307] 	 train loss: 0.226948 	 lr: 0.00051
[epoch  84: 180/307] 	 train loss: 0.333111 	 lr: 0.00051
[epoch  84: 200/307] 	 train loss: 0.091587 	 lr: 0.00051
[epoch  84: 220/307] 	 train loss: 0.330139 	 lr: 0.00051
[epoch  84: 240/307] 	 train loss: 0.200818 	 lr: 0.00051
[epoch  84: 260/307] 	 train loss: 0.170419 	 lr: 0.00051
[epoch  84: 280/307] 	 train loss: 0.151706 	 lr: 0.00051

val loss: 0.326174 	 acc: 0.905186

[epoch  84: 300/307] 	 train loss: 0.228329 	 lr: 0.00051
[epoch  85:   0/307] 	 train loss: 0.354879 	 lr: 0.00041
[epoch  85:  20/307] 	 train loss: 0.302934 	 lr: 0.00041
[epoch  85:  40/307] 	 train loss: 0.211298 	 lr: 0.00041
[epoch  85:  60/307] 	 train loss: 0.065209 	 lr: 0.00041
[epoch  85:  80/307] 	 train loss: 0.394828 	 lr: 0.00041
[epoch  85: 100/307] 	 train loss: 0.203922 	 lr: 0.00041
[epoch  85: 120/307] 	 train loss: 0.173052 	 lr: 0.00041

val loss: 0.317020 	 acc: 0.910049

[epoch  85: 140/307] 	 train loss: 0.156186 	 lr: 0.00041
[epoch  85: 160/307] 	 train loss: 0.255457 	 lr: 0.00041
[epoch  85: 180/307] 	 train loss: 0.158849 	 lr: 0.00041
[epoch  85: 200/307] 	 train loss: 0.030893 	 lr: 0.00041
[epoch  85: 220/307] 	 train loss: 0.248124 	 lr: 0.00041
[epoch  85: 240/307] 	 train loss: 0.311300 	 lr: 0.00041
[epoch  85: 260/307] 	 train loss: 0.130692 	 lr: 0.00041
[epoch  85: 280/307] 	 train loss: 0.229868 	 lr: 0.00041

val loss: 0.326143 	 acc: 0.902350

[epoch  85: 300/307] 	 train loss: 0.294796 	 lr: 0.00041
[epoch  86:   0/307] 	 train loss: 0.116555 	 lr: 0.00041
[epoch  86:  20/307] 	 train loss: 0.137014 	 lr: 0.00041
[epoch  86:  40/307] 	 train loss: 0.255476 	 lr: 0.00041
[epoch  86:  60/307] 	 train loss: 0.112403 	 lr: 0.00041
[epoch  86:  80/307] 	 train loss: 0.176617 	 lr: 0.00041
[epoch  86: 100/307] 	 train loss: 0.428872 	 lr: 0.00041
[epoch  86: 120/307] 	 train loss: 0.389872 	 lr: 0.00041

val loss: 0.330533 	 acc: 0.902350

[epoch  86: 140/307] 	 train loss: 0.146886 	 lr: 0.00041
[epoch  86: 160/307] 	 train loss: 0.328859 	 lr: 0.00041
[epoch  86: 180/307] 	 train loss: 0.241645 	 lr: 0.00041
[epoch  86: 200/307] 	 train loss: 0.143741 	 lr: 0.00041
[epoch  86: 220/307] 	 train loss: 0.444511 	 lr: 0.00041
[epoch  86: 240/307] 	 train loss: 0.260417 	 lr: 0.00041
[epoch  86: 260/307] 	 train loss: 0.374264 	 lr: 0.00041
[epoch  86: 280/307] 	 train loss: 0.051544 	 lr: 0.00041

val loss: 0.319148 	 acc: 0.897083

[epoch  86: 300/307] 	 train loss: 0.084949 	 lr: 0.00041
[epoch  87:   0/307] 	 train loss: 0.406975 	 lr: 0.00041
[epoch  87:  20/307] 	 train loss: 0.401179 	 lr: 0.00041
[epoch  87:  40/307] 	 train loss: 0.267686 	 lr: 0.00041
[epoch  87:  60/307] 	 train loss: 0.029375 	 lr: 0.00041
[epoch  87:  80/307] 	 train loss: 0.141875 	 lr: 0.00041
[epoch  87: 100/307] 	 train loss: 0.151154 	 lr: 0.00041
[epoch  87: 120/307] 	 train loss: 0.147477 	 lr: 0.00041

val loss: 0.334856 	 acc: 0.902350

[epoch  87: 140/307] 	 train loss: 0.175893 	 lr: 0.00041
[epoch  87: 160/307] 	 train loss: 0.179965 	 lr: 0.00041
[epoch  87: 180/307] 	 train loss: 0.077673 	 lr: 0.00041
[epoch  87: 200/307] 	 train loss: 0.351420 	 lr: 0.00041
[epoch  87: 220/307] 	 train loss: 0.166628 	 lr: 0.00041
[epoch  87: 240/307] 	 train loss: 0.181114 	 lr: 0.00041
[epoch  87: 260/307] 	 train loss: 0.346823 	 lr: 0.00041
[epoch  87: 280/307] 	 train loss: 0.110318 	 lr: 0.00041

val loss: 0.304579 	 acc: 0.905592

[epoch  87: 300/307] 	 train loss: 0.226927 	 lr: 0.00041
[epoch  88:   0/307] 	 train loss: 0.150072 	 lr: 0.00041
[epoch  88:  20/307] 	 train loss: 0.097274 	 lr: 0.00041
[epoch  88:  40/307] 	 train loss: 0.328595 	 lr: 0.00041
[epoch  88:  60/307] 	 train loss: 0.134434 	 lr: 0.00041
[epoch  88:  80/307] 	 train loss: 0.240119 	 lr: 0.00041
[epoch  88: 100/307] 	 train loss: 0.182114 	 lr: 0.00041
[epoch  88: 120/307] 	 train loss: 0.158023 	 lr: 0.00041

val loss: 0.333963 	 acc: 0.898298

[epoch  88: 140/307] 	 train loss: 0.483508 	 lr: 0.00041
[epoch  88: 160/307] 	 train loss: 0.162268 	 lr: 0.00041
[epoch  88: 180/307] 	 train loss: 0.107479 	 lr: 0.00041
[epoch  88: 200/307] 	 train loss: 0.210371 	 lr: 0.00041
[epoch  88: 220/307] 	 train loss: 0.193693 	 lr: 0.00041
[epoch  88: 240/307] 	 train loss: 0.115389 	 lr: 0.00041
[epoch  88: 260/307] 	 train loss: 0.185985 	 lr: 0.00041
[epoch  88: 280/307] 	 train loss: 0.316349 	 lr: 0.00041

val loss: 0.310494 	 acc: 0.907212

[epoch  88: 300/307] 	 train loss: 0.221534 	 lr: 0.00041
[epoch  89:   0/307] 	 train loss: 0.136143 	 lr: 0.00041
[epoch  89:  20/307] 	 train loss: 0.107428 	 lr: 0.00041
[epoch  89:  40/307] 	 train loss: 0.141349 	 lr: 0.00041
[epoch  89:  60/307] 	 train loss: 0.233224 	 lr: 0.00041
[epoch  89:  80/307] 	 train loss: 0.176586 	 lr: 0.00041
[epoch  89: 100/307] 	 train loss: 0.228096 	 lr: 0.00041
[epoch  89: 120/307] 	 train loss: 0.055125 	 lr: 0.00041

val loss: 0.323446 	 acc: 0.905186

[epoch  89: 140/307] 	 train loss: 0.096005 	 lr: 0.00041
[epoch  89: 160/307] 	 train loss: 0.114985 	 lr: 0.00041
[epoch  89: 180/307] 	 train loss: 0.022636 	 lr: 0.00041
[epoch  89: 200/307] 	 train loss: 0.218074 	 lr: 0.00041
[epoch  89: 220/307] 	 train loss: 0.447855 	 lr: 0.00041
[epoch  89: 240/307] 	 train loss: 0.414798 	 lr: 0.00041
[epoch  89: 260/307] 	 train loss: 0.324087 	 lr: 0.00041
[epoch  89: 280/307] 	 train loss: 0.223250 	 lr: 0.00041

val loss: 0.325344 	 acc: 0.900324

[epoch  89: 300/307] 	 train loss: 0.264277 	 lr: 0.00041
[epoch  90:   0/307] 	 train loss: 0.142454 	 lr: 0.00041
[epoch  90:  20/307] 	 train loss: 0.194896 	 lr: 0.00041
[epoch  90:  40/307] 	 train loss: 0.416993 	 lr: 0.00041
[epoch  90:  60/307] 	 train loss: 0.243613 	 lr: 0.00041
[epoch  90:  80/307] 	 train loss: 0.313600 	 lr: 0.00041
[epoch  90: 100/307] 	 train loss: 0.061869 	 lr: 0.00041
[epoch  90: 120/307] 	 train loss: 0.273168 	 lr: 0.00041

val loss: 0.329260 	 acc: 0.903160

[epoch  90: 140/307] 	 train loss: 0.569782 	 lr: 0.00041
[epoch  90: 160/307] 	 train loss: 0.501778 	 lr: 0.00041
[epoch  90: 180/307] 	 train loss: 0.288898 	 lr: 0.00041
[epoch  90: 200/307] 	 train loss: 0.196594 	 lr: 0.00041
[epoch  90: 220/307] 	 train loss: 0.318544 	 lr: 0.00041
[epoch  90: 240/307] 	 train loss: 0.246731 	 lr: 0.00041
[epoch  90: 260/307] 	 train loss: 0.106745 	 lr: 0.00041
[epoch  90: 280/307] 	 train loss: 0.532185 	 lr: 0.00041

val loss: 0.344404 	 acc: 0.903160

[epoch  90: 300/307] 	 train loss: 0.405445 	 lr: 0.00041
[epoch  91:   0/307] 	 train loss: 0.332679 	 lr: 0.00041
[epoch  91:  20/307] 	 train loss: 0.292801 	 lr: 0.00041
[epoch  91:  40/307] 	 train loss: 0.151993 	 lr: 0.00041
[epoch  91:  60/307] 	 train loss: 0.327601 	 lr: 0.00041
[epoch  91:  80/307] 	 train loss: 0.266169 	 lr: 0.00041
[epoch  91: 100/307] 	 train loss: 0.364578 	 lr: 0.00041
[epoch  91: 120/307] 	 train loss: 0.285715 	 lr: 0.00041

val loss: 0.301542 	 acc: 0.906402

[epoch  91: 140/307] 	 train loss: 0.359159 	 lr: 0.00041
[epoch  91: 160/307] 	 train loss: 0.419981 	 lr: 0.00041
[epoch  91: 180/307] 	 train loss: 0.050923 	 lr: 0.00041
[epoch  91: 200/307] 	 train loss: 0.302610 	 lr: 0.00041
[epoch  91: 220/307] 	 train loss: 0.305138 	 lr: 0.00041
[epoch  91: 240/307] 	 train loss: 0.124402 	 lr: 0.00041
[epoch  91: 260/307] 	 train loss: 0.231572 	 lr: 0.00041

val loss: 0.318766 	 acc: 0.908428

[epoch  91: 280/307] 	 train loss: 0.242193 	 lr: 0.00041
[epoch  91: 300/307] 	 train loss: 0.254429 	 lr: 0.00041
[epoch  92:   0/307] 	 train loss: 0.402903 	 lr: 0.00041
[epoch  92:  20/307] 	 train loss: 0.169188 	 lr: 0.00041
[epoch  92:  40/307] 	 train loss: 0.171821 	 lr: 0.00041
[epoch  92:  60/307] 	 train loss: 0.281213 	 lr: 0.00041
[epoch  92:  80/307] 	 train loss: 0.291885 	 lr: 0.00041
[epoch  92: 100/307] 	 train loss: 0.232287 	 lr: 0.00041
[epoch  92: 120/307] 	 train loss: 0.203689 	 lr: 0.00041

val loss: 0.327950 	 acc: 0.902350

[epoch  92: 140/307] 	 train loss: 0.456531 	 lr: 0.00041
[epoch  92: 160/307] 	 train loss: 0.582917 	 lr: 0.00041
[epoch  92: 180/307] 	 train loss: 0.163699 	 lr: 0.00041
[epoch  92: 200/307] 	 train loss: 0.332056 	 lr: 0.00041
[epoch  92: 220/307] 	 train loss: 0.249636 	 lr: 0.00041
[epoch  92: 240/307] 	 train loss: 0.164464 	 lr: 0.00041
[epoch  92: 260/307] 	 train loss: 0.226542 	 lr: 0.00041

val loss: 0.325452 	 acc: 0.898298

[epoch  92: 280/307] 	 train loss: 0.276419 	 lr: 0.00041
[epoch  92: 300/307] 	 train loss: 0.128002 	 lr: 0.00041
[epoch  93:   0/307] 	 train loss: 0.228244 	 lr: 0.00041
[epoch  93:  20/307] 	 train loss: 0.177341 	 lr: 0.00041
[epoch  93:  40/307] 	 train loss: 0.190901 	 lr: 0.00041
[epoch  93:  60/307] 	 train loss: 0.194944 	 lr: 0.00041
[epoch  93:  80/307] 	 train loss: 0.835602 	 lr: 0.00041
[epoch  93: 100/307] 	 train loss: 0.161469 	 lr: 0.00041
[epoch  93: 120/307] 	 train loss: 0.196184 	 lr: 0.00041

val loss: 0.326441 	 acc: 0.908833

[epoch  93: 140/307] 	 train loss: 0.314911 	 lr: 0.00041
[epoch  93: 160/307] 	 train loss: 0.114378 	 lr: 0.00041
[epoch  93: 180/307] 	 train loss: 0.320712 	 lr: 0.00041
[epoch  93: 200/307] 	 train loss: 0.232767 	 lr: 0.00041
[epoch  93: 220/307] 	 train loss: 0.358206 	 lr: 0.00041
[epoch  93: 240/307] 	 train loss: 0.209283 	 lr: 0.00041
[epoch  93: 260/307] 	 train loss: 0.208332 	 lr: 0.00041

val loss: 0.291190 	 acc: 0.911264

[epoch  93: 280/307] 	 train loss: 0.191127 	 lr: 0.00041
[epoch  93: 300/307] 	 train loss: 0.211362 	 lr: 0.00041
[epoch  94:   0/307] 	 train loss: 0.133097 	 lr: 0.00041
[epoch  94:  20/307] 	 train loss: 0.201166 	 lr: 0.00041
[epoch  94:  40/307] 	 train loss: 0.164550 	 lr: 0.00041
[epoch  94:  60/307] 	 train loss: 0.079020 	 lr: 0.00041
[epoch  94:  80/307] 	 train loss: 0.319096 	 lr: 0.00041
[epoch  94: 100/307] 	 train loss: 0.143557 	 lr: 0.00041

val loss: 0.318886 	 acc: 0.903566

[epoch  94: 120/307] 	 train loss: 0.158118 	 lr: 0.00041
[epoch  94: 140/307] 	 train loss: 0.633115 	 lr: 0.00041
[epoch  94: 160/307] 	 train loss: 0.170945 	 lr: 0.00041
[epoch  94: 180/307] 	 train loss: 0.061612 	 lr: 0.00041
[epoch  94: 200/307] 	 train loss: 0.406147 	 lr: 0.00041
[epoch  94: 220/307] 	 train loss: 0.271611 	 lr: 0.00041
[epoch  94: 240/307] 	 train loss: 0.486356 	 lr: 0.00041
[epoch  94: 260/307] 	 train loss: 0.150588 	 lr: 0.00041

val loss: 0.301565 	 acc: 0.905186

[epoch  94: 280/307] 	 train loss: 0.222297 	 lr: 0.00041
[epoch  94: 300/307] 	 train loss: 0.085947 	 lr: 0.00041
[epoch  95:   0/307] 	 train loss: 0.615228 	 lr: 0.00041
[epoch  95:  20/307] 	 train loss: 0.220345 	 lr: 0.00041
[epoch  95:  40/307] 	 train loss: 0.153888 	 lr: 0.00041
[epoch  95:  60/307] 	 train loss: 0.087326 	 lr: 0.00041
[epoch  95:  80/307] 	 train loss: 0.165359 	 lr: 0.00041
[epoch  95: 100/307] 	 train loss: 0.147107 	 lr: 0.00041

val loss: 0.327522 	 acc: 0.903971

[epoch  95: 120/307] 	 train loss: 0.120867 	 lr: 0.00041
[epoch  95: 140/307] 	 train loss: 0.344302 	 lr: 0.00041
[epoch  95: 160/307] 	 train loss: 0.131788 	 lr: 0.00041
[epoch  95: 180/307] 	 train loss: 0.068351 	 lr: 0.00041
[epoch  95: 200/307] 	 train loss: 0.278133 	 lr: 0.00041
[epoch  95: 220/307] 	 train loss: 0.484607 	 lr: 0.00041
[epoch  95: 240/307] 	 train loss: 0.043818 	 lr: 0.00041
[epoch  95: 260/307] 	 train loss: 0.379993 	 lr: 0.00041

val loss: 0.314136 	 acc: 0.912885

saved model with accuracy  0.9128849270664505
[epoch  95: 280/307] 	 train loss: 0.207565 	 lr: 0.00041
[epoch  95: 300/307] 	 train loss: 0.220873 	 lr: 0.00041
[epoch  96:   0/307] 	 train loss: 0.277812 	 lr: 0.00041
[epoch  96:  20/307] 	 train loss: 0.184954 	 lr: 0.00041
[epoch  96:  40/307] 	 train loss: 0.183094 	 lr: 0.00041
[epoch  96:  60/307] 	 train loss: 0.255110 	 lr: 0.00041
[epoch  96:  80/307] 	 train loss: 0.150926 	 lr: 0.00041
[epoch  96: 100/307] 	 train loss: 0.127507 	 lr: 0.00041

val loss: 0.343411 	 acc: 0.903160

[epoch  96: 120/307] 	 train loss: 0.222827 	 lr: 0.00041
[epoch  96: 140/307] 	 train loss: 0.234063 	 lr: 0.00041
[epoch  96: 160/307] 	 train loss: 0.086820 	 lr: 0.00041
[epoch  96: 180/307] 	 train loss: 0.371561 	 lr: 0.00041
[epoch  96: 200/307] 	 train loss: 0.380899 	 lr: 0.00041
[epoch  96: 220/307] 	 train loss: 0.447457 	 lr: 0.00041
[epoch  96: 240/307] 	 train loss: 0.174351 	 lr: 0.00041
[epoch  96: 260/307] 	 train loss: 0.078444 	 lr: 0.00041

val loss: 0.325082 	 acc: 0.899919

[epoch  96: 280/307] 	 train loss: 0.328593 	 lr: 0.00041
[epoch  96: 300/307] 	 train loss: 0.291617 	 lr: 0.00041
[epoch  97:   0/307] 	 train loss: 0.334260 	 lr: 0.00041
[epoch  97:  20/307] 	 train loss: 0.371156 	 lr: 0.00041
[epoch  97:  40/307] 	 train loss: 0.101386 	 lr: 0.00041
[epoch  97:  60/307] 	 train loss: 0.414237 	 lr: 0.00041
[epoch  97:  80/307] 	 train loss: 0.510416 	 lr: 0.00041
[epoch  97: 100/307] 	 train loss: 0.047976 	 lr: 0.00041

val loss: 0.327249 	 acc: 0.906402

[epoch  97: 120/307] 	 train loss: 0.121370 	 lr: 0.00041
[epoch  97: 140/307] 	 train loss: 0.081267 	 lr: 0.00041
[epoch  97: 160/307] 	 train loss: 0.065375 	 lr: 0.00041
[epoch  97: 180/307] 	 train loss: 0.225412 	 lr: 0.00041
[epoch  97: 200/307] 	 train loss: 0.149685 	 lr: 0.00041
[epoch  97: 220/307] 	 train loss: 0.277246 	 lr: 0.00041
[epoch  97: 240/307] 	 train loss: 0.273069 	 lr: 0.00041
[epoch  97: 260/307] 	 train loss: 0.198520 	 lr: 0.00041

val loss: 0.329518 	 acc: 0.901540

[epoch  97: 280/307] 	 train loss: 0.211755 	 lr: 0.00041
[epoch  97: 300/307] 	 train loss: 0.224400 	 lr: 0.00041
[epoch  98:   0/307] 	 train loss: 0.232026 	 lr: 0.00041
[epoch  98:  20/307] 	 train loss: 0.056180 	 lr: 0.00041
[epoch  98:  40/307] 	 train loss: 0.144543 	 lr: 0.00041
[epoch  98:  60/307] 	 train loss: 0.094355 	 lr: 0.00041
[epoch  98:  80/307] 	 train loss: 0.327409 	 lr: 0.00041
[epoch  98: 100/307] 	 train loss: 0.253801 	 lr: 0.00041

val loss: 0.317661 	 acc: 0.901540

[epoch  98: 120/307] 	 train loss: 0.152717 	 lr: 0.00041
[epoch  98: 140/307] 	 train loss: 0.270532 	 lr: 0.00041
[epoch  98: 160/307] 	 train loss: 0.153399 	 lr: 0.00041
[epoch  98: 180/307] 	 train loss: 0.330536 	 lr: 0.00041
[epoch  98: 200/307] 	 train loss: 0.212206 	 lr: 0.00041
[epoch  98: 220/307] 	 train loss: 0.187907 	 lr: 0.00041
[epoch  98: 240/307] 	 train loss: 0.226979 	 lr: 0.00041
[epoch  98: 260/307] 	 train loss: 0.127492 	 lr: 0.00041

val loss: 0.339520 	 acc: 0.899919

[epoch  98: 280/307] 	 train loss: 0.193944 	 lr: 0.00041
[epoch  98: 300/307] 	 train loss: 0.164692 	 lr: 0.00041
[epoch  99:   0/307] 	 train loss: 0.366665 	 lr: 0.00041
[epoch  99:  20/307] 	 train loss: 0.117934 	 lr: 0.00041
[epoch  99:  40/307] 	 train loss: 0.161602 	 lr: 0.00041
[epoch  99:  60/307] 	 train loss: 0.309629 	 lr: 0.00041
[epoch  99:  80/307] 	 train loss: 0.192182 	 lr: 0.00041
[epoch  99: 100/307] 	 train loss: 0.204586 	 lr: 0.00041

val loss: 0.318981 	 acc: 0.906402

[epoch  99: 120/307] 	 train loss: 0.093469 	 lr: 0.00041
[epoch  99: 140/307] 	 train loss: 0.321602 	 lr: 0.00041
[epoch  99: 160/307] 	 train loss: 0.104975 	 lr: 0.00041
[epoch  99: 180/307] 	 train loss: 0.205254 	 lr: 0.00041
[epoch  99: 200/307] 	 train loss: 0.397868 	 lr: 0.00041
[epoch  99: 220/307] 	 train loss: 0.049547 	 lr: 0.00041
[epoch  99: 240/307] 	 train loss: 0.304142 	 lr: 0.00041
[epoch  99: 260/307] 	 train loss: 0.358046 	 lr: 0.00041

val loss: 0.329787 	 acc: 0.903566

[epoch  99: 280/307] 	 train loss: 0.060225 	 lr: 0.00041
[epoch  99: 300/307] 	 train loss: 0.304976 	 lr: 0.00041
[epoch 100:   0/307] 	 train loss: 0.337537 	 lr: 0.00041
[epoch 100:  20/307] 	 train loss: 0.074354 	 lr: 0.00041
[epoch 100:  40/307] 	 train loss: 0.239814 	 lr: 0.00041
[epoch 100:  60/307] 	 train loss: 0.337035 	 lr: 0.00041
[epoch 100:  80/307] 	 train loss: 0.028152 	 lr: 0.00041
[epoch 100: 100/307] 	 train loss: 0.282531 	 lr: 0.00041

val loss: 0.322634 	 acc: 0.905997

[epoch 100: 120/307] 	 train loss: 0.222924 	 lr: 0.00041
[epoch 100: 140/307] 	 train loss: 0.312032 	 lr: 0.00041
[epoch 100: 160/307] 	 train loss: 0.367077 	 lr: 0.00041
[epoch 100: 180/307] 	 train loss: 0.374175 	 lr: 0.00041
[epoch 100: 200/307] 	 train loss: 0.217542 	 lr: 0.00041
[epoch 100: 220/307] 	 train loss: 0.229256 	 lr: 0.00041
[epoch 100: 240/307] 	 train loss: 0.317457 	 lr: 0.00041
[epoch 100: 260/307] 	 train loss: 0.120892 	 lr: 0.00041

val loss: 0.321303 	 acc: 0.901540

[epoch 100: 280/307] 	 train loss: 0.392439 	 lr: 0.00041
[epoch 100: 300/307] 	 train loss: 0.118229 	 lr: 0.00041
[epoch 101:   0/307] 	 train loss: 0.216773 	 lr: 0.00041
[epoch 101:  20/307] 	 train loss: 0.147890 	 lr: 0.00041
[epoch 101:  40/307] 	 train loss: 0.112899 	 lr: 0.00041
[epoch 101:  60/307] 	 train loss: 0.346988 	 lr: 0.00041
[epoch 101:  80/307] 	 train loss: 0.409256 	 lr: 0.00041
[epoch 101: 100/307] 	 train loss: 0.311237 	 lr: 0.00041

val loss: 0.327075 	 acc: 0.904376

[epoch 101: 120/307] 	 train loss: 0.300742 	 lr: 0.00041
[epoch 101: 140/307] 	 train loss: 0.083657 	 lr: 0.00041
[epoch 101: 160/307] 	 train loss: 0.164782 	 lr: 0.00041
[epoch 101: 180/307] 	 train loss: 0.389855 	 lr: 0.00041
[epoch 101: 200/307] 	 train loss: 0.131212 	 lr: 0.00041
[epoch 101: 220/307] 	 train loss: 0.098381 	 lr: 0.00041
[epoch 101: 240/307] 	 train loss: 0.197544 	 lr: 0.00041

val loss: 0.337844 	 acc: 0.903566

[epoch 101: 260/307] 	 train loss: 0.280002 	 lr: 0.00041
[epoch 101: 280/307] 	 train loss: 0.142452 	 lr: 0.00041
[epoch 101: 300/307] 	 train loss: 0.232949 	 lr: 0.00041
[epoch 102:   0/307] 	 train loss: 0.185564 	 lr: 0.00041
[epoch 102:  20/307] 	 train loss: 0.199668 	 lr: 0.00041
[epoch 102:  40/307] 	 train loss: 0.245268 	 lr: 0.00041
[epoch 102:  60/307] 	 train loss: 0.390878 	 lr: 0.00041
[epoch 102:  80/307] 	 train loss: 0.199895 	 lr: 0.00041
[epoch 102: 100/307] 	 train loss: 0.319580 	 lr: 0.00041

val loss: 0.317337 	 acc: 0.902350

[epoch 102: 120/307] 	 train loss: 0.074515 	 lr: 0.00041
[epoch 102: 140/307] 	 train loss: 0.252752 	 lr: 0.00041
[epoch 102: 160/307] 	 train loss: 0.111677 	 lr: 0.00041
[epoch 102: 180/307] 	 train loss: 0.253933 	 lr: 0.00041
[epoch 102: 200/307] 	 train loss: 0.046825 	 lr: 0.00041
[epoch 102: 220/307] 	 train loss: 0.266343 	 lr: 0.00041
[epoch 102: 240/307] 	 train loss: 0.186448 	 lr: 0.00041

val loss: 0.322697 	 acc: 0.903566

[epoch 102: 260/307] 	 train loss: 0.262227 	 lr: 0.00041
[epoch 102: 280/307] 	 train loss: 0.203236 	 lr: 0.00041
[epoch 102: 300/307] 	 train loss: 0.402766 	 lr: 0.00041
[epoch 103:   0/307] 	 train loss: 0.353554 	 lr: 0.00041
[epoch 103:  20/307] 	 train loss: 0.405792 	 lr: 0.00041
[epoch 103:  40/307] 	 train loss: 0.333375 	 lr: 0.00041
[epoch 103:  60/307] 	 train loss: 0.197492 	 lr: 0.00041
[epoch 103:  80/307] 	 train loss: 0.343930 	 lr: 0.00041
[epoch 103: 100/307] 	 train loss: 0.173471 	 lr: 0.00041

val loss: 0.326001 	 acc: 0.908428

[epoch 103: 120/307] 	 train loss: 0.086230 	 lr: 0.00041
[epoch 103: 140/307] 	 train loss: 0.143409 	 lr: 0.00041
[epoch 103: 160/307] 	 train loss: 0.172789 	 lr: 0.00041
[epoch 103: 180/307] 	 train loss: 0.339279 	 lr: 0.00041
[epoch 103: 200/307] 	 train loss: 0.069865 	 lr: 0.00041
[epoch 103: 220/307] 	 train loss: 0.150887 	 lr: 0.00041
[epoch 103: 240/307] 	 train loss: 0.118128 	 lr: 0.00041

val loss: 0.326381 	 acc: 0.905186

[epoch 103: 260/307] 	 train loss: 0.230864 	 lr: 0.00041
[epoch 103: 280/307] 	 train loss: 0.368344 	 lr: 0.00041
[epoch 103: 300/307] 	 train loss: 0.209524 	 lr: 0.00041
[epoch 104:   0/307] 	 train loss: 0.227582 	 lr: 0.00041
[epoch 104:  20/307] 	 train loss: 0.227059 	 lr: 0.00041
[epoch 104:  40/307] 	 train loss: 0.141341 	 lr: 0.00041
[epoch 104:  60/307] 	 train loss: 0.182525 	 lr: 0.00041
[epoch 104:  80/307] 	 train loss: 0.255814 	 lr: 0.00041

val loss: 0.326567 	 acc: 0.904376

[epoch 104: 100/307] 	 train loss: 0.269203 	 lr: 0.00041
[epoch 104: 120/307] 	 train loss: 0.094398 	 lr: 0.00041
[epoch 104: 140/307] 	 train loss: 0.594099 	 lr: 0.00041
[epoch 104: 160/307] 	 train loss: 0.525584 	 lr: 0.00041
[epoch 104: 180/307] 	 train loss: 0.101863 	 lr: 0.00041
[epoch 104: 200/307] 	 train loss: 0.173492 	 lr: 0.00041
[epoch 104: 220/307] 	 train loss: 0.270452 	 lr: 0.00041
[epoch 104: 240/307] 	 train loss: 0.297406 	 lr: 0.00041

val loss: 0.311156 	 acc: 0.906807

[epoch 104: 260/307] 	 train loss: 0.277287 	 lr: 0.00041
[epoch 104: 280/307] 	 train loss: 0.442700 	 lr: 0.00041
[epoch 104: 300/307] 	 train loss: 0.203312 	 lr: 0.00041
[epoch 105:   0/307] 	 train loss: 0.189770 	 lr: 0.00041
[epoch 105:  20/307] 	 train loss: 0.158717 	 lr: 0.00041
[epoch 105:  40/307] 	 train loss: 0.108162 	 lr: 0.00041
[epoch 105:  60/307] 	 train loss: 0.224023 	 lr: 0.00041
[epoch 105:  80/307] 	 train loss: 0.360903 	 lr: 0.00041

val loss: 0.356100 	 acc: 0.902350

[epoch 105: 100/307] 	 train loss: 0.129638 	 lr: 0.00041
[epoch 105: 120/307] 	 train loss: 0.183580 	 lr: 0.00041
[epoch 105: 140/307] 	 train loss: 0.228926 	 lr: 0.00041
[epoch 105: 160/307] 	 train loss: 0.164180 	 lr: 0.00041
[epoch 105: 180/307] 	 train loss: 0.389870 	 lr: 0.00041
[epoch 105: 200/307] 	 train loss: 0.256922 	 lr: 0.00041
[epoch 105: 220/307] 	 train loss: 0.159231 	 lr: 0.00041
[epoch 105: 240/307] 	 train loss: 0.253570 	 lr: 0.00041

val loss: 0.297417 	 acc: 0.908833

[epoch 105: 260/307] 	 train loss: 0.502555 	 lr: 0.00041
[epoch 105: 280/307] 	 train loss: 0.137671 	 lr: 0.00041
[epoch 105: 300/307] 	 train loss: 0.434623 	 lr: 0.00041
[epoch 106:   0/307] 	 train loss: 0.044237 	 lr: 0.00033
[epoch 106:  20/307] 	 train loss: 0.175770 	 lr: 0.00033
[epoch 106:  40/307] 	 train loss: 0.444783 	 lr: 0.00033
[epoch 106:  60/307] 	 train loss: 0.164266 	 lr: 0.00033
[epoch 106:  80/307] 	 train loss: 0.256277 	 lr: 0.00033

val loss: 0.329624 	 acc: 0.905592

[epoch 106: 100/307] 	 train loss: 0.385271 	 lr: 0.00033
[epoch 106: 120/307] 	 train loss: 0.098891 	 lr: 0.00033
[epoch 106: 140/307] 	 train loss: 0.263961 	 lr: 0.00033
[epoch 106: 160/307] 	 train loss: 0.044470 	 lr: 0.00033
[epoch 106: 180/307] 	 train loss: 0.245189 	 lr: 0.00033
[epoch 106: 200/307] 	 train loss: 0.346812 	 lr: 0.00033
[epoch 106: 220/307] 	 train loss: 0.239356 	 lr: 0.00033
[epoch 106: 240/307] 	 train loss: 0.346261 	 lr: 0.00033

val loss: 0.305539 	 acc: 0.906402

[epoch 106: 260/307] 	 train loss: 0.401104 	 lr: 0.00033
[epoch 106: 280/307] 	 train loss: 0.199740 	 lr: 0.00033
[epoch 106: 300/307] 	 train loss: 0.386736 	 lr: 0.00033
[epoch 107:   0/307] 	 train loss: 0.272473 	 lr: 0.00033
[epoch 107:  20/307] 	 train loss: 0.161311 	 lr: 0.00033
[epoch 107:  40/307] 	 train loss: 0.137627 	 lr: 0.00033
[epoch 107:  60/307] 	 train loss: 0.131332 	 lr: 0.00033
[epoch 107:  80/307] 	 train loss: 0.434813 	 lr: 0.00033

val loss: 0.335796 	 acc: 0.895867

[epoch 107: 100/307] 	 train loss: 0.192967 	 lr: 0.00033
[epoch 107: 120/307] 	 train loss: 0.421676 	 lr: 0.00033
[epoch 107: 140/307] 	 train loss: 0.178347 	 lr: 0.00033
[epoch 107: 160/307] 	 train loss: 0.089428 	 lr: 0.00033
[epoch 107: 180/307] 	 train loss: 0.130880 	 lr: 0.00033
[epoch 107: 200/307] 	 train loss: 0.124708 	 lr: 0.00033
[epoch 107: 220/307] 	 train loss: 0.313999 	 lr: 0.00033
[epoch 107: 240/307] 	 train loss: 0.344930 	 lr: 0.00033

val loss: 0.317681 	 acc: 0.905186

[epoch 107: 260/307] 	 train loss: 0.185552 	 lr: 0.00033
[epoch 107: 280/307] 	 train loss: 0.342467 	 lr: 0.00033
[epoch 107: 300/307] 	 train loss: 0.243663 	 lr: 0.00033
[epoch 108:   0/307] 	 train loss: 0.278566 	 lr: 0.00033
[epoch 108:  20/307] 	 train loss: 0.469792 	 lr: 0.00033
[epoch 108:  40/307] 	 train loss: 0.133224 	 lr: 0.00033
[epoch 108:  60/307] 	 train loss: 0.155729 	 lr: 0.00033
[epoch 108:  80/307] 	 train loss: 0.136272 	 lr: 0.00033

val loss: 0.307096 	 acc: 0.908833

[epoch 108: 100/307] 	 train loss: 0.082424 	 lr: 0.00033
[epoch 108: 120/307] 	 train loss: 0.206131 	 lr: 0.00033
[epoch 108: 140/307] 	 train loss: 0.188989 	 lr: 0.00033
[epoch 108: 160/307] 	 train loss: 0.051955 	 lr: 0.00033
[epoch 108: 180/307] 	 train loss: 0.150520 	 lr: 0.00033
[epoch 108: 200/307] 	 train loss: 0.254648 	 lr: 0.00033
[epoch 108: 220/307] 	 train loss: 0.378428 	 lr: 0.00033
[epoch 108: 240/307] 	 train loss: 0.136777 	 lr: 0.00033

val loss: 0.321657 	 acc: 0.904376

[epoch 108: 260/307] 	 train loss: 0.126938 	 lr: 0.00033
[epoch 108: 280/307] 	 train loss: 0.176145 	 lr: 0.00033
[epoch 108: 300/307] 	 train loss: 0.127262 	 lr: 0.00033
[epoch 109:   0/307] 	 train loss: 0.258706 	 lr: 0.00033
[epoch 109:  20/307] 	 train loss: 0.155639 	 lr: 0.00033
[epoch 109:  40/307] 	 train loss: 0.094073 	 lr: 0.00033
[epoch 109:  60/307] 	 train loss: 0.123478 	 lr: 0.00033
[epoch 109:  80/307] 	 train loss: 0.199494 	 lr: 0.00033

val loss: 0.316949 	 acc: 0.897083

[epoch 109: 100/307] 	 train loss: 0.179981 	 lr: 0.00033
[epoch 109: 120/307] 	 train loss: 0.385884 	 lr: 0.00033
[epoch 109: 140/307] 	 train loss: 0.080586 	 lr: 0.00033
[epoch 109: 160/307] 	 train loss: 0.064687 	 lr: 0.00033
[epoch 109: 180/307] 	 train loss: 0.177480 	 lr: 0.00033
[epoch 109: 200/307] 	 train loss: 0.103632 	 lr: 0.00033
[epoch 109: 220/307] 	 train loss: 0.120136 	 lr: 0.00033
[epoch 109: 240/307] 	 train loss: 0.188991 	 lr: 0.00033

val loss: 0.343017 	 acc: 0.899109

[epoch 109: 260/307] 	 train loss: 0.232831 	 lr: 0.00033
[epoch 109: 280/307] 	 train loss: 0.259234 	 lr: 0.00033
[epoch 109: 300/307] 	 train loss: 0.163678 	 lr: 0.00033
[epoch 110:   0/307] 	 train loss: 0.128353 	 lr: 0.00033
[epoch 110:  20/307] 	 train loss: 0.115608 	 lr: 0.00033
[epoch 110:  40/307] 	 train loss: 0.135488 	 lr: 0.00033
[epoch 110:  60/307] 	 train loss: 0.180935 	 lr: 0.00033
[epoch 110:  80/307] 	 train loss: 0.274628 	 lr: 0.00033

val loss: 0.335508 	 acc: 0.905186

[epoch 110: 100/307] 	 train loss: 0.209996 	 lr: 0.00033
[epoch 110: 120/307] 	 train loss: 0.231945 	 lr: 0.00033
[epoch 110: 140/307] 	 train loss: 0.132191 	 lr: 0.00033
[epoch 110: 160/307] 	 train loss: 0.081039 	 lr: 0.00033
[epoch 110: 180/307] 	 train loss: 0.351663 	 lr: 0.00033
[epoch 110: 200/307] 	 train loss: 0.191398 	 lr: 0.00033
[epoch 110: 220/307] 	 train loss: 0.032429 	 lr: 0.00033
[epoch 110: 240/307] 	 train loss: 0.114431 	 lr: 0.00033

val loss: 0.334059 	 acc: 0.905997

[epoch 110: 260/307] 	 train loss: 0.053985 	 lr: 0.00033
[epoch 110: 280/307] 	 train loss: 0.022845 	 lr: 0.00033
[epoch 110: 300/307] 	 train loss: 0.138358 	 lr: 0.00033
[epoch 111:   0/307] 	 train loss: 0.379478 	 lr: 0.00033
[epoch 111:  20/307] 	 train loss: 0.111171 	 lr: 0.00033
[epoch 111:  40/307] 	 train loss: 0.171970 	 lr: 0.00033
[epoch 111:  60/307] 	 train loss: 0.069675 	 lr: 0.00033
[epoch 111:  80/307] 	 train loss: 0.271283 	 lr: 0.00033

val loss: 0.332286 	 acc: 0.899919

[epoch 111: 100/307] 	 train loss: 0.053109 	 lr: 0.00033
[epoch 111: 120/307] 	 train loss: 0.194555 	 lr: 0.00033
[epoch 111: 140/307] 	 train loss: 0.223756 	 lr: 0.00033
[epoch 111: 160/307] 	 train loss: 0.126193 	 lr: 0.00033
[epoch 111: 180/307] 	 train loss: 0.154811 	 lr: 0.00033
[epoch 111: 200/307] 	 train loss: 0.197696 	 lr: 0.00033
[epoch 111: 220/307] 	 train loss: 0.170424 	 lr: 0.00033

val loss: 0.318093 	 acc: 0.902755

[epoch 111: 240/307] 	 train loss: 0.202181 	 lr: 0.00033
[epoch 111: 260/307] 	 train loss: 0.078333 	 lr: 0.00033
[epoch 111: 280/307] 	 train loss: 0.521135 	 lr: 0.00033
[epoch 111: 300/307] 	 train loss: 0.363751 	 lr: 0.00033
[epoch 112:   0/307] 	 train loss: 0.173823 	 lr: 0.00033
[epoch 112:  20/307] 	 train loss: 0.077445 	 lr: 0.00033
[epoch 112:  40/307] 	 train loss: 0.284005 	 lr: 0.00033
[epoch 112:  60/307] 	 train loss: 0.123473 	 lr: 0.00033
[epoch 112:  80/307] 	 train loss: 0.146989 	 lr: 0.00033

val loss: 0.343198 	 acc: 0.905186

[epoch 112: 100/307] 	 train loss: 0.129460 	 lr: 0.00033
[epoch 112: 120/307] 	 train loss: 0.463657 	 lr: 0.00033
[epoch 112: 140/307] 	 train loss: 0.160206 	 lr: 0.00033
[epoch 112: 160/307] 	 train loss: 0.071048 	 lr: 0.00033
[epoch 112: 180/307] 	 train loss: 0.238961 	 lr: 0.00033
[epoch 112: 200/307] 	 train loss: 0.149639 	 lr: 0.00033
[epoch 112: 220/307] 	 train loss: 0.309560 	 lr: 0.00033

val loss: 0.321870 	 acc: 0.900324

[epoch 112: 240/307] 	 train loss: 0.179087 	 lr: 0.00033
[epoch 112: 260/307] 	 train loss: 0.211967 	 lr: 0.00033
[epoch 112: 280/307] 	 train loss: 0.309924 	 lr: 0.00033
[epoch 112: 300/307] 	 train loss: 0.051524 	 lr: 0.00033
[epoch 113:   0/307] 	 train loss: 0.099763 	 lr: 0.00033
[epoch 113:  20/307] 	 train loss: 0.453269 	 lr: 0.00033
[epoch 113:  40/307] 	 train loss: 0.234493 	 lr: 0.00033
[epoch 113:  60/307] 	 train loss: 0.180256 	 lr: 0.00033
[epoch 113:  80/307] 	 train loss: 0.162513 	 lr: 0.00033

val loss: 0.327815 	 acc: 0.902350

[epoch 113: 100/307] 	 train loss: 0.090781 	 lr: 0.00033
[epoch 113: 120/307] 	 train loss: 0.048656 	 lr: 0.00033
[epoch 113: 140/307] 	 train loss: 0.284157 	 lr: 0.00033
[epoch 113: 160/307] 	 train loss: 0.102911 	 lr: 0.00033
[epoch 113: 180/307] 	 train loss: 0.321149 	 lr: 0.00033
[epoch 113: 200/307] 	 train loss: 0.071000 	 lr: 0.00033
[epoch 113: 220/307] 	 train loss: 0.366447 	 lr: 0.00033

val loss: 0.340736 	 acc: 0.895057

[epoch 113: 240/307] 	 train loss: 0.142181 	 lr: 0.00033
[epoch 113: 260/307] 	 train loss: 0.074891 	 lr: 0.00033
[epoch 113: 280/307] 	 train loss: 0.157303 	 lr: 0.00033
[epoch 113: 300/307] 	 train loss: 0.265019 	 lr: 0.00033
[epoch 114:   0/307] 	 train loss: 0.463964 	 lr: 0.00033
[epoch 114:  20/307] 	 train loss: 0.326719 	 lr: 0.00033
[epoch 114:  40/307] 	 train loss: 0.168561 	 lr: 0.00033
[epoch 114:  60/307] 	 train loss: 0.250291 	 lr: 0.00033

val loss: 0.323021 	 acc: 0.904376

[epoch 114:  80/307] 	 train loss: 0.111546 	 lr: 0.00033
[epoch 114: 100/307] 	 train loss: 0.039715 	 lr: 0.00033
[epoch 114: 120/307] 	 train loss: 0.231826 	 lr: 0.00033
[epoch 114: 140/307] 	 train loss: 0.299538 	 lr: 0.00033
[epoch 114: 160/307] 	 train loss: 0.101240 	 lr: 0.00033
[epoch 114: 180/307] 	 train loss: 0.098271 	 lr: 0.00033
[epoch 114: 200/307] 	 train loss: 0.285845 	 lr: 0.00033
[epoch 114: 220/307] 	 train loss: 0.272086 	 lr: 0.00033

val loss: 0.332240 	 acc: 0.902350

[epoch 114: 240/307] 	 train loss: 0.266132 	 lr: 0.00033
[epoch 114: 260/307] 	 train loss: 0.308534 	 lr: 0.00033
[epoch 114: 280/307] 	 train loss: 0.239367 	 lr: 0.00033
[epoch 114: 300/307] 	 train loss: 0.312135 	 lr: 0.00033
[epoch 115:   0/307] 	 train loss: 0.629472 	 lr: 0.00033
[epoch 115:  20/307] 	 train loss: 0.183968 	 lr: 0.00033
[epoch 115:  40/307] 	 train loss: 0.284496 	 lr: 0.00033
[epoch 115:  60/307] 	 train loss: 0.075028 	 lr: 0.00033

val loss: 0.346640 	 acc: 0.901945

[epoch 115:  80/307] 	 train loss: 0.045049 	 lr: 0.00033
[epoch 115: 100/307] 	 train loss: 0.172719 	 lr: 0.00033
[epoch 115: 120/307] 	 train loss: 0.171944 	 lr: 0.00033
[epoch 115: 140/307] 	 train loss: 0.183298 	 lr: 0.00033
[epoch 115: 160/307] 	 train loss: 0.245782 	 lr: 0.00033
[epoch 115: 180/307] 	 train loss: 0.129787 	 lr: 0.00033
[epoch 115: 200/307] 	 train loss: 0.365365 	 lr: 0.00033
[epoch 115: 220/307] 	 train loss: 0.332842 	 lr: 0.00033

val loss: 0.318015 	 acc: 0.905186

[epoch 115: 240/307] 	 train loss: 0.393942 	 lr: 0.00033
[epoch 115: 260/307] 	 train loss: 0.214702 	 lr: 0.00033
[epoch 115: 280/307] 	 train loss: 0.065147 	 lr: 0.00033
[epoch 115: 300/307] 	 train loss: 0.036147 	 lr: 0.00033
[epoch 116:   0/307] 	 train loss: 0.133360 	 lr: 0.00033
[epoch 116:  20/307] 	 train loss: 0.323423 	 lr: 0.00033
[epoch 116:  40/307] 	 train loss: 0.160713 	 lr: 0.00033
[epoch 116:  60/307] 	 train loss: 0.405175 	 lr: 0.00033

val loss: 0.315127 	 acc: 0.910049

[epoch 116:  80/307] 	 train loss: 0.373955 	 lr: 0.00033
[epoch 116: 100/307] 	 train loss: 0.337196 	 lr: 0.00033
[epoch 116: 120/307] 	 train loss: 0.162525 	 lr: 0.00033
[epoch 116: 140/307] 	 train loss: 0.533695 	 lr: 0.00033
[epoch 116: 160/307] 	 train loss: 0.327955 	 lr: 0.00033
[epoch 116: 180/307] 	 train loss: 0.400028 	 lr: 0.00033
[epoch 116: 200/307] 	 train loss: 0.153681 	 lr: 0.00033
[epoch 116: 220/307] 	 train loss: 0.233219 	 lr: 0.00033

val loss: 0.328673 	 acc: 0.906807

[epoch 116: 240/307] 	 train loss: 0.154723 	 lr: 0.00033
[epoch 116: 260/307] 	 train loss: 0.328594 	 lr: 0.00033
[epoch 116: 280/307] 	 train loss: 0.319233 	 lr: 0.00033
[epoch 116: 300/307] 	 train loss: 0.083918 	 lr: 0.00033
[epoch 117:   0/307] 	 train loss: 0.142971 	 lr: 0.00033
[epoch 117:  20/307] 	 train loss: 0.170545 	 lr: 0.00033
[epoch 117:  40/307] 	 train loss: 0.106642 	 lr: 0.00033
[epoch 117:  60/307] 	 train loss: 0.255129 	 lr: 0.00033

val loss: 0.347391 	 acc: 0.897083

[epoch 117:  80/307] 	 train loss: 0.083424 	 lr: 0.00033
[epoch 117: 100/307] 	 train loss: 0.097100 	 lr: 0.00033
[epoch 117: 120/307] 	 train loss: 0.121294 	 lr: 0.00033
[epoch 117: 140/307] 	 train loss: 0.215372 	 lr: 0.00033
[epoch 117: 160/307] 	 train loss: 0.171028 	 lr: 0.00033
[epoch 117: 180/307] 	 train loss: 0.080421 	 lr: 0.00033
[epoch 117: 200/307] 	 train loss: 0.135230 	 lr: 0.00033
[epoch 117: 220/307] 	 train loss: 0.096695 	 lr: 0.00033

val loss: 0.320657 	 acc: 0.907618

[epoch 117: 240/307] 	 train loss: 0.137802 	 lr: 0.00033
[epoch 117: 260/307] 	 train loss: 0.318087 	 lr: 0.00033
[epoch 117: 280/307] 	 train loss: 0.202467 	 lr: 0.00033
[epoch 117: 300/307] 	 train loss: 0.086792 	 lr: 0.00033
[epoch 118:   0/307] 	 train loss: 0.206934 	 lr: 0.00033
[epoch 118:  20/307] 	 train loss: 0.152116 	 lr: 0.00033
[epoch 118:  40/307] 	 train loss: 0.175233 	 lr: 0.00033
[epoch 118:  60/307] 	 train loss: 0.250883 	 lr: 0.00033

val loss: 0.334213 	 acc: 0.903160

[epoch 118:  80/307] 	 train loss: 0.081974 	 lr: 0.00033
[epoch 118: 100/307] 	 train loss: 0.311897 	 lr: 0.00033
[epoch 118: 120/307] 	 train loss: 0.156346 	 lr: 0.00033
[epoch 118: 140/307] 	 train loss: 0.078661 	 lr: 0.00033
[epoch 118: 160/307] 	 train loss: 0.139651 	 lr: 0.00033
[epoch 118: 180/307] 	 train loss: 0.336191 	 lr: 0.00033
[epoch 118: 200/307] 	 train loss: 0.213812 	 lr: 0.00033
[epoch 118: 220/307] 	 train loss: 0.088838 	 lr: 0.00033

val loss: 0.334050 	 acc: 0.900324

[epoch 118: 240/307] 	 train loss: 0.115917 	 lr: 0.00033
[epoch 118: 260/307] 	 train loss: 0.306099 	 lr: 0.00033
[epoch 118: 280/307] 	 train loss: 0.150477 	 lr: 0.00033
[epoch 118: 300/307] 	 train loss: 0.072140 	 lr: 0.00033
[epoch 119:   0/307] 	 train loss: 0.322508 	 lr: 0.00033
[epoch 119:  20/307] 	 train loss: 0.223637 	 lr: 0.00033
[epoch 119:  40/307] 	 train loss: 0.165575 	 lr: 0.00033
[epoch 119:  60/307] 	 train loss: 0.214371 	 lr: 0.00033

val loss: 0.349196 	 acc: 0.897083

[epoch 119:  80/307] 	 train loss: 0.478903 	 lr: 0.00033
[epoch 119: 100/307] 	 train loss: 0.096426 	 lr: 0.00033
[epoch 119: 120/307] 	 train loss: 0.342068 	 lr: 0.00033
[epoch 119: 140/307] 	 train loss: 0.241133 	 lr: 0.00033
[epoch 119: 160/307] 	 train loss: 0.152732 	 lr: 0.00033
[epoch 119: 180/307] 	 train loss: 0.365268 	 lr: 0.00033
[epoch 119: 200/307] 	 train loss: 0.193672 	 lr: 0.00033
[epoch 119: 220/307] 	 train loss: 0.033564 	 lr: 0.00033

val loss: 0.338070 	 acc: 0.899514

[epoch 119: 240/307] 	 train loss: 0.085287 	 lr: 0.00033
[epoch 119: 260/307] 	 train loss: 0.058343 	 lr: 0.00033
[epoch 119: 280/307] 	 train loss: 0.141396 	 lr: 0.00033
[epoch 119: 300/307] 	 train loss: 0.161586 	 lr: 0.00033
[epoch 120:   0/307] 	 train loss: 0.316223 	 lr: 0.00033
[epoch 120:  20/307] 	 train loss: 0.056432 	 lr: 0.00033
[epoch 120:  40/307] 	 train loss: 0.086297 	 lr: 0.00033
[epoch 120:  60/307] 	 train loss: 0.167398 	 lr: 0.00033

val loss: 0.334005 	 acc: 0.901135

[epoch 120:  80/307] 	 train loss: 0.117414 	 lr: 0.00033
[epoch 120: 100/307] 	 train loss: 0.509423 	 lr: 0.00033
[epoch 120: 120/307] 	 train loss: 0.239070 	 lr: 0.00033
[epoch 120: 140/307] 	 train loss: 0.279236 	 lr: 0.00033
[epoch 120: 160/307] 	 train loss: 0.260407 	 lr: 0.00033
[epoch 120: 180/307] 	 train loss: 0.181315 	 lr: 0.00033
[epoch 120: 200/307] 	 train loss: 0.229802 	 lr: 0.00033
[epoch 120: 220/307] 	 train loss: 0.503178 	 lr: 0.00033

val loss: 0.363449 	 acc: 0.906402

[epoch 120: 240/307] 	 train loss: 0.071596 	 lr: 0.00033
[epoch 120: 260/307] 	 train loss: 0.237462 	 lr: 0.00033
[epoch 120: 280/307] 	 train loss: 0.049372 	 lr: 0.00033
[epoch 120: 300/307] 	 train loss: 0.228817 	 lr: 0.00033
[epoch 121:   0/307] 	 train loss: 0.362743 	 lr: 0.00033
[epoch 121:  20/307] 	 train loss: 0.168989 	 lr: 0.00033
[epoch 121:  40/307] 	 train loss: 0.406181 	 lr: 0.00033
[epoch 121:  60/307] 	 train loss: 0.107514 	 lr: 0.00033

val loss: 0.360356 	 acc: 0.895462

[epoch 121:  80/307] 	 train loss: 0.113937 	 lr: 0.00033
[epoch 121: 100/307] 	 train loss: 0.228430 	 lr: 0.00033
[epoch 121: 120/307] 	 train loss: 0.215801 	 lr: 0.00033
[epoch 121: 140/307] 	 train loss: 0.157593 	 lr: 0.00033
[epoch 121: 160/307] 	 train loss: 0.167973 	 lr: 0.00033
[epoch 121: 180/307] 	 train loss: 0.386090 	 lr: 0.00033
[epoch 121: 200/307] 	 train loss: 0.153075 	 lr: 0.00033

val loss: 0.343254 	 acc: 0.905997

[epoch 121: 220/307] 	 train loss: 0.260591 	 lr: 0.00033
[epoch 121: 240/307] 	 train loss: 0.073679 	 lr: 0.00033
[epoch 121: 260/307] 	 train loss: 0.104224 	 lr: 0.00033
[epoch 121: 280/307] 	 train loss: 0.202562 	 lr: 0.00033
[epoch 121: 300/307] 	 train loss: 0.319248 	 lr: 0.00033
[epoch 122:   0/307] 	 train loss: 0.122187 	 lr: 0.00033
[epoch 122:  20/307] 	 train loss: 0.039232 	 lr: 0.00033
[epoch 122:  40/307] 	 train loss: 0.216580 	 lr: 0.00033
[epoch 122:  60/307] 	 train loss: 0.153674 	 lr: 0.00033

val loss: 0.325359 	 acc: 0.905997

[epoch 122:  80/307] 	 train loss: 0.269432 	 lr: 0.00033
[epoch 122: 100/307] 	 train loss: 0.101535 	 lr: 0.00033
[epoch 122: 120/307] 	 train loss: 0.173369 	 lr: 0.00033
[epoch 122: 140/307] 	 train loss: 0.202045 	 lr: 0.00033
[epoch 122: 160/307] 	 train loss: 0.175851 	 lr: 0.00033
[epoch 122: 180/307] 	 train loss: 0.104648 	 lr: 0.00033
[epoch 122: 200/307] 	 train loss: 0.083437 	 lr: 0.00033

val loss: 0.349638 	 acc: 0.903566

[epoch 122: 220/307] 	 train loss: 0.193138 	 lr: 0.00033
[epoch 122: 240/307] 	 train loss: 0.207611 	 lr: 0.00033
[epoch 122: 260/307] 	 train loss: 0.150436 	 lr: 0.00033
[epoch 122: 280/307] 	 train loss: 0.218077 	 lr: 0.00033
[epoch 122: 300/307] 	 train loss: 0.041415 	 lr: 0.00033
[epoch 123:   0/307] 	 train loss: 0.177170 	 lr: 0.00033
[epoch 123:  20/307] 	 train loss: 0.121218 	 lr: 0.00033
[epoch 123:  40/307] 	 train loss: 0.129128 	 lr: 0.00033
[epoch 123:  60/307] 	 train loss: 0.103246 	 lr: 0.00033

val loss: 0.352091 	 acc: 0.898298

[epoch 123:  80/307] 	 train loss: 0.515418 	 lr: 0.00033
[epoch 123: 100/307] 	 train loss: 0.162880 	 lr: 0.00033
[epoch 123: 120/307] 	 train loss: 0.231417 	 lr: 0.00033
[epoch 123: 140/307] 	 train loss: 0.143976 	 lr: 0.00033
[epoch 123: 160/307] 	 train loss: 0.279822 	 lr: 0.00033
[epoch 123: 180/307] 	 train loss: 0.303493 	 lr: 0.00033
[epoch 123: 200/307] 	 train loss: 0.146549 	 lr: 0.00033

val loss: 0.344529 	 acc: 0.904376

[epoch 123: 220/307] 	 train loss: 0.240749 	 lr: 0.00033
[epoch 123: 240/307] 	 train loss: 0.008087 	 lr: 0.00033
[epoch 123: 260/307] 	 train loss: 0.221100 	 lr: 0.00033
[epoch 123: 280/307] 	 train loss: 0.222515 	 lr: 0.00033
[epoch 123: 300/307] 	 train loss: 0.454002 	 lr: 0.00033
[epoch 124:   0/307] 	 train loss: 0.266167 	 lr: 0.00033
[epoch 124:  20/307] 	 train loss: 0.449608 	 lr: 0.00033
[epoch 124:  40/307] 	 train loss: 0.071185 	 lr: 0.00033

val loss: 0.319768 	 acc: 0.903971

[epoch 124:  60/307] 	 train loss: 0.271895 	 lr: 0.00033
[epoch 124:  80/307] 	 train loss: 0.173833 	 lr: 0.00033
[epoch 124: 100/307] 	 train loss: 0.069953 	 lr: 0.00033
[epoch 124: 120/307] 	 train loss: 0.171354 	 lr: 0.00033
[epoch 124: 140/307] 	 train loss: 0.089660 	 lr: 0.00033
[epoch 124: 160/307] 	 train loss: 0.405652 	 lr: 0.00033
[epoch 124: 180/307] 	 train loss: 0.447312 	 lr: 0.00033
[epoch 124: 200/307] 	 train loss: 0.123154 	 lr: 0.00033

val loss: 0.303460 	 acc: 0.909238

[epoch 124: 220/307] 	 train loss: 0.088202 	 lr: 0.00033
[epoch 124: 240/307] 	 train loss: 0.265865 	 lr: 0.00033
[epoch 124: 260/307] 	 train loss: 0.262715 	 lr: 0.00033
[epoch 124: 280/307] 	 train loss: 0.129321 	 lr: 0.00033
[epoch 124: 300/307] 	 train loss: 0.313873 	 lr: 0.00033
[epoch 125:   0/307] 	 train loss: 0.143461 	 lr: 0.00033
[epoch 125:  20/307] 	 train loss: 0.201706 	 lr: 0.00033
[epoch 125:  40/307] 	 train loss: 0.140733 	 lr: 0.00033

val loss: 0.325201 	 acc: 0.904781

[epoch 125:  60/307] 	 train loss: 0.131853 	 lr: 0.00033
[epoch 125:  80/307] 	 train loss: 0.228678 	 lr: 0.00033
[epoch 125: 100/307] 	 train loss: 0.361206 	 lr: 0.00033
[epoch 125: 120/307] 	 train loss: 0.134917 	 lr: 0.00033
[epoch 125: 140/307] 	 train loss: 0.327813 	 lr: 0.00033
[epoch 125: 160/307] 	 train loss: 0.047653 	 lr: 0.00033
[epoch 125: 180/307] 	 train loss: 0.412757 	 lr: 0.00033
[epoch 125: 200/307] 	 train loss: 0.115033 	 lr: 0.00033

val loss: 0.330511 	 acc: 0.906807

[epoch 125: 220/307] 	 train loss: 0.223600 	 lr: 0.00033
[epoch 125: 240/307] 	 train loss: 0.195254 	 lr: 0.00033
[epoch 125: 260/307] 	 train loss: 0.268217 	 lr: 0.00033
[epoch 125: 280/307] 	 train loss: 0.173039 	 lr: 0.00033
[epoch 125: 300/307] 	 train loss: 0.112008 	 lr: 0.00033
[epoch 126:   0/307] 	 train loss: 0.167052 	 lr: 0.00033
[epoch 126:  20/307] 	 train loss: 0.501155 	 lr: 0.00033
[epoch 126:  40/307] 	 train loss: 0.307544 	 lr: 0.00033

val loss: 0.342825 	 acc: 0.902350

[epoch 126:  60/307] 	 train loss: 0.208241 	 lr: 0.00033
[epoch 126:  80/307] 	 train loss: 0.336532 	 lr: 0.00033
[epoch 126: 100/307] 	 train loss: 0.287611 	 lr: 0.00033
[epoch 126: 120/307] 	 train loss: 0.243126 	 lr: 0.00033
[epoch 126: 140/307] 	 train loss: 0.368840 	 lr: 0.00033
[epoch 126: 160/307] 	 train loss: 0.380410 	 lr: 0.00033
[epoch 126: 180/307] 	 train loss: 0.116692 	 lr: 0.00033
[epoch 126: 200/307] 	 train loss: 0.125596 	 lr: 0.00033

val loss: 0.310690 	 acc: 0.905997

[epoch 126: 220/307] 	 train loss: 0.164683 	 lr: 0.00033
[epoch 126: 240/307] 	 train loss: 0.113440 	 lr: 0.00033
[epoch 126: 260/307] 	 train loss: 0.214452 	 lr: 0.00033
[epoch 126: 280/307] 	 train loss: 0.128510 	 lr: 0.00033
[epoch 126: 300/307] 	 train loss: 0.411746 	 lr: 0.00033
[epoch 127:   0/307] 	 train loss: 0.231241 	 lr: 0.00026
[epoch 127:  20/307] 	 train loss: 0.154043 	 lr: 0.00026
[epoch 127:  40/307] 	 train loss: 0.217640 	 lr: 0.00026

val loss: 0.339275 	 acc: 0.899919

[epoch 127:  60/307] 	 train loss: 0.391712 	 lr: 0.00026
[epoch 127:  80/307] 	 train loss: 0.174714 	 lr: 0.00026
[epoch 127: 100/307] 	 train loss: 0.220722 	 lr: 0.00026
[epoch 127: 120/307] 	 train loss: 0.124091 	 lr: 0.00026
[epoch 127: 140/307] 	 train loss: 0.149413 	 lr: 0.00026
[epoch 127: 160/307] 	 train loss: 0.274613 	 lr: 0.00026
[epoch 127: 180/307] 	 train loss: 0.320687 	 lr: 0.00026
[epoch 127: 200/307] 	 train loss: 0.212653 	 lr: 0.00026

val loss: 0.318951 	 acc: 0.906807

[epoch 127: 220/307] 	 train loss: 0.030539 	 lr: 0.00026
[epoch 127: 240/307] 	 train loss: 0.168990 	 lr: 0.00026
[epoch 127: 260/307] 	 train loss: 0.160163 	 lr: 0.00026
[epoch 127: 280/307] 	 train loss: 0.218465 	 lr: 0.00026
[epoch 127: 300/307] 	 train loss: 0.175370 	 lr: 0.00026
[epoch 128:   0/307] 	 train loss: 0.098025 	 lr: 0.00026
[epoch 128:  20/307] 	 train loss: 0.078147 	 lr: 0.00026
[epoch 128:  40/307] 	 train loss: 0.265599 	 lr: 0.00026

val loss: 0.332053 	 acc: 0.899514

[epoch 128:  60/307] 	 train loss: 0.143594 	 lr: 0.00026
[epoch 128:  80/307] 	 train loss: 0.242327 	 lr: 0.00026
[epoch 128: 100/307] 	 train loss: 0.187653 	 lr: 0.00026
[epoch 128: 120/307] 	 train loss: 0.297757 	 lr: 0.00026
[epoch 128: 140/307] 	 train loss: 0.179874 	 lr: 0.00026
[epoch 128: 160/307] 	 train loss: 0.258314 	 lr: 0.00026
[epoch 128: 180/307] 	 train loss: 0.238978 	 lr: 0.00026
[epoch 128: 200/307] 	 train loss: 0.180762 	 lr: 0.00026

val loss: 0.350326 	 acc: 0.894652

[epoch 128: 220/307] 	 train loss: 0.068808 	 lr: 0.00026
[epoch 128: 240/307] 	 train loss: 0.108397 	 lr: 0.00026
[epoch 128: 260/307] 	 train loss: 0.064888 	 lr: 0.00026
[epoch 128: 280/307] 	 train loss: 0.271578 	 lr: 0.00026
[epoch 128: 300/307] 	 train loss: 0.091311 	 lr: 0.00026
[epoch 129:   0/307] 	 train loss: 0.293568 	 lr: 0.00026
[epoch 129:  20/307] 	 train loss: 0.244530 	 lr: 0.00026
[epoch 129:  40/307] 	 train loss: 0.335189 	 lr: 0.00026

val loss: 0.316440 	 acc: 0.907618

[epoch 129:  60/307] 	 train loss: 0.377269 	 lr: 0.00026
[epoch 129:  80/307] 	 train loss: 0.043851 	 lr: 0.00026
[epoch 129: 100/307] 	 train loss: 0.085072 	 lr: 0.00026
[epoch 129: 120/307] 	 train loss: 0.158608 	 lr: 0.00026
[epoch 129: 140/307] 	 train loss: 0.084069 	 lr: 0.00026
[epoch 129: 160/307] 	 train loss: 0.223130 	 lr: 0.00026
[epoch 129: 180/307] 	 train loss: 0.119470 	 lr: 0.00026
[epoch 129: 200/307] 	 train loss: 0.111386 	 lr: 0.00026

val loss: 0.314808 	 acc: 0.909238

[epoch 129: 220/307] 	 train loss: 0.470605 	 lr: 0.00026
[epoch 129: 240/307] 	 train loss: 0.319617 	 lr: 0.00026
[epoch 129: 260/307] 	 train loss: 0.218067 	 lr: 0.00026
[epoch 129: 280/307] 	 train loss: 0.084643 	 lr: 0.00026
[epoch 129: 300/307] 	 train loss: 0.167397 	 lr: 0.00026
[epoch 130:   0/307] 	 train loss: 0.168822 	 lr: 0.00026
[epoch 130:  20/307] 	 train loss: 0.424970 	 lr: 0.00026
[epoch 130:  40/307] 	 train loss: 0.570755 	 lr: 0.00026

val loss: 0.331217 	 acc: 0.907618

[epoch 130:  60/307] 	 train loss: 0.200082 	 lr: 0.00026
[epoch 130:  80/307] 	 train loss: 0.137844 	 lr: 0.00026
[epoch 130: 100/307] 	 train loss: 0.414745 	 lr: 0.00026
[epoch 130: 120/307] 	 train loss: 0.028327 	 lr: 0.00026
[epoch 130: 140/307] 	 train loss: 0.294238 	 lr: 0.00026
[epoch 130: 160/307] 	 train loss: 0.095908 	 lr: 0.00026
[epoch 130: 180/307] 	 train loss: 0.234077 	 lr: 0.00026
[epoch 130: 200/307] 	 train loss: 0.455982 	 lr: 0.00026

val loss: 0.331422 	 acc: 0.900729

[epoch 130: 220/307] 	 train loss: 0.103291 	 lr: 0.00026
[epoch 130: 240/307] 	 train loss: 0.119398 	 lr: 0.00026
[epoch 130: 260/307] 	 train loss: 0.311949 	 lr: 0.00026
[epoch 130: 280/307] 	 train loss: 0.350098 	 lr: 0.00026
[epoch 130: 300/307] 	 train loss: 0.065636 	 lr: 0.00026
[epoch 131:   0/307] 	 train loss: 0.278978 	 lr: 0.00026
[epoch 131:  20/307] 	 train loss: 0.317097 	 lr: 0.00026
[epoch 131:  40/307] 	 train loss: 0.230057 	 lr: 0.00026

val loss: 0.340503 	 acc: 0.903160

[epoch 131:  60/307] 	 train loss: 0.156597 	 lr: 0.00026
[epoch 131:  80/307] 	 train loss: 0.248622 	 lr: 0.00026
[epoch 131: 100/307] 	 train loss: 0.136129 	 lr: 0.00026
[epoch 131: 120/307] 	 train loss: 0.134477 	 lr: 0.00026
[epoch 131: 140/307] 	 train loss: 0.067322 	 lr: 0.00026
[epoch 131: 160/307] 	 train loss: 0.143962 	 lr: 0.00026
[epoch 131: 180/307] 	 train loss: 0.148699 	 lr: 0.00026

val loss: 0.332277 	 acc: 0.904781

[epoch 131: 200/307] 	 train loss: 0.198269 	 lr: 0.00026
[epoch 131: 220/307] 	 train loss: 0.221146 	 lr: 0.00026
[epoch 131: 240/307] 	 train loss: 0.251625 	 lr: 0.00026
[epoch 131: 260/307] 	 train loss: 0.045143 	 lr: 0.00026
[epoch 131: 280/307] 	 train loss: 0.222750 	 lr: 0.00026
[epoch 131: 300/307] 	 train loss: 0.231566 	 lr: 0.00026
[epoch 132:   0/307] 	 train loss: 0.283321 	 lr: 0.00026
[epoch 132:  20/307] 	 train loss: 0.267021 	 lr: 0.00026
[epoch 132:  40/307] 	 train loss: 0.137413 	 lr: 0.00026

val loss: 0.331364 	 acc: 0.908833

[epoch 132:  60/307] 	 train loss: 0.236695 	 lr: 0.00026
[epoch 132:  80/307] 	 train loss: 0.192761 	 lr: 0.00026
[epoch 132: 100/307] 	 train loss: 0.159040 	 lr: 0.00026
[epoch 132: 120/307] 	 train loss: 0.113101 	 lr: 0.00026
[epoch 132: 140/307] 	 train loss: 0.312083 	 lr: 0.00026
[epoch 132: 160/307] 	 train loss: 0.099265 	 lr: 0.00026
[epoch 132: 180/307] 	 train loss: 0.035587 	 lr: 0.00026

val loss: 0.350703 	 acc: 0.903971

[epoch 132: 200/307] 	 train loss: 0.265462 	 lr: 0.00026
[epoch 132: 220/307] 	 train loss: 0.082929 	 lr: 0.00026
[epoch 132: 240/307] 	 train loss: 0.293592 	 lr: 0.00026
[epoch 132: 260/307] 	 train loss: 0.171167 	 lr: 0.00026
[epoch 132: 280/307] 	 train loss: 0.375624 	 lr: 0.00026
[epoch 132: 300/307] 	 train loss: 0.072074 	 lr: 0.00026
[epoch 133:   0/307] 	 train loss: 0.270309 	 lr: 0.00026
[epoch 133:  20/307] 	 train loss: 0.179239 	 lr: 0.00026
[epoch 133:  40/307] 	 train loss: 0.150633 	 lr: 0.00026

val loss: 0.337055 	 acc: 0.903160

[epoch 133:  60/307] 	 train loss: 0.104606 	 lr: 0.00026
[epoch 133:  80/307] 	 train loss: 0.038597 	 lr: 0.00026
[epoch 133: 100/307] 	 train loss: 0.300721 	 lr: 0.00026
[epoch 133: 120/307] 	 train loss: 0.388578 	 lr: 0.00026
[epoch 133: 140/307] 	 train loss: 0.075006 	 lr: 0.00026
[epoch 133: 160/307] 	 train loss: 0.356005 	 lr: 0.00026
[epoch 133: 180/307] 	 train loss: 0.081826 	 lr: 0.00026

val loss: 0.336088 	 acc: 0.904781

[epoch 133: 200/307] 	 train loss: 0.160597 	 lr: 0.00026
[epoch 133: 220/307] 	 train loss: 0.172375 	 lr: 0.00026
[epoch 133: 240/307] 	 train loss: 0.269238 	 lr: 0.00026
[epoch 133: 260/307] 	 train loss: 0.107019 	 lr: 0.00026
[epoch 133: 280/307] 	 train loss: 0.050586 	 lr: 0.00026
[epoch 133: 300/307] 	 train loss: 0.197102 	 lr: 0.00026
[epoch 134:   0/307] 	 train loss: 0.199433 	 lr: 0.00026
[epoch 134:  20/307] 	 train loss: 0.341304 	 lr: 0.00026

val loss: 0.348139 	 acc: 0.897488

[epoch 134:  40/307] 	 train loss: 0.080359 	 lr: 0.00026
[epoch 134:  60/307] 	 train loss: 0.076331 	 lr: 0.00026
[epoch 134:  80/307] 	 train loss: 0.274765 	 lr: 0.00026
[epoch 134: 100/307] 	 train loss: 0.184839 	 lr: 0.00026
[epoch 134: 120/307] 	 train loss: 0.084725 	 lr: 0.00026
[epoch 134: 140/307] 	 train loss: 0.037838 	 lr: 0.00026
[epoch 134: 160/307] 	 train loss: 0.346309 	 lr: 0.00026
[epoch 134: 180/307] 	 train loss: 0.096554 	 lr: 0.00026

val loss: 0.317952 	 acc: 0.907618

[epoch 134: 200/307] 	 train loss: 0.287638 	 lr: 0.00026
[epoch 134: 220/307] 	 train loss: 0.279901 	 lr: 0.00026
[epoch 134: 240/307] 	 train loss: 0.333800 	 lr: 0.00026
[epoch 134: 260/307] 	 train loss: 0.125787 	 lr: 0.00026
[epoch 134: 280/307] 	 train loss: 0.186044 	 lr: 0.00026
[epoch 134: 300/307] 	 train loss: 0.109927 	 lr: 0.00026
[epoch 135:   0/307] 	 train loss: 0.332349 	 lr: 0.00026
[epoch 135:  20/307] 	 train loss: 0.077731 	 lr: 0.00026

val loss: 0.335115 	 acc: 0.910454

[epoch 135:  40/307] 	 train loss: 0.198470 	 lr: 0.00026
[epoch 135:  60/307] 	 train loss: 0.058595 	 lr: 0.00026
[epoch 135:  80/307] 	 train loss: 0.239364 	 lr: 0.00026
[epoch 135: 100/307] 	 train loss: 0.060052 	 lr: 0.00026
[epoch 135: 120/307] 	 train loss: 0.077530 	 lr: 0.00026
[epoch 135: 140/307] 	 train loss: 0.140673 	 lr: 0.00026
[epoch 135: 160/307] 	 train loss: 0.085636 	 lr: 0.00026
[epoch 135: 180/307] 	 train loss: 0.276831 	 lr: 0.00026

val loss: 0.335620 	 acc: 0.901945

[epoch 135: 200/307] 	 train loss: 0.026945 	 lr: 0.00026
[epoch 135: 220/307] 	 train loss: 0.015930 	 lr: 0.00026
[epoch 135: 240/307] 	 train loss: 0.090601 	 lr: 0.00026
[epoch 135: 260/307] 	 train loss: 0.216318 	 lr: 0.00026
[epoch 135: 280/307] 	 train loss: 0.217901 	 lr: 0.00026
[epoch 135: 300/307] 	 train loss: 0.112702 	 lr: 0.00026
[epoch 136:   0/307] 	 train loss: 0.173789 	 lr: 0.00026
[epoch 136:  20/307] 	 train loss: 0.232343 	 lr: 0.00026

val loss: 0.350173 	 acc: 0.901945

[epoch 136:  40/307] 	 train loss: 0.144640 	 lr: 0.00026
[epoch 136:  60/307] 	 train loss: 0.261562 	 lr: 0.00026
[epoch 136:  80/307] 	 train loss: 0.203804 	 lr: 0.00026
[epoch 136: 100/307] 	 train loss: 0.326895 	 lr: 0.00026
[epoch 136: 120/307] 	 train loss: 0.192485 	 lr: 0.00026
[epoch 136: 140/307] 	 train loss: 0.346923 	 lr: 0.00026
[epoch 136: 160/307] 	 train loss: 0.112880 	 lr: 0.00026
[epoch 136: 180/307] 	 train loss: 0.189118 	 lr: 0.00026

val loss: 0.338537 	 acc: 0.906402

[epoch 136: 200/307] 	 train loss: 0.090544 	 lr: 0.00026
[epoch 136: 220/307] 	 train loss: 0.020392 	 lr: 0.00026
[epoch 136: 240/307] 	 train loss: 0.132164 	 lr: 0.00026
[epoch 136: 260/307] 	 train loss: 0.222438 	 lr: 0.00026
[epoch 136: 280/307] 	 train loss: 0.249553 	 lr: 0.00026
[epoch 136: 300/307] 	 train loss: 0.304913 	 lr: 0.00026
[epoch 137:   0/307] 	 train loss: 0.176763 	 lr: 0.00026
[epoch 137:  20/307] 	 train loss: 0.177152 	 lr: 0.00026

val loss: 0.317949 	 acc: 0.905997

[epoch 137:  40/307] 	 train loss: 0.144384 	 lr: 0.00026
[epoch 137:  60/307] 	 train loss: 0.213879 	 lr: 0.00026
[epoch 137:  80/307] 	 train loss: 0.032445 	 lr: 0.00026
[epoch 137: 100/307] 	 train loss: 0.391635 	 lr: 0.00026
[epoch 137: 120/307] 	 train loss: 0.081298 	 lr: 0.00026
[epoch 137: 140/307] 	 train loss: 0.051655 	 lr: 0.00026
[epoch 137: 160/307] 	 train loss: 0.036938 	 lr: 0.00026
[epoch 137: 180/307] 	 train loss: 0.091004 	 lr: 0.00026

val loss: 0.336863 	 acc: 0.899514

[epoch 137: 200/307] 	 train loss: 0.371552 	 lr: 0.00026
[epoch 137: 220/307] 	 train loss: 0.143739 	 lr: 0.00026
[epoch 137: 240/307] 	 train loss: 0.059825 	 lr: 0.00026
[epoch 137: 260/307] 	 train loss: 0.244804 	 lr: 0.00026
[epoch 137: 280/307] 	 train loss: 0.211091 	 lr: 0.00026
[epoch 137: 300/307] 	 train loss: 0.118582 	 lr: 0.00026
[epoch 138:   0/307] 	 train loss: 0.186177 	 lr: 0.00026
[epoch 138:  20/307] 	 train loss: 0.255313 	 lr: 0.00026

val loss: 0.340347 	 acc: 0.905592

[epoch 138:  40/307] 	 train loss: 0.042029 	 lr: 0.00026
[epoch 138:  60/307] 	 train loss: 0.098193 	 lr: 0.00026
[epoch 138:  80/307] 	 train loss: 0.136880 	 lr: 0.00026
[epoch 138: 100/307] 	 train loss: 0.078394 	 lr: 0.00026
[epoch 138: 120/307] 	 train loss: 0.383309 	 lr: 0.00026
[epoch 138: 140/307] 	 train loss: 0.192034 	 lr: 0.00026
[epoch 138: 160/307] 	 train loss: 0.119801 	 lr: 0.00026
[epoch 138: 180/307] 	 train loss: 0.118370 	 lr: 0.00026

val loss: 0.338309 	 acc: 0.904781

[epoch 138: 200/307] 	 train loss: 0.214618 	 lr: 0.00026
[epoch 138: 220/307] 	 train loss: 0.137543 	 lr: 0.00026
[epoch 138: 240/307] 	 train loss: 0.075403 	 lr: 0.00026
[epoch 138: 260/307] 	 train loss: 0.324251 	 lr: 0.00026
[epoch 138: 280/307] 	 train loss: 0.151883 	 lr: 0.00026
[epoch 138: 300/307] 	 train loss: 0.318380 	 lr: 0.00026
[epoch 139:   0/307] 	 train loss: 0.273794 	 lr: 0.00026
[epoch 139:  20/307] 	 train loss: 0.114129 	 lr: 0.00026

val loss: 0.349109 	 acc: 0.906402

[epoch 139:  40/307] 	 train loss: 0.206978 	 lr: 0.00026
[epoch 139:  60/307] 	 train loss: 0.118661 	 lr: 0.00026
[epoch 139:  80/307] 	 train loss: 0.084906 	 lr: 0.00026
[epoch 139: 100/307] 	 train loss: 0.101007 	 lr: 0.00026
[epoch 139: 120/307] 	 train loss: 0.225469 	 lr: 0.00026
[epoch 139: 140/307] 	 train loss: 0.359570 	 lr: 0.00026
[epoch 139: 160/307] 	 train loss: 0.411928 	 lr: 0.00026
[epoch 139: 180/307] 	 train loss: 0.586596 	 lr: 0.00026

val loss: 0.367470 	 acc: 0.900324

[epoch 139: 200/307] 	 train loss: 0.159830 	 lr: 0.00026
[epoch 139: 220/307] 	 train loss: 0.754008 	 lr: 0.00026
[epoch 139: 240/307] 	 train loss: 0.184993 	 lr: 0.00026
[epoch 139: 260/307] 	 train loss: 0.387934 	 lr: 0.00026
[epoch 139: 280/307] 	 train loss: 0.222773 	 lr: 0.00026
[epoch 139: 300/307] 	 train loss: 0.111793 	 lr: 0.00026
[epoch 140:   0/307] 	 train loss: 0.075756 	 lr: 0.00026
[epoch 140:  20/307] 	 train loss: 0.117604 	 lr: 0.00026

val loss: 0.333133 	 acc: 0.904376

[epoch 140:  40/307] 	 train loss: 0.106217 	 lr: 0.00026
[epoch 140:  60/307] 	 train loss: 0.113050 	 lr: 0.00026
[epoch 140:  80/307] 	 train loss: 0.154078 	 lr: 0.00026
[epoch 140: 100/307] 	 train loss: 0.154187 	 lr: 0.00026
[epoch 140: 120/307] 	 train loss: 0.233816 	 lr: 0.00026
[epoch 140: 140/307] 	 train loss: 0.137368 	 lr: 0.00026
[epoch 140: 160/307] 	 train loss: 0.082922 	 lr: 0.00026
[epoch 140: 180/307] 	 train loss: 0.162614 	 lr: 0.00026

val loss: 0.335914 	 acc: 0.905592

[epoch 140: 200/307] 	 train loss: 0.135038 	 lr: 0.00026
[epoch 140: 220/307] 	 train loss: 0.242265 	 lr: 0.00026
[epoch 140: 240/307] 	 train loss: 0.160721 	 lr: 0.00026
[epoch 140: 260/307] 	 train loss: 0.139085 	 lr: 0.00026
[epoch 140: 280/307] 	 train loss: 0.126965 	 lr: 0.00026
[epoch 140: 300/307] 	 train loss: 0.156363 	 lr: 0.00026
[epoch 141:   0/307] 	 train loss: 0.244677 	 lr: 0.00026
[epoch 141:  20/307] 	 train loss: 0.384679 	 lr: 0.00026

val loss: 0.341261 	 acc: 0.906807

[epoch 141:  40/307] 	 train loss: 0.145691 	 lr: 0.00026
[epoch 141:  60/307] 	 train loss: 0.165494 	 lr: 0.00026
[epoch 141:  80/307] 	 train loss: 0.245399 	 lr: 0.00026
[epoch 141: 100/307] 	 train loss: 0.268325 	 lr: 0.00026
[epoch 141: 120/307] 	 train loss: 0.086351 	 lr: 0.00026
[epoch 141: 140/307] 	 train loss: 0.261541 	 lr: 0.00026
[epoch 141: 160/307] 	 train loss: 0.102459 	 lr: 0.00026

val loss: 0.342906 	 acc: 0.899919

[epoch 141: 180/307] 	 train loss: 0.120382 	 lr: 0.00026
[epoch 141: 200/307] 	 train loss: 0.259719 	 lr: 0.00026
[epoch 141: 220/307] 	 train loss: 0.101349 	 lr: 0.00026
[epoch 141: 240/307] 	 train loss: 0.150538 	 lr: 0.00026
[epoch 141: 260/307] 	 train loss: 0.147940 	 lr: 0.00026
[epoch 141: 280/307] 	 train loss: 0.445716 	 lr: 0.00026
[epoch 141: 300/307] 	 train loss: 0.040494 	 lr: 0.00026
[epoch 142:   0/307] 	 train loss: 0.246543 	 lr: 0.00026
[epoch 142:  20/307] 	 train loss: 0.037162 	 lr: 0.00026

val loss: 0.331573 	 acc: 0.912480

[epoch 142:  40/307] 	 train loss: 0.181674 	 lr: 0.00026
[epoch 142:  60/307] 	 train loss: 0.111397 	 lr: 0.00026
[epoch 142:  80/307] 	 train loss: 0.262781 	 lr: 0.00026
[epoch 142: 100/307] 	 train loss: 0.177096 	 lr: 0.00026
[epoch 142: 120/307] 	 train loss: 0.205679 	 lr: 0.00026
[epoch 142: 140/307] 	 train loss: 0.168373 	 lr: 0.00026
[epoch 142: 160/307] 	 train loss: 0.078663 	 lr: 0.00026

val loss: 0.326841 	 acc: 0.901135

[epoch 142: 180/307] 	 train loss: 0.175855 	 lr: 0.00026
[epoch 142: 200/307] 	 train loss: 0.245736 	 lr: 0.00026
[epoch 142: 220/307] 	 train loss: 0.171326 	 lr: 0.00026
[epoch 142: 240/307] 	 train loss: 0.038183 	 lr: 0.00026
[epoch 142: 260/307] 	 train loss: 0.089019 	 lr: 0.00026
[epoch 142: 280/307] 	 train loss: 0.110699 	 lr: 0.00026
[epoch 142: 300/307] 	 train loss: 0.144172 	 lr: 0.00026
[epoch 143:   0/307] 	 train loss: 0.039266 	 lr: 0.00026
[epoch 143:  20/307] 	 train loss: 0.386504 	 lr: 0.00026

val loss: 0.328752 	 acc: 0.906402

[epoch 143:  40/307] 	 train loss: 0.123271 	 lr: 0.00026
[epoch 143:  60/307] 	 train loss: 0.113287 	 lr: 0.00026
[epoch 143:  80/307] 	 train loss: 0.259457 	 lr: 0.00026
[epoch 143: 100/307] 	 train loss: 0.136492 	 lr: 0.00026
[epoch 143: 120/307] 	 train loss: 0.236024 	 lr: 0.00026
[epoch 143: 140/307] 	 train loss: 0.223182 	 lr: 0.00026
[epoch 143: 160/307] 	 train loss: 0.225866 	 lr: 0.00026

val loss: 0.353108 	 acc: 0.905592

[epoch 143: 180/307] 	 train loss: 0.069161 	 lr: 0.00026
[epoch 143: 200/307] 	 train loss: 0.150255 	 lr: 0.00026
[epoch 143: 220/307] 	 train loss: 0.085672 	 lr: 0.00026
[epoch 143: 240/307] 	 train loss: 0.165557 	 lr: 0.00026
[epoch 143: 260/307] 	 train loss: 0.211414 	 lr: 0.00026
[epoch 143: 280/307] 	 train loss: 0.125576 	 lr: 0.00026
[epoch 143: 300/307] 	 train loss: 0.328806 	 lr: 0.00026
[epoch 144:   0/307] 	 train loss: 0.074874 	 lr: 0.00026

val loss: 0.341058 	 acc: 0.898703

[epoch 144:  20/307] 	 train loss: 0.105602 	 lr: 0.00026
[epoch 144:  40/307] 	 train loss: 0.231364 	 lr: 0.00026
[epoch 144:  60/307] 	 train loss: 0.216013 	 lr: 0.00026
[epoch 144:  80/307] 	 train loss: 0.201011 	 lr: 0.00026
[epoch 144: 100/307] 	 train loss: 0.118453 	 lr: 0.00026
[epoch 144: 120/307] 	 train loss: 0.236137 	 lr: 0.00026
[epoch 144: 140/307] 	 train loss: 0.197242 	 lr: 0.00026
[epoch 144: 160/307] 	 train loss: 0.043423 	 lr: 0.00026

val loss: 0.321613 	 acc: 0.908833

[epoch 144: 180/307] 	 train loss: 0.077783 	 lr: 0.00026
[epoch 144: 200/307] 	 train loss: 0.179410 	 lr: 0.00026
[epoch 144: 220/307] 	 train loss: 0.170926 	 lr: 0.00026
[epoch 144: 240/307] 	 train loss: 0.168840 	 lr: 0.00026
[epoch 144: 260/307] 	 train loss: 0.097586 	 lr: 0.00026
[epoch 144: 280/307] 	 train loss: 0.295880 	 lr: 0.00026
[epoch 144: 300/307] 	 train loss: 0.247310 	 lr: 0.00026
[epoch 145:   0/307] 	 train loss: 0.264719 	 lr: 0.00026

val loss: 0.324433 	 acc: 0.905997

[epoch 145:  20/307] 	 train loss: 0.069755 	 lr: 0.00026
[epoch 145:  40/307] 	 train loss: 0.078543 	 lr: 0.00026
[epoch 145:  60/307] 	 train loss: 0.083916 	 lr: 0.00026
[epoch 145:  80/307] 	 train loss: 0.279416 	 lr: 0.00026
[epoch 145: 100/307] 	 train loss: 0.097065 	 lr: 0.00026
[epoch 145: 120/307] 	 train loss: 0.054538 	 lr: 0.00026
[epoch 145: 140/307] 	 train loss: 0.150831 	 lr: 0.00026
[epoch 145: 160/307] 	 train loss: 0.152347 	 lr: 0.00026

val loss: 0.316363 	 acc: 0.909643

[epoch 145: 180/307] 	 train loss: 0.384094 	 lr: 0.00026
[epoch 145: 200/307] 	 train loss: 0.124079 	 lr: 0.00026
[epoch 145: 220/307] 	 train loss: 0.374848 	 lr: 0.00026
[epoch 145: 240/307] 	 train loss: 0.218277 	 lr: 0.00026
[epoch 145: 260/307] 	 train loss: 0.205530 	 lr: 0.00026
[epoch 145: 280/307] 	 train loss: 0.083881 	 lr: 0.00026
[epoch 145: 300/307] 	 train loss: 0.275351 	 lr: 0.00026
[epoch 146:   0/307] 	 train loss: 0.397102 	 lr: 0.00026

val loss: 0.338019 	 acc: 0.901135

[epoch 146:  20/307] 	 train loss: 0.072979 	 lr: 0.00026
[epoch 146:  40/307] 	 train loss: 0.179392 	 lr: 0.00026
[epoch 146:  60/307] 	 train loss: 0.357684 	 lr: 0.00026
[epoch 146:  80/307] 	 train loss: 0.124280 	 lr: 0.00026
[epoch 146: 100/307] 	 train loss: 0.280420 	 lr: 0.00026
[epoch 146: 120/307] 	 train loss: 0.161671 	 lr: 0.00026
[epoch 146: 140/307] 	 train loss: 0.149179 	 lr: 0.00026
[epoch 146: 160/307] 	 train loss: 0.018588 	 lr: 0.00026

val loss: 0.332658 	 acc: 0.902350

[epoch 146: 180/307] 	 train loss: 0.255933 	 lr: 0.00026
[epoch 146: 200/307] 	 train loss: 0.141077 	 lr: 0.00026
[epoch 146: 220/307] 	 train loss: 0.178034 	 lr: 0.00026
[epoch 146: 240/307] 	 train loss: 0.036048 	 lr: 0.00026
[epoch 146: 260/307] 	 train loss: 0.113999 	 lr: 0.00026
[epoch 146: 280/307] 	 train loss: 0.088675 	 lr: 0.00026
[epoch 146: 300/307] 	 train loss: 0.178788 	 lr: 0.00026
[epoch 147:   0/307] 	 train loss: 0.108780 	 lr: 0.00026

val loss: 0.332467 	 acc: 0.903971

[epoch 147:  20/307] 	 train loss: 0.131162 	 lr: 0.00026
[epoch 147:  40/307] 	 train loss: 0.350291 	 lr: 0.00026
[epoch 147:  60/307] 	 train loss: 0.359085 	 lr: 0.00026
[epoch 147:  80/307] 	 train loss: 0.173843 	 lr: 0.00026
[epoch 147: 100/307] 	 train loss: 0.162039 	 lr: 0.00026
[epoch 147: 120/307] 	 train loss: 0.285654 	 lr: 0.00026
[epoch 147: 140/307] 	 train loss: 0.136609 	 lr: 0.00026
[epoch 147: 160/307] 	 train loss: 0.082059 	 lr: 0.00026

val loss: 0.314174 	 acc: 0.907618

[epoch 147: 180/307] 	 train loss: 0.218715 	 lr: 0.00026
[epoch 147: 200/307] 	 train loss: 0.149607 	 lr: 0.00026
[epoch 147: 220/307] 	 train loss: 0.105360 	 lr: 0.00026
[epoch 147: 240/307] 	 train loss: 0.249305 	 lr: 0.00026
[epoch 147: 260/307] 	 train loss: 0.237280 	 lr: 0.00026
[epoch 147: 280/307] 	 train loss: 0.092508 	 lr: 0.00026
[epoch 147: 300/307] 	 train loss: 0.194658 	 lr: 0.00026
[epoch 148:   0/307] 	 train loss: 0.043598 	 lr: 0.00021

val loss: 0.335272 	 acc: 0.899514

[epoch 148:  20/307] 	 train loss: 0.139385 	 lr: 0.00021
[epoch 148:  40/307] 	 train loss: 0.588026 	 lr: 0.00021
[epoch 148:  60/307] 	 train loss: 0.142837 	 lr: 0.00021
[epoch 148:  80/307] 	 train loss: 0.104569 	 lr: 0.00021
[epoch 148: 100/307] 	 train loss: 0.340277 	 lr: 0.00021
[epoch 148: 120/307] 	 train loss: 0.342371 	 lr: 0.00021
[epoch 148: 140/307] 	 train loss: 0.345548 	 lr: 0.00021
[epoch 148: 160/307] 	 train loss: 0.267154 	 lr: 0.00021

val loss: 0.325285 	 acc: 0.902755

[epoch 148: 180/307] 	 train loss: 0.251591 	 lr: 0.00021
[epoch 148: 200/307] 	 train loss: 0.092065 	 lr: 0.00021
[epoch 148: 220/307] 	 train loss: 0.221314 	 lr: 0.00021
[epoch 148: 240/307] 	 train loss: 0.475492 	 lr: 0.00021
[epoch 148: 260/307] 	 train loss: 0.147780 	 lr: 0.00021
[epoch 148: 280/307] 	 train loss: 0.357342 	 lr: 0.00021
[epoch 148: 300/307] 	 train loss: 0.116231 	 lr: 0.00021
[epoch 149:   0/307] 	 train loss: 0.107955 	 lr: 0.00021

val loss: 0.304707 	 acc: 0.913695

saved model with accuracy  0.9136952998379254
[epoch 149:  20/307] 	 train loss: 0.150212 	 lr: 0.00021
[epoch 149:  40/307] 	 train loss: 0.037489 	 lr: 0.00021
[epoch 149:  60/307] 	 train loss: 0.162764 	 lr: 0.00021
[epoch 149:  80/307] 	 train loss: 0.157921 	 lr: 0.00021
[epoch 149: 100/307] 	 train loss: 0.062999 	 lr: 0.00021
[epoch 149: 120/307] 	 train loss: 0.319260 	 lr: 0.00021
[epoch 149: 140/307] 	 train loss: 0.071384 	 lr: 0.00021
[epoch 149: 160/307] 	 train loss: 0.386455 	 lr: 0.00021

val loss: 0.330204 	 acc: 0.905592

[epoch 149: 180/307] 	 train loss: 0.086162 	 lr: 0.00021
[epoch 149: 200/307] 	 train loss: 0.198382 	 lr: 0.00021
[epoch 149: 220/307] 	 train loss: 0.205974 	 lr: 0.00021
[epoch 149: 240/307] 	 train loss: 0.110169 	 lr: 0.00021
[epoch 149: 260/307] 	 train loss: 0.122187 	 lr: 0.00021
[epoch 149: 280/307] 	 train loss: 0.104908 	 lr: 0.00021
[epoch 149: 300/307] 	 train loss: 0.073966 	 lr: 0.00021
[epoch 150:   0/307] 	 train loss: 0.060898 	 lr: 0.00021

val loss: 0.336221 	 acc: 0.908023

[epoch 150:  20/307] 	 train loss: 0.256543 	 lr: 0.00021
[epoch 150:  40/307] 	 train loss: 0.244943 	 lr: 0.00021
[epoch 150:  60/307] 	 train loss: 0.055770 	 lr: 0.00021
[epoch 150:  80/307] 	 train loss: 0.033939 	 lr: 0.00021
[epoch 150: 100/307] 	 train loss: 0.443048 	 lr: 0.00021
[epoch 150: 120/307] 	 train loss: 0.439428 	 lr: 0.00021
[epoch 150: 140/307] 	 train loss: 0.116989 	 lr: 0.00021
[epoch 150: 160/307] 	 train loss: 0.123491 	 lr: 0.00021

val loss: 0.318900 	 acc: 0.912480

[epoch 150: 180/307] 	 train loss: 0.224558 	 lr: 0.00021
[epoch 150: 200/307] 	 train loss: 0.376449 	 lr: 0.00021
[epoch 150: 220/307] 	 train loss: 0.127347 	 lr: 0.00021
[epoch 150: 240/307] 	 train loss: 0.179062 	 lr: 0.00021
[epoch 150: 260/307] 	 train loss: 0.125159 	 lr: 0.00021
[epoch 150: 280/307] 	 train loss: 0.346143 	 lr: 0.00021
[epoch 150: 300/307] 	 train loss: 0.133377 	 lr: 0.00021
[epoch 151:   0/307] 	 train loss: 0.037134 	 lr: 0.00021

val loss: 0.335514 	 acc: 0.905997

[epoch 151:  20/307] 	 train loss: 0.065852 	 lr: 0.00021
[epoch 151:  40/307] 	 train loss: 0.103494 	 lr: 0.00021
[epoch 151:  60/307] 	 train loss: 0.229940 	 lr: 0.00021
[epoch 151:  80/307] 	 train loss: 0.058593 	 lr: 0.00021
[epoch 151: 100/307] 	 train loss: 0.136255 	 lr: 0.00021
[epoch 151: 120/307] 	 train loss: 0.128508 	 lr: 0.00021
[epoch 151: 140/307] 	 train loss: 0.123248 	 lr: 0.00021

val loss: 0.322323 	 acc: 0.905592

[epoch 151: 160/307] 	 train loss: 0.397382 	 lr: 0.00021
[epoch 151: 180/307] 	 train loss: 0.220935 	 lr: 0.00021
[epoch 151: 200/307] 	 train loss: 0.322195 	 lr: 0.00021
[epoch 151: 220/307] 	 train loss: 0.030692 	 lr: 0.00021
[epoch 151: 240/307] 	 train loss: 0.146035 	 lr: 0.00021
[epoch 151: 260/307] 	 train loss: 0.137620 	 lr: 0.00021
[epoch 151: 280/307] 	 train loss: 0.549648 	 lr: 0.00021
[epoch 151: 300/307] 	 train loss: 0.111114 	 lr: 0.00021
[epoch 152:   0/307] 	 train loss: 0.092485 	 lr: 0.00021

val loss: 0.326031 	 acc: 0.906402

[epoch 152:  20/307] 	 train loss: 0.209204 	 lr: 0.00021
[epoch 152:  40/307] 	 train loss: 0.273305 	 lr: 0.00021
[epoch 152:  60/307] 	 train loss: 0.279329 	 lr: 0.00021
[epoch 152:  80/307] 	 train loss: 0.247892 	 lr: 0.00021
[epoch 152: 100/307] 	 train loss: 0.091901 	 lr: 0.00021
[epoch 152: 120/307] 	 train loss: 0.269728 	 lr: 0.00021
[epoch 152: 140/307] 	 train loss: 0.274548 	 lr: 0.00021

val loss: 0.346441 	 acc: 0.901540

[epoch 152: 160/307] 	 train loss: 0.196213 	 lr: 0.00021
[epoch 152: 180/307] 	 train loss: 0.353223 	 lr: 0.00021
[epoch 152: 200/307] 	 train loss: 0.377851 	 lr: 0.00021
[epoch 152: 220/307] 	 train loss: 0.155892 	 lr: 0.00021
[epoch 152: 240/307] 	 train loss: 0.280770 	 lr: 0.00021
[epoch 152: 260/307] 	 train loss: 0.113888 	 lr: 0.00021
[epoch 152: 280/307] 	 train loss: 0.051572 	 lr: 0.00021
[epoch 152: 300/307] 	 train loss: 0.188348 	 lr: 0.00021
[epoch 153:   0/307] 	 train loss: 0.306768 	 lr: 0.00021

val loss: 0.338549 	 acc: 0.907212

[epoch 153:  20/307] 	 train loss: 0.024381 	 lr: 0.00021
[epoch 153:  40/307] 	 train loss: 0.220937 	 lr: 0.00021
[epoch 153:  60/307] 	 train loss: 0.231490 	 lr: 0.00021
[epoch 153:  80/307] 	 train loss: 0.438251 	 lr: 0.00021
[epoch 153: 100/307] 	 train loss: 0.138423 	 lr: 0.00021
[epoch 153: 120/307] 	 train loss: 0.224470 	 lr: 0.00021
[epoch 153: 140/307] 	 train loss: 0.170018 	 lr: 0.00021

val loss: 0.328302 	 acc: 0.908428

[epoch 153: 160/307] 	 train loss: 0.173863 	 lr: 0.00021
[epoch 153: 180/307] 	 train loss: 0.190933 	 lr: 0.00021
[epoch 153: 200/307] 	 train loss: 0.269165 	 lr: 0.00021
[epoch 153: 220/307] 	 train loss: 0.272936 	 lr: 0.00021
[epoch 153: 240/307] 	 train loss: 0.281416 	 lr: 0.00021
[epoch 153: 260/307] 	 train loss: 0.210449 	 lr: 0.00021
[epoch 153: 280/307] 	 train loss: 0.150676 	 lr: 0.00021
[epoch 153: 300/307] 	 train loss: 0.347957 	 lr: 0.00021

val loss: 0.328125 	 acc: 0.903971

[epoch 154:   0/307] 	 train loss: 0.240803 	 lr: 0.00021
[epoch 154:  20/307] 	 train loss: 0.086830 	 lr: 0.00021
[epoch 154:  40/307] 	 train loss: 0.162830 	 lr: 0.00021
[epoch 154:  60/307] 	 train loss: 0.376754 	 lr: 0.00021
[epoch 154:  80/307] 	 train loss: 0.157035 	 lr: 0.00021
[epoch 154: 100/307] 	 train loss: 0.059446 	 lr: 0.00021
[epoch 154: 120/307] 	 train loss: 0.148188 	 lr: 0.00021
[epoch 154: 140/307] 	 train loss: 0.083926 	 lr: 0.00021

val loss: 0.342177 	 acc: 0.905592

[epoch 154: 160/307] 	 train loss: 0.132297 	 lr: 0.00021
[epoch 154: 180/307] 	 train loss: 0.076820 	 lr: 0.00021
[epoch 154: 200/307] 	 train loss: 0.154796 	 lr: 0.00021
[epoch 154: 220/307] 	 train loss: 0.198868 	 lr: 0.00021
[epoch 154: 240/307] 	 train loss: 0.103931 	 lr: 0.00021
[epoch 154: 260/307] 	 train loss: 0.093773 	 lr: 0.00021
[epoch 154: 280/307] 	 train loss: 0.302188 	 lr: 0.00021
[epoch 154: 300/307] 	 train loss: 0.086387 	 lr: 0.00021

val loss: 0.335673 	 acc: 0.909238

[epoch 155:   0/307] 	 train loss: 0.260409 	 lr: 0.00021
[epoch 155:  20/307] 	 train loss: 0.213338 	 lr: 0.00021
[epoch 155:  40/307] 	 train loss: 0.179489 	 lr: 0.00021
[epoch 155:  60/307] 	 train loss: 0.150402 	 lr: 0.00021
[epoch 155:  80/307] 	 train loss: 0.254364 	 lr: 0.00021
[epoch 155: 100/307] 	 train loss: 0.262156 	 lr: 0.00021
[epoch 155: 120/307] 	 train loss: 0.295357 	 lr: 0.00021
[epoch 155: 140/307] 	 train loss: 0.236211 	 lr: 0.00021

val loss: 0.327605 	 acc: 0.909238

[epoch 155: 160/307] 	 train loss: 0.137654 	 lr: 0.00021
[epoch 155: 180/307] 	 train loss: 0.074970 	 lr: 0.00021
[epoch 155: 200/307] 	 train loss: 0.273839 	 lr: 0.00021
[epoch 155: 220/307] 	 train loss: 0.234886 	 lr: 0.00021
[epoch 155: 240/307] 	 train loss: 0.532026 	 lr: 0.00021
[epoch 155: 260/307] 	 train loss: 0.139028 	 lr: 0.00021
[epoch 155: 280/307] 	 train loss: 0.299336 	 lr: 0.00021
[epoch 155: 300/307] 	 train loss: 0.077822 	 lr: 0.00021

val loss: 0.321640 	 acc: 0.909643

[epoch 156:   0/307] 	 train loss: 0.076700 	 lr: 0.00021
[epoch 156:  20/307] 	 train loss: 0.070469 	 lr: 0.00021
[epoch 156:  40/307] 	 train loss: 0.179470 	 lr: 0.00021
[epoch 156:  60/307] 	 train loss: 0.117738 	 lr: 0.00021
[epoch 156:  80/307] 	 train loss: 0.229934 	 lr: 0.00021
[epoch 156: 100/307] 	 train loss: 0.059120 	 lr: 0.00021
[epoch 156: 120/307] 	 train loss: 0.125209 	 lr: 0.00021
[epoch 156: 140/307] 	 train loss: 0.259538 	 lr: 0.00021

val loss: 0.348525 	 acc: 0.906807

[epoch 156: 160/307] 	 train loss: 0.128402 	 lr: 0.00021
[epoch 156: 180/307] 	 train loss: 0.100994 	 lr: 0.00021
[epoch 156: 200/307] 	 train loss: 0.145981 	 lr: 0.00021
[epoch 156: 220/307] 	 train loss: 0.383969 	 lr: 0.00021
[epoch 156: 240/307] 	 train loss: 0.118214 	 lr: 0.00021
[epoch 156: 260/307] 	 train loss: 0.178530 	 lr: 0.00021
[epoch 156: 280/307] 	 train loss: 0.324173 	 lr: 0.00021
[epoch 156: 300/307] 	 train loss: 0.307078 	 lr: 0.00021

val loss: 0.325307 	 acc: 0.903566

[epoch 157:   0/307] 	 train loss: 0.221730 	 lr: 0.00021
[epoch 157:  20/307] 	 train loss: 0.200137 	 lr: 0.00021
[epoch 157:  40/307] 	 train loss: 0.203181 	 lr: 0.00021
[epoch 157:  60/307] 	 train loss: 0.140719 	 lr: 0.00021
[epoch 157:  80/307] 	 train loss: 0.121423 	 lr: 0.00021
[epoch 157: 100/307] 	 train loss: 0.331859 	 lr: 0.00021
[epoch 157: 120/307] 	 train loss: 0.107477 	 lr: 0.00021
[epoch 157: 140/307] 	 train loss: 0.095820 	 lr: 0.00021

val loss: 0.316188 	 acc: 0.907618

[epoch 157: 160/307] 	 train loss: 0.301161 	 lr: 0.00021
[epoch 157: 180/307] 	 train loss: 0.279085 	 lr: 0.00021
[epoch 157: 200/307] 	 train loss: 0.099999 	 lr: 0.00021
[epoch 157: 220/307] 	 train loss: 0.142401 	 lr: 0.00021
[epoch 157: 240/307] 	 train loss: 0.128350 	 lr: 0.00021
[epoch 157: 260/307] 	 train loss: 0.090797 	 lr: 0.00021
[epoch 157: 280/307] 	 train loss: 0.296646 	 lr: 0.00021

val loss: 0.350529 	 acc: 0.900729

[epoch 157: 300/307] 	 train loss: 0.665452 	 lr: 0.00021
[epoch 158:   0/307] 	 train loss: 0.067984 	 lr: 0.00021
[epoch 158:  20/307] 	 train loss: 0.076573 	 lr: 0.00021
[epoch 158:  40/307] 	 train loss: 0.199525 	 lr: 0.00021
[epoch 158:  60/307] 	 train loss: 0.221296 	 lr: 0.00021
[epoch 158:  80/307] 	 train loss: 0.104433 	 lr: 0.00021
[epoch 158: 100/307] 	 train loss: 0.113720 	 lr: 0.00021
[epoch 158: 120/307] 	 train loss: 0.192936 	 lr: 0.00021
[epoch 158: 140/307] 	 train loss: 0.157640 	 lr: 0.00021

val loss: 0.341780 	 acc: 0.906402

[epoch 158: 160/307] 	 train loss: 0.221146 	 lr: 0.00021
[epoch 158: 180/307] 	 train loss: 0.416909 	 lr: 0.00021
[epoch 158: 200/307] 	 train loss: 0.238113 	 lr: 0.00021
[epoch 158: 220/307] 	 train loss: 0.297396 	 lr: 0.00021
[epoch 158: 240/307] 	 train loss: 0.170654 	 lr: 0.00021
[epoch 158: 260/307] 	 train loss: 0.224608 	 lr: 0.00021
[epoch 158: 280/307] 	 train loss: 0.194155 	 lr: 0.00021

val loss: 0.331754 	 acc: 0.905186

[epoch 158: 300/307] 	 train loss: 0.212879 	 lr: 0.00021
[epoch 159:   0/307] 	 train loss: 0.187885 	 lr: 0.00021
[epoch 159:  20/307] 	 train loss: 0.138241 	 lr: 0.00021
[epoch 159:  40/307] 	 train loss: 0.077019 	 lr: 0.00021
[epoch 159:  60/307] 	 train loss: 0.091868 	 lr: 0.00021
[epoch 159:  80/307] 	 train loss: 0.081082 	 lr: 0.00021
[epoch 159: 100/307] 	 train loss: 0.222337 	 lr: 0.00021
[epoch 159: 120/307] 	 train loss: 0.270184 	 lr: 0.00021
[epoch 159: 140/307] 	 train loss: 0.215271 	 lr: 0.00021

val loss: 0.364546 	 acc: 0.900324

[epoch 159: 160/307] 	 train loss: 0.201724 	 lr: 0.00021
[epoch 159: 180/307] 	 train loss: 0.351371 	 lr: 0.00021
[epoch 159: 200/307] 	 train loss: 0.170940 	 lr: 0.00021
[epoch 159: 220/307] 	 train loss: 0.178765 	 lr: 0.00021
[epoch 159: 240/307] 	 train loss: 0.326670 	 lr: 0.00021
[epoch 159: 260/307] 	 train loss: 0.050635 	 lr: 0.00021
[epoch 159: 280/307] 	 train loss: 0.074598 	 lr: 0.00021

val loss: 0.324334 	 acc: 0.907618

[epoch 159: 300/307] 	 train loss: 0.102874 	 lr: 0.00021
[epoch 160:   0/307] 	 train loss: 0.143104 	 lr: 0.00021
[epoch 160:  20/307] 	 train loss: 0.094330 	 lr: 0.00021
[epoch 160:  40/307] 	 train loss: 0.179903 	 lr: 0.00021
[epoch 160:  60/307] 	 train loss: 0.069757 	 lr: 0.00021
[epoch 160:  80/307] 	 train loss: 0.037594 	 lr: 0.00021
[epoch 160: 100/307] 	 train loss: 0.155391 	 lr: 0.00021
[epoch 160: 120/307] 	 train loss: 0.188845 	 lr: 0.00021
[epoch 160: 140/307] 	 train loss: 0.180191 	 lr: 0.00021

val loss: 0.312532 	 acc: 0.903971

[epoch 160: 160/307] 	 train loss: 0.239278 	 lr: 0.00021
[epoch 160: 180/307] 	 train loss: 0.294475 	 lr: 0.00021
[epoch 160: 200/307] 	 train loss: 0.109947 	 lr: 0.00021
[epoch 160: 220/307] 	 train loss: 0.268371 	 lr: 0.00021
[epoch 160: 240/307] 	 train loss: 0.121053 	 lr: 0.00021
[epoch 160: 260/307] 	 train loss: 0.165799 	 lr: 0.00021
[epoch 160: 280/307] 	 train loss: 0.237625 	 lr: 0.00021

val loss: 0.318537 	 acc: 0.905592

[epoch 160: 300/307] 	 train loss: 0.219040 	 lr: 0.00021
[epoch 161:   0/307] 	 train loss: 0.153344 	 lr: 0.00021
[epoch 161:  20/307] 	 train loss: 0.010899 	 lr: 0.00021
[epoch 161:  40/307] 	 train loss: 0.158235 	 lr: 0.00021
[epoch 161:  60/307] 	 train loss: 0.098234 	 lr: 0.00021
[epoch 161:  80/307] 	 train loss: 0.067715 	 lr: 0.00021
[epoch 161: 100/307] 	 train loss: 0.292408 	 lr: 0.00021
[epoch 161: 120/307] 	 train loss: 0.195297 	 lr: 0.00021

val loss: 0.347393 	 acc: 0.902755

[epoch 161: 140/307] 	 train loss: 0.179948 	 lr: 0.00021
[epoch 161: 160/307] 	 train loss: 0.247270 	 lr: 0.00021
[epoch 161: 180/307] 	 train loss: 0.097501 	 lr: 0.00021
[epoch 161: 200/307] 	 train loss: 0.499229 	 lr: 0.00021
[epoch 161: 220/307] 	 train loss: 0.339129 	 lr: 0.00021
[epoch 161: 240/307] 	 train loss: 0.059514 	 lr: 0.00021
[epoch 161: 260/307] 	 train loss: 0.056144 	 lr: 0.00021
[epoch 161: 280/307] 	 train loss: 0.112796 	 lr: 0.00021

val loss: 0.341593 	 acc: 0.905186

[epoch 161: 300/307] 	 train loss: 0.128708 	 lr: 0.00021
[epoch 162:   0/307] 	 train loss: 0.104687 	 lr: 0.00021
[epoch 162:  20/307] 	 train loss: 0.148371 	 lr: 0.00021
[epoch 162:  40/307] 	 train loss: 0.070849 	 lr: 0.00021
[epoch 162:  60/307] 	 train loss: 0.276329 	 lr: 0.00021
[epoch 162:  80/307] 	 train loss: 0.080979 	 lr: 0.00021
[epoch 162: 100/307] 	 train loss: 0.067495 	 lr: 0.00021
[epoch 162: 120/307] 	 train loss: 0.207408 	 lr: 0.00021

val loss: 0.311083 	 acc: 0.909643

[epoch 162: 140/307] 	 train loss: 0.278720 	 lr: 0.00021
[epoch 162: 160/307] 	 train loss: 0.482415 	 lr: 0.00021
[epoch 162: 180/307] 	 train loss: 0.119751 	 lr: 0.00021
[epoch 162: 200/307] 	 train loss: 0.361258 	 lr: 0.00021
[epoch 162: 220/307] 	 train loss: 0.149593 	 lr: 0.00021
[epoch 162: 240/307] 	 train loss: 0.243537 	 lr: 0.00021
[epoch 162: 260/307] 	 train loss: 0.367312 	 lr: 0.00021
[epoch 162: 280/307] 	 train loss: 0.144757 	 lr: 0.00021

val loss: 0.332407 	 acc: 0.902755

[epoch 162: 300/307] 	 train loss: 0.343389 	 lr: 0.00021
[epoch 163:   0/307] 	 train loss: 0.306682 	 lr: 0.00021
[epoch 163:  20/307] 	 train loss: 0.219265 	 lr: 0.00021
[epoch 163:  40/307] 	 train loss: 0.167338 	 lr: 0.00021
[epoch 163:  60/307] 	 train loss: 0.121867 	 lr: 0.00021
[epoch 163:  80/307] 	 train loss: 0.149606 	 lr: 0.00021
[epoch 163: 100/307] 	 train loss: 0.419680 	 lr: 0.00021
[epoch 163: 120/307] 	 train loss: 0.084693 	 lr: 0.00021

val loss: 0.335948 	 acc: 0.901135

[epoch 163: 140/307] 	 train loss: 0.029216 	 lr: 0.00021
[epoch 163: 160/307] 	 train loss: 0.234295 	 lr: 0.00021
[epoch 163: 180/307] 	 train loss: 0.170965 	 lr: 0.00021
[epoch 163: 200/307] 	 train loss: 0.202884 	 lr: 0.00021
[epoch 163: 220/307] 	 train loss: 0.156192 	 lr: 0.00021
[epoch 163: 240/307] 	 train loss: 0.078436 	 lr: 0.00021
[epoch 163: 260/307] 	 train loss: 0.121829 	 lr: 0.00021
[epoch 163: 280/307] 	 train loss: 0.144774 	 lr: 0.00021

val loss: 0.322215 	 acc: 0.911264

[epoch 163: 300/307] 	 train loss: 0.092098 	 lr: 0.00021
[epoch 164:   0/307] 	 train loss: 0.205733 	 lr: 0.00021
[epoch 164:  20/307] 	 train loss: 0.128850 	 lr: 0.00021
[epoch 164:  40/307] 	 train loss: 0.191462 	 lr: 0.00021
[epoch 164:  60/307] 	 train loss: 0.141694 	 lr: 0.00021
[epoch 164:  80/307] 	 train loss: 0.093484 	 lr: 0.00021
[epoch 164: 100/307] 	 train loss: 0.171695 	 lr: 0.00021
[epoch 164: 120/307] 	 train loss: 0.158876 	 lr: 0.00021

val loss: 0.338257 	 acc: 0.910454

[epoch 164: 140/307] 	 train loss: 0.214572 	 lr: 0.00021
[epoch 164: 160/307] 	 train loss: 0.110018 	 lr: 0.00021
[epoch 164: 180/307] 	 train loss: 0.195603 	 lr: 0.00021
[epoch 164: 200/307] 	 train loss: 0.448461 	 lr: 0.00021
[epoch 164: 220/307] 	 train loss: 0.079921 	 lr: 0.00021
[epoch 164: 240/307] 	 train loss: 0.433543 	 lr: 0.00021
[epoch 164: 260/307] 	 train loss: 0.082249 	 lr: 0.00021
[epoch 164: 280/307] 	 train loss: 0.130341 	 lr: 0.00021

val loss: 0.326391 	 acc: 0.907618

[epoch 164: 300/307] 	 train loss: 0.202280 	 lr: 0.00021
[epoch 165:   0/307] 	 train loss: 0.035065 	 lr: 0.00021
[epoch 165:  20/307] 	 train loss: 0.084125 	 lr: 0.00021
[epoch 165:  40/307] 	 train loss: 0.091592 	 lr: 0.00021
[epoch 165:  60/307] 	 train loss: 0.123378 	 lr: 0.00021
[epoch 165:  80/307] 	 train loss: 0.325862 	 lr: 0.00021
[epoch 165: 100/307] 	 train loss: 0.184440 	 lr: 0.00021
[epoch 165: 120/307] 	 train loss: 0.261599 	 lr: 0.00021

val loss: 0.327856 	 acc: 0.906807

[epoch 165: 140/307] 	 train loss: 0.225382 	 lr: 0.00021
[epoch 165: 160/307] 	 train loss: 0.226558 	 lr: 0.00021
[epoch 165: 180/307] 	 train loss: 0.239778 	 lr: 0.00021
[epoch 165: 200/307] 	 train loss: 0.120999 	 lr: 0.00021
[epoch 165: 220/307] 	 train loss: 0.405041 	 lr: 0.00021
[epoch 165: 240/307] 	 train loss: 0.148507 	 lr: 0.00021
[epoch 165: 260/307] 	 train loss: 0.304604 	 lr: 0.00021
[epoch 165: 280/307] 	 train loss: 0.266690 	 lr: 0.00021

val loss: 0.341655 	 acc: 0.911669

[epoch 165: 300/307] 	 train loss: 0.037151 	 lr: 0.00021
[epoch 166:   0/307] 	 train loss: 0.195937 	 lr: 0.00021
[epoch 166:  20/307] 	 train loss: 0.145941 	 lr: 0.00021
[epoch 166:  40/307] 	 train loss: 0.219207 	 lr: 0.00021
[epoch 166:  60/307] 	 train loss: 0.143528 	 lr: 0.00021
[epoch 166:  80/307] 	 train loss: 0.251378 	 lr: 0.00021
[epoch 166: 100/307] 	 train loss: 0.245482 	 lr: 0.00021
[epoch 166: 120/307] 	 train loss: 0.590542 	 lr: 0.00021

val loss: 0.333108 	 acc: 0.908428

[epoch 166: 140/307] 	 train loss: 0.194494 	 lr: 0.00021
[epoch 166: 160/307] 	 train loss: 0.120450 	 lr: 0.00021
[epoch 166: 180/307] 	 train loss: 0.155060 	 lr: 0.00021
[epoch 166: 200/307] 	 train loss: 0.127942 	 lr: 0.00021
[epoch 166: 220/307] 	 train loss: 0.060663 	 lr: 0.00021
[epoch 166: 240/307] 	 train loss: 0.330097 	 lr: 0.00021
[epoch 166: 260/307] 	 train loss: 0.284525 	 lr: 0.00021
[epoch 166: 280/307] 	 train loss: 0.164447 	 lr: 0.00021

val loss: 0.317658 	 acc: 0.907212

[epoch 166: 300/307] 	 train loss: 0.214896 	 lr: 0.00021
[epoch 167:   0/307] 	 train loss: 0.118447 	 lr: 0.00021
[epoch 167:  20/307] 	 train loss: 0.342609 	 lr: 0.00021
[epoch 167:  40/307] 	 train loss: 0.168276 	 lr: 0.00021
[epoch 167:  60/307] 	 train loss: 0.156874 	 lr: 0.00021
[epoch 167:  80/307] 	 train loss: 0.108192 	 lr: 0.00021
[epoch 167: 100/307] 	 train loss: 0.372034 	 lr: 0.00021
[epoch 167: 120/307] 	 train loss: 0.073650 	 lr: 0.00021

val loss: 0.339060 	 acc: 0.903566

[epoch 167: 140/307] 	 train loss: 0.201743 	 lr: 0.00021
[epoch 167: 160/307] 	 train loss: 0.160066 	 lr: 0.00021
[epoch 167: 180/307] 	 train loss: 0.322902 	 lr: 0.00021
[epoch 167: 200/307] 	 train loss: 0.150685 	 lr: 0.00021
[epoch 167: 220/307] 	 train loss: 0.063227 	 lr: 0.00021
[epoch 167: 240/307] 	 train loss: 0.227082 	 lr: 0.00021
[epoch 167: 260/307] 	 train loss: 0.033374 	 lr: 0.00021

val loss: 0.325323 	 acc: 0.904781

[epoch 167: 280/307] 	 train loss: 0.315226 	 lr: 0.00021
[epoch 167: 300/307] 	 train loss: 0.110333 	 lr: 0.00021
[epoch 168:   0/307] 	 train loss: 0.036651 	 lr: 0.00021
[epoch 168:  20/307] 	 train loss: 0.041021 	 lr: 0.00021
[epoch 168:  40/307] 	 train loss: 0.074216 	 lr: 0.00021
[epoch 168:  60/307] 	 train loss: 0.302630 	 lr: 0.00021
[epoch 168:  80/307] 	 train loss: 0.072114 	 lr: 0.00021
[epoch 168: 100/307] 	 train loss: 0.094768 	 lr: 0.00021
[epoch 168: 120/307] 	 train loss: 0.055553 	 lr: 0.00021

val loss: 0.365845 	 acc: 0.901945

[epoch 168: 140/307] 	 train loss: 0.253742 	 lr: 0.00021
[epoch 168: 160/307] 	 train loss: 0.738794 	 lr: 0.00021
[epoch 168: 180/307] 	 train loss: 0.145212 	 lr: 0.00021
[epoch 168: 200/307] 	 train loss: 0.033862 	 lr: 0.00021
[epoch 168: 220/307] 	 train loss: 0.073975 	 lr: 0.00021
[epoch 168: 240/307] 	 train loss: 0.395383 	 lr: 0.00021
[epoch 168: 260/307] 	 train loss: 0.134324 	 lr: 0.00021

val loss: 0.331036 	 acc: 0.903160

[epoch 168: 280/307] 	 train loss: 0.310513 	 lr: 0.00021
[epoch 168: 300/307] 	 train loss: 0.131159 	 lr: 0.00021
[epoch 169:   0/307] 	 train loss: 0.047792 	 lr: 0.00017
[epoch 169:  20/307] 	 train loss: 0.072229 	 lr: 0.00017
[epoch 169:  40/307] 	 train loss: 0.052921 	 lr: 0.00017
[epoch 169:  60/307] 	 train loss: 0.346029 	 lr: 0.00017
[epoch 169:  80/307] 	 train loss: 0.150788 	 lr: 0.00017
[epoch 169: 100/307] 	 train loss: 0.039584 	 lr: 0.00017
[epoch 169: 120/307] 	 train loss: 0.151858 	 lr: 0.00017

val loss: 0.342736 	 acc: 0.910454

[epoch 169: 140/307] 	 train loss: 0.128071 	 lr: 0.00017
[epoch 169: 160/307] 	 train loss: 0.050797 	 lr: 0.00017
[epoch 169: 180/307] 	 train loss: 0.265013 	 lr: 0.00017
[epoch 169: 200/307] 	 train loss: 0.197961 	 lr: 0.00017
[epoch 169: 220/307] 	 train loss: 0.231737 	 lr: 0.00017
[epoch 169: 240/307] 	 train loss: 0.396529 	 lr: 0.00017
[epoch 169: 260/307] 	 train loss: 0.198878 	 lr: 0.00017

val loss: 0.334316 	 acc: 0.912480

[epoch 169: 280/307] 	 train loss: 0.229736 	 lr: 0.00017
[epoch 169: 300/307] 	 train loss: 0.216400 	 lr: 0.00017
[epoch 170:   0/307] 	 train loss: 0.403725 	 lr: 0.00017
[epoch 170:  20/307] 	 train loss: 0.241129 	 lr: 0.00017
[epoch 170:  40/307] 	 train loss: 0.219355 	 lr: 0.00017
[epoch 170:  60/307] 	 train loss: 0.156185 	 lr: 0.00017
[epoch 170:  80/307] 	 train loss: 0.325469 	 lr: 0.00017
[epoch 170: 100/307] 	 train loss: 0.287263 	 lr: 0.00017
[epoch 170: 120/307] 	 train loss: 0.135178 	 lr: 0.00017

val loss: 0.340184 	 acc: 0.899919

[epoch 170: 140/307] 	 train loss: 0.334506 	 lr: 0.00017
[epoch 170: 160/307] 	 train loss: 0.074766 	 lr: 0.00017
[epoch 170: 180/307] 	 train loss: 0.069200 	 lr: 0.00017
[epoch 170: 200/307] 	 train loss: 0.340367 	 lr: 0.00017
[epoch 170: 220/307] 	 train loss: 0.117587 	 lr: 0.00017
[epoch 170: 240/307] 	 train loss: 0.067380 	 lr: 0.00017
[epoch 170: 260/307] 	 train loss: 0.202144 	 lr: 0.00017

val loss: 0.319589 	 acc: 0.903971

[epoch 170: 280/307] 	 train loss: 0.308549 	 lr: 0.00017
[epoch 170: 300/307] 	 train loss: 0.138805 	 lr: 0.00017
[epoch 171:   0/307] 	 train loss: 0.164380 	 lr: 0.00017
[epoch 171:  20/307] 	 train loss: 0.100239 	 lr: 0.00017
[epoch 171:  40/307] 	 train loss: 0.310128 	 lr: 0.00017
[epoch 171:  60/307] 	 train loss: 0.316116 	 lr: 0.00017
[epoch 171:  80/307] 	 train loss: 0.223557 	 lr: 0.00017
[epoch 171: 100/307] 	 train loss: 0.263299 	 lr: 0.00017

val loss: 0.315081 	 acc: 0.908428

[epoch 171: 120/307] 	 train loss: 0.177654 	 lr: 0.00017
[epoch 171: 140/307] 	 train loss: 0.220169 	 lr: 0.00017
[epoch 171: 160/307] 	 train loss: 0.069921 	 lr: 0.00017
[epoch 171: 180/307] 	 train loss: 0.290531 	 lr: 0.00017
[epoch 171: 200/307] 	 train loss: 0.195866 	 lr: 0.00017
[epoch 171: 220/307] 	 train loss: 0.254273 	 lr: 0.00017
[epoch 171: 240/307] 	 train loss: 0.391629 	 lr: 0.00017
[epoch 171: 260/307] 	 train loss: 0.195094 	 lr: 0.00017

val loss: 0.329019 	 acc: 0.903566

[epoch 171: 280/307] 	 train loss: 0.076678 	 lr: 0.00017
[epoch 171: 300/307] 	 train loss: 0.280310 	 lr: 0.00017
[epoch 172:   0/307] 	 train loss: 0.057181 	 lr: 0.00017
[epoch 172:  20/307] 	 train loss: 0.131139 	 lr: 0.00017
[epoch 172:  40/307] 	 train loss: 0.088082 	 lr: 0.00017
[epoch 172:  60/307] 	 train loss: 0.138639 	 lr: 0.00017
[epoch 172:  80/307] 	 train loss: 0.122473 	 lr: 0.00017
[epoch 172: 100/307] 	 train loss: 0.155418 	 lr: 0.00017

val loss: 0.332833 	 acc: 0.909238

[epoch 172: 120/307] 	 train loss: 0.282727 	 lr: 0.00017
[epoch 172: 140/307] 	 train loss: 0.309933 	 lr: 0.00017
[epoch 172: 160/307] 	 train loss: 0.364024 	 lr: 0.00017
[epoch 172: 180/307] 	 train loss: 0.141173 	 lr: 0.00017
[epoch 172: 200/307] 	 train loss: 0.086214 	 lr: 0.00017
[epoch 172: 220/307] 	 train loss: 0.114395 	 lr: 0.00017
[epoch 172: 240/307] 	 train loss: 0.146864 	 lr: 0.00017
[epoch 172: 260/307] 	 train loss: 0.180604 	 lr: 0.00017

val loss: 0.324456 	 acc: 0.911669

[epoch 172: 280/307] 	 train loss: 0.136832 	 lr: 0.00017
[epoch 172: 300/307] 	 train loss: 0.087471 	 lr: 0.00017
[epoch 173:   0/307] 	 train loss: 0.209527 	 lr: 0.00017
[epoch 173:  20/307] 	 train loss: 0.121018 	 lr: 0.00017
[epoch 173:  40/307] 	 train loss: 0.201053 	 lr: 0.00017
[epoch 173:  60/307] 	 train loss: 0.389204 	 lr: 0.00017
[epoch 173:  80/307] 	 train loss: 0.147699 	 lr: 0.00017
[epoch 173: 100/307] 	 train loss: 0.118104 	 lr: 0.00017

val loss: 0.307071 	 acc: 0.914506

saved model with accuracy  0.9145056726094003
[epoch 173: 120/307] 	 train loss: 0.297075 	 lr: 0.00017
[epoch 173: 140/307] 	 train loss: 0.272913 	 lr: 0.00017
[epoch 173: 160/307] 	 train loss: 0.191970 	 lr: 0.00017
[epoch 173: 180/307] 	 train loss: 0.142248 	 lr: 0.00017
[epoch 173: 200/307] 	 train loss: 0.214722 	 lr: 0.00017
[epoch 173: 220/307] 	 train loss: 0.156230 	 lr: 0.00017
[epoch 173: 240/307] 	 train loss: 0.030755 	 lr: 0.00017
[epoch 173: 260/307] 	 train loss: 0.084539 	 lr: 0.00017

val loss: 0.334644 	 acc: 0.907212

[epoch 173: 280/307] 	 train loss: 0.073571 	 lr: 0.00017
[epoch 173: 300/307] 	 train loss: 0.241427 	 lr: 0.00017
[epoch 174:   0/307] 	 train loss: 0.233160 	 lr: 0.00017
[epoch 174:  20/307] 	 train loss: 0.235013 	 lr: 0.00017
[epoch 174:  40/307] 	 train loss: 0.147268 	 lr: 0.00017
[epoch 174:  60/307] 	 train loss: 0.057854 	 lr: 0.00017
[epoch 174:  80/307] 	 train loss: 0.142157 	 lr: 0.00017
[epoch 174: 100/307] 	 train loss: 0.214444 	 lr: 0.00017

val loss: 0.360783 	 acc: 0.899109

[epoch 174: 120/307] 	 train loss: 0.119140 	 lr: 0.00017
[epoch 174: 140/307] 	 train loss: 0.226950 	 lr: 0.00017
[epoch 174: 160/307] 	 train loss: 0.171280 	 lr: 0.00017
[epoch 174: 180/307] 	 train loss: 0.039173 	 lr: 0.00017
[epoch 174: 200/307] 	 train loss: 0.061127 	 lr: 0.00017
[epoch 174: 220/307] 	 train loss: 0.045190 	 lr: 0.00017
[epoch 174: 240/307] 	 train loss: 0.131742 	 lr: 0.00017
[epoch 174: 260/307] 	 train loss: 0.167292 	 lr: 0.00017

val loss: 0.340199 	 acc: 0.902350

[epoch 174: 280/307] 	 train loss: 0.041723 	 lr: 0.00017
[epoch 174: 300/307] 	 train loss: 0.111231 	 lr: 0.00017
[epoch 175:   0/307] 	 train loss: 0.102989 	 lr: 0.00017
[epoch 175:  20/307] 	 train loss: 0.085520 	 lr: 0.00017
[epoch 175:  40/307] 	 train loss: 0.164242 	 lr: 0.00017
[epoch 175:  60/307] 	 train loss: 0.084900 	 lr: 0.00017
[epoch 175:  80/307] 	 train loss: 0.206069 	 lr: 0.00017
[epoch 175: 100/307] 	 train loss: 0.422005 	 lr: 0.00017

val loss: 0.332795 	 acc: 0.903160

[epoch 175: 120/307] 	 train loss: 0.544271 	 lr: 0.00017
[epoch 175: 140/307] 	 train loss: 0.269262 	 lr: 0.00017
[epoch 175: 160/307] 	 train loss: 0.409652 	 lr: 0.00017
[epoch 175: 180/307] 	 train loss: 0.205727 	 lr: 0.00017
[epoch 175: 200/307] 	 train loss: 0.017947 	 lr: 0.00017
[epoch 175: 220/307] 	 train loss: 0.224495 	 lr: 0.00017
[epoch 175: 240/307] 	 train loss: 0.079484 	 lr: 0.00017
[epoch 175: 260/307] 	 train loss: 0.208466 	 lr: 0.00017

val loss: 0.305181 	 acc: 0.917342

saved model with accuracy  0.9173419773095624
[epoch 175: 280/307] 	 train loss: 0.110713 	 lr: 0.00017
[epoch 175: 300/307] 	 train loss: 0.075315 	 lr: 0.00017
[epoch 176:   0/307] 	 train loss: 0.164070 	 lr: 0.00017
[epoch 176:  20/307] 	 train loss: 0.070170 	 lr: 0.00017
[epoch 176:  40/307] 	 train loss: 0.256922 	 lr: 0.00017
[epoch 176:  60/307] 	 train loss: 0.282001 	 lr: 0.00017
[epoch 176:  80/307] 	 train loss: 0.070181 	 lr: 0.00017
[epoch 176: 100/307] 	 train loss: 0.079718 	 lr: 0.00017

val loss: 0.311906 	 acc: 0.910859

[epoch 176: 120/307] 	 train loss: 0.054045 	 lr: 0.00017
[epoch 176: 140/307] 	 train loss: 0.461774 	 lr: 0.00017
[epoch 176: 160/307] 	 train loss: 0.103860 	 lr: 0.00017
[epoch 176: 180/307] 	 train loss: 0.128331 	 lr: 0.00017
[epoch 176: 200/307] 	 train loss: 0.113255 	 lr: 0.00017
[epoch 176: 220/307] 	 train loss: 0.501470 	 lr: 0.00017
[epoch 176: 240/307] 	 train loss: 0.117367 	 lr: 0.00017
[epoch 176: 260/307] 	 train loss: 0.093189 	 lr: 0.00017

val loss: 0.337574 	 acc: 0.907212

[epoch 176: 280/307] 	 train loss: 0.352828 	 lr: 0.00017
[epoch 176: 300/307] 	 train loss: 0.161167 	 lr: 0.00017
[epoch 177:   0/307] 	 train loss: 0.044187 	 lr: 0.00017
[epoch 177:  20/307] 	 train loss: 0.174917 	 lr: 0.00017
[epoch 177:  40/307] 	 train loss: 0.089943 	 lr: 0.00017
[epoch 177:  60/307] 	 train loss: 0.148222 	 lr: 0.00017
[epoch 177:  80/307] 	 train loss: 0.157693 	 lr: 0.00017
[epoch 177: 100/307] 	 train loss: 0.278232 	 lr: 0.00017

val loss: 0.333411 	 acc: 0.910049

[epoch 177: 120/307] 	 train loss: 0.229750 	 lr: 0.00017
[epoch 177: 140/307] 	 train loss: 0.065277 	 lr: 0.00017
[epoch 177: 160/307] 	 train loss: 0.109088 	 lr: 0.00017
[epoch 177: 180/307] 	 train loss: 0.528969 	 lr: 0.00017
[epoch 177: 200/307] 	 train loss: 0.054558 	 lr: 0.00017
[epoch 177: 220/307] 	 train loss: 0.171190 	 lr: 0.00017
[epoch 177: 240/307] 	 train loss: 0.071614 	 lr: 0.00017

val loss: 0.315172 	 acc: 0.910454

[epoch 177: 260/307] 	 train loss: 0.189119 	 lr: 0.00017
[epoch 177: 280/307] 	 train loss: 0.187943 	 lr: 0.00017
[epoch 177: 300/307] 	 train loss: 0.196796 	 lr: 0.00017
[epoch 178:   0/307] 	 train loss: 0.053410 	 lr: 0.00017
[epoch 178:  20/307] 	 train loss: 0.144254 	 lr: 0.00017
[epoch 178:  40/307] 	 train loss: 0.223568 	 lr: 0.00017
[epoch 178:  60/307] 	 train loss: 0.076598 	 lr: 0.00017
[epoch 178:  80/307] 	 train loss: 0.202173 	 lr: 0.00017
[epoch 178: 100/307] 	 train loss: 0.085356 	 lr: 0.00017

val loss: 0.334240 	 acc: 0.904781

[epoch 178: 120/307] 	 train loss: 0.225902 	 lr: 0.00017
[epoch 178: 140/307] 	 train loss: 0.039344 	 lr: 0.00017
[epoch 178: 160/307] 	 train loss: 0.259344 	 lr: 0.00017
[epoch 178: 180/307] 	 train loss: 0.224686 	 lr: 0.00017
[epoch 178: 200/307] 	 train loss: 0.106742 	 lr: 0.00017
[epoch 178: 220/307] 	 train loss: 0.239923 	 lr: 0.00017
[epoch 178: 240/307] 	 train loss: 0.200000 	 lr: 0.00017

val loss: 0.326311 	 acc: 0.905997

[epoch 178: 260/307] 	 train loss: 0.037896 	 lr: 0.00017
[epoch 178: 280/307] 	 train loss: 0.087361 	 lr: 0.00017
[epoch 178: 300/307] 	 train loss: 0.054802 	 lr: 0.00017
[epoch 179:   0/307] 	 train loss: 0.127358 	 lr: 0.00017
[epoch 179:  20/307] 	 train loss: 0.232009 	 lr: 0.00017
[epoch 179:  40/307] 	 train loss: 0.311905 	 lr: 0.00017
[epoch 179:  60/307] 	 train loss: 0.139618 	 lr: 0.00017
[epoch 179:  80/307] 	 train loss: 0.116002 	 lr: 0.00017
[epoch 179: 100/307] 	 train loss: 0.500979 	 lr: 0.00017

val loss: 0.331573 	 acc: 0.914100

[epoch 179: 120/307] 	 train loss: 0.345949 	 lr: 0.00017
[epoch 179: 140/307] 	 train loss: 0.319600 	 lr: 0.00017
[epoch 179: 160/307] 	 train loss: 0.165516 	 lr: 0.00017
[epoch 179: 180/307] 	 train loss: 0.095157 	 lr: 0.00017
[epoch 179: 200/307] 	 train loss: 0.128327 	 lr: 0.00017
[epoch 179: 220/307] 	 train loss: 0.161369 	 lr: 0.00017
[epoch 179: 240/307] 	 train loss: 0.277505 	 lr: 0.00017

val loss: 0.335766 	 acc: 0.903566

[epoch 179: 260/307] 	 train loss: 0.308353 	 lr: 0.00017
[epoch 179: 280/307] 	 train loss: 0.184298 	 lr: 0.00017
[epoch 179: 300/307] 	 train loss: 0.183257 	 lr: 0.00017
[epoch 180:   0/307] 	 train loss: 0.217406 	 lr: 0.00017
[epoch 180:  20/307] 	 train loss: 0.123070 	 lr: 0.00017
[epoch 180:  40/307] 	 train loss: 0.433157 	 lr: 0.00017
[epoch 180:  60/307] 	 train loss: 0.319070 	 lr: 0.00017
[epoch 180:  80/307] 	 train loss: 0.534728 	 lr: 0.00017
[epoch 180: 100/307] 	 train loss: 0.162343 	 lr: 0.00017

val loss: 0.320896 	 acc: 0.909238

[epoch 180: 120/307] 	 train loss: 0.139545 	 lr: 0.00017
[epoch 180: 140/307] 	 train loss: 0.158885 	 lr: 0.00017
[epoch 180: 160/307] 	 train loss: 0.360113 	 lr: 0.00017
[epoch 180: 180/307] 	 train loss: 0.202696 	 lr: 0.00017
[epoch 180: 200/307] 	 train loss: 0.080917 	 lr: 0.00017
[epoch 180: 220/307] 	 train loss: 0.154436 	 lr: 0.00017
[epoch 180: 240/307] 	 train loss: 0.120655 	 lr: 0.00017

val loss: 0.341446 	 acc: 0.901945

[epoch 180: 260/307] 	 train loss: 0.068070 	 lr: 0.00017
[epoch 180: 280/307] 	 train loss: 0.153951 	 lr: 0.00017
[epoch 180: 300/307] 	 train loss: 0.211532 	 lr: 0.00017
[epoch 181:   0/307] 	 train loss: 0.077829 	 lr: 0.00017
[epoch 181:  20/307] 	 train loss: 0.149534 	 lr: 0.00017
[epoch 181:  40/307] 	 train loss: 0.070028 	 lr: 0.00017
[epoch 181:  60/307] 	 train loss: 0.282713 	 lr: 0.00017
[epoch 181:  80/307] 	 train loss: 0.381529 	 lr: 0.00017

val loss: 0.335957 	 acc: 0.908023

[epoch 181: 100/307] 	 train loss: 0.094144 	 lr: 0.00017
[epoch 181: 120/307] 	 train loss: 0.087898 	 lr: 0.00017
[epoch 181: 140/307] 	 train loss: 0.182895 	 lr: 0.00017
[epoch 181: 160/307] 	 train loss: 0.184760 	 lr: 0.00017
[epoch 181: 180/307] 	 train loss: 0.161970 	 lr: 0.00017
[epoch 181: 200/307] 	 train loss: 0.057812 	 lr: 0.00017
[epoch 181: 220/307] 	 train loss: 0.341460 	 lr: 0.00017
[epoch 181: 240/307] 	 train loss: 0.192600 	 lr: 0.00017

val loss: 0.323044 	 acc: 0.910049

[epoch 181: 260/307] 	 train loss: 0.178755 	 lr: 0.00017
[epoch 181: 280/307] 	 train loss: 0.430794 	 lr: 0.00017
[epoch 181: 300/307] 	 train loss: 0.140940 	 lr: 0.00017
[epoch 182:   0/307] 	 train loss: 0.035488 	 lr: 0.00017
[epoch 182:  20/307] 	 train loss: 0.378193 	 lr: 0.00017
[epoch 182:  40/307] 	 train loss: 0.112654 	 lr: 0.00017
[epoch 182:  60/307] 	 train loss: 0.163718 	 lr: 0.00017
[epoch 182:  80/307] 	 train loss: 0.153917 	 lr: 0.00017

val loss: 0.323531 	 acc: 0.910049

[epoch 182: 100/307] 	 train loss: 0.082308 	 lr: 0.00017
[epoch 182: 120/307] 	 train loss: 0.057653 	 lr: 0.00017
[epoch 182: 140/307] 	 train loss: 0.092934 	 lr: 0.00017
[epoch 182: 160/307] 	 train loss: 0.075866 	 lr: 0.00017
[epoch 182: 180/307] 	 train loss: 0.110314 	 lr: 0.00017
[epoch 182: 200/307] 	 train loss: 0.071261 	 lr: 0.00017
[epoch 182: 220/307] 	 train loss: 0.060942 	 lr: 0.00017
[epoch 182: 240/307] 	 train loss: 0.035350 	 lr: 0.00017

val loss: 0.318252 	 acc: 0.910859

[epoch 182: 260/307] 	 train loss: 0.014590 	 lr: 0.00017
[epoch 182: 280/307] 	 train loss: 0.200139 	 lr: 0.00017
[epoch 182: 300/307] 	 train loss: 0.061259 	 lr: 0.00017
[epoch 183:   0/307] 	 train loss: 0.251490 	 lr: 0.00017
[epoch 183:  20/307] 	 train loss: 0.070075 	 lr: 0.00017
[epoch 183:  40/307] 	 train loss: 0.228867 	 lr: 0.00017
[epoch 183:  60/307] 	 train loss: 0.351151 	 lr: 0.00017
[epoch 183:  80/307] 	 train loss: 0.118958 	 lr: 0.00017

val loss: 0.322943 	 acc: 0.908023

[epoch 183: 100/307] 	 train loss: 0.467331 	 lr: 0.00017
[epoch 183: 120/307] 	 train loss: 0.513187 	 lr: 0.00017
[epoch 183: 140/307] 	 train loss: 0.150082 	 lr: 0.00017
[epoch 183: 160/307] 	 train loss: 0.103352 	 lr: 0.00017
[epoch 183: 180/307] 	 train loss: 0.070236 	 lr: 0.00017
[epoch 183: 200/307] 	 train loss: 0.188627 	 lr: 0.00017
[epoch 183: 220/307] 	 train loss: 0.120124 	 lr: 0.00017
[epoch 183: 240/307] 	 train loss: 0.171414 	 lr: 0.00017

val loss: 0.329871 	 acc: 0.906807

[epoch 183: 260/307] 	 train loss: 0.133369 	 lr: 0.00017
[epoch 183: 280/307] 	 train loss: 0.305012 	 lr: 0.00017
[epoch 183: 300/307] 	 train loss: 0.268091 	 lr: 0.00017
[epoch 184:   0/307] 	 train loss: 0.102215 	 lr: 0.00017
[epoch 184:  20/307] 	 train loss: 0.102166 	 lr: 0.00017
[epoch 184:  40/307] 	 train loss: 0.395242 	 lr: 0.00017
[epoch 184:  60/307] 	 train loss: 0.202094 	 lr: 0.00017
[epoch 184:  80/307] 	 train loss: 0.257258 	 lr: 0.00017

val loss: 0.341061 	 acc: 0.909238

[epoch 184: 100/307] 	 train loss: 0.156933 	 lr: 0.00017
[epoch 184: 120/307] 	 train loss: 0.209204 	 lr: 0.00017
[epoch 184: 140/307] 	 train loss: 0.140795 	 lr: 0.00017
[epoch 184: 160/307] 	 train loss: 0.044703 	 lr: 0.00017
[epoch 184: 180/307] 	 train loss: 0.040150 	 lr: 0.00017
[epoch 184: 200/307] 	 train loss: 0.036338 	 lr: 0.00017
[epoch 184: 220/307] 	 train loss: 0.111194 	 lr: 0.00017
[epoch 184: 240/307] 	 train loss: 0.388925 	 lr: 0.00017

val loss: 0.330669 	 acc: 0.910454

[epoch 184: 260/307] 	 train loss: 0.111069 	 lr: 0.00017
[epoch 184: 280/307] 	 train loss: 0.179150 	 lr: 0.00017
[epoch 184: 300/307] 	 train loss: 0.051997 	 lr: 0.00017
[epoch 185:   0/307] 	 train loss: 0.161309 	 lr: 0.00017
[epoch 185:  20/307] 	 train loss: 0.116657 	 lr: 0.00017
[epoch 185:  40/307] 	 train loss: 0.273091 	 lr: 0.00017
[epoch 185:  60/307] 	 train loss: 0.017383 	 lr: 0.00017
[epoch 185:  80/307] 	 train loss: 0.194984 	 lr: 0.00017

val loss: 0.310726 	 acc: 0.908833

[epoch 185: 100/307] 	 train loss: 0.220722 	 lr: 0.00017
[epoch 185: 120/307] 	 train loss: 0.241323 	 lr: 0.00017
[epoch 185: 140/307] 	 train loss: 0.039618 	 lr: 0.00017
[epoch 185: 160/307] 	 train loss: 0.042985 	 lr: 0.00017
[epoch 185: 180/307] 	 train loss: 0.077569 	 lr: 0.00017
[epoch 185: 200/307] 	 train loss: 0.145408 	 lr: 0.00017
[epoch 185: 220/307] 	 train loss: 0.421567 	 lr: 0.00017
[epoch 185: 240/307] 	 train loss: 0.068356 	 lr: 0.00017

val loss: 0.324066 	 acc: 0.898703

[epoch 185: 260/307] 	 train loss: 0.165154 	 lr: 0.00017
[epoch 185: 280/307] 	 train loss: 0.109318 	 lr: 0.00017
[epoch 185: 300/307] 	 train loss: 0.011943 	 lr: 0.00017
[epoch 186:   0/307] 	 train loss: 0.269572 	 lr: 0.00017
[epoch 186:  20/307] 	 train loss: 0.167308 	 lr: 0.00017
[epoch 186:  40/307] 	 train loss: 0.057843 	 lr: 0.00017
[epoch 186:  60/307] 	 train loss: 0.085356 	 lr: 0.00017
[epoch 186:  80/307] 	 train loss: 0.139146 	 lr: 0.00017

val loss: 0.314848 	 acc: 0.909643

[epoch 186: 100/307] 	 train loss: 0.272622 	 lr: 0.00017
[epoch 186: 120/307] 	 train loss: 0.241798 	 lr: 0.00017
[epoch 186: 140/307] 	 train loss: 0.169149 	 lr: 0.00017
[epoch 186: 160/307] 	 train loss: 0.095313 	 lr: 0.00017
[epoch 186: 180/307] 	 train loss: 0.291768 	 lr: 0.00017
[epoch 186: 200/307] 	 train loss: 0.228220 	 lr: 0.00017
[epoch 186: 220/307] 	 train loss: 0.185838 	 lr: 0.00017
[epoch 186: 240/307] 	 train loss: 0.132777 	 lr: 0.00017

val loss: 0.324429 	 acc: 0.904781

[epoch 186: 260/307] 	 train loss: 0.026943 	 lr: 0.00017
[epoch 186: 280/307] 	 train loss: 0.215066 	 lr: 0.00017
[epoch 186: 300/307] 	 train loss: 0.115220 	 lr: 0.00017
[epoch 187:   0/307] 	 train loss: 0.052378 	 lr: 0.00017
[epoch 187:  20/307] 	 train loss: 0.054781 	 lr: 0.00017
[epoch 187:  40/307] 	 train loss: 0.204966 	 lr: 0.00017
[epoch 187:  60/307] 	 train loss: 0.107308 	 lr: 0.00017
[epoch 187:  80/307] 	 train loss: 0.283878 	 lr: 0.00017

val loss: 0.320974 	 acc: 0.902350

[epoch 187: 100/307] 	 train loss: 0.412729 	 lr: 0.00017
[epoch 187: 120/307] 	 train loss: 0.229343 	 lr: 0.00017
[epoch 187: 140/307] 	 train loss: 0.042340 	 lr: 0.00017
[epoch 187: 160/307] 	 train loss: 0.080377 	 lr: 0.00017
[epoch 187: 180/307] 	 train loss: 0.111397 	 lr: 0.00017
[epoch 187: 200/307] 	 train loss: 0.291537 	 lr: 0.00017
[epoch 187: 220/307] 	 train loss: 0.050379 	 lr: 0.00017

val loss: 0.319690 	 acc: 0.910049

[epoch 187: 240/307] 	 train loss: 0.078715 	 lr: 0.00017
[epoch 187: 260/307] 	 train loss: 0.084124 	 lr: 0.00017
[epoch 187: 280/307] 	 train loss: 0.239687 	 lr: 0.00017
[epoch 187: 300/307] 	 train loss: 0.058465 	 lr: 0.00017
[epoch 188:   0/307] 	 train loss: 0.055607 	 lr: 0.00017
[epoch 188:  20/307] 	 train loss: 0.128376 	 lr: 0.00017
[epoch 188:  40/307] 	 train loss: 0.066914 	 lr: 0.00017
[epoch 188:  60/307] 	 train loss: 0.248371 	 lr: 0.00017
[epoch 188:  80/307] 	 train loss: 0.093088 	 lr: 0.00017

val loss: 0.312314 	 acc: 0.901945

[epoch 188: 100/307] 	 train loss: 0.276606 	 lr: 0.00017
[epoch 188: 120/307] 	 train loss: 0.078795 	 lr: 0.00017
[epoch 188: 140/307] 	 train loss: 0.207243 	 lr: 0.00017
[epoch 188: 160/307] 	 train loss: 0.203998 	 lr: 0.00017
[epoch 188: 180/307] 	 train loss: 0.168444 	 lr: 0.00017
[epoch 188: 200/307] 	 train loss: 0.105286 	 lr: 0.00017
[epoch 188: 220/307] 	 train loss: 0.283042 	 lr: 0.00017

val loss: 0.325669 	 acc: 0.902350

[epoch 188: 240/307] 	 train loss: 0.133110 	 lr: 0.00017
[epoch 188: 260/307] 	 train loss: 0.351763 	 lr: 0.00017
[epoch 188: 280/307] 	 train loss: 0.059003 	 lr: 0.00017
[epoch 188: 300/307] 	 train loss: 0.233644 	 lr: 0.00017
[epoch 189:   0/307] 	 train loss: 0.228152 	 lr: 0.00017
[epoch 189:  20/307] 	 train loss: 0.305305 	 lr: 0.00017
[epoch 189:  40/307] 	 train loss: 0.180019 	 lr: 0.00017
[epoch 189:  60/307] 	 train loss: 0.142502 	 lr: 0.00017
[epoch 189:  80/307] 	 train loss: 0.136833 	 lr: 0.00017

val loss: 0.315481 	 acc: 0.907618

[epoch 189: 100/307] 	 train loss: 0.249838 	 lr: 0.00017
[epoch 189: 120/307] 	 train loss: 0.238355 	 lr: 0.00017
[epoch 189: 140/307] 	 train loss: 0.170229 	 lr: 0.00017
[epoch 189: 160/307] 	 train loss: 0.194775 	 lr: 0.00017
[epoch 189: 180/307] 	 train loss: 0.150239 	 lr: 0.00017
[epoch 189: 200/307] 	 train loss: 0.086511 	 lr: 0.00017
[epoch 189: 220/307] 	 train loss: 0.120787 	 lr: 0.00017

val loss: 0.337215 	 acc: 0.904376

[epoch 189: 240/307] 	 train loss: 0.242528 	 lr: 0.00017
[epoch 189: 260/307] 	 train loss: 0.232662 	 lr: 0.00017
[epoch 189: 280/307] 	 train loss: 0.075313 	 lr: 0.00017
[epoch 189: 300/307] 	 train loss: 0.199949 	 lr: 0.00017
[epoch 190:   0/307] 	 train loss: 0.228603 	 lr: 0.00013
[epoch 190:  20/307] 	 train loss: 0.238652 	 lr: 0.00013
[epoch 190:  40/307] 	 train loss: 0.289927 	 lr: 0.00013
[epoch 190:  60/307] 	 train loss: 0.219084 	 lr: 0.00013
[epoch 190:  80/307] 	 train loss: 0.149890 	 lr: 0.00013

val loss: 0.333169 	 acc: 0.905592

[epoch 190: 100/307] 	 train loss: 0.139153 	 lr: 0.00013
[epoch 190: 120/307] 	 train loss: 0.082824 	 lr: 0.00013
[epoch 190: 140/307] 	 train loss: 0.161926 	 lr: 0.00013
[epoch 190: 160/307] 	 train loss: 0.126685 	 lr: 0.00013
[epoch 190: 180/307] 	 train loss: 0.087060 	 lr: 0.00013
[epoch 190: 200/307] 	 train loss: 0.054611 	 lr: 0.00013
[epoch 190: 220/307] 	 train loss: 0.209320 	 lr: 0.00013

val loss: 0.331221 	 acc: 0.901135

[epoch 190: 240/307] 	 train loss: 0.151691 	 lr: 0.00013
[epoch 190: 260/307] 	 train loss: 0.246251 	 lr: 0.00013
[epoch 190: 280/307] 	 train loss: 0.132817 	 lr: 0.00013
[epoch 190: 300/307] 	 train loss: 0.245459 	 lr: 0.00013
[epoch 191:   0/307] 	 train loss: 0.232861 	 lr: 0.00013
[epoch 191:  20/307] 	 train loss: 0.254248 	 lr: 0.00013
[epoch 191:  40/307] 	 train loss: 0.177125 	 lr: 0.00013
[epoch 191:  60/307] 	 train loss: 0.293061 	 lr: 0.00013

val loss: 0.324287 	 acc: 0.905997

[epoch 191:  80/307] 	 train loss: 0.159549 	 lr: 0.00013
[epoch 191: 100/307] 	 train loss: 0.040455 	 lr: 0.00013
[epoch 191: 120/307] 	 train loss: 0.224432 	 lr: 0.00013
[epoch 191: 140/307] 	 train loss: 0.099064 	 lr: 0.00013
[epoch 191: 160/307] 	 train loss: 0.108510 	 lr: 0.00013
[epoch 191: 180/307] 	 train loss: 0.107023 	 lr: 0.00013
[epoch 191: 200/307] 	 train loss: 0.073702 	 lr: 0.00013
[epoch 191: 220/307] 	 train loss: 0.129430 	 lr: 0.00013

val loss: 0.311912 	 acc: 0.912480

[epoch 191: 240/307] 	 train loss: 0.113701 	 lr: 0.00013
[epoch 191: 260/307] 	 train loss: 0.086752 	 lr: 0.00013
[epoch 191: 280/307] 	 train loss: 0.116732 	 lr: 0.00013
[epoch 191: 300/307] 	 train loss: 0.279797 	 lr: 0.00013
[epoch 192:   0/307] 	 train loss: 0.285893 	 lr: 0.00013
[epoch 192:  20/307] 	 train loss: 0.187982 	 lr: 0.00013
[epoch 192:  40/307] 	 train loss: 0.149619 	 lr: 0.00013
[epoch 192:  60/307] 	 train loss: 0.303567 	 lr: 0.00013

val loss: 0.333843 	 acc: 0.906807

[epoch 192:  80/307] 	 train loss: 0.062561 	 lr: 0.00013
[epoch 192: 100/307] 	 train loss: 0.145377 	 lr: 0.00013
[epoch 192: 120/307] 	 train loss: 0.302191 	 lr: 0.00013
[epoch 192: 140/307] 	 train loss: 0.069509 	 lr: 0.00013
[epoch 192: 160/307] 	 train loss: 0.240059 	 lr: 0.00013
[epoch 192: 180/307] 	 train loss: 0.198874 	 lr: 0.00013
[epoch 192: 200/307] 	 train loss: 0.379397 	 lr: 0.00013
[epoch 192: 220/307] 	 train loss: 0.472191 	 lr: 0.00013

val loss: 0.339813 	 acc: 0.902755

[epoch 192: 240/307] 	 train loss: 0.139935 	 lr: 0.00013
[epoch 192: 260/307] 	 train loss: 0.288483 	 lr: 0.00013
[epoch 192: 280/307] 	 train loss: 0.128095 	 lr: 0.00013
[epoch 192: 300/307] 	 train loss: 0.157494 	 lr: 0.00013
[epoch 193:   0/307] 	 train loss: 0.063897 	 lr: 0.00013
[epoch 193:  20/307] 	 train loss: 0.167618 	 lr: 0.00013
[epoch 193:  40/307] 	 train loss: 0.466758 	 lr: 0.00013
[epoch 193:  60/307] 	 train loss: 0.094249 	 lr: 0.00013

val loss: 0.322413 	 acc: 0.911264

[epoch 193:  80/307] 	 train loss: 0.175828 	 lr: 0.00013
[epoch 193: 100/307] 	 train loss: 0.472353 	 lr: 0.00013
[epoch 193: 120/307] 	 train loss: 0.087094 	 lr: 0.00013
[epoch 193: 140/307] 	 train loss: 0.288374 	 lr: 0.00013
[epoch 193: 160/307] 	 train loss: 0.110703 	 lr: 0.00013
[epoch 193: 180/307] 	 train loss: 0.095560 	 lr: 0.00013
[epoch 193: 200/307] 	 train loss: 0.204336 	 lr: 0.00013
[epoch 193: 220/307] 	 train loss: 0.169736 	 lr: 0.00013

val loss: 0.308039 	 acc: 0.908428

[epoch 193: 240/307] 	 train loss: 0.295187 	 lr: 0.00013
[epoch 193: 260/307] 	 train loss: 0.097818 	 lr: 0.00013
[epoch 193: 280/307] 	 train loss: 0.230545 	 lr: 0.00013
[epoch 193: 300/307] 	 train loss: 0.281893 	 lr: 0.00013
[epoch 194:   0/307] 	 train loss: 0.112866 	 lr: 0.00013
[epoch 194:  20/307] 	 train loss: 0.136740 	 lr: 0.00013
[epoch 194:  40/307] 	 train loss: 0.331276 	 lr: 0.00013
[epoch 194:  60/307] 	 train loss: 0.215391 	 lr: 0.00013

val loss: 0.339984 	 acc: 0.906807

[epoch 194:  80/307] 	 train loss: 0.031151 	 lr: 0.00013
[epoch 194: 100/307] 	 train loss: 0.116589 	 lr: 0.00013
[epoch 194: 120/307] 	 train loss: 0.218843 	 lr: 0.00013
[epoch 194: 140/307] 	 train loss: 0.049772 	 lr: 0.00013
[epoch 194: 160/307] 	 train loss: 0.062003 	 lr: 0.00013
[epoch 194: 180/307] 	 train loss: 0.085268 	 lr: 0.00013
[epoch 194: 200/307] 	 train loss: 0.229655 	 lr: 0.00013
[epoch 194: 220/307] 	 train loss: 0.178000 	 lr: 0.00013

val loss: 0.344651 	 acc: 0.903971

[epoch 194: 240/307] 	 train loss: 0.053738 	 lr: 0.00013
[epoch 194: 260/307] 	 train loss: 0.338141 	 lr: 0.00013
[epoch 194: 280/307] 	 train loss: 0.093092 	 lr: 0.00013
[epoch 194: 300/307] 	 train loss: 0.177153 	 lr: 0.00013
[epoch 195:   0/307] 	 train loss: 0.090036 	 lr: 0.00013
[epoch 195:  20/307] 	 train loss: 0.203124 	 lr: 0.00013
[epoch 195:  40/307] 	 train loss: 0.158162 	 lr: 0.00013
[epoch 195:  60/307] 	 train loss: 0.386310 	 lr: 0.00013

val loss: 0.307759 	 acc: 0.908428

[epoch 195:  80/307] 	 train loss: 0.235773 	 lr: 0.00013
[epoch 195: 100/307] 	 train loss: 0.106788 	 lr: 0.00013
[epoch 195: 120/307] 	 train loss: 0.074059 	 lr: 0.00013
[epoch 195: 140/307] 	 train loss: 0.032820 	 lr: 0.00013
[epoch 195: 160/307] 	 train loss: 0.092910 	 lr: 0.00013
[epoch 195: 180/307] 	 train loss: 0.235202 	 lr: 0.00013
[epoch 195: 200/307] 	 train loss: 0.067481 	 lr: 0.00013
[epoch 195: 220/307] 	 train loss: 0.381494 	 lr: 0.00013

val loss: 0.333885 	 acc: 0.903160

[epoch 195: 240/307] 	 train loss: 0.074586 	 lr: 0.00013
[epoch 195: 260/307] 	 train loss: 0.308229 	 lr: 0.00013
[epoch 195: 280/307] 	 train loss: 0.164245 	 lr: 0.00013
[epoch 195: 300/307] 	 train loss: 0.045247 	 lr: 0.00013
[epoch 196:   0/307] 	 train loss: 0.129710 	 lr: 0.00013
[epoch 196:  20/307] 	 train loss: 0.149941 	 lr: 0.00013
[epoch 196:  40/307] 	 train loss: 0.194812 	 lr: 0.00013
[epoch 196:  60/307] 	 train loss: 0.108843 	 lr: 0.00013

val loss: 0.317879 	 acc: 0.918152

saved model with accuracy  0.9181523500810372
[epoch 196:  80/307] 	 train loss: 0.339255 	 lr: 0.00013
[epoch 196: 100/307] 	 train loss: 0.327447 	 lr: 0.00013
[epoch 196: 120/307] 	 train loss: 0.172284 	 lr: 0.00013
[epoch 196: 140/307] 	 train loss: 0.110639 	 lr: 0.00013
[epoch 196: 160/307] 	 train loss: 0.120270 	 lr: 0.00013
[epoch 196: 180/307] 	 train loss: 0.269425 	 lr: 0.00013
[epoch 196: 200/307] 	 train loss: 0.239722 	 lr: 0.00013
[epoch 196: 220/307] 	 train loss: 0.306207 	 lr: 0.00013

val loss: 0.332014 	 acc: 0.909643

[epoch 196: 240/307] 	 train loss: 0.211426 	 lr: 0.00013
[epoch 196: 260/307] 	 train loss: 0.252553 	 lr: 0.00013
[epoch 196: 280/307] 	 train loss: 0.171721 	 lr: 0.00013
[epoch 196: 300/307] 	 train loss: 0.224798 	 lr: 0.00013
[epoch 197:   0/307] 	 train loss: 0.041564 	 lr: 0.00013
[epoch 197:  20/307] 	 train loss: 0.046117 	 lr: 0.00013
[epoch 197:  40/307] 	 train loss: 0.056550 	 lr: 0.00013
[epoch 197:  60/307] 	 train loss: 0.078991 	 lr: 0.00013

val loss: 0.326081 	 acc: 0.912480

[epoch 197:  80/307] 	 train loss: 0.023387 	 lr: 0.00013
[epoch 197: 100/307] 	 train loss: 0.247397 	 lr: 0.00013
[epoch 197: 120/307] 	 train loss: 0.028774 	 lr: 0.00013
[epoch 197: 140/307] 	 train loss: 0.252808 	 lr: 0.00013
[epoch 197: 160/307] 	 train loss: 0.247466 	 lr: 0.00013
[epoch 197: 180/307] 	 train loss: 0.281726 	 lr: 0.00013
[epoch 197: 200/307] 	 train loss: 0.104427 	 lr: 0.00013

val loss: 0.340015 	 acc: 0.907618

[epoch 197: 220/307] 	 train loss: 0.182373 	 lr: 0.00013
[epoch 197: 240/307] 	 train loss: 0.101569 	 lr: 0.00013
[epoch 197: 260/307] 	 train loss: 0.168305 	 lr: 0.00013
[epoch 197: 280/307] 	 train loss: 0.229605 	 lr: 0.00013
[epoch 197: 300/307] 	 train loss: 0.156200 	 lr: 0.00013
[epoch 198:   0/307] 	 train loss: 0.115070 	 lr: 0.00013
[epoch 198:  20/307] 	 train loss: 0.331728 	 lr: 0.00013
[epoch 198:  40/307] 	 train loss: 0.349147 	 lr: 0.00013
[epoch 198:  60/307] 	 train loss: 0.385706 	 lr: 0.00013

val loss: 0.330652 	 acc: 0.910049

[epoch 198:  80/307] 	 train loss: 0.322065 	 lr: 0.00013
[epoch 198: 100/307] 	 train loss: 0.132691 	 lr: 0.00013
[epoch 198: 120/307] 	 train loss: 0.152532 	 lr: 0.00013
[epoch 198: 140/307] 	 train loss: 0.177169 	 lr: 0.00013
[epoch 198: 160/307] 	 train loss: 0.123536 	 lr: 0.00013
[epoch 198: 180/307] 	 train loss: 0.110876 	 lr: 0.00013
[epoch 198: 200/307] 	 train loss: 0.556298 	 lr: 0.00013

val loss: 0.306067 	 acc: 0.906807

[epoch 198: 220/307] 	 train loss: 0.102767 	 lr: 0.00013
[epoch 198: 240/307] 	 train loss: 0.108451 	 lr: 0.00013
[epoch 198: 260/307] 	 train loss: 0.118054 	 lr: 0.00013
[epoch 198: 280/307] 	 train loss: 0.420766 	 lr: 0.00013
[epoch 198: 300/307] 	 train loss: 0.089725 	 lr: 0.00013
[epoch 199:   0/307] 	 train loss: 0.276096 	 lr: 0.00013
[epoch 199:  20/307] 	 train loss: 0.061204 	 lr: 0.00013
[epoch 199:  40/307] 	 train loss: 0.155295 	 lr: 0.00013
[epoch 199:  60/307] 	 train loss: 0.158914 	 lr: 0.00013

val loss: 0.332759 	 acc: 0.905186

[epoch 199:  80/307] 	 train loss: 0.109495 	 lr: 0.00013
[epoch 199: 100/307] 	 train loss: 0.063841 	 lr: 0.00013
[epoch 199: 120/307] 	 train loss: 0.117777 	 lr: 0.00013
[epoch 199: 140/307] 	 train loss: 0.031020 	 lr: 0.00013
[epoch 199: 160/307] 	 train loss: 0.018719 	 lr: 0.00013
[epoch 199: 180/307] 	 train loss: 0.145571 	 lr: 0.00013
[epoch 199: 200/307] 	 train loss: 0.168147 	 lr: 0.00013

val loss: 0.336406 	 acc: 0.903566

[epoch 199: 220/307] 	 train loss: 0.403671 	 lr: 0.00013
[epoch 199: 240/307] 	 train loss: 0.281700 	 lr: 0.00013
[epoch 199: 260/307] 	 train loss: 0.184980 	 lr: 0.00013
[epoch 199: 280/307] 	 train loss: 0.188600 	 lr: 0.00013
[epoch 199: 300/307] 	 train loss: 0.405115 	 lr: 0.00013
[epoch 200:   0/307] 	 train loss: 0.012186 	 lr: 0.00013
[epoch 200:  20/307] 	 train loss: 0.216812 	 lr: 0.00013
[epoch 200:  40/307] 	 train loss: 0.245509 	 lr: 0.00013
[epoch 200:  60/307] 	 train loss: 0.194554 	 lr: 0.00013

val loss: 0.321549 	 acc: 0.907212

[epoch 200:  80/307] 	 train loss: 0.140450 	 lr: 0.00013
[epoch 200: 100/307] 	 train loss: 0.072871 	 lr: 0.00013
[epoch 200: 120/307] 	 train loss: 0.085469 	 lr: 0.00013
[epoch 200: 140/307] 	 train loss: 0.505458 	 lr: 0.00013
[epoch 200: 160/307] 	 train loss: 0.050617 	 lr: 0.00013
[epoch 200: 180/307] 	 train loss: 0.111688 	 lr: 0.00013
[epoch 200: 200/307] 	 train loss: 0.161902 	 lr: 0.00013

val loss: 0.327116 	 acc: 0.910859

[epoch 200: 220/307] 	 train loss: 0.187178 	 lr: 0.00013
[epoch 200: 240/307] 	 train loss: 0.121195 	 lr: 0.00013
[epoch 200: 260/307] 	 train loss: 0.108464 	 lr: 0.00013
[epoch 200: 280/307] 	 train loss: 0.148541 	 lr: 0.00013
[epoch 200: 300/307] 	 train loss: 0.077060 	 lr: 0.00013
