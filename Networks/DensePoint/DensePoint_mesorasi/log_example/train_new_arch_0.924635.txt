
**************************

[epochs]: 400

[checkpoint]: 

[workers]: 1

[decay_step]: 21

[batch_size]: 32

[print_freq_iter]: 20

[num_points]: 1024

[lr_clip]: 1e-05

[val_freq_epoch]: 0.5

[bn_decay]: 0.5

[input_channels]: 0

[evaluate]: 1

[bnm_clip]: 0.01

[lr_decay]: 0.8

[base_lr]: 0.001

[num_classes]: 40

[save_path]: cls

[data_root]: ModelNet40

[weight_decay]: 0

[bn_momentum]: 0.9

**************************

[epoch   1:   0/307] 	 train loss: 3.970863 	 lr: 0.00100
[epoch   1:  20/307] 	 train loss: 2.814231 	 lr: 0.00100
[epoch   1:  40/307] 	 train loss: 2.135728 	 lr: 0.00100
[epoch   1:  60/307] 	 train loss: 1.615086 	 lr: 0.00100
[epoch   1:  80/307] 	 train loss: 1.823151 	 lr: 0.00100
[epoch   1: 100/307] 	 train loss: 1.317072 	 lr: 0.00100
[epoch   1: 120/307] 	 train loss: 1.834490 	 lr: 0.00100
[epoch   1: 140/307] 	 train loss: 1.103330 	 lr: 0.00100

val loss: 2.548582 	 acc: 0.433955

[epoch   1: 160/307] 	 train loss: 1.216634 	 lr: 0.00100
[epoch   1: 180/307] 	 train loss: 1.311214 	 lr: 0.00100
[epoch   1: 200/307] 	 train loss: 1.484734 	 lr: 0.00100
[epoch   1: 220/307] 	 train loss: 1.069482 	 lr: 0.00100
[epoch   1: 240/307] 	 train loss: 1.139051 	 lr: 0.00100
[epoch   1: 260/307] 	 train loss: 1.408137 	 lr: 0.00100
[epoch   1: 280/307] 	 train loss: 1.317657 	 lr: 0.00100
[epoch   1: 300/307] 	 train loss: 1.600143 	 lr: 0.00100

val loss: 2.166157 	 acc: 0.482172

[epoch   2:   0/307] 	 train loss: 1.077993 	 lr: 0.00100
[epoch   2:  20/307] 	 train loss: 1.378602 	 lr: 0.00100
[epoch   2:  40/307] 	 train loss: 0.753699 	 lr: 0.00100
[epoch   2:  60/307] 	 train loss: 1.075102 	 lr: 0.00100
[epoch   2:  80/307] 	 train loss: 1.049642 	 lr: 0.00100
[epoch   2: 100/307] 	 train loss: 0.964725 	 lr: 0.00100
[epoch   2: 120/307] 	 train loss: 1.031918 	 lr: 0.00100
[epoch   2: 140/307] 	 train loss: 0.913879 	 lr: 0.00100

val loss: 0.749234 	 acc: 0.785251

[epoch   2: 160/307] 	 train loss: 0.674395 	 lr: 0.00100
[epoch   2: 180/307] 	 train loss: 0.941480 	 lr: 0.00100
[epoch   2: 200/307] 	 train loss: 0.946730 	 lr: 0.00100
[epoch   2: 220/307] 	 train loss: 1.023868 	 lr: 0.00100
[epoch   2: 240/307] 	 train loss: 1.050195 	 lr: 0.00100
[epoch   2: 260/307] 	 train loss: 1.038676 	 lr: 0.00100
[epoch   2: 280/307] 	 train loss: 0.864282 	 lr: 0.00100
[epoch   2: 300/307] 	 train loss: 0.817274 	 lr: 0.00100

val loss: 0.660167 	 acc: 0.800243

[epoch   3:   0/307] 	 train loss: 0.746094 	 lr: 0.00100
[epoch   3:  20/307] 	 train loss: 0.941305 	 lr: 0.00100
[epoch   3:  40/307] 	 train loss: 0.720812 	 lr: 0.00100
[epoch   3:  60/307] 	 train loss: 0.782513 	 lr: 0.00100
[epoch   3:  80/307] 	 train loss: 0.846454 	 lr: 0.00100
[epoch   3: 100/307] 	 train loss: 0.748249 	 lr: 0.00100
[epoch   3: 120/307] 	 train loss: 0.782336 	 lr: 0.00100
[epoch   3: 140/307] 	 train loss: 0.898912 	 lr: 0.00100

val loss: 0.653844 	 acc: 0.805105

[epoch   3: 160/307] 	 train loss: 0.664620 	 lr: 0.00100
[epoch   3: 180/307] 	 train loss: 0.869281 	 lr: 0.00100
[epoch   3: 200/307] 	 train loss: 0.333641 	 lr: 0.00100
[epoch   3: 220/307] 	 train loss: 0.498405 	 lr: 0.00100
[epoch   3: 240/307] 	 train loss: 0.696269 	 lr: 0.00100
[epoch   3: 260/307] 	 train loss: 0.559358 	 lr: 0.00100
[epoch   3: 280/307] 	 train loss: 0.702870 	 lr: 0.00100
[epoch   3: 300/307] 	 train loss: 0.846673 	 lr: 0.00100

val loss: 0.594626 	 acc: 0.817666

[epoch   4:   0/307] 	 train loss: 0.704094 	 lr: 0.00100
[epoch   4:  20/307] 	 train loss: 0.556010 	 lr: 0.00100
[epoch   4:  40/307] 	 train loss: 0.625665 	 lr: 0.00100
[epoch   4:  60/307] 	 train loss: 0.653546 	 lr: 0.00100
[epoch   4:  80/307] 	 train loss: 0.726784 	 lr: 0.00100
[epoch   4: 100/307] 	 train loss: 0.694893 	 lr: 0.00100
[epoch   4: 120/307] 	 train loss: 0.707165 	 lr: 0.00100
[epoch   4: 140/307] 	 train loss: 0.974501 	 lr: 0.00100

val loss: 0.540870 	 acc: 0.835900

[epoch   4: 160/307] 	 train loss: 0.610078 	 lr: 0.00100
[epoch   4: 180/307] 	 train loss: 0.632752 	 lr: 0.00100
[epoch   4: 200/307] 	 train loss: 0.571820 	 lr: 0.00100
[epoch   4: 220/307] 	 train loss: 0.410839 	 lr: 0.00100
[epoch   4: 240/307] 	 train loss: 0.656639 	 lr: 0.00100
[epoch   4: 260/307] 	 train loss: 0.790704 	 lr: 0.00100
[epoch   4: 280/307] 	 train loss: 0.404690 	 lr: 0.00100

val loss: 0.538788 	 acc: 0.837925

[epoch   4: 300/307] 	 train loss: 1.096869 	 lr: 0.00100
[epoch   5:   0/307] 	 train loss: 0.540574 	 lr: 0.00100
[epoch   5:  20/307] 	 train loss: 0.620710 	 lr: 0.00100
[epoch   5:  40/307] 	 train loss: 0.473041 	 lr: 0.00100
[epoch   5:  60/307] 	 train loss: 0.544379 	 lr: 0.00100
[epoch   5:  80/307] 	 train loss: 0.807055 	 lr: 0.00100
[epoch   5: 100/307] 	 train loss: 0.702386 	 lr: 0.00100
[epoch   5: 120/307] 	 train loss: 0.656717 	 lr: 0.00100
[epoch   5: 140/307] 	 train loss: 0.633263 	 lr: 0.00100

val loss: 0.523970 	 acc: 0.837115

[epoch   5: 160/307] 	 train loss: 0.670047 	 lr: 0.00100
[epoch   5: 180/307] 	 train loss: 0.804656 	 lr: 0.00100
[epoch   5: 200/307] 	 train loss: 0.406221 	 lr: 0.00100
[epoch   5: 220/307] 	 train loss: 0.651260 	 lr: 0.00100
[epoch   5: 240/307] 	 train loss: 0.730892 	 lr: 0.00100
[epoch   5: 260/307] 	 train loss: 0.437541 	 lr: 0.00100
[epoch   5: 280/307] 	 train loss: 0.466563 	 lr: 0.00100

val loss: 0.486188 	 acc: 0.850486

[epoch   5: 300/307] 	 train loss: 0.438976 	 lr: 0.00100
[epoch   6:   0/307] 	 train loss: 0.438049 	 lr: 0.00100
[epoch   6:  20/307] 	 train loss: 0.580960 	 lr: 0.00100
[epoch   6:  40/307] 	 train loss: 0.248679 	 lr: 0.00100
[epoch   6:  60/307] 	 train loss: 0.615105 	 lr: 0.00100
[epoch   6:  80/307] 	 train loss: 0.734332 	 lr: 0.00100
[epoch   6: 100/307] 	 train loss: 0.422019 	 lr: 0.00100
[epoch   6: 120/307] 	 train loss: 0.676030 	 lr: 0.00100
[epoch   6: 140/307] 	 train loss: 0.655604 	 lr: 0.00100

val loss: 0.519583 	 acc: 0.844003

[epoch   6: 160/307] 	 train loss: 0.415821 	 lr: 0.00100
[epoch   6: 180/307] 	 train loss: 0.786687 	 lr: 0.00100
[epoch   6: 200/307] 	 train loss: 0.630005 	 lr: 0.00100
[epoch   6: 220/307] 	 train loss: 0.424760 	 lr: 0.00100
[epoch   6: 240/307] 	 train loss: 0.554664 	 lr: 0.00100
[epoch   6: 260/307] 	 train loss: 0.499705 	 lr: 0.00100
[epoch   6: 280/307] 	 train loss: 0.515392 	 lr: 0.00100

val loss: 0.457566 	 acc: 0.865478

[epoch   6: 300/307] 	 train loss: 0.242108 	 lr: 0.00100
[epoch   7:   0/307] 	 train loss: 0.311197 	 lr: 0.00100
[epoch   7:  20/307] 	 train loss: 0.395748 	 lr: 0.00100
[epoch   7:  40/307] 	 train loss: 0.682443 	 lr: 0.00100
[epoch   7:  60/307] 	 train loss: 0.402129 	 lr: 0.00100
[epoch   7:  80/307] 	 train loss: 0.476940 	 lr: 0.00100
[epoch   7: 100/307] 	 train loss: 0.276590 	 lr: 0.00100
[epoch   7: 120/307] 	 train loss: 0.198361 	 lr: 0.00100
[epoch   7: 140/307] 	 train loss: 0.710617 	 lr: 0.00100

val loss: 0.439492 	 acc: 0.870746

[epoch   7: 160/307] 	 train loss: 0.538708 	 lr: 0.00100
[epoch   7: 180/307] 	 train loss: 0.596353 	 lr: 0.00100
[epoch   7: 200/307] 	 train loss: 0.386929 	 lr: 0.00100
[epoch   7: 220/307] 	 train loss: 0.457405 	 lr: 0.00100
[epoch   7: 240/307] 	 train loss: 0.269048 	 lr: 0.00100
[epoch   7: 260/307] 	 train loss: 1.199883 	 lr: 0.00100
[epoch   7: 280/307] 	 train loss: 0.305109 	 lr: 0.00100

val loss: 0.426008 	 acc: 0.870746

[epoch   7: 300/307] 	 train loss: 0.634079 	 lr: 0.00100
[epoch   8:   0/307] 	 train loss: 0.287247 	 lr: 0.00100
[epoch   8:  20/307] 	 train loss: 0.465077 	 lr: 0.00100
[epoch   8:  40/307] 	 train loss: 0.342936 	 lr: 0.00100
[epoch   8:  60/307] 	 train loss: 0.528251 	 lr: 0.00100
[epoch   8:  80/307] 	 train loss: 1.044900 	 lr: 0.00100
[epoch   8: 100/307] 	 train loss: 0.705946 	 lr: 0.00100
[epoch   8: 120/307] 	 train loss: 0.464941 	 lr: 0.00100

val loss: 0.442966 	 acc: 0.858590

[epoch   8: 140/307] 	 train loss: 0.789789 	 lr: 0.00100
[epoch   8: 160/307] 	 train loss: 0.341721 	 lr: 0.00100
[epoch   8: 180/307] 	 train loss: 0.487430 	 lr: 0.00100
[epoch   8: 200/307] 	 train loss: 0.490929 	 lr: 0.00100
[epoch   8: 220/307] 	 train loss: 0.396787 	 lr: 0.00100
[epoch   8: 240/307] 	 train loss: 0.690614 	 lr: 0.00100
[epoch   8: 260/307] 	 train loss: 0.385809 	 lr: 0.00100
[epoch   8: 280/307] 	 train loss: 0.692236 	 lr: 0.00100

val loss: 0.466943 	 acc: 0.862642

[epoch   8: 300/307] 	 train loss: 0.449961 	 lr: 0.00100
[epoch   9:   0/307] 	 train loss: 0.478345 	 lr: 0.00100
[epoch   9:  20/307] 	 train loss: 1.418266 	 lr: 0.00100
[epoch   9:  40/307] 	 train loss: 0.359212 	 lr: 0.00100
[epoch   9:  60/307] 	 train loss: 0.380333 	 lr: 0.00100
[epoch   9:  80/307] 	 train loss: 0.398237 	 lr: 0.00100
[epoch   9: 100/307] 	 train loss: 0.596072 	 lr: 0.00100
[epoch   9: 120/307] 	 train loss: 0.803193 	 lr: 0.00100

val loss: 0.377872 	 acc: 0.886143

[epoch   9: 140/307] 	 train loss: 0.524934 	 lr: 0.00100
[epoch   9: 160/307] 	 train loss: 0.434408 	 lr: 0.00100
[epoch   9: 180/307] 	 train loss: 0.349140 	 lr: 0.00100
[epoch   9: 200/307] 	 train loss: 0.840916 	 lr: 0.00100
[epoch   9: 220/307] 	 train loss: 0.258000 	 lr: 0.00100
[epoch   9: 240/307] 	 train loss: 0.332135 	 lr: 0.00100
[epoch   9: 260/307] 	 train loss: 0.590586 	 lr: 0.00100
[epoch   9: 280/307] 	 train loss: 0.300104 	 lr: 0.00100

val loss: 0.441252 	 acc: 0.869530

[epoch   9: 300/307] 	 train loss: 0.496189 	 lr: 0.00100
[epoch  10:   0/307] 	 train loss: 0.524082 	 lr: 0.00100
[epoch  10:  20/307] 	 train loss: 0.268686 	 lr: 0.00100
[epoch  10:  40/307] 	 train loss: 0.306241 	 lr: 0.00100
[epoch  10:  60/307] 	 train loss: 0.300863 	 lr: 0.00100
[epoch  10:  80/307] 	 train loss: 0.474870 	 lr: 0.00100
[epoch  10: 100/307] 	 train loss: 0.243616 	 lr: 0.00100
[epoch  10: 120/307] 	 train loss: 0.318449 	 lr: 0.00100

val loss: 0.432417 	 acc: 0.860616

[epoch  10: 140/307] 	 train loss: 0.472405 	 lr: 0.00100
[epoch  10: 160/307] 	 train loss: 0.663252 	 lr: 0.00100
[epoch  10: 180/307] 	 train loss: 0.314518 	 lr: 0.00100
[epoch  10: 200/307] 	 train loss: 0.931859 	 lr: 0.00100
[epoch  10: 220/307] 	 train loss: 0.425520 	 lr: 0.00100
[epoch  10: 240/307] 	 train loss: 0.600344 	 lr: 0.00100
[epoch  10: 260/307] 	 train loss: 0.666095 	 lr: 0.00100
[epoch  10: 280/307] 	 train loss: 0.463311 	 lr: 0.00100

val loss: 0.442088 	 acc: 0.856969

[epoch  10: 300/307] 	 train loss: 0.616838 	 lr: 0.00100
[epoch  11:   0/307] 	 train loss: 0.218680 	 lr: 0.00100
[epoch  11:  20/307] 	 train loss: 0.520567 	 lr: 0.00100
[epoch  11:  40/307] 	 train loss: 0.314205 	 lr: 0.00100
[epoch  11:  60/307] 	 train loss: 0.342134 	 lr: 0.00100
[epoch  11:  80/307] 	 train loss: 0.201056 	 lr: 0.00100
[epoch  11: 100/307] 	 train loss: 0.210144 	 lr: 0.00100
[epoch  11: 120/307] 	 train loss: 0.385963 	 lr: 0.00100

val loss: 0.366447 	 acc: 0.891005

[epoch  11: 140/307] 	 train loss: 0.197543 	 lr: 0.00100
[epoch  11: 160/307] 	 train loss: 0.317997 	 lr: 0.00100
[epoch  11: 180/307] 	 train loss: 0.393069 	 lr: 0.00100
[epoch  11: 200/307] 	 train loss: 0.526724 	 lr: 0.00100
[epoch  11: 220/307] 	 train loss: 0.164788 	 lr: 0.00100
[epoch  11: 240/307] 	 train loss: 0.675960 	 lr: 0.00100
[epoch  11: 260/307] 	 train loss: 0.248187 	 lr: 0.00100
[epoch  11: 280/307] 	 train loss: 0.543219 	 lr: 0.00100

val loss: 0.393186 	 acc: 0.882901

[epoch  11: 300/307] 	 train loss: 0.525548 	 lr: 0.00100
[epoch  12:   0/307] 	 train loss: 0.700484 	 lr: 0.00100
[epoch  12:  20/307] 	 train loss: 0.269248 	 lr: 0.00100
[epoch  12:  40/307] 	 train loss: 0.629188 	 lr: 0.00100
[epoch  12:  60/307] 	 train loss: 0.431810 	 lr: 0.00100
[epoch  12:  80/307] 	 train loss: 0.446488 	 lr: 0.00100
[epoch  12: 100/307] 	 train loss: 0.575569 	 lr: 0.00100
[epoch  12: 120/307] 	 train loss: 0.836500 	 lr: 0.00100

val loss: 0.417682 	 acc: 0.871556

[epoch  12: 140/307] 	 train loss: 0.250757 	 lr: 0.00100
[epoch  12: 160/307] 	 train loss: 0.402090 	 lr: 0.00100
[epoch  12: 180/307] 	 train loss: 0.586932 	 lr: 0.00100
[epoch  12: 200/307] 	 train loss: 0.747475 	 lr: 0.00100
[epoch  12: 220/307] 	 train loss: 0.393496 	 lr: 0.00100
[epoch  12: 240/307] 	 train loss: 0.398371 	 lr: 0.00100
[epoch  12: 260/307] 	 train loss: 0.421505 	 lr: 0.00100
[epoch  12: 280/307] 	 train loss: 0.651483 	 lr: 0.00100

val loss: 0.391143 	 acc: 0.881686

[epoch  12: 300/307] 	 train loss: 0.815831 	 lr: 0.00100
[epoch  13:   0/307] 	 train loss: 0.401435 	 lr: 0.00100
[epoch  13:  20/307] 	 train loss: 0.340582 	 lr: 0.00100
[epoch  13:  40/307] 	 train loss: 0.369142 	 lr: 0.00100
[epoch  13:  60/307] 	 train loss: 0.329495 	 lr: 0.00100
[epoch  13:  80/307] 	 train loss: 0.324458 	 lr: 0.00100
[epoch  13: 100/307] 	 train loss: 1.063179 	 lr: 0.00100
[epoch  13: 120/307] 	 train loss: 0.476511 	 lr: 0.00100

val loss: 0.377585 	 acc: 0.887358

[epoch  13: 140/307] 	 train loss: 0.300797 	 lr: 0.00100
[epoch  13: 160/307] 	 train loss: 0.501246 	 lr: 0.00100
[epoch  13: 180/307] 	 train loss: 0.288328 	 lr: 0.00100
[epoch  13: 200/307] 	 train loss: 0.401356 	 lr: 0.00100
[epoch  13: 220/307] 	 train loss: 0.727952 	 lr: 0.00100
[epoch  13: 240/307] 	 train loss: 0.435580 	 lr: 0.00100
[epoch  13: 260/307] 	 train loss: 0.501083 	 lr: 0.00100
[epoch  13: 280/307] 	 train loss: 0.709819 	 lr: 0.00100

val loss: 0.383671 	 acc: 0.888979

[epoch  13: 300/307] 	 train loss: 0.379223 	 lr: 0.00100
[epoch  14:   0/307] 	 train loss: 0.911398 	 lr: 0.00100
[epoch  14:  20/307] 	 train loss: 0.397822 	 lr: 0.00100
[epoch  14:  40/307] 	 train loss: 0.367123 	 lr: 0.00100
[epoch  14:  60/307] 	 train loss: 0.584203 	 lr: 0.00100
[epoch  14:  80/307] 	 train loss: 0.440155 	 lr: 0.00100
[epoch  14: 100/307] 	 train loss: 0.653340 	 lr: 0.00100
[epoch  14: 120/307] 	 train loss: 0.143262 	 lr: 0.00100

val loss: 0.364756 	 acc: 0.895057

[epoch  14: 140/307] 	 train loss: 0.239912 	 lr: 0.00100
[epoch  14: 160/307] 	 train loss: 0.368294 	 lr: 0.00100
[epoch  14: 180/307] 	 train loss: 0.561999 	 lr: 0.00100
[epoch  14: 200/307] 	 train loss: 0.252951 	 lr: 0.00100
[epoch  14: 220/307] 	 train loss: 0.205846 	 lr: 0.00100
[epoch  14: 240/307] 	 train loss: 0.755208 	 lr: 0.00100
[epoch  14: 260/307] 	 train loss: 0.636247 	 lr: 0.00100

val loss: 0.401509 	 acc: 0.878039

[epoch  14: 280/307] 	 train loss: 0.391727 	 lr: 0.00100
[epoch  14: 300/307] 	 train loss: 0.346014 	 lr: 0.00100
[epoch  15:   0/307] 	 train loss: 0.470968 	 lr: 0.00100
[epoch  15:  20/307] 	 train loss: 0.183993 	 lr: 0.00100
[epoch  15:  40/307] 	 train loss: 0.262413 	 lr: 0.00100
[epoch  15:  60/307] 	 train loss: 0.402468 	 lr: 0.00100
[epoch  15:  80/307] 	 train loss: 0.361347 	 lr: 0.00100
[epoch  15: 100/307] 	 train loss: 0.140077 	 lr: 0.00100
[epoch  15: 120/307] 	 train loss: 0.265920 	 lr: 0.00100

val loss: 0.377313 	 acc: 0.893436

[epoch  15: 140/307] 	 train loss: 0.489704 	 lr: 0.00100
[epoch  15: 160/307] 	 train loss: 0.318713 	 lr: 0.00100
[epoch  15: 180/307] 	 train loss: 0.598465 	 lr: 0.00100
[epoch  15: 200/307] 	 train loss: 0.519786 	 lr: 0.00100
[epoch  15: 220/307] 	 train loss: 0.539282 	 lr: 0.00100
[epoch  15: 240/307] 	 train loss: 0.300631 	 lr: 0.00100
[epoch  15: 260/307] 	 train loss: 0.330432 	 lr: 0.00100

val loss: 0.405226 	 acc: 0.886953

[epoch  15: 280/307] 	 train loss: 0.517161 	 lr: 0.00100
[epoch  15: 300/307] 	 train loss: 0.380677 	 lr: 0.00100
[epoch  16:   0/307] 	 train loss: 0.269546 	 lr: 0.00100
[epoch  16:  20/307] 	 train loss: 0.399785 	 lr: 0.00100
[epoch  16:  40/307] 	 train loss: 0.382997 	 lr: 0.00100
[epoch  16:  60/307] 	 train loss: 0.467646 	 lr: 0.00100
[epoch  16:  80/307] 	 train loss: 0.822187 	 lr: 0.00100
[epoch  16: 100/307] 	 train loss: 0.279877 	 lr: 0.00100
[epoch  16: 120/307] 	 train loss: 0.190646 	 lr: 0.00100

val loss: 0.370780 	 acc: 0.887763

[epoch  16: 140/307] 	 train loss: 0.782310 	 lr: 0.00100
[epoch  16: 160/307] 	 train loss: 0.372972 	 lr: 0.00100
[epoch  16: 180/307] 	 train loss: 0.838023 	 lr: 0.00100
[epoch  16: 200/307] 	 train loss: 0.326684 	 lr: 0.00100
[epoch  16: 220/307] 	 train loss: 0.387280 	 lr: 0.00100
[epoch  16: 240/307] 	 train loss: 0.470319 	 lr: 0.00100
[epoch  16: 260/307] 	 train loss: 0.457322 	 lr: 0.00100

val loss: 0.398339 	 acc: 0.886143

[epoch  16: 280/307] 	 train loss: 0.540124 	 lr: 0.00100
[epoch  16: 300/307] 	 train loss: 0.297441 	 lr: 0.00100
[epoch  17:   0/307] 	 train loss: 0.333998 	 lr: 0.00100
[epoch  17:  20/307] 	 train loss: 0.422888 	 lr: 0.00100
[epoch  17:  40/307] 	 train loss: 0.226716 	 lr: 0.00100
[epoch  17:  60/307] 	 train loss: 0.233061 	 lr: 0.00100
[epoch  17:  80/307] 	 train loss: 0.407352 	 lr: 0.00100
[epoch  17: 100/307] 	 train loss: 0.389363 	 lr: 0.00100
[epoch  17: 120/307] 	 train loss: 0.473150 	 lr: 0.00100

val loss: 0.394190 	 acc: 0.886953

[epoch  17: 140/307] 	 train loss: 0.401653 	 lr: 0.00100
[epoch  17: 160/307] 	 train loss: 0.729755 	 lr: 0.00100
[epoch  17: 180/307] 	 train loss: 0.145477 	 lr: 0.00100
[epoch  17: 200/307] 	 train loss: 0.431392 	 lr: 0.00100
[epoch  17: 220/307] 	 train loss: 0.473255 	 lr: 0.00100
[epoch  17: 240/307] 	 train loss: 0.293040 	 lr: 0.00100
[epoch  17: 260/307] 	 train loss: 0.566271 	 lr: 0.00100

val loss: 0.342959 	 acc: 0.897893

[epoch  17: 280/307] 	 train loss: 0.412918 	 lr: 0.00100
[epoch  17: 300/307] 	 train loss: 0.502884 	 lr: 0.00100
[epoch  18:   0/307] 	 train loss: 0.373932 	 lr: 0.00100
[epoch  18:  20/307] 	 train loss: 0.423166 	 lr: 0.00100
[epoch  18:  40/307] 	 train loss: 0.451677 	 lr: 0.00100
[epoch  18:  60/307] 	 train loss: 0.335248 	 lr: 0.00100
[epoch  18:  80/307] 	 train loss: 0.157879 	 lr: 0.00100
[epoch  18: 100/307] 	 train loss: 0.279885 	 lr: 0.00100

val loss: 0.371427 	 acc: 0.886143

[epoch  18: 120/307] 	 train loss: 0.274456 	 lr: 0.00100
[epoch  18: 140/307] 	 train loss: 0.117287 	 lr: 0.00100
[epoch  18: 160/307] 	 train loss: 0.361510 	 lr: 0.00100
[epoch  18: 180/307] 	 train loss: 0.328789 	 lr: 0.00100
[epoch  18: 200/307] 	 train loss: 0.354823 	 lr: 0.00100
[epoch  18: 220/307] 	 train loss: 0.214163 	 lr: 0.00100
[epoch  18: 240/307] 	 train loss: 0.214264 	 lr: 0.00100
[epoch  18: 260/307] 	 train loss: 0.575393 	 lr: 0.00100

val loss: 0.398829 	 acc: 0.869125

[epoch  18: 280/307] 	 train loss: 0.424463 	 lr: 0.00100
[epoch  18: 300/307] 	 train loss: 0.446939 	 lr: 0.00100
[epoch  19:   0/307] 	 train loss: 0.249192 	 lr: 0.00100
[epoch  19:  20/307] 	 train loss: 0.641486 	 lr: 0.00100
[epoch  19:  40/307] 	 train loss: 0.209734 	 lr: 0.00100
[epoch  19:  60/307] 	 train loss: 0.488050 	 lr: 0.00100
[epoch  19:  80/307] 	 train loss: 0.472860 	 lr: 0.00100
[epoch  19: 100/307] 	 train loss: 0.547654 	 lr: 0.00100

val loss: 0.389991 	 acc: 0.883306

[epoch  19: 120/307] 	 train loss: 0.164021 	 lr: 0.00100
[epoch  19: 140/307] 	 train loss: 0.286708 	 lr: 0.00100
[epoch  19: 160/307] 	 train loss: 0.142473 	 lr: 0.00100
[epoch  19: 180/307] 	 train loss: 0.187851 	 lr: 0.00100
[epoch  19: 200/307] 	 train loss: 0.558066 	 lr: 0.00100
[epoch  19: 220/307] 	 train loss: 0.376725 	 lr: 0.00100
[epoch  19: 240/307] 	 train loss: 0.369295 	 lr: 0.00100
[epoch  19: 260/307] 	 train loss: 0.446712 	 lr: 0.00100

val loss: 0.353860 	 acc: 0.888979

[epoch  19: 280/307] 	 train loss: 0.220633 	 lr: 0.00100
[epoch  19: 300/307] 	 train loss: 0.244215 	 lr: 0.00100
[epoch  20:   0/307] 	 train loss: 0.162140 	 lr: 0.00100
[epoch  20:  20/307] 	 train loss: 0.198318 	 lr: 0.00100
[epoch  20:  40/307] 	 train loss: 0.196156 	 lr: 0.00100
[epoch  20:  60/307] 	 train loss: 0.291470 	 lr: 0.00100
[epoch  20:  80/307] 	 train loss: 0.443722 	 lr: 0.00100
[epoch  20: 100/307] 	 train loss: 0.318932 	 lr: 0.00100

val loss: 0.369766 	 acc: 0.881280

[epoch  20: 120/307] 	 train loss: 0.250898 	 lr: 0.00100
[epoch  20: 140/307] 	 train loss: 0.243874 	 lr: 0.00100
[epoch  20: 160/307] 	 train loss: 0.229960 	 lr: 0.00100
[epoch  20: 180/307] 	 train loss: 0.136960 	 lr: 0.00100
[epoch  20: 200/307] 	 train loss: 0.292579 	 lr: 0.00100
[epoch  20: 220/307] 	 train loss: 0.483169 	 lr: 0.00100
[epoch  20: 240/307] 	 train loss: 0.412359 	 lr: 0.00100
[epoch  20: 260/307] 	 train loss: 0.563874 	 lr: 0.00100

val loss: 0.375931 	 acc: 0.894246

[epoch  20: 280/307] 	 train loss: 0.412358 	 lr: 0.00100
[epoch  20: 300/307] 	 train loss: 0.457700 	 lr: 0.00100
[epoch  21:   0/307] 	 train loss: 0.081423 	 lr: 0.00100
[epoch  21:  20/307] 	 train loss: 0.334765 	 lr: 0.00100
[epoch  21:  40/307] 	 train loss: 0.385674 	 lr: 0.00100
[epoch  21:  60/307] 	 train loss: 0.335369 	 lr: 0.00100
[epoch  21:  80/307] 	 train loss: 0.419589 	 lr: 0.00100
[epoch  21: 100/307] 	 train loss: 0.210817 	 lr: 0.00100

val loss: 0.344554 	 acc: 0.901135

[epoch  21: 120/307] 	 train loss: 0.246343 	 lr: 0.00100
[epoch  21: 140/307] 	 train loss: 0.197342 	 lr: 0.00100
[epoch  21: 160/307] 	 train loss: 0.303923 	 lr: 0.00100
[epoch  21: 180/307] 	 train loss: 0.428013 	 lr: 0.00100
[epoch  21: 200/307] 	 train loss: 0.382485 	 lr: 0.00100
[epoch  21: 220/307] 	 train loss: 0.795153 	 lr: 0.00100
[epoch  21: 240/307] 	 train loss: 0.576788 	 lr: 0.00100
[epoch  21: 260/307] 	 train loss: 0.252298 	 lr: 0.00100

val loss: 0.382212 	 acc: 0.881280

[epoch  21: 280/307] 	 train loss: 0.515041 	 lr: 0.00100
[epoch  21: 300/307] 	 train loss: 0.299026 	 lr: 0.00100
[epoch  22:   0/307] 	 train loss: 0.205726 	 lr: 0.00080
[epoch  22:  20/307] 	 train loss: 0.368054 	 lr: 0.00080
[epoch  22:  40/307] 	 train loss: 0.253561 	 lr: 0.00080
[epoch  22:  60/307] 	 train loss: 0.766289 	 lr: 0.00080
[epoch  22:  80/307] 	 train loss: 0.404824 	 lr: 0.00080
[epoch  22: 100/307] 	 train loss: 0.693875 	 lr: 0.00080

val loss: 0.372971 	 acc: 0.884117

[epoch  22: 120/307] 	 train loss: 0.367038 	 lr: 0.00080
[epoch  22: 140/307] 	 train loss: 0.581443 	 lr: 0.00080
[epoch  22: 160/307] 	 train loss: 0.322645 	 lr: 0.00080
[epoch  22: 180/307] 	 train loss: 0.561973 	 lr: 0.00080
[epoch  22: 200/307] 	 train loss: 0.269536 	 lr: 0.00080
[epoch  22: 220/307] 	 train loss: 0.660690 	 lr: 0.00080
[epoch  22: 240/307] 	 train loss: 0.547653 	 lr: 0.00080
[epoch  22: 260/307] 	 train loss: 0.325297 	 lr: 0.00080

val loss: 0.360669 	 acc: 0.891005

[epoch  22: 280/307] 	 train loss: 0.120357 	 lr: 0.00080
[epoch  22: 300/307] 	 train loss: 0.563160 	 lr: 0.00080
[epoch  23:   0/307] 	 train loss: 0.111448 	 lr: 0.00080
[epoch  23:  20/307] 	 train loss: 0.277290 	 lr: 0.00080
[epoch  23:  40/307] 	 train loss: 0.291573 	 lr: 0.00080
[epoch  23:  60/307] 	 train loss: 0.517429 	 lr: 0.00080
[epoch  23:  80/307] 	 train loss: 0.471969 	 lr: 0.00080
[epoch  23: 100/307] 	 train loss: 0.230183 	 lr: 0.00080

val loss: 0.323556 	 acc: 0.905592

[epoch  23: 120/307] 	 train loss: 0.383641 	 lr: 0.00080
[epoch  23: 140/307] 	 train loss: 0.193213 	 lr: 0.00080
[epoch  23: 160/307] 	 train loss: 0.135356 	 lr: 0.00080
[epoch  23: 180/307] 	 train loss: 0.412608 	 lr: 0.00080
[epoch  23: 200/307] 	 train loss: 0.309871 	 lr: 0.00080
[epoch  23: 220/307] 	 train loss: 0.511434 	 lr: 0.00080
[epoch  23: 240/307] 	 train loss: 0.289097 	 lr: 0.00080
[epoch  23: 260/307] 	 train loss: 0.209390 	 lr: 0.00080

val loss: 0.333253 	 acc: 0.903566

[epoch  23: 280/307] 	 train loss: 0.141058 	 lr: 0.00080
[epoch  23: 300/307] 	 train loss: 0.435591 	 lr: 0.00080
[epoch  24:   0/307] 	 train loss: 0.416274 	 lr: 0.00080
[epoch  24:  20/307] 	 train loss: 0.368916 	 lr: 0.00080
[epoch  24:  40/307] 	 train loss: 0.266864 	 lr: 0.00080
[epoch  24:  60/307] 	 train loss: 0.262998 	 lr: 0.00080
[epoch  24:  80/307] 	 train loss: 0.433075 	 lr: 0.00080
[epoch  24: 100/307] 	 train loss: 0.238971 	 lr: 0.00080

val loss: 0.336570 	 acc: 0.901135

[epoch  24: 120/307] 	 train loss: 0.319075 	 lr: 0.00080
[epoch  24: 140/307] 	 train loss: 0.356855 	 lr: 0.00080
[epoch  24: 160/307] 	 train loss: 0.119990 	 lr: 0.00080
[epoch  24: 180/307] 	 train loss: 0.259221 	 lr: 0.00080
[epoch  24: 200/307] 	 train loss: 0.284766 	 lr: 0.00080
[epoch  24: 220/307] 	 train loss: 0.184721 	 lr: 0.00080
[epoch  24: 240/307] 	 train loss: 0.565221 	 lr: 0.00080

val loss: 0.363946 	 acc: 0.891410

[epoch  24: 260/307] 	 train loss: 0.624667 	 lr: 0.00080
[epoch  24: 280/307] 	 train loss: 0.375389 	 lr: 0.00080
[epoch  24: 300/307] 	 train loss: 0.159641 	 lr: 0.00080
[epoch  25:   0/307] 	 train loss: 0.586171 	 lr: 0.00080
[epoch  25:  20/307] 	 train loss: 0.243459 	 lr: 0.00080
[epoch  25:  40/307] 	 train loss: 0.383790 	 lr: 0.00080
[epoch  25:  60/307] 	 train loss: 0.140428 	 lr: 0.00080
[epoch  25:  80/307] 	 train loss: 0.233262 	 lr: 0.00080
[epoch  25: 100/307] 	 train loss: 0.141329 	 lr: 0.00080

val loss: 0.336352 	 acc: 0.900324

[epoch  25: 120/307] 	 train loss: 0.285909 	 lr: 0.00080
[epoch  25: 140/307] 	 train loss: 0.314132 	 lr: 0.00080
[epoch  25: 160/307] 	 train loss: 0.252185 	 lr: 0.00080
[epoch  25: 180/307] 	 train loss: 0.244357 	 lr: 0.00080
[epoch  25: 200/307] 	 train loss: 0.409800 	 lr: 0.00080
[epoch  25: 220/307] 	 train loss: 0.229559 	 lr: 0.00080
[epoch  25: 240/307] 	 train loss: 0.193338 	 lr: 0.00080

val loss: 0.321693 	 acc: 0.903566

[epoch  25: 260/307] 	 train loss: 0.272672 	 lr: 0.00080
[epoch  25: 280/307] 	 train loss: 0.148314 	 lr: 0.00080
[epoch  25: 300/307] 	 train loss: 0.228478 	 lr: 0.00080
[epoch  26:   0/307] 	 train loss: 0.316840 	 lr: 0.00080
[epoch  26:  20/307] 	 train loss: 0.336691 	 lr: 0.00080
[epoch  26:  40/307] 	 train loss: 0.105245 	 lr: 0.00080
[epoch  26:  60/307] 	 train loss: 0.488820 	 lr: 0.00080
[epoch  26:  80/307] 	 train loss: 0.238011 	 lr: 0.00080
[epoch  26: 100/307] 	 train loss: 0.280947 	 lr: 0.00080

val loss: 0.334897 	 acc: 0.901945

[epoch  26: 120/307] 	 train loss: 0.505808 	 lr: 0.00080
[epoch  26: 140/307] 	 train loss: 0.207082 	 lr: 0.00080
[epoch  26: 160/307] 	 train loss: 0.296190 	 lr: 0.00080
[epoch  26: 180/307] 	 train loss: 0.602095 	 lr: 0.00080
[epoch  26: 200/307] 	 train loss: 0.407862 	 lr: 0.00080
[epoch  26: 220/307] 	 train loss: 0.234650 	 lr: 0.00080
[epoch  26: 240/307] 	 train loss: 0.636773 	 lr: 0.00080

val loss: 0.334826 	 acc: 0.895057

[epoch  26: 260/307] 	 train loss: 0.266978 	 lr: 0.00080
[epoch  26: 280/307] 	 train loss: 0.325811 	 lr: 0.00080
[epoch  26: 300/307] 	 train loss: 0.400762 	 lr: 0.00080
[epoch  27:   0/307] 	 train loss: 0.199125 	 lr: 0.00080
[epoch  27:  20/307] 	 train loss: 0.235056 	 lr: 0.00080
[epoch  27:  40/307] 	 train loss: 0.218000 	 lr: 0.00080
[epoch  27:  60/307] 	 train loss: 0.386682 	 lr: 0.00080
[epoch  27:  80/307] 	 train loss: 0.134412 	 lr: 0.00080
[epoch  27: 100/307] 	 train loss: 0.271292 	 lr: 0.00080

val loss: 0.348135 	 acc: 0.893031

[epoch  27: 120/307] 	 train loss: 0.310379 	 lr: 0.00080
[epoch  27: 140/307] 	 train loss: 0.286876 	 lr: 0.00080
[epoch  27: 160/307] 	 train loss: 0.170421 	 lr: 0.00080
[epoch  27: 180/307] 	 train loss: 0.392303 	 lr: 0.00080
[epoch  27: 200/307] 	 train loss: 0.547468 	 lr: 0.00080
[epoch  27: 220/307] 	 train loss: 0.173571 	 lr: 0.00080
[epoch  27: 240/307] 	 train loss: 0.358141 	 lr: 0.00080

val loss: 0.317594 	 acc: 0.905592

[epoch  27: 260/307] 	 train loss: 0.117178 	 lr: 0.00080
[epoch  27: 280/307] 	 train loss: 0.392261 	 lr: 0.00080
[epoch  27: 300/307] 	 train loss: 0.499642 	 lr: 0.00080
[epoch  28:   0/307] 	 train loss: 0.124761 	 lr: 0.00080
[epoch  28:  20/307] 	 train loss: 0.213933 	 lr: 0.00080
[epoch  28:  40/307] 	 train loss: 0.096891 	 lr: 0.00080
[epoch  28:  60/307] 	 train loss: 0.175497 	 lr: 0.00080
[epoch  28:  80/307] 	 train loss: 0.466255 	 lr: 0.00080

val loss: 0.305812 	 acc: 0.905186

[epoch  28: 100/307] 	 train loss: 0.288486 	 lr: 0.00080
[epoch  28: 120/307] 	 train loss: 0.242361 	 lr: 0.00080
[epoch  28: 140/307] 	 train loss: 0.580548 	 lr: 0.00080
[epoch  28: 160/307] 	 train loss: 0.273172 	 lr: 0.00080
[epoch  28: 180/307] 	 train loss: 0.285389 	 lr: 0.00080
[epoch  28: 200/307] 	 train loss: 0.562844 	 lr: 0.00080
[epoch  28: 220/307] 	 train loss: 0.604251 	 lr: 0.00080
[epoch  28: 240/307] 	 train loss: 0.140937 	 lr: 0.00080

val loss: 0.315270 	 acc: 0.897083

[epoch  28: 260/307] 	 train loss: 0.067237 	 lr: 0.00080
[epoch  28: 280/307] 	 train loss: 0.267540 	 lr: 0.00080
[epoch  28: 300/307] 	 train loss: 0.133480 	 lr: 0.00080
[epoch  29:   0/307] 	 train loss: 0.179792 	 lr: 0.00080
[epoch  29:  20/307] 	 train loss: 0.315891 	 lr: 0.00080
[epoch  29:  40/307] 	 train loss: 0.267212 	 lr: 0.00080
[epoch  29:  60/307] 	 train loss: 0.302260 	 lr: 0.00080
[epoch  29:  80/307] 	 train loss: 0.465268 	 lr: 0.00080

val loss: 0.345554 	 acc: 0.894246

[epoch  29: 100/307] 	 train loss: 0.313411 	 lr: 0.00080
[epoch  29: 120/307] 	 train loss: 0.309263 	 lr: 0.00080
[epoch  29: 140/307] 	 train loss: 0.557891 	 lr: 0.00080
[epoch  29: 160/307] 	 train loss: 0.358379 	 lr: 0.00080
[epoch  29: 180/307] 	 train loss: 0.339879 	 lr: 0.00080
[epoch  29: 200/307] 	 train loss: 0.176317 	 lr: 0.00080
[epoch  29: 220/307] 	 train loss: 0.374770 	 lr: 0.00080
[epoch  29: 240/307] 	 train loss: 0.239562 	 lr: 0.00080

val loss: 0.319297 	 acc: 0.912885

saved model with accuracy %0.6f:  0.9128849270664505
[epoch  29: 260/307] 	 train loss: 0.278817 	 lr: 0.00080
[epoch  29: 280/307] 	 train loss: 0.177769 	 lr: 0.00080
[epoch  29: 300/307] 	 train loss: 0.497989 	 lr: 0.00080
[epoch  30:   0/307] 	 train loss: 0.267140 	 lr: 0.00080
[epoch  30:  20/307] 	 train loss: 0.337915 	 lr: 0.00080
[epoch  30:  40/307] 	 train loss: 0.492623 	 lr: 0.00080
[epoch  30:  60/307] 	 train loss: 0.100326 	 lr: 0.00080
[epoch  30:  80/307] 	 train loss: 0.197841 	 lr: 0.00080

val loss: 0.323013 	 acc: 0.899514

[epoch  30: 100/307] 	 train loss: 0.389624 	 lr: 0.00080
[epoch  30: 120/307] 	 train loss: 0.191598 	 lr: 0.00080
[epoch  30: 140/307] 	 train loss: 0.364761 	 lr: 0.00080
[epoch  30: 160/307] 	 train loss: 0.243279 	 lr: 0.00080
[epoch  30: 180/307] 	 train loss: 0.349218 	 lr: 0.00080
[epoch  30: 200/307] 	 train loss: 0.452473 	 lr: 0.00080
[epoch  30: 220/307] 	 train loss: 0.317785 	 lr: 0.00080
[epoch  30: 240/307] 	 train loss: 0.289323 	 lr: 0.00080

val loss: 0.334626 	 acc: 0.895867

[epoch  30: 260/307] 	 train loss: 0.366611 	 lr: 0.00080
[epoch  30: 280/307] 	 train loss: 0.354849 	 lr: 0.00080
[epoch  30: 300/307] 	 train loss: 0.300978 	 lr: 0.00080
[epoch  31:   0/307] 	 train loss: 0.607076 	 lr: 0.00080
[epoch  31:  20/307] 	 train loss: 0.211930 	 lr: 0.00080
[epoch  31:  40/307] 	 train loss: 0.368151 	 lr: 0.00080
[epoch  31:  60/307] 	 train loss: 0.236615 	 lr: 0.00080
[epoch  31:  80/307] 	 train loss: 0.221495 	 lr: 0.00080

val loss: 0.333320 	 acc: 0.903971

[epoch  31: 100/307] 	 train loss: 0.145150 	 lr: 0.00080
[epoch  31: 120/307] 	 train loss: 0.283348 	 lr: 0.00080
[epoch  31: 140/307] 	 train loss: 0.424980 	 lr: 0.00080
[epoch  31: 160/307] 	 train loss: 0.723003 	 lr: 0.00080
[epoch  31: 180/307] 	 train loss: 0.324701 	 lr: 0.00080
[epoch  31: 200/307] 	 train loss: 0.181246 	 lr: 0.00080
[epoch  31: 220/307] 	 train loss: 0.338471 	 lr: 0.00080
[epoch  31: 240/307] 	 train loss: 0.189206 	 lr: 0.00080

val loss: 0.317935 	 acc: 0.898298

[epoch  31: 260/307] 	 train loss: 0.357824 	 lr: 0.00080
[epoch  31: 280/307] 	 train loss: 0.460212 	 lr: 0.00080
[epoch  31: 300/307] 	 train loss: 0.262782 	 lr: 0.00080
[epoch  32:   0/307] 	 train loss: 0.436790 	 lr: 0.00080
[epoch  32:  20/307] 	 train loss: 0.450100 	 lr: 0.00080
[epoch  32:  40/307] 	 train loss: 0.488605 	 lr: 0.00080
[epoch  32:  60/307] 	 train loss: 0.221431 	 lr: 0.00080
[epoch  32:  80/307] 	 train loss: 0.406646 	 lr: 0.00080

val loss: 0.319580 	 acc: 0.907212

[epoch  32: 100/307] 	 train loss: 0.209758 	 lr: 0.00080
[epoch  32: 120/307] 	 train loss: 0.485984 	 lr: 0.00080
[epoch  32: 140/307] 	 train loss: 0.264510 	 lr: 0.00080
[epoch  32: 160/307] 	 train loss: 0.290548 	 lr: 0.00080
[epoch  32: 180/307] 	 train loss: 0.369976 	 lr: 0.00080
[epoch  32: 200/307] 	 train loss: 0.105026 	 lr: 0.00080
[epoch  32: 220/307] 	 train loss: 0.406069 	 lr: 0.00080
[epoch  32: 240/307] 	 train loss: 0.168102 	 lr: 0.00080

val loss: 0.322957 	 acc: 0.902755

[epoch  32: 260/307] 	 train loss: 0.252906 	 lr: 0.00080
[epoch  32: 280/307] 	 train loss: 0.332891 	 lr: 0.00080
[epoch  32: 300/307] 	 train loss: 0.516038 	 lr: 0.00080
[epoch  33:   0/307] 	 train loss: 0.258595 	 lr: 0.00080
[epoch  33:  20/307] 	 train loss: 0.256678 	 lr: 0.00080
[epoch  33:  40/307] 	 train loss: 0.242048 	 lr: 0.00080
[epoch  33:  60/307] 	 train loss: 0.178377 	 lr: 0.00080
[epoch  33:  80/307] 	 train loss: 0.153566 	 lr: 0.00080

val loss: 0.325066 	 acc: 0.903971

[epoch  33: 100/307] 	 train loss: 0.207663 	 lr: 0.00080
[epoch  33: 120/307] 	 train loss: 0.682371 	 lr: 0.00080
[epoch  33: 140/307] 	 train loss: 1.026086 	 lr: 0.00080
[epoch  33: 160/307] 	 train loss: 0.700461 	 lr: 0.00080
[epoch  33: 180/307] 	 train loss: 0.420138 	 lr: 0.00080
[epoch  33: 200/307] 	 train loss: 0.401483 	 lr: 0.00080
[epoch  33: 220/307] 	 train loss: 0.169794 	 lr: 0.00080
[epoch  33: 240/307] 	 train loss: 0.685235 	 lr: 0.00080

val loss: 0.329376 	 acc: 0.904781

[epoch  33: 260/307] 	 train loss: 0.344420 	 lr: 0.00080
[epoch  33: 280/307] 	 train loss: 0.095414 	 lr: 0.00080
[epoch  33: 300/307] 	 train loss: 0.184587 	 lr: 0.00080
[epoch  34:   0/307] 	 train loss: 0.546997 	 lr: 0.00080
[epoch  34:  20/307] 	 train loss: 0.274404 	 lr: 0.00080
[epoch  34:  40/307] 	 train loss: 0.305043 	 lr: 0.00080
[epoch  34:  60/307] 	 train loss: 0.450089 	 lr: 0.00080
[epoch  34:  80/307] 	 train loss: 0.184062 	 lr: 0.00080

val loss: 0.313767 	 acc: 0.907212

[epoch  34: 100/307] 	 train loss: 0.330884 	 lr: 0.00080
[epoch  34: 120/307] 	 train loss: 0.176157 	 lr: 0.00080
[epoch  34: 140/307] 	 train loss: 0.096431 	 lr: 0.00080
[epoch  34: 160/307] 	 train loss: 0.264291 	 lr: 0.00080
[epoch  34: 180/307] 	 train loss: 0.589194 	 lr: 0.00080
[epoch  34: 200/307] 	 train loss: 0.047612 	 lr: 0.00080
[epoch  34: 220/307] 	 train loss: 0.306284 	 lr: 0.00080

val loss: 0.310398 	 acc: 0.911264

[epoch  34: 240/307] 	 train loss: 0.711047 	 lr: 0.00080
[epoch  34: 260/307] 	 train loss: 0.185613 	 lr: 0.00080
[epoch  34: 280/307] 	 train loss: 0.330790 	 lr: 0.00080
[epoch  34: 300/307] 	 train loss: 0.246504 	 lr: 0.00080
[epoch  35:   0/307] 	 train loss: 0.342717 	 lr: 0.00080
[epoch  35:  20/307] 	 train loss: 0.182587 	 lr: 0.00080
[epoch  35:  40/307] 	 train loss: 0.253735 	 lr: 0.00080
[epoch  35:  60/307] 	 train loss: 0.281425 	 lr: 0.00080
[epoch  35:  80/307] 	 train loss: 0.194714 	 lr: 0.00080

val loss: 0.358072 	 acc: 0.897083

[epoch  35: 100/307] 	 train loss: 0.171801 	 lr: 0.00080
[epoch  35: 120/307] 	 train loss: 0.254416 	 lr: 0.00080
[epoch  35: 140/307] 	 train loss: 0.081330 	 lr: 0.00080
[epoch  35: 160/307] 	 train loss: 0.406449 	 lr: 0.00080
[epoch  35: 180/307] 	 train loss: 0.382755 	 lr: 0.00080
[epoch  35: 200/307] 	 train loss: 0.206003 	 lr: 0.00080
[epoch  35: 220/307] 	 train loss: 0.095286 	 lr: 0.00080

val loss: 0.294679 	 acc: 0.912075

[epoch  35: 240/307] 	 train loss: 0.192304 	 lr: 0.00080
[epoch  35: 260/307] 	 train loss: 0.157479 	 lr: 0.00080
[epoch  35: 280/307] 	 train loss: 0.352570 	 lr: 0.00080
[epoch  35: 300/307] 	 train loss: 0.213399 	 lr: 0.00080
[epoch  36:   0/307] 	 train loss: 0.281244 	 lr: 0.00080
[epoch  36:  20/307] 	 train loss: 0.424455 	 lr: 0.00080
[epoch  36:  40/307] 	 train loss: 0.406041 	 lr: 0.00080
[epoch  36:  60/307] 	 train loss: 0.278100 	 lr: 0.00080
[epoch  36:  80/307] 	 train loss: 0.198402 	 lr: 0.00080

val loss: 0.313213 	 acc: 0.910454

[epoch  36: 100/307] 	 train loss: 0.218551 	 lr: 0.00080
[epoch  36: 120/307] 	 train loss: 0.170130 	 lr: 0.00080
[epoch  36: 140/307] 	 train loss: 0.132734 	 lr: 0.00080
[epoch  36: 160/307] 	 train loss: 0.491642 	 lr: 0.00080
[epoch  36: 180/307] 	 train loss: 0.130835 	 lr: 0.00080
[epoch  36: 200/307] 	 train loss: 0.318836 	 lr: 0.00080
[epoch  36: 220/307] 	 train loss: 0.254246 	 lr: 0.00080

val loss: 0.317260 	 acc: 0.907618

[epoch  36: 240/307] 	 train loss: 0.357458 	 lr: 0.00080
[epoch  36: 260/307] 	 train loss: 0.497550 	 lr: 0.00080
[epoch  36: 280/307] 	 train loss: 0.648628 	 lr: 0.00080
[epoch  36: 300/307] 	 train loss: 0.362274 	 lr: 0.00080
[epoch  37:   0/307] 	 train loss: 0.129814 	 lr: 0.00080
[epoch  37:  20/307] 	 train loss: 0.235952 	 lr: 0.00080
[epoch  37:  40/307] 	 train loss: 0.434143 	 lr: 0.00080
[epoch  37:  60/307] 	 train loss: 0.258830 	 lr: 0.00080
[epoch  37:  80/307] 	 train loss: 0.623226 	 lr: 0.00080

val loss: 0.309534 	 acc: 0.907618

[epoch  37: 100/307] 	 train loss: 0.334703 	 lr: 0.00080
[epoch  37: 120/307] 	 train loss: 0.057345 	 lr: 0.00080
[epoch  37: 140/307] 	 train loss: 0.297064 	 lr: 0.00080
[epoch  37: 160/307] 	 train loss: 0.607937 	 lr: 0.00080
[epoch  37: 180/307] 	 train loss: 0.129088 	 lr: 0.00080
[epoch  37: 200/307] 	 train loss: 0.376885 	 lr: 0.00080
[epoch  37: 220/307] 	 train loss: 0.358013 	 lr: 0.00080

val loss: 0.320435 	 acc: 0.896677

[epoch  37: 240/307] 	 train loss: 0.158544 	 lr: 0.00080
[epoch  37: 260/307] 	 train loss: 0.130011 	 lr: 0.00080
[epoch  37: 280/307] 	 train loss: 0.368341 	 lr: 0.00080
[epoch  37: 300/307] 	 train loss: 0.257055 	 lr: 0.00080
[epoch  38:   0/307] 	 train loss: 0.266570 	 lr: 0.00080
[epoch  38:  20/307] 	 train loss: 0.309769 	 lr: 0.00080
[epoch  38:  40/307] 	 train loss: 0.175751 	 lr: 0.00080
[epoch  38:  60/307] 	 train loss: 0.416438 	 lr: 0.00080

val loss: 0.323875 	 acc: 0.901540

[epoch  38:  80/307] 	 train loss: 0.198794 	 lr: 0.00080
[epoch  38: 100/307] 	 train loss: 0.185096 	 lr: 0.00080
[epoch  38: 120/307] 	 train loss: 0.174887 	 lr: 0.00080
[epoch  38: 140/307] 	 train loss: 0.344253 	 lr: 0.00080
[epoch  38: 160/307] 	 train loss: 0.247236 	 lr: 0.00080
[epoch  38: 180/307] 	 train loss: 0.290584 	 lr: 0.00080
[epoch  38: 200/307] 	 train loss: 0.186878 	 lr: 0.00080
[epoch  38: 220/307] 	 train loss: 0.234237 	 lr: 0.00080

val loss: 0.319661 	 acc: 0.901945

[epoch  38: 240/307] 	 train loss: 0.407285 	 lr: 0.00080
[epoch  38: 260/307] 	 train loss: 0.256457 	 lr: 0.00080
[epoch  38: 280/307] 	 train loss: 0.149443 	 lr: 0.00080
[epoch  38: 300/307] 	 train loss: 0.194325 	 lr: 0.00080
[epoch  39:   0/307] 	 train loss: 0.121921 	 lr: 0.00080
[epoch  39:  20/307] 	 train loss: 0.149084 	 lr: 0.00080
[epoch  39:  40/307] 	 train loss: 0.561981 	 lr: 0.00080
[epoch  39:  60/307] 	 train loss: 0.214362 	 lr: 0.00080

val loss: 0.315667 	 acc: 0.902350

[epoch  39:  80/307] 	 train loss: 0.390876 	 lr: 0.00080
[epoch  39: 100/307] 	 train loss: 0.239481 	 lr: 0.00080
[epoch  39: 120/307] 	 train loss: 0.252327 	 lr: 0.00080
[epoch  39: 140/307] 	 train loss: 0.174108 	 lr: 0.00080
[epoch  39: 160/307] 	 train loss: 0.367317 	 lr: 0.00080
[epoch  39: 180/307] 	 train loss: 0.251846 	 lr: 0.00080
[epoch  39: 200/307] 	 train loss: 0.308821 	 lr: 0.00080
[epoch  39: 220/307] 	 train loss: 0.222323 	 lr: 0.00080

val loss: 0.323788 	 acc: 0.910049

[epoch  39: 240/307] 	 train loss: 0.495140 	 lr: 0.00080
[epoch  39: 260/307] 	 train loss: 0.207496 	 lr: 0.00080
[epoch  39: 280/307] 	 train loss: 0.229733 	 lr: 0.00080
[epoch  39: 300/307] 	 train loss: 0.324817 	 lr: 0.00080
[epoch  40:   0/307] 	 train loss: 0.128940 	 lr: 0.00080
[epoch  40:  20/307] 	 train loss: 0.245708 	 lr: 0.00080
[epoch  40:  40/307] 	 train loss: 0.212000 	 lr: 0.00080
[epoch  40:  60/307] 	 train loss: 0.169086 	 lr: 0.00080

val loss: 0.301288 	 acc: 0.910049

[epoch  40:  80/307] 	 train loss: 0.363179 	 lr: 0.00080
[epoch  40: 100/307] 	 train loss: 0.220171 	 lr: 0.00080
[epoch  40: 120/307] 	 train loss: 0.238331 	 lr: 0.00080
[epoch  40: 140/307] 	 train loss: 0.229514 	 lr: 0.00080
[epoch  40: 160/307] 	 train loss: 0.230510 	 lr: 0.00080
[epoch  40: 180/307] 	 train loss: 0.379481 	 lr: 0.00080
[epoch  40: 200/307] 	 train loss: 0.270204 	 lr: 0.00080
[epoch  40: 220/307] 	 train loss: 0.208922 	 lr: 0.00080

val loss: 0.307560 	 acc: 0.909643

[epoch  40: 240/307] 	 train loss: 0.093089 	 lr: 0.00080
[epoch  40: 260/307] 	 train loss: 0.140628 	 lr: 0.00080
[epoch  40: 280/307] 	 train loss: 0.232191 	 lr: 0.00080
[epoch  40: 300/307] 	 train loss: 0.319500 	 lr: 0.00080
[epoch  41:   0/307] 	 train loss: 0.405280 	 lr: 0.00080
[epoch  41:  20/307] 	 train loss: 0.372273 	 lr: 0.00080
[epoch  41:  40/307] 	 train loss: 0.087321 	 lr: 0.00080
[epoch  41:  60/307] 	 train loss: 0.203112 	 lr: 0.00080

val loss: 0.311714 	 acc: 0.909238

[epoch  41:  80/307] 	 train loss: 0.170958 	 lr: 0.00080
[epoch  41: 100/307] 	 train loss: 0.164907 	 lr: 0.00080
[epoch  41: 120/307] 	 train loss: 0.150377 	 lr: 0.00080
[epoch  41: 140/307] 	 train loss: 0.311151 	 lr: 0.00080
[epoch  41: 160/307] 	 train loss: 0.177848 	 lr: 0.00080
[epoch  41: 180/307] 	 train loss: 0.222824 	 lr: 0.00080
[epoch  41: 200/307] 	 train loss: 0.418732 	 lr: 0.00080
[epoch  41: 220/307] 	 train loss: 0.342179 	 lr: 0.00080

val loss: 0.345998 	 acc: 0.894246

[epoch  41: 240/307] 	 train loss: 0.191912 	 lr: 0.00080
[epoch  41: 260/307] 	 train loss: 0.319888 	 lr: 0.00080
[epoch  41: 280/307] 	 train loss: 0.209007 	 lr: 0.00080
[epoch  41: 300/307] 	 train loss: 0.333673 	 lr: 0.00080
[epoch  42:   0/307] 	 train loss: 0.445147 	 lr: 0.00080
[epoch  42:  20/307] 	 train loss: 0.267270 	 lr: 0.00080
[epoch  42:  40/307] 	 train loss: 0.329075 	 lr: 0.00080
[epoch  42:  60/307] 	 train loss: 0.270015 	 lr: 0.00080

val loss: 0.323468 	 acc: 0.904781

[epoch  42:  80/307] 	 train loss: 0.257209 	 lr: 0.00080
[epoch  42: 100/307] 	 train loss: 0.309887 	 lr: 0.00080
[epoch  42: 120/307] 	 train loss: 0.120682 	 lr: 0.00080
[epoch  42: 140/307] 	 train loss: 0.212018 	 lr: 0.00080
[epoch  42: 160/307] 	 train loss: 0.067682 	 lr: 0.00080
[epoch  42: 180/307] 	 train loss: 0.146913 	 lr: 0.00080
[epoch  42: 200/307] 	 train loss: 0.301991 	 lr: 0.00080
[epoch  42: 220/307] 	 train loss: 0.256412 	 lr: 0.00080

val loss: 0.316319 	 acc: 0.904781

[epoch  42: 240/307] 	 train loss: 0.344686 	 lr: 0.00080
[epoch  42: 260/307] 	 train loss: 0.181333 	 lr: 0.00080
[epoch  42: 280/307] 	 train loss: 0.352653 	 lr: 0.00080
[epoch  42: 300/307] 	 train loss: 0.260131 	 lr: 0.00080
[epoch  43:   0/307] 	 train loss: 0.330615 	 lr: 0.00064
[epoch  43:  20/307] 	 train loss: 0.304263 	 lr: 0.00064
[epoch  43:  40/307] 	 train loss: 0.397001 	 lr: 0.00064
[epoch  43:  60/307] 	 train loss: 0.249652 	 lr: 0.00064

val loss: 0.311056 	 acc: 0.905186

[epoch  43:  80/307] 	 train loss: 0.218121 	 lr: 0.00064
[epoch  43: 100/307] 	 train loss: 0.223177 	 lr: 0.00064
[epoch  43: 120/307] 	 train loss: 0.456803 	 lr: 0.00064
[epoch  43: 140/307] 	 train loss: 0.553446 	 lr: 0.00064
[epoch  43: 160/307] 	 train loss: 0.220127 	 lr: 0.00064
[epoch  43: 180/307] 	 train loss: 0.196859 	 lr: 0.00064
[epoch  43: 200/307] 	 train loss: 0.219763 	 lr: 0.00064
[epoch  43: 220/307] 	 train loss: 0.305973 	 lr: 0.00064

val loss: 0.310062 	 acc: 0.912885

[epoch  43: 240/307] 	 train loss: 0.631433 	 lr: 0.00064
[epoch  43: 260/307] 	 train loss: 0.167465 	 lr: 0.00064
[epoch  43: 280/307] 	 train loss: 0.225682 	 lr: 0.00064
[epoch  43: 300/307] 	 train loss: 0.237441 	 lr: 0.00064
[epoch  44:   0/307] 	 train loss: 0.561541 	 lr: 0.00064
[epoch  44:  20/307] 	 train loss: 0.300208 	 lr: 0.00064
[epoch  44:  40/307] 	 train loss: 0.258418 	 lr: 0.00064
[epoch  44:  60/307] 	 train loss: 0.264560 	 lr: 0.00064

val loss: 0.301620 	 acc: 0.911669

[epoch  44:  80/307] 	 train loss: 0.385513 	 lr: 0.00064
[epoch  44: 100/307] 	 train loss: 0.314586 	 lr: 0.00064
[epoch  44: 120/307] 	 train loss: 0.171423 	 lr: 0.00064
[epoch  44: 140/307] 	 train loss: 0.251408 	 lr: 0.00064
[epoch  44: 160/307] 	 train loss: 0.230810 	 lr: 0.00064
[epoch  44: 180/307] 	 train loss: 0.408121 	 lr: 0.00064
[epoch  44: 200/307] 	 train loss: 0.447254 	 lr: 0.00064

val loss: 0.302320 	 acc: 0.912480

[epoch  44: 220/307] 	 train loss: 0.140270 	 lr: 0.00064
[epoch  44: 240/307] 	 train loss: 0.484249 	 lr: 0.00064
[epoch  44: 260/307] 	 train loss: 0.357442 	 lr: 0.00064
[epoch  44: 280/307] 	 train loss: 0.112834 	 lr: 0.00064
[epoch  44: 300/307] 	 train loss: 0.243815 	 lr: 0.00064
[epoch  45:   0/307] 	 train loss: 0.059262 	 lr: 0.00064
[epoch  45:  20/307] 	 train loss: 0.280004 	 lr: 0.00064
[epoch  45:  40/307] 	 train loss: 0.491577 	 lr: 0.00064
[epoch  45:  60/307] 	 train loss: 0.281291 	 lr: 0.00064

val loss: 0.290683 	 acc: 0.915721

saved model with accuracy %0.6f:  0.9157212317666127
[epoch  45:  80/307] 	 train loss: 0.403207 	 lr: 0.00064
[epoch  45: 100/307] 	 train loss: 0.218750 	 lr: 0.00064
[epoch  45: 120/307] 	 train loss: 0.242322 	 lr: 0.00064
[epoch  45: 140/307] 	 train loss: 0.161086 	 lr: 0.00064
[epoch  45: 160/307] 	 train loss: 0.183126 	 lr: 0.00064
[epoch  45: 180/307] 	 train loss: 0.176914 	 lr: 0.00064
[epoch  45: 200/307] 	 train loss: 0.278209 	 lr: 0.00064

val loss: 0.328790 	 acc: 0.908023

[epoch  45: 220/307] 	 train loss: 0.351123 	 lr: 0.00064
[epoch  45: 240/307] 	 train loss: 0.145859 	 lr: 0.00064
[epoch  45: 260/307] 	 train loss: 0.309299 	 lr: 0.00064
[epoch  45: 280/307] 	 train loss: 0.224385 	 lr: 0.00064
[epoch  45: 300/307] 	 train loss: 0.290375 	 lr: 0.00064
[epoch  46:   0/307] 	 train loss: 0.285634 	 lr: 0.00064
[epoch  46:  20/307] 	 train loss: 0.327357 	 lr: 0.00064
[epoch  46:  40/307] 	 train loss: 0.138073 	 lr: 0.00064
[epoch  46:  60/307] 	 train loss: 0.120308 	 lr: 0.00064

val loss: 0.292509 	 acc: 0.916532

saved model with accuracy %0.6f:  0.9165316045380876
[epoch  46:  80/307] 	 train loss: 0.232207 	 lr: 0.00064
[epoch  46: 100/307] 	 train loss: 0.334535 	 lr: 0.00064
[epoch  46: 120/307] 	 train loss: 0.221126 	 lr: 0.00064
[epoch  46: 140/307] 	 train loss: 0.106370 	 lr: 0.00064
[epoch  46: 160/307] 	 train loss: 0.188196 	 lr: 0.00064
[epoch  46: 180/307] 	 train loss: 0.132535 	 lr: 0.00064
[epoch  46: 200/307] 	 train loss: 0.254933 	 lr: 0.00064

val loss: 0.313356 	 acc: 0.907212

[epoch  46: 220/307] 	 train loss: 0.398986 	 lr: 0.00064
[epoch  46: 240/307] 	 train loss: 0.146040 	 lr: 0.00064
[epoch  46: 260/307] 	 train loss: 0.070057 	 lr: 0.00064
[epoch  46: 280/307] 	 train loss: 0.324623 	 lr: 0.00064
[epoch  46: 300/307] 	 train loss: 0.109558 	 lr: 0.00064
[epoch  47:   0/307] 	 train loss: 0.424820 	 lr: 0.00064
[epoch  47:  20/307] 	 train loss: 0.346060 	 lr: 0.00064
[epoch  47:  40/307] 	 train loss: 0.095450 	 lr: 0.00064
[epoch  47:  60/307] 	 train loss: 0.058228 	 lr: 0.00064

val loss: 0.314732 	 acc: 0.905592

[epoch  47:  80/307] 	 train loss: 0.262984 	 lr: 0.00064
[epoch  47: 100/307] 	 train loss: 0.368799 	 lr: 0.00064
[epoch  47: 120/307] 	 train loss: 0.339520 	 lr: 0.00064
[epoch  47: 140/307] 	 train loss: 0.379020 	 lr: 0.00064
[epoch  47: 160/307] 	 train loss: 0.084590 	 lr: 0.00064
[epoch  47: 180/307] 	 train loss: 0.174690 	 lr: 0.00064
[epoch  47: 200/307] 	 train loss: 0.236994 	 lr: 0.00064

val loss: 0.335068 	 acc: 0.899919

[epoch  47: 220/307] 	 train loss: 0.333781 	 lr: 0.00064
[epoch  47: 240/307] 	 train loss: 0.045973 	 lr: 0.00064
[epoch  47: 260/307] 	 train loss: 0.135049 	 lr: 0.00064
[epoch  47: 280/307] 	 train loss: 0.281039 	 lr: 0.00064
[epoch  47: 300/307] 	 train loss: 0.369231 	 lr: 0.00064
[epoch  48:   0/307] 	 train loss: 0.217160 	 lr: 0.00064
[epoch  48:  20/307] 	 train loss: 0.072182 	 lr: 0.00064
[epoch  48:  40/307] 	 train loss: 0.622112 	 lr: 0.00064

val loss: 0.314188 	 acc: 0.911264

[epoch  48:  60/307] 	 train loss: 0.244558 	 lr: 0.00064
[epoch  48:  80/307] 	 train loss: 0.246878 	 lr: 0.00064
[epoch  48: 100/307] 	 train loss: 0.258697 	 lr: 0.00064
[epoch  48: 120/307] 	 train loss: 0.107307 	 lr: 0.00064
[epoch  48: 140/307] 	 train loss: 0.384011 	 lr: 0.00064
[epoch  48: 160/307] 	 train loss: 0.354171 	 lr: 0.00064
[epoch  48: 180/307] 	 train loss: 0.505991 	 lr: 0.00064
[epoch  48: 200/307] 	 train loss: 0.613826 	 lr: 0.00064

val loss: 0.310250 	 acc: 0.909238

[epoch  48: 220/307] 	 train loss: 0.201472 	 lr: 0.00064
[epoch  48: 240/307] 	 train loss: 0.458333 	 lr: 0.00064
[epoch  48: 260/307] 	 train loss: 0.282932 	 lr: 0.00064
[epoch  48: 280/307] 	 train loss: 0.062516 	 lr: 0.00064
[epoch  48: 300/307] 	 train loss: 0.229198 	 lr: 0.00064
[epoch  49:   0/307] 	 train loss: 0.292119 	 lr: 0.00064
[epoch  49:  20/307] 	 train loss: 0.327712 	 lr: 0.00064
[epoch  49:  40/307] 	 train loss: 0.460134 	 lr: 0.00064

val loss: 0.282952 	 acc: 0.917342

saved model with accuracy %0.6f:  0.9173419773095624
[epoch  49:  60/307] 	 train loss: 0.251484 	 lr: 0.00064
[epoch  49:  80/307] 	 train loss: 0.064437 	 lr: 0.00064
[epoch  49: 100/307] 	 train loss: 0.239031 	 lr: 0.00064
[epoch  49: 120/307] 	 train loss: 0.146891 	 lr: 0.00064
[epoch  49: 140/307] 	 train loss: 0.373223 	 lr: 0.00064
[epoch  49: 160/307] 	 train loss: 0.236741 	 lr: 0.00064
[epoch  49: 180/307] 	 train loss: 0.089688 	 lr: 0.00064
[epoch  49: 200/307] 	 train loss: 0.188140 	 lr: 0.00064

val loss: 0.311694 	 acc: 0.908833

[epoch  49: 220/307] 	 train loss: 0.092231 	 lr: 0.00064
[epoch  49: 240/307] 	 train loss: 0.199911 	 lr: 0.00064
[epoch  49: 260/307] 	 train loss: 0.264663 	 lr: 0.00064
[epoch  49: 280/307] 	 train loss: 0.349304 	 lr: 0.00064
[epoch  49: 300/307] 	 train loss: 0.078707 	 lr: 0.00064
[epoch  50:   0/307] 	 train loss: 0.181267 	 lr: 0.00064
[epoch  50:  20/307] 	 train loss: 0.183090 	 lr: 0.00064
[epoch  50:  40/307] 	 train loss: 0.187472 	 lr: 0.00064

val loss: 0.313778 	 acc: 0.908023

[epoch  50:  60/307] 	 train loss: 0.385097 	 lr: 0.00064
[epoch  50:  80/307] 	 train loss: 0.253573 	 lr: 0.00064
[epoch  50: 100/307] 	 train loss: 0.123344 	 lr: 0.00064
[epoch  50: 120/307] 	 train loss: 0.427417 	 lr: 0.00064
[epoch  50: 140/307] 	 train loss: 0.245738 	 lr: 0.00064
[epoch  50: 160/307] 	 train loss: 0.109369 	 lr: 0.00064
[epoch  50: 180/307] 	 train loss: 0.285654 	 lr: 0.00064
[epoch  50: 200/307] 	 train loss: 0.293279 	 lr: 0.00064

val loss: 0.327191 	 acc: 0.895462

[epoch  50: 220/307] 	 train loss: 0.338052 	 lr: 0.00064
[epoch  50: 240/307] 	 train loss: 0.481642 	 lr: 0.00064
[epoch  50: 260/307] 	 train loss: 0.571007 	 lr: 0.00064
[epoch  50: 280/307] 	 train loss: 0.265510 	 lr: 0.00064
[epoch  50: 300/307] 	 train loss: 0.102467 	 lr: 0.00064
[epoch  51:   0/307] 	 train loss: 0.094858 	 lr: 0.00064
[epoch  51:  20/307] 	 train loss: 0.471476 	 lr: 0.00064
[epoch  51:  40/307] 	 train loss: 0.194716 	 lr: 0.00064

val loss: 0.330746 	 acc: 0.898298

[epoch  51:  60/307] 	 train loss: 0.301416 	 lr: 0.00064
[epoch  51:  80/307] 	 train loss: 0.297276 	 lr: 0.00064
[epoch  51: 100/307] 	 train loss: 0.402847 	 lr: 0.00064
[epoch  51: 120/307] 	 train loss: 0.175410 	 lr: 0.00064
[epoch  51: 140/307] 	 train loss: 0.304646 	 lr: 0.00064
[epoch  51: 160/307] 	 train loss: 0.096282 	 lr: 0.00064
[epoch  51: 180/307] 	 train loss: 0.107021 	 lr: 0.00064
[epoch  51: 200/307] 	 train loss: 0.100862 	 lr: 0.00064

val loss: 0.312880 	 acc: 0.909238

[epoch  51: 220/307] 	 train loss: 0.142140 	 lr: 0.00064
[epoch  51: 240/307] 	 train loss: 0.089458 	 lr: 0.00064
[epoch  51: 260/307] 	 train loss: 0.546213 	 lr: 0.00064
[epoch  51: 280/307] 	 train loss: 0.118727 	 lr: 0.00064
[epoch  51: 300/307] 	 train loss: 0.262085 	 lr: 0.00064
[epoch  52:   0/307] 	 train loss: 0.247071 	 lr: 0.00064
[epoch  52:  20/307] 	 train loss: 0.171141 	 lr: 0.00064
[epoch  52:  40/307] 	 train loss: 0.180158 	 lr: 0.00064

val loss: 0.298944 	 acc: 0.915316

[epoch  52:  60/307] 	 train loss: 0.334986 	 lr: 0.00064
[epoch  52:  80/307] 	 train loss: 0.330560 	 lr: 0.00064
[epoch  52: 100/307] 	 train loss: 0.134966 	 lr: 0.00064
[epoch  52: 120/307] 	 train loss: 0.192170 	 lr: 0.00064
[epoch  52: 140/307] 	 train loss: 0.184948 	 lr: 0.00064
[epoch  52: 160/307] 	 train loss: 0.201920 	 lr: 0.00064
[epoch  52: 180/307] 	 train loss: 0.073218 	 lr: 0.00064
[epoch  52: 200/307] 	 train loss: 0.186375 	 lr: 0.00064

val loss: 0.302194 	 acc: 0.911264

[epoch  52: 220/307] 	 train loss: 0.142218 	 lr: 0.00064
[epoch  52: 240/307] 	 train loss: 0.131656 	 lr: 0.00064
[epoch  52: 260/307] 	 train loss: 0.228752 	 lr: 0.00064
[epoch  52: 280/307] 	 train loss: 0.094363 	 lr: 0.00064
[epoch  52: 300/307] 	 train loss: 0.114718 	 lr: 0.00064
[epoch  53:   0/307] 	 train loss: 0.400956 	 lr: 0.00064
[epoch  53:  20/307] 	 train loss: 0.159962 	 lr: 0.00064
[epoch  53:  40/307] 	 train loss: 0.124145 	 lr: 0.00064

val loss: 0.322504 	 acc: 0.907212

[epoch  53:  60/307] 	 train loss: 0.258595 	 lr: 0.00064
[epoch  53:  80/307] 	 train loss: 0.334126 	 lr: 0.00064
[epoch  53: 100/307] 	 train loss: 0.195634 	 lr: 0.00064
[epoch  53: 120/307] 	 train loss: 0.348366 	 lr: 0.00064
[epoch  53: 140/307] 	 train loss: 0.181762 	 lr: 0.00064
[epoch  53: 160/307] 	 train loss: 0.304129 	 lr: 0.00064
[epoch  53: 180/307] 	 train loss: 0.235444 	 lr: 0.00064
[epoch  53: 200/307] 	 train loss: 0.156765 	 lr: 0.00064

val loss: 0.310887 	 acc: 0.905592

[epoch  53: 220/307] 	 train loss: 0.352952 	 lr: 0.00064
[epoch  53: 240/307] 	 train loss: 0.230547 	 lr: 0.00064
[epoch  53: 260/307] 	 train loss: 0.050273 	 lr: 0.00064
[epoch  53: 280/307] 	 train loss: 0.199721 	 lr: 0.00064
[epoch  53: 300/307] 	 train loss: 0.082535 	 lr: 0.00064
[epoch  54:   0/307] 	 train loss: 0.332833 	 lr: 0.00064
[epoch  54:  20/307] 	 train loss: 0.168680 	 lr: 0.00064
[epoch  54:  40/307] 	 train loss: 0.307094 	 lr: 0.00064

val loss: 0.302312 	 acc: 0.909238

[epoch  54:  60/307] 	 train loss: 0.261508 	 lr: 0.00064
[epoch  54:  80/307] 	 train loss: 0.153707 	 lr: 0.00064
[epoch  54: 100/307] 	 train loss: 0.147235 	 lr: 0.00064
[epoch  54: 120/307] 	 train loss: 0.177258 	 lr: 0.00064
[epoch  54: 140/307] 	 train loss: 0.202533 	 lr: 0.00064
[epoch  54: 160/307] 	 train loss: 0.397399 	 lr: 0.00064
[epoch  54: 180/307] 	 train loss: 0.118892 	 lr: 0.00064

val loss: 0.304478 	 acc: 0.905186

[epoch  54: 200/307] 	 train loss: 0.135432 	 lr: 0.00064
[epoch  54: 220/307] 	 train loss: 0.477821 	 lr: 0.00064
[epoch  54: 240/307] 	 train loss: 0.360766 	 lr: 0.00064
[epoch  54: 260/307] 	 train loss: 0.090896 	 lr: 0.00064
[epoch  54: 280/307] 	 train loss: 0.158542 	 lr: 0.00064
[epoch  54: 300/307] 	 train loss: 0.209093 	 lr: 0.00064
[epoch  55:   0/307] 	 train loss: 0.338180 	 lr: 0.00064
[epoch  55:  20/307] 	 train loss: 0.189070 	 lr: 0.00064
[epoch  55:  40/307] 	 train loss: 0.302459 	 lr: 0.00064

val loss: 0.299316 	 acc: 0.909238

[epoch  55:  60/307] 	 train loss: 0.265266 	 lr: 0.00064
[epoch  55:  80/307] 	 train loss: 0.406425 	 lr: 0.00064
[epoch  55: 100/307] 	 train loss: 0.194350 	 lr: 0.00064
[epoch  55: 120/307] 	 train loss: 0.243681 	 lr: 0.00064
[epoch  55: 140/307] 	 train loss: 0.285108 	 lr: 0.00064
[epoch  55: 160/307] 	 train loss: 0.160524 	 lr: 0.00064
[epoch  55: 180/307] 	 train loss: 0.083383 	 lr: 0.00064

val loss: 0.300338 	 acc: 0.917342

[epoch  55: 200/307] 	 train loss: 0.292245 	 lr: 0.00064
[epoch  55: 220/307] 	 train loss: 0.374399 	 lr: 0.00064
[epoch  55: 240/307] 	 train loss: 0.180774 	 lr: 0.00064
[epoch  55: 260/307] 	 train loss: 0.216215 	 lr: 0.00064
[epoch  55: 280/307] 	 train loss: 0.268828 	 lr: 0.00064
[epoch  55: 300/307] 	 train loss: 0.202151 	 lr: 0.00064
[epoch  56:   0/307] 	 train loss: 0.199633 	 lr: 0.00064
[epoch  56:  20/307] 	 train loss: 0.276859 	 lr: 0.00064
[epoch  56:  40/307] 	 train loss: 0.064463 	 lr: 0.00064

val loss: 0.294883 	 acc: 0.913695

[epoch  56:  60/307] 	 train loss: 0.154629 	 lr: 0.00064
[epoch  56:  80/307] 	 train loss: 0.327891 	 lr: 0.00064
[epoch  56: 100/307] 	 train loss: 0.218168 	 lr: 0.00064
[epoch  56: 120/307] 	 train loss: 0.555948 	 lr: 0.00064
[epoch  56: 140/307] 	 train loss: 0.431007 	 lr: 0.00064
[epoch  56: 160/307] 	 train loss: 0.130286 	 lr: 0.00064
[epoch  56: 180/307] 	 train loss: 0.362845 	 lr: 0.00064

val loss: 0.324655 	 acc: 0.910859

[epoch  56: 200/307] 	 train loss: 0.046388 	 lr: 0.00064
[epoch  56: 220/307] 	 train loss: 0.095967 	 lr: 0.00064
[epoch  56: 240/307] 	 train loss: 0.190693 	 lr: 0.00064
[epoch  56: 260/307] 	 train loss: 0.149780 	 lr: 0.00064
[epoch  56: 280/307] 	 train loss: 0.063784 	 lr: 0.00064
[epoch  56: 300/307] 	 train loss: 0.209827 	 lr: 0.00064
[epoch  57:   0/307] 	 train loss: 0.242062 	 lr: 0.00064
[epoch  57:  20/307] 	 train loss: 0.143871 	 lr: 0.00064
[epoch  57:  40/307] 	 train loss: 0.319564 	 lr: 0.00064

val loss: 0.322007 	 acc: 0.906402

[epoch  57:  60/307] 	 train loss: 0.319936 	 lr: 0.00064
[epoch  57:  80/307] 	 train loss: 0.298923 	 lr: 0.00064
[epoch  57: 100/307] 	 train loss: 0.091299 	 lr: 0.00064
[epoch  57: 120/307] 	 train loss: 0.180182 	 lr: 0.00064
[epoch  57: 140/307] 	 train loss: 0.297170 	 lr: 0.00064
[epoch  57: 160/307] 	 train loss: 0.054809 	 lr: 0.00064
[epoch  57: 180/307] 	 train loss: 0.331889 	 lr: 0.00064

val loss: 0.320911 	 acc: 0.912480

[epoch  57: 200/307] 	 train loss: 0.197403 	 lr: 0.00064
[epoch  57: 220/307] 	 train loss: 0.168133 	 lr: 0.00064
[epoch  57: 240/307] 	 train loss: 0.443435 	 lr: 0.00064
[epoch  57: 260/307] 	 train loss: 0.384386 	 lr: 0.00064
[epoch  57: 280/307] 	 train loss: 0.564948 	 lr: 0.00064
[epoch  57: 300/307] 	 train loss: 0.251394 	 lr: 0.00064
[epoch  58:   0/307] 	 train loss: 0.437145 	 lr: 0.00064
[epoch  58:  20/307] 	 train loss: 0.362019 	 lr: 0.00064

val loss: 0.297488 	 acc: 0.914911

[epoch  58:  40/307] 	 train loss: 0.048165 	 lr: 0.00064
[epoch  58:  60/307] 	 train loss: 0.243027 	 lr: 0.00064
[epoch  58:  80/307] 	 train loss: 0.208851 	 lr: 0.00064
[epoch  58: 100/307] 	 train loss: 0.339414 	 lr: 0.00064
[epoch  58: 120/307] 	 train loss: 0.172609 	 lr: 0.00064
[epoch  58: 140/307] 	 train loss: 0.322238 	 lr: 0.00064
[epoch  58: 160/307] 	 train loss: 0.208097 	 lr: 0.00064
[epoch  58: 180/307] 	 train loss: 0.088075 	 lr: 0.00064

val loss: 0.301414 	 acc: 0.911264

[epoch  58: 200/307] 	 train loss: 0.192000 	 lr: 0.00064
[epoch  58: 220/307] 	 train loss: 0.073859 	 lr: 0.00064
[epoch  58: 240/307] 	 train loss: 0.172308 	 lr: 0.00064
[epoch  58: 260/307] 	 train loss: 0.180814 	 lr: 0.00064
[epoch  58: 280/307] 	 train loss: 0.213165 	 lr: 0.00064
[epoch  58: 300/307] 	 train loss: 0.527016 	 lr: 0.00064
[epoch  59:   0/307] 	 train loss: 0.263681 	 lr: 0.00064
[epoch  59:  20/307] 	 train loss: 0.320168 	 lr: 0.00064

val loss: 0.320703 	 acc: 0.910049

[epoch  59:  40/307] 	 train loss: 0.067795 	 lr: 0.00064
[epoch  59:  60/307] 	 train loss: 0.082974 	 lr: 0.00064
[epoch  59:  80/307] 	 train loss: 0.313472 	 lr: 0.00064
[epoch  59: 100/307] 	 train loss: 0.299236 	 lr: 0.00064
[epoch  59: 120/307] 	 train loss: 0.395671 	 lr: 0.00064
[epoch  59: 140/307] 	 train loss: 0.116818 	 lr: 0.00064
[epoch  59: 160/307] 	 train loss: 0.362428 	 lr: 0.00064
[epoch  59: 180/307] 	 train loss: 0.070370 	 lr: 0.00064

val loss: 0.313651 	 acc: 0.911669

[epoch  59: 200/307] 	 train loss: 0.071986 	 lr: 0.00064
[epoch  59: 220/307] 	 train loss: 0.261213 	 lr: 0.00064
[epoch  59: 240/307] 	 train loss: 0.335640 	 lr: 0.00064
[epoch  59: 260/307] 	 train loss: 0.246263 	 lr: 0.00064
[epoch  59: 280/307] 	 train loss: 0.134332 	 lr: 0.00064
[epoch  59: 300/307] 	 train loss: 0.167774 	 lr: 0.00064
[epoch  60:   0/307] 	 train loss: 0.092570 	 lr: 0.00064
[epoch  60:  20/307] 	 train loss: 0.276441 	 lr: 0.00064

val loss: 0.334347 	 acc: 0.907618

[epoch  60:  40/307] 	 train loss: 0.142109 	 lr: 0.00064
[epoch  60:  60/307] 	 train loss: 0.100200 	 lr: 0.00064
[epoch  60:  80/307] 	 train loss: 0.148705 	 lr: 0.00064
[epoch  60: 100/307] 	 train loss: 0.016454 	 lr: 0.00064
[epoch  60: 120/307] 	 train loss: 0.212804 	 lr: 0.00064
[epoch  60: 140/307] 	 train loss: 0.312037 	 lr: 0.00064
[epoch  60: 160/307] 	 train loss: 0.192068 	 lr: 0.00064
[epoch  60: 180/307] 	 train loss: 0.340038 	 lr: 0.00064

val loss: 0.324965 	 acc: 0.913290

[epoch  60: 200/307] 	 train loss: 0.424565 	 lr: 0.00064
[epoch  60: 220/307] 	 train loss: 0.203256 	 lr: 0.00064
[epoch  60: 240/307] 	 train loss: 0.177341 	 lr: 0.00064
[epoch  60: 260/307] 	 train loss: 0.381179 	 lr: 0.00064
[epoch  60: 280/307] 	 train loss: 0.188788 	 lr: 0.00064
[epoch  60: 300/307] 	 train loss: 0.095333 	 lr: 0.00064
[epoch  61:   0/307] 	 train loss: 0.325835 	 lr: 0.00064
[epoch  61:  20/307] 	 train loss: 0.156088 	 lr: 0.00064

val loss: 0.324426 	 acc: 0.912885

[epoch  61:  40/307] 	 train loss: 0.140306 	 lr: 0.00064
[epoch  61:  60/307] 	 train loss: 0.290011 	 lr: 0.00064
[epoch  61:  80/307] 	 train loss: 0.181927 	 lr: 0.00064
[epoch  61: 100/307] 	 train loss: 0.151552 	 lr: 0.00064
[epoch  61: 120/307] 	 train loss: 0.290764 	 lr: 0.00064
[epoch  61: 140/307] 	 train loss: 0.529373 	 lr: 0.00064
[epoch  61: 160/307] 	 train loss: 0.382125 	 lr: 0.00064
[epoch  61: 180/307] 	 train loss: 0.253703 	 lr: 0.00064

val loss: 0.309457 	 acc: 0.916126

[epoch  61: 200/307] 	 train loss: 0.281957 	 lr: 0.00064
[epoch  61: 220/307] 	 train loss: 0.216068 	 lr: 0.00064
[epoch  61: 240/307] 	 train loss: 0.192653 	 lr: 0.00064
[epoch  61: 260/307] 	 train loss: 0.186477 	 lr: 0.00064
[epoch  61: 280/307] 	 train loss: 0.288325 	 lr: 0.00064
[epoch  61: 300/307] 	 train loss: 0.225794 	 lr: 0.00064
[epoch  62:   0/307] 	 train loss: 0.054043 	 lr: 0.00064
[epoch  62:  20/307] 	 train loss: 0.540115 	 lr: 0.00064

val loss: 0.309844 	 acc: 0.911669

[epoch  62:  40/307] 	 train loss: 0.188851 	 lr: 0.00064
[epoch  62:  60/307] 	 train loss: 0.148207 	 lr: 0.00064
[epoch  62:  80/307] 	 train loss: 0.104847 	 lr: 0.00064
[epoch  62: 100/307] 	 train loss: 0.120096 	 lr: 0.00064
[epoch  62: 120/307] 	 train loss: 0.170867 	 lr: 0.00064
[epoch  62: 140/307] 	 train loss: 0.110781 	 lr: 0.00064
[epoch  62: 160/307] 	 train loss: 0.300841 	 lr: 0.00064
[epoch  62: 180/307] 	 train loss: 0.139880 	 lr: 0.00064

val loss: 0.317956 	 acc: 0.910454

[epoch  62: 200/307] 	 train loss: 0.321523 	 lr: 0.00064
[epoch  62: 220/307] 	 train loss: 0.135648 	 lr: 0.00064
[epoch  62: 240/307] 	 train loss: 0.081999 	 lr: 0.00064
[epoch  62: 260/307] 	 train loss: 0.447441 	 lr: 0.00064
[epoch  62: 280/307] 	 train loss: 0.281160 	 lr: 0.00064
[epoch  62: 300/307] 	 train loss: 0.323686 	 lr: 0.00064
[epoch  63:   0/307] 	 train loss: 0.071294 	 lr: 0.00064
[epoch  63:  20/307] 	 train loss: 0.228088 	 lr: 0.00064

val loss: 0.310381 	 acc: 0.906402

[epoch  63:  40/307] 	 train loss: 0.121941 	 lr: 0.00064
[epoch  63:  60/307] 	 train loss: 0.280671 	 lr: 0.00064
[epoch  63:  80/307] 	 train loss: 0.206845 	 lr: 0.00064
[epoch  63: 100/307] 	 train loss: 0.218962 	 lr: 0.00064
[epoch  63: 120/307] 	 train loss: 0.129772 	 lr: 0.00064
[epoch  63: 140/307] 	 train loss: 0.268394 	 lr: 0.00064
[epoch  63: 160/307] 	 train loss: 0.075996 	 lr: 0.00064
[epoch  63: 180/307] 	 train loss: 0.495355 	 lr: 0.00064

val loss: 0.322294 	 acc: 0.911264

[epoch  63: 200/307] 	 train loss: 0.262763 	 lr: 0.00064
[epoch  63: 220/307] 	 train loss: 0.372104 	 lr: 0.00064
[epoch  63: 240/307] 	 train loss: 0.267790 	 lr: 0.00064
[epoch  63: 260/307] 	 train loss: 0.278473 	 lr: 0.00064
[epoch  63: 280/307] 	 train loss: 0.123023 	 lr: 0.00064
[epoch  63: 300/307] 	 train loss: 0.129008 	 lr: 0.00064
[epoch  64:   0/307] 	 train loss: 0.344844 	 lr: 0.00051
[epoch  64:  20/307] 	 train loss: 0.287676 	 lr: 0.00051

val loss: 0.306230 	 acc: 0.914100

[epoch  64:  40/307] 	 train loss: 0.170522 	 lr: 0.00051
[epoch  64:  60/307] 	 train loss: 0.206421 	 lr: 0.00051
[epoch  64:  80/307] 	 train loss: 0.097200 	 lr: 0.00051
[epoch  64: 100/307] 	 train loss: 0.413932 	 lr: 0.00051
[epoch  64: 120/307] 	 train loss: 0.157552 	 lr: 0.00051
[epoch  64: 140/307] 	 train loss: 0.301461 	 lr: 0.00051
[epoch  64: 160/307] 	 train loss: 0.247898 	 lr: 0.00051

val loss: 0.343069 	 acc: 0.906402

[epoch  64: 180/307] 	 train loss: 0.225738 	 lr: 0.00051
[epoch  64: 200/307] 	 train loss: 0.057958 	 lr: 0.00051
[epoch  64: 220/307] 	 train loss: 0.133621 	 lr: 0.00051
[epoch  64: 240/307] 	 train loss: 0.136391 	 lr: 0.00051
[epoch  64: 260/307] 	 train loss: 0.217171 	 lr: 0.00051
[epoch  64: 280/307] 	 train loss: 0.357341 	 lr: 0.00051
[epoch  64: 300/307] 	 train loss: 0.229296 	 lr: 0.00051
[epoch  65:   0/307] 	 train loss: 0.183531 	 lr: 0.00051
[epoch  65:  20/307] 	 train loss: 0.178832 	 lr: 0.00051

val loss: 0.312905 	 acc: 0.911264

[epoch  65:  40/307] 	 train loss: 0.159607 	 lr: 0.00051
[epoch  65:  60/307] 	 train loss: 0.278043 	 lr: 0.00051
[epoch  65:  80/307] 	 train loss: 0.297755 	 lr: 0.00051
[epoch  65: 100/307] 	 train loss: 0.302627 	 lr: 0.00051
[epoch  65: 120/307] 	 train loss: 0.244112 	 lr: 0.00051
[epoch  65: 140/307] 	 train loss: 0.054950 	 lr: 0.00051
[epoch  65: 160/307] 	 train loss: 0.380117 	 lr: 0.00051

val loss: 0.308575 	 acc: 0.917342

[epoch  65: 180/307] 	 train loss: 0.114559 	 lr: 0.00051
[epoch  65: 200/307] 	 train loss: 0.180332 	 lr: 0.00051
[epoch  65: 220/307] 	 train loss: 0.498921 	 lr: 0.00051
[epoch  65: 240/307] 	 train loss: 0.161931 	 lr: 0.00051
[epoch  65: 260/307] 	 train loss: 0.331507 	 lr: 0.00051
[epoch  65: 280/307] 	 train loss: 0.203096 	 lr: 0.00051
[epoch  65: 300/307] 	 train loss: 0.055925 	 lr: 0.00051
[epoch  66:   0/307] 	 train loss: 0.209879 	 lr: 0.00051
[epoch  66:  20/307] 	 train loss: 0.326998 	 lr: 0.00051

val loss: 0.318351 	 acc: 0.906807

[epoch  66:  40/307] 	 train loss: 0.232552 	 lr: 0.00051
[epoch  66:  60/307] 	 train loss: 0.095257 	 lr: 0.00051
[epoch  66:  80/307] 	 train loss: 0.124925 	 lr: 0.00051
[epoch  66: 100/307] 	 train loss: 0.086419 	 lr: 0.00051
[epoch  66: 120/307] 	 train loss: 0.163017 	 lr: 0.00051
[epoch  66: 140/307] 	 train loss: 0.165966 	 lr: 0.00051
[epoch  66: 160/307] 	 train loss: 0.095461 	 lr: 0.00051

val loss: 0.298898 	 acc: 0.916937

[epoch  66: 180/307] 	 train loss: 0.034043 	 lr: 0.00051
[epoch  66: 200/307] 	 train loss: 0.149051 	 lr: 0.00051
[epoch  66: 220/307] 	 train loss: 0.191493 	 lr: 0.00051
[epoch  66: 240/307] 	 train loss: 0.220023 	 lr: 0.00051
[epoch  66: 260/307] 	 train loss: 0.111648 	 lr: 0.00051
[epoch  66: 280/307] 	 train loss: 0.255720 	 lr: 0.00051
[epoch  66: 300/307] 	 train loss: 0.112289 	 lr: 0.00051
[epoch  67:   0/307] 	 train loss: 0.210686 	 lr: 0.00051
[epoch  67:  20/307] 	 train loss: 0.236771 	 lr: 0.00051

val loss: 0.303036 	 acc: 0.915721

[epoch  67:  40/307] 	 train loss: 0.053714 	 lr: 0.00051
[epoch  67:  60/307] 	 train loss: 0.120570 	 lr: 0.00051
[epoch  67:  80/307] 	 train loss: 0.109865 	 lr: 0.00051
[epoch  67: 100/307] 	 train loss: 0.133610 	 lr: 0.00051
[epoch  67: 120/307] 	 train loss: 0.193536 	 lr: 0.00051
[epoch  67: 140/307] 	 train loss: 0.290369 	 lr: 0.00051
[epoch  67: 160/307] 	 train loss: 0.134701 	 lr: 0.00051

val loss: 0.327380 	 acc: 0.914100

[epoch  67: 180/307] 	 train loss: 0.188843 	 lr: 0.00051
[epoch  67: 200/307] 	 train loss: 0.186017 	 lr: 0.00051
[epoch  67: 220/307] 	 train loss: 0.253604 	 lr: 0.00051
[epoch  67: 240/307] 	 train loss: 0.309271 	 lr: 0.00051
[epoch  67: 260/307] 	 train loss: 0.154594 	 lr: 0.00051
[epoch  67: 280/307] 	 train loss: 0.398796 	 lr: 0.00051
[epoch  67: 300/307] 	 train loss: 0.128659 	 lr: 0.00051
[epoch  68:   0/307] 	 train loss: 0.199990 	 lr: 0.00051

val loss: 0.345858 	 acc: 0.906807

[epoch  68:  20/307] 	 train loss: 0.251102 	 lr: 0.00051
[epoch  68:  40/307] 	 train loss: 0.248657 	 lr: 0.00051
[epoch  68:  60/307] 	 train loss: 0.199900 	 lr: 0.00051
[epoch  68:  80/307] 	 train loss: 0.239179 	 lr: 0.00051
[epoch  68: 100/307] 	 train loss: 0.174685 	 lr: 0.00051
[epoch  68: 120/307] 	 train loss: 0.070188 	 lr: 0.00051
[epoch  68: 140/307] 	 train loss: 0.112153 	 lr: 0.00051
[epoch  68: 160/307] 	 train loss: 0.188204 	 lr: 0.00051

val loss: 0.308543 	 acc: 0.918558

saved model with accuracy %0.6f:  0.9185575364667747
[epoch  68: 180/307] 	 train loss: 0.356264 	 lr: 0.00051
[epoch  68: 200/307] 	 train loss: 0.161170 	 lr: 0.00051
[epoch  68: 220/307] 	 train loss: 0.231574 	 lr: 0.00051
[epoch  68: 240/307] 	 train loss: 0.064503 	 lr: 0.00051
[epoch  68: 260/307] 	 train loss: 0.147096 	 lr: 0.00051
[epoch  68: 280/307] 	 train loss: 0.231195 	 lr: 0.00051
[epoch  68: 300/307] 	 train loss: 0.044264 	 lr: 0.00051
[epoch  69:   0/307] 	 train loss: 0.067766 	 lr: 0.00051

val loss: 0.320936 	 acc: 0.911669

[epoch  69:  20/307] 	 train loss: 0.126328 	 lr: 0.00051
[epoch  69:  40/307] 	 train loss: 0.202511 	 lr: 0.00051
[epoch  69:  60/307] 	 train loss: 0.193439 	 lr: 0.00051
[epoch  69:  80/307] 	 train loss: 0.105902 	 lr: 0.00051
[epoch  69: 100/307] 	 train loss: 0.226233 	 lr: 0.00051
[epoch  69: 120/307] 	 train loss: 0.063247 	 lr: 0.00051
[epoch  69: 140/307] 	 train loss: 0.043521 	 lr: 0.00051
[epoch  69: 160/307] 	 train loss: 0.106230 	 lr: 0.00051

val loss: 0.321189 	 acc: 0.910454

[epoch  69: 180/307] 	 train loss: 0.244518 	 lr: 0.00051
[epoch  69: 200/307] 	 train loss: 0.276641 	 lr: 0.00051
[epoch  69: 220/307] 	 train loss: 0.203510 	 lr: 0.00051
[epoch  69: 240/307] 	 train loss: 0.461332 	 lr: 0.00051
[epoch  69: 260/307] 	 train loss: 0.213096 	 lr: 0.00051
[epoch  69: 280/307] 	 train loss: 0.187746 	 lr: 0.00051
[epoch  69: 300/307] 	 train loss: 0.167464 	 lr: 0.00051
[epoch  70:   0/307] 	 train loss: 0.270431 	 lr: 0.00051

val loss: 0.312078 	 acc: 0.910454

[epoch  70:  20/307] 	 train loss: 0.186279 	 lr: 0.00051
[epoch  70:  40/307] 	 train loss: 0.112863 	 lr: 0.00051
[epoch  70:  60/307] 	 train loss: 0.273456 	 lr: 0.00051
[epoch  70:  80/307] 	 train loss: 0.127959 	 lr: 0.00051
[epoch  70: 100/307] 	 train loss: 0.359089 	 lr: 0.00051
[epoch  70: 120/307] 	 train loss: 0.382653 	 lr: 0.00051
[epoch  70: 140/307] 	 train loss: 0.309321 	 lr: 0.00051
[epoch  70: 160/307] 	 train loss: 0.182042 	 lr: 0.00051

val loss: 0.295161 	 acc: 0.918963

saved model with accuracy %0.6f:  0.9189627228525121
[epoch  70: 180/307] 	 train loss: 0.112604 	 lr: 0.00051
[epoch  70: 200/307] 	 train loss: 0.525277 	 lr: 0.00051
[epoch  70: 220/307] 	 train loss: 0.164305 	 lr: 0.00051
[epoch  70: 240/307] 	 train loss: 0.341298 	 lr: 0.00051
[epoch  70: 260/307] 	 train loss: 0.263469 	 lr: 0.00051
[epoch  70: 280/307] 	 train loss: 0.182985 	 lr: 0.00051
[epoch  70: 300/307] 	 train loss: 0.080566 	 lr: 0.00051
[epoch  71:   0/307] 	 train loss: 0.414568 	 lr: 0.00051

val loss: 0.300411 	 acc: 0.916532

[epoch  71:  20/307] 	 train loss: 0.173488 	 lr: 0.00051
[epoch  71:  40/307] 	 train loss: 0.295426 	 lr: 0.00051
[epoch  71:  60/307] 	 train loss: 0.236968 	 lr: 0.00051
[epoch  71:  80/307] 	 train loss: 0.279081 	 lr: 0.00051
[epoch  71: 100/307] 	 train loss: 0.152250 	 lr: 0.00051
[epoch  71: 120/307] 	 train loss: 0.145168 	 lr: 0.00051
[epoch  71: 140/307] 	 train loss: 0.196337 	 lr: 0.00051
[epoch  71: 160/307] 	 train loss: 0.078731 	 lr: 0.00051

val loss: 0.304856 	 acc: 0.915721

[epoch  71: 180/307] 	 train loss: 0.154703 	 lr: 0.00051
[epoch  71: 200/307] 	 train loss: 0.123263 	 lr: 0.00051
[epoch  71: 220/307] 	 train loss: 0.126758 	 lr: 0.00051
[epoch  71: 240/307] 	 train loss: 0.106645 	 lr: 0.00051
[epoch  71: 260/307] 	 train loss: 0.110263 	 lr: 0.00051
[epoch  71: 280/307] 	 train loss: 0.219162 	 lr: 0.00051
[epoch  71: 300/307] 	 train loss: 0.212499 	 lr: 0.00051
[epoch  72:   0/307] 	 train loss: 0.200446 	 lr: 0.00051

val loss: 0.311792 	 acc: 0.915721

[epoch  72:  20/307] 	 train loss: 0.058523 	 lr: 0.00051
[epoch  72:  40/307] 	 train loss: 0.142290 	 lr: 0.00051
[epoch  72:  60/307] 	 train loss: 0.228777 	 lr: 0.00051
[epoch  72:  80/307] 	 train loss: 0.139565 	 lr: 0.00051
[epoch  72: 100/307] 	 train loss: 0.374517 	 lr: 0.00051
[epoch  72: 120/307] 	 train loss: 0.363154 	 lr: 0.00051
[epoch  72: 140/307] 	 train loss: 0.190141 	 lr: 0.00051
[epoch  72: 160/307] 	 train loss: 0.072954 	 lr: 0.00051

val loss: 0.305941 	 acc: 0.912480

[epoch  72: 180/307] 	 train loss: 0.049897 	 lr: 0.00051
[epoch  72: 200/307] 	 train loss: 0.186108 	 lr: 0.00051
[epoch  72: 220/307] 	 train loss: 0.236764 	 lr: 0.00051
[epoch  72: 240/307] 	 train loss: 0.121747 	 lr: 0.00051
[epoch  72: 260/307] 	 train loss: 0.305597 	 lr: 0.00051
[epoch  72: 280/307] 	 train loss: 0.057127 	 lr: 0.00051
[epoch  72: 300/307] 	 train loss: 0.227110 	 lr: 0.00051
[epoch  73:   0/307] 	 train loss: 0.350923 	 lr: 0.00051

val loss: 0.299801 	 acc: 0.915316

[epoch  73:  20/307] 	 train loss: 0.253325 	 lr: 0.00051
[epoch  73:  40/307] 	 train loss: 0.177781 	 lr: 0.00051
[epoch  73:  60/307] 	 train loss: 0.316832 	 lr: 0.00051
[epoch  73:  80/307] 	 train loss: 0.278124 	 lr: 0.00051
[epoch  73: 100/307] 	 train loss: 0.059761 	 lr: 0.00051
[epoch  73: 120/307] 	 train loss: 0.162021 	 lr: 0.00051
[epoch  73: 140/307] 	 train loss: 0.260196 	 lr: 0.00051
[epoch  73: 160/307] 	 train loss: 0.349010 	 lr: 0.00051

val loss: 0.304367 	 acc: 0.906807

[epoch  73: 180/307] 	 train loss: 0.091332 	 lr: 0.00051
[epoch  73: 200/307] 	 train loss: 0.192666 	 lr: 0.00051
[epoch  73: 220/307] 	 train loss: 0.286527 	 lr: 0.00051
[epoch  73: 240/307] 	 train loss: 0.154862 	 lr: 0.00051
[epoch  73: 260/307] 	 train loss: 0.216979 	 lr: 0.00051
[epoch  73: 280/307] 	 train loss: 0.154406 	 lr: 0.00051
[epoch  73: 300/307] 	 train loss: 0.157566 	 lr: 0.00051
[epoch  74:   0/307] 	 train loss: 0.243519 	 lr: 0.00051

val loss: 0.308336 	 acc: 0.911264

[epoch  74:  20/307] 	 train loss: 0.163505 	 lr: 0.00051
[epoch  74:  40/307] 	 train loss: 0.388922 	 lr: 0.00051
[epoch  74:  60/307] 	 train loss: 0.340018 	 lr: 0.00051
[epoch  74:  80/307] 	 train loss: 0.270204 	 lr: 0.00051
[epoch  74: 100/307] 	 train loss: 0.207573 	 lr: 0.00051
[epoch  74: 120/307] 	 train loss: 0.155453 	 lr: 0.00051
[epoch  74: 140/307] 	 train loss: 0.036759 	 lr: 0.00051

val loss: 0.345213 	 acc: 0.900324

[epoch  74: 160/307] 	 train loss: 0.139270 	 lr: 0.00051
[epoch  74: 180/307] 	 train loss: 0.080281 	 lr: 0.00051
[epoch  74: 200/307] 	 train loss: 0.352935 	 lr: 0.00051
[epoch  74: 220/307] 	 train loss: 0.023273 	 lr: 0.00051
[epoch  74: 240/307] 	 train loss: 0.221330 	 lr: 0.00051
[epoch  74: 260/307] 	 train loss: 0.237850 	 lr: 0.00051
[epoch  74: 280/307] 	 train loss: 0.119265 	 lr: 0.00051
[epoch  74: 300/307] 	 train loss: 0.063192 	 lr: 0.00051
[epoch  75:   0/307] 	 train loss: 0.078487 	 lr: 0.00051

val loss: 0.340847 	 acc: 0.897893

[epoch  75:  20/307] 	 train loss: 0.208661 	 lr: 0.00051
[epoch  75:  40/307] 	 train loss: 0.228030 	 lr: 0.00051
[epoch  75:  60/307] 	 train loss: 0.234939 	 lr: 0.00051
[epoch  75:  80/307] 	 train loss: 0.035136 	 lr: 0.00051
[epoch  75: 100/307] 	 train loss: 0.143276 	 lr: 0.00051
[epoch  75: 120/307] 	 train loss: 0.111382 	 lr: 0.00051
[epoch  75: 140/307] 	 train loss: 0.165765 	 lr: 0.00051

val loss: 0.321561 	 acc: 0.906402

[epoch  75: 160/307] 	 train loss: 0.129878 	 lr: 0.00051
[epoch  75: 180/307] 	 train loss: 0.314178 	 lr: 0.00051
[epoch  75: 200/307] 	 train loss: 0.085183 	 lr: 0.00051
[epoch  75: 220/307] 	 train loss: 0.455001 	 lr: 0.00051
[epoch  75: 240/307] 	 train loss: 0.304375 	 lr: 0.00051
[epoch  75: 260/307] 	 train loss: 0.181604 	 lr: 0.00051
[epoch  75: 280/307] 	 train loss: 0.293485 	 lr: 0.00051
[epoch  75: 300/307] 	 train loss: 0.268998 	 lr: 0.00051
[epoch  76:   0/307] 	 train loss: 0.144704 	 lr: 0.00051

val loss: 0.297373 	 acc: 0.916532

[epoch  76:  20/307] 	 train loss: 0.329651 	 lr: 0.00051
[epoch  76:  40/307] 	 train loss: 0.112049 	 lr: 0.00051
[epoch  76:  60/307] 	 train loss: 0.050653 	 lr: 0.00051
[epoch  76:  80/307] 	 train loss: 0.378209 	 lr: 0.00051
[epoch  76: 100/307] 	 train loss: 0.165262 	 lr: 0.00051
[epoch  76: 120/307] 	 train loss: 0.170465 	 lr: 0.00051
[epoch  76: 140/307] 	 train loss: 0.126404 	 lr: 0.00051

val loss: 0.316683 	 acc: 0.913290

[epoch  76: 160/307] 	 train loss: 0.391599 	 lr: 0.00051
[epoch  76: 180/307] 	 train loss: 0.182092 	 lr: 0.00051
[epoch  76: 200/307] 	 train loss: 0.286405 	 lr: 0.00051
[epoch  76: 220/307] 	 train loss: 0.343712 	 lr: 0.00051
[epoch  76: 240/307] 	 train loss: 0.118317 	 lr: 0.00051
[epoch  76: 260/307] 	 train loss: 0.294605 	 lr: 0.00051
[epoch  76: 280/307] 	 train loss: 0.333099 	 lr: 0.00051
[epoch  76: 300/307] 	 train loss: 0.084410 	 lr: 0.00051
[epoch  77:   0/307] 	 train loss: 0.151214 	 lr: 0.00051

val loss: 0.327696 	 acc: 0.904376

[epoch  77:  20/307] 	 train loss: 0.224397 	 lr: 0.00051
[epoch  77:  40/307] 	 train loss: 0.545803 	 lr: 0.00051
[epoch  77:  60/307] 	 train loss: 0.217199 	 lr: 0.00051
[epoch  77:  80/307] 	 train loss: 0.188021 	 lr: 0.00051
[epoch  77: 100/307] 	 train loss: 0.074181 	 lr: 0.00051
[epoch  77: 120/307] 	 train loss: 0.405855 	 lr: 0.00051
[epoch  77: 140/307] 	 train loss: 0.074882 	 lr: 0.00051

val loss: 0.329515 	 acc: 0.910859

[epoch  77: 160/307] 	 train loss: 0.019506 	 lr: 0.00051
[epoch  77: 180/307] 	 train loss: 0.156709 	 lr: 0.00051
[epoch  77: 200/307] 	 train loss: 0.385386 	 lr: 0.00051
[epoch  77: 220/307] 	 train loss: 0.267978 	 lr: 0.00051
[epoch  77: 240/307] 	 train loss: 0.156882 	 lr: 0.00051
[epoch  77: 260/307] 	 train loss: 0.537956 	 lr: 0.00051
[epoch  77: 280/307] 	 train loss: 0.459814 	 lr: 0.00051
[epoch  77: 300/307] 	 train loss: 0.081737 	 lr: 0.00051

val loss: 0.326592 	 acc: 0.912075

[epoch  78:   0/307] 	 train loss: 0.599069 	 lr: 0.00051
[epoch  78:  20/307] 	 train loss: 0.207506 	 lr: 0.00051
[epoch  78:  40/307] 	 train loss: 0.179568 	 lr: 0.00051
[epoch  78:  60/307] 	 train loss: 0.174298 	 lr: 0.00051
[epoch  78:  80/307] 	 train loss: 0.024924 	 lr: 0.00051
[epoch  78: 100/307] 	 train loss: 0.217221 	 lr: 0.00051
[epoch  78: 120/307] 	 train loss: 0.076652 	 lr: 0.00051
[epoch  78: 140/307] 	 train loss: 0.044181 	 lr: 0.00051

val loss: 0.314047 	 acc: 0.917747

[epoch  78: 160/307] 	 train loss: 0.223039 	 lr: 0.00051
[epoch  78: 180/307] 	 train loss: 0.232280 	 lr: 0.00051
[epoch  78: 200/307] 	 train loss: 0.056146 	 lr: 0.00051
[epoch  78: 220/307] 	 train loss: 0.110273 	 lr: 0.00051
[epoch  78: 240/307] 	 train loss: 0.063104 	 lr: 0.00051
[epoch  78: 260/307] 	 train loss: 0.273993 	 lr: 0.00051
[epoch  78: 280/307] 	 train loss: 0.296069 	 lr: 0.00051
[epoch  78: 300/307] 	 train loss: 0.069963 	 lr: 0.00051

val loss: 0.350648 	 acc: 0.899919

[epoch  79:   0/307] 	 train loss: 0.211557 	 lr: 0.00051
[epoch  79:  20/307] 	 train loss: 0.086331 	 lr: 0.00051
[epoch  79:  40/307] 	 train loss: 0.164035 	 lr: 0.00051
[epoch  79:  60/307] 	 train loss: 0.125904 	 lr: 0.00051
[epoch  79:  80/307] 	 train loss: 0.120844 	 lr: 0.00051
[epoch  79: 100/307] 	 train loss: 0.217346 	 lr: 0.00051
[epoch  79: 120/307] 	 train loss: 0.205232 	 lr: 0.00051
[epoch  79: 140/307] 	 train loss: 0.129763 	 lr: 0.00051

val loss: 0.314075 	 acc: 0.911669

[epoch  79: 160/307] 	 train loss: 0.046653 	 lr: 0.00051
[epoch  79: 180/307] 	 train loss: 0.133585 	 lr: 0.00051
[epoch  79: 200/307] 	 train loss: 0.457952 	 lr: 0.00051
[epoch  79: 220/307] 	 train loss: 0.119743 	 lr: 0.00051
[epoch  79: 240/307] 	 train loss: 0.089009 	 lr: 0.00051
[epoch  79: 260/307] 	 train loss: 0.125840 	 lr: 0.00051
[epoch  79: 280/307] 	 train loss: 0.051108 	 lr: 0.00051
[epoch  79: 300/307] 	 train loss: 0.052816 	 lr: 0.00051

val loss: 0.327527 	 acc: 0.911669

[epoch  80:   0/307] 	 train loss: 0.206062 	 lr: 0.00051
[epoch  80:  20/307] 	 train loss: 0.040557 	 lr: 0.00051
[epoch  80:  40/307] 	 train loss: 0.274263 	 lr: 0.00051
[epoch  80:  60/307] 	 train loss: 0.450068 	 lr: 0.00051
[epoch  80:  80/307] 	 train loss: 0.119419 	 lr: 0.00051
[epoch  80: 100/307] 	 train loss: 0.080958 	 lr: 0.00051
[epoch  80: 120/307] 	 train loss: 0.171063 	 lr: 0.00051
[epoch  80: 140/307] 	 train loss: 0.064447 	 lr: 0.00051

val loss: 0.319560 	 acc: 0.912480

[epoch  80: 160/307] 	 train loss: 0.182560 	 lr: 0.00051
[epoch  80: 180/307] 	 train loss: 0.068044 	 lr: 0.00051
[epoch  80: 200/307] 	 train loss: 0.433415 	 lr: 0.00051
[epoch  80: 220/307] 	 train loss: 0.165169 	 lr: 0.00051
[epoch  80: 240/307] 	 train loss: 0.057376 	 lr: 0.00051
[epoch  80: 260/307] 	 train loss: 0.151744 	 lr: 0.00051
[epoch  80: 280/307] 	 train loss: 0.151296 	 lr: 0.00051
[epoch  80: 300/307] 	 train loss: 0.296487 	 lr: 0.00051

val loss: 0.318977 	 acc: 0.912885

[epoch  81:   0/307] 	 train loss: 0.020073 	 lr: 0.00051
[epoch  81:  20/307] 	 train loss: 0.175788 	 lr: 0.00051
[epoch  81:  40/307] 	 train loss: 0.379947 	 lr: 0.00051
[epoch  81:  60/307] 	 train loss: 0.178813 	 lr: 0.00051
[epoch  81:  80/307] 	 train loss: 0.175616 	 lr: 0.00051
[epoch  81: 100/307] 	 train loss: 0.239373 	 lr: 0.00051
[epoch  81: 120/307] 	 train loss: 0.095436 	 lr: 0.00051
[epoch  81: 140/307] 	 train loss: 0.035845 	 lr: 0.00051

val loss: 0.320974 	 acc: 0.907212

[epoch  81: 160/307] 	 train loss: 0.290171 	 lr: 0.00051
[epoch  81: 180/307] 	 train loss: 0.226735 	 lr: 0.00051
[epoch  81: 200/307] 	 train loss: 0.395082 	 lr: 0.00051
[epoch  81: 220/307] 	 train loss: 0.817312 	 lr: 0.00051
[epoch  81: 240/307] 	 train loss: 0.070804 	 lr: 0.00051
[epoch  81: 260/307] 	 train loss: 0.079180 	 lr: 0.00051
[epoch  81: 280/307] 	 train loss: 0.154709 	 lr: 0.00051

val loss: 0.306764 	 acc: 0.909238

[epoch  81: 300/307] 	 train loss: 0.405659 	 lr: 0.00051
[epoch  82:   0/307] 	 train loss: 0.262812 	 lr: 0.00051
[epoch  82:  20/307] 	 train loss: 0.156228 	 lr: 0.00051
[epoch  82:  40/307] 	 train loss: 0.045314 	 lr: 0.00051
[epoch  82:  60/307] 	 train loss: 0.378700 	 lr: 0.00051
[epoch  82:  80/307] 	 train loss: 0.243115 	 lr: 0.00051
[epoch  82: 100/307] 	 train loss: 0.133852 	 lr: 0.00051
[epoch  82: 120/307] 	 train loss: 0.288336 	 lr: 0.00051
[epoch  82: 140/307] 	 train loss: 0.141047 	 lr: 0.00051

val loss: 0.332310 	 acc: 0.903566

[epoch  82: 160/307] 	 train loss: 0.140921 	 lr: 0.00051
[epoch  82: 180/307] 	 train loss: 0.194212 	 lr: 0.00051
[epoch  82: 200/307] 	 train loss: 0.212759 	 lr: 0.00051
[epoch  82: 220/307] 	 train loss: 0.173081 	 lr: 0.00051
[epoch  82: 240/307] 	 train loss: 0.076720 	 lr: 0.00051
[epoch  82: 260/307] 	 train loss: 0.249816 	 lr: 0.00051
[epoch  82: 280/307] 	 train loss: 0.208134 	 lr: 0.00051

val loss: 0.307514 	 acc: 0.916937

[epoch  82: 300/307] 	 train loss: 0.103823 	 lr: 0.00051
[epoch  83:   0/307] 	 train loss: 0.094292 	 lr: 0.00051
[epoch  83:  20/307] 	 train loss: 0.118956 	 lr: 0.00051
[epoch  83:  40/307] 	 train loss: 0.245367 	 lr: 0.00051
[epoch  83:  60/307] 	 train loss: 0.150146 	 lr: 0.00051
[epoch  83:  80/307] 	 train loss: 0.089909 	 lr: 0.00051
[epoch  83: 100/307] 	 train loss: 0.083776 	 lr: 0.00051
[epoch  83: 120/307] 	 train loss: 0.182211 	 lr: 0.00051
[epoch  83: 140/307] 	 train loss: 0.134988 	 lr: 0.00051

val loss: 0.314270 	 acc: 0.911264

[epoch  83: 160/307] 	 train loss: 0.352819 	 lr: 0.00051
[epoch  83: 180/307] 	 train loss: 0.022325 	 lr: 0.00051
[epoch  83: 200/307] 	 train loss: 0.162211 	 lr: 0.00051
[epoch  83: 220/307] 	 train loss: 0.103174 	 lr: 0.00051
[epoch  83: 240/307] 	 train loss: 0.443767 	 lr: 0.00051
[epoch  83: 260/307] 	 train loss: 0.128616 	 lr: 0.00051
[epoch  83: 280/307] 	 train loss: 0.042657 	 lr: 0.00051

val loss: 0.291037 	 acc: 0.922204

saved model with accuracy %0.6f:  0.9222042139384117
[epoch  83: 300/307] 	 train loss: 0.420961 	 lr: 0.00051
[epoch  84:   0/307] 	 train loss: 0.045477 	 lr: 0.00051
[epoch  84:  20/307] 	 train loss: 0.086061 	 lr: 0.00051
[epoch  84:  40/307] 	 train loss: 0.144484 	 lr: 0.00051
[epoch  84:  60/307] 	 train loss: 0.247830 	 lr: 0.00051
[epoch  84:  80/307] 	 train loss: 0.198883 	 lr: 0.00051
[epoch  84: 100/307] 	 train loss: 0.114377 	 lr: 0.00051
[epoch  84: 120/307] 	 train loss: 0.247515 	 lr: 0.00051

val loss: 0.290846 	 acc: 0.916532

[epoch  84: 140/307] 	 train loss: 0.236778 	 lr: 0.00051
[epoch  84: 160/307] 	 train loss: 0.155595 	 lr: 0.00051
[epoch  84: 180/307] 	 train loss: 0.160225 	 lr: 0.00051
[epoch  84: 200/307] 	 train loss: 0.074505 	 lr: 0.00051
[epoch  84: 220/307] 	 train loss: 0.189038 	 lr: 0.00051
[epoch  84: 240/307] 	 train loss: 0.132537 	 lr: 0.00051
[epoch  84: 260/307] 	 train loss: 0.211797 	 lr: 0.00051
[epoch  84: 280/307] 	 train loss: 0.219285 	 lr: 0.00051

val loss: 0.291846 	 acc: 0.918963

[epoch  84: 300/307] 	 train loss: 0.206964 	 lr: 0.00051
[epoch  85:   0/307] 	 train loss: 0.365555 	 lr: 0.00041
[epoch  85:  20/307] 	 train loss: 0.190366 	 lr: 0.00041
[epoch  85:  40/307] 	 train loss: 0.292588 	 lr: 0.00041
[epoch  85:  60/307] 	 train loss: 0.077244 	 lr: 0.00041
[epoch  85:  80/307] 	 train loss: 0.034628 	 lr: 0.00041
[epoch  85: 100/307] 	 train loss: 0.296737 	 lr: 0.00041
[epoch  85: 120/307] 	 train loss: 0.094136 	 lr: 0.00041

val loss: 0.285771 	 acc: 0.919368

[epoch  85: 140/307] 	 train loss: 0.107390 	 lr: 0.00041
[epoch  85: 160/307] 	 train loss: 0.369290 	 lr: 0.00041
[epoch  85: 180/307] 	 train loss: 0.122749 	 lr: 0.00041
[epoch  85: 200/307] 	 train loss: 0.055604 	 lr: 0.00041
[epoch  85: 220/307] 	 train loss: 0.136646 	 lr: 0.00041
[epoch  85: 240/307] 	 train loss: 0.102385 	 lr: 0.00041
[epoch  85: 260/307] 	 train loss: 0.081294 	 lr: 0.00041
[epoch  85: 280/307] 	 train loss: 0.327436 	 lr: 0.00041

val loss: 0.301468 	 acc: 0.916937

[epoch  85: 300/307] 	 train loss: 0.341253 	 lr: 0.00041
[epoch  86:   0/307] 	 train loss: 0.044510 	 lr: 0.00041
[epoch  86:  20/307] 	 train loss: 0.051552 	 lr: 0.00041
[epoch  86:  40/307] 	 train loss: 0.318540 	 lr: 0.00041
[epoch  86:  60/307] 	 train loss: 0.126883 	 lr: 0.00041
[epoch  86:  80/307] 	 train loss: 0.143250 	 lr: 0.00041
[epoch  86: 100/307] 	 train loss: 0.376234 	 lr: 0.00041
[epoch  86: 120/307] 	 train loss: 0.258776 	 lr: 0.00041

val loss: 0.325096 	 acc: 0.910049

[epoch  86: 140/307] 	 train loss: 0.191561 	 lr: 0.00041
[epoch  86: 160/307] 	 train loss: 0.178214 	 lr: 0.00041
[epoch  86: 180/307] 	 train loss: 0.121827 	 lr: 0.00041
[epoch  86: 200/307] 	 train loss: 0.143549 	 lr: 0.00041
[epoch  86: 220/307] 	 train loss: 0.344177 	 lr: 0.00041
[epoch  86: 240/307] 	 train loss: 0.286832 	 lr: 0.00041
[epoch  86: 260/307] 	 train loss: 0.349401 	 lr: 0.00041
[epoch  86: 280/307] 	 train loss: 0.043548 	 lr: 0.00041

val loss: 0.312555 	 acc: 0.911264

[epoch  86: 300/307] 	 train loss: 0.038879 	 lr: 0.00041
[epoch  87:   0/307] 	 train loss: 0.265382 	 lr: 0.00041
[epoch  87:  20/307] 	 train loss: 0.165645 	 lr: 0.00041
[epoch  87:  40/307] 	 train loss: 0.329561 	 lr: 0.00041
[epoch  87:  60/307] 	 train loss: 0.032785 	 lr: 0.00041
[epoch  87:  80/307] 	 train loss: 0.144769 	 lr: 0.00041
[epoch  87: 100/307] 	 train loss: 0.205479 	 lr: 0.00041
[epoch  87: 120/307] 	 train loss: 0.127382 	 lr: 0.00041

val loss: 0.326340 	 acc: 0.910049

[epoch  87: 140/307] 	 train loss: 0.221230 	 lr: 0.00041
[epoch  87: 160/307] 	 train loss: 0.136267 	 lr: 0.00041
[epoch  87: 180/307] 	 train loss: 0.088690 	 lr: 0.00041
[epoch  87: 200/307] 	 train loss: 0.156670 	 lr: 0.00041
[epoch  87: 220/307] 	 train loss: 0.287229 	 lr: 0.00041
[epoch  87: 240/307] 	 train loss: 0.119079 	 lr: 0.00041
[epoch  87: 260/307] 	 train loss: 0.359751 	 lr: 0.00041
[epoch  87: 280/307] 	 train loss: 0.170932 	 lr: 0.00041

val loss: 0.307641 	 acc: 0.914100

[epoch  87: 300/307] 	 train loss: 0.107345 	 lr: 0.00041
[epoch  88:   0/307] 	 train loss: 0.039710 	 lr: 0.00041
[epoch  88:  20/307] 	 train loss: 0.059952 	 lr: 0.00041
[epoch  88:  40/307] 	 train loss: 0.148822 	 lr: 0.00041
[epoch  88:  60/307] 	 train loss: 0.262375 	 lr: 0.00041
[epoch  88:  80/307] 	 train loss: 0.148968 	 lr: 0.00041
[epoch  88: 100/307] 	 train loss: 0.062850 	 lr: 0.00041
[epoch  88: 120/307] 	 train loss: 0.065162 	 lr: 0.00041

val loss: 0.308054 	 acc: 0.914100

[epoch  88: 140/307] 	 train loss: 0.492709 	 lr: 0.00041
[epoch  88: 160/307] 	 train loss: 0.096886 	 lr: 0.00041
[epoch  88: 180/307] 	 train loss: 0.083540 	 lr: 0.00041
[epoch  88: 200/307] 	 train loss: 0.106731 	 lr: 0.00041
[epoch  88: 220/307] 	 train loss: 0.226445 	 lr: 0.00041
[epoch  88: 240/307] 	 train loss: 0.032823 	 lr: 0.00041
[epoch  88: 260/307] 	 train loss: 0.061693 	 lr: 0.00041
[epoch  88: 280/307] 	 train loss: 0.249347 	 lr: 0.00041

val loss: 0.296840 	 acc: 0.910859

[epoch  88: 300/307] 	 train loss: 0.160695 	 lr: 0.00041
[epoch  89:   0/307] 	 train loss: 0.066345 	 lr: 0.00041
[epoch  89:  20/307] 	 train loss: 0.115128 	 lr: 0.00041
[epoch  89:  40/307] 	 train loss: 0.037640 	 lr: 0.00041
[epoch  89:  60/307] 	 train loss: 0.299146 	 lr: 0.00041
[epoch  89:  80/307] 	 train loss: 0.293312 	 lr: 0.00041
[epoch  89: 100/307] 	 train loss: 0.192538 	 lr: 0.00041
[epoch  89: 120/307] 	 train loss: 0.079706 	 lr: 0.00041

val loss: 0.305093 	 acc: 0.917342

[epoch  89: 140/307] 	 train loss: 0.070722 	 lr: 0.00041
[epoch  89: 160/307] 	 train loss: 0.136035 	 lr: 0.00041
[epoch  89: 180/307] 	 train loss: 0.047310 	 lr: 0.00041
[epoch  89: 200/307] 	 train loss: 0.156635 	 lr: 0.00041
[epoch  89: 220/307] 	 train loss: 0.596857 	 lr: 0.00041
[epoch  89: 240/307] 	 train loss: 0.188505 	 lr: 0.00041
[epoch  89: 260/307] 	 train loss: 0.200279 	 lr: 0.00041
[epoch  89: 280/307] 	 train loss: 0.220216 	 lr: 0.00041

val loss: 0.313456 	 acc: 0.909238

[epoch  89: 300/307] 	 train loss: 0.289822 	 lr: 0.00041
[epoch  90:   0/307] 	 train loss: 0.095840 	 lr: 0.00041
[epoch  90:  20/307] 	 train loss: 0.125945 	 lr: 0.00041
[epoch  90:  40/307] 	 train loss: 0.296248 	 lr: 0.00041
[epoch  90:  60/307] 	 train loss: 0.287095 	 lr: 0.00041
[epoch  90:  80/307] 	 train loss: 0.161671 	 lr: 0.00041
[epoch  90: 100/307] 	 train loss: 0.057493 	 lr: 0.00041
[epoch  90: 120/307] 	 train loss: 0.125932 	 lr: 0.00041

val loss: 0.300723 	 acc: 0.911669

[epoch  90: 140/307] 	 train loss: 0.225088 	 lr: 0.00041
[epoch  90: 160/307] 	 train loss: 0.382721 	 lr: 0.00041
[epoch  90: 180/307] 	 train loss: 0.115426 	 lr: 0.00041
[epoch  90: 200/307] 	 train loss: 0.198409 	 lr: 0.00041
[epoch  90: 220/307] 	 train loss: 0.198793 	 lr: 0.00041
[epoch  90: 240/307] 	 train loss: 0.178335 	 lr: 0.00041
[epoch  90: 260/307] 	 train loss: 0.105782 	 lr: 0.00041
[epoch  90: 280/307] 	 train loss: 0.277581 	 lr: 0.00041

val loss: 0.322844 	 acc: 0.911669

[epoch  90: 300/307] 	 train loss: 0.240580 	 lr: 0.00041
[epoch  91:   0/307] 	 train loss: 0.109785 	 lr: 0.00041
[epoch  91:  20/307] 	 train loss: 0.126710 	 lr: 0.00041
[epoch  91:  40/307] 	 train loss: 0.148753 	 lr: 0.00041
[epoch  91:  60/307] 	 train loss: 0.069774 	 lr: 0.00041
[epoch  91:  80/307] 	 train loss: 0.128487 	 lr: 0.00041
[epoch  91: 100/307] 	 train loss: 0.179221 	 lr: 0.00041
[epoch  91: 120/307] 	 train loss: 0.154996 	 lr: 0.00041

val loss: 0.285403 	 acc: 0.921799

[epoch  91: 140/307] 	 train loss: 0.144597 	 lr: 0.00041
[epoch  91: 160/307] 	 train loss: 0.315459 	 lr: 0.00041
[epoch  91: 180/307] 	 train loss: 0.072541 	 lr: 0.00041
[epoch  91: 200/307] 	 train loss: 0.251831 	 lr: 0.00041
[epoch  91: 220/307] 	 train loss: 0.210381 	 lr: 0.00041
[epoch  91: 240/307] 	 train loss: 0.088271 	 lr: 0.00041
[epoch  91: 260/307] 	 train loss: 0.250548 	 lr: 0.00041

val loss: 0.298020 	 acc: 0.922204

[epoch  91: 280/307] 	 train loss: 0.092331 	 lr: 0.00041
[epoch  91: 300/307] 	 train loss: 0.424729 	 lr: 0.00041
[epoch  92:   0/307] 	 train loss: 0.131179 	 lr: 0.00041
[epoch  92:  20/307] 	 train loss: 0.055526 	 lr: 0.00041
[epoch  92:  40/307] 	 train loss: 0.021531 	 lr: 0.00041
[epoch  92:  60/307] 	 train loss: 0.082846 	 lr: 0.00041
[epoch  92:  80/307] 	 train loss: 0.158437 	 lr: 0.00041
[epoch  92: 100/307] 	 train loss: 0.136252 	 lr: 0.00041
[epoch  92: 120/307] 	 train loss: 0.074817 	 lr: 0.00041

val loss: 0.316318 	 acc: 0.912075

[epoch  92: 140/307] 	 train loss: 0.154997 	 lr: 0.00041
[epoch  92: 160/307] 	 train loss: 0.604623 	 lr: 0.00041
[epoch  92: 180/307] 	 train loss: 0.052172 	 lr: 0.00041
[epoch  92: 200/307] 	 train loss: 0.163335 	 lr: 0.00041
[epoch  92: 220/307] 	 train loss: 0.147073 	 lr: 0.00041
[epoch  92: 240/307] 	 train loss: 0.118745 	 lr: 0.00041
[epoch  92: 260/307] 	 train loss: 0.103601 	 lr: 0.00041

val loss: 0.301639 	 acc: 0.918152

[epoch  92: 280/307] 	 train loss: 0.053577 	 lr: 0.00041
[epoch  92: 300/307] 	 train loss: 0.213412 	 lr: 0.00041
[epoch  93:   0/307] 	 train loss: 0.211704 	 lr: 0.00041
[epoch  93:  20/307] 	 train loss: 0.173099 	 lr: 0.00041
[epoch  93:  40/307] 	 train loss: 0.279307 	 lr: 0.00041
[epoch  93:  60/307] 	 train loss: 0.093657 	 lr: 0.00041
[epoch  93:  80/307] 	 train loss: 0.415904 	 lr: 0.00041
[epoch  93: 100/307] 	 train loss: 0.479107 	 lr: 0.00041
[epoch  93: 120/307] 	 train loss: 0.159910 	 lr: 0.00041

val loss: 0.314151 	 acc: 0.915316

[epoch  93: 140/307] 	 train loss: 0.216010 	 lr: 0.00041
[epoch  93: 160/307] 	 train loss: 0.046094 	 lr: 0.00041
[epoch  93: 180/307] 	 train loss: 0.217505 	 lr: 0.00041
[epoch  93: 200/307] 	 train loss: 0.192101 	 lr: 0.00041
[epoch  93: 220/307] 	 train loss: 0.153635 	 lr: 0.00041
[epoch  93: 240/307] 	 train loss: 0.218533 	 lr: 0.00041
[epoch  93: 260/307] 	 train loss: 0.182420 	 lr: 0.00041

val loss: 0.321709 	 acc: 0.913695

[epoch  93: 280/307] 	 train loss: 0.201658 	 lr: 0.00041
[epoch  93: 300/307] 	 train loss: 0.213480 	 lr: 0.00041
[epoch  94:   0/307] 	 train loss: 0.075685 	 lr: 0.00041
[epoch  94:  20/307] 	 train loss: 0.093907 	 lr: 0.00041
[epoch  94:  40/307] 	 train loss: 0.237731 	 lr: 0.00041
[epoch  94:  60/307] 	 train loss: 0.125204 	 lr: 0.00041
[epoch  94:  80/307] 	 train loss: 0.228329 	 lr: 0.00041
[epoch  94: 100/307] 	 train loss: 0.108103 	 lr: 0.00041

val loss: 0.310887 	 acc: 0.911669

[epoch  94: 120/307] 	 train loss: 0.098820 	 lr: 0.00041
[epoch  94: 140/307] 	 train loss: 0.380038 	 lr: 0.00041
[epoch  94: 160/307] 	 train loss: 0.075726 	 lr: 0.00041
[epoch  94: 180/307] 	 train loss: 0.196940 	 lr: 0.00041
[epoch  94: 200/307] 	 train loss: 0.212890 	 lr: 0.00041
[epoch  94: 220/307] 	 train loss: 0.252459 	 lr: 0.00041
[epoch  94: 240/307] 	 train loss: 0.244522 	 lr: 0.00041
[epoch  94: 260/307] 	 train loss: 0.111968 	 lr: 0.00041

val loss: 0.308730 	 acc: 0.912480

[epoch  94: 280/307] 	 train loss: 0.083218 	 lr: 0.00041
[epoch  94: 300/307] 	 train loss: 0.207600 	 lr: 0.00041
[epoch  95:   0/307] 	 train loss: 0.230673 	 lr: 0.00041
[epoch  95:  20/307] 	 train loss: 0.134218 	 lr: 0.00041
[epoch  95:  40/307] 	 train loss: 0.255364 	 lr: 0.00041
[epoch  95:  60/307] 	 train loss: 0.262526 	 lr: 0.00041
[epoch  95:  80/307] 	 train loss: 0.142175 	 lr: 0.00041
[epoch  95: 100/307] 	 train loss: 0.099361 	 lr: 0.00041

val loss: 0.309384 	 acc: 0.916126

[epoch  95: 120/307] 	 train loss: 0.075162 	 lr: 0.00041
[epoch  95: 140/307] 	 train loss: 0.512224 	 lr: 0.00041
[epoch  95: 160/307] 	 train loss: 0.097497 	 lr: 0.00041
[epoch  95: 180/307] 	 train loss: 0.104541 	 lr: 0.00041
[epoch  95: 200/307] 	 train loss: 0.188980 	 lr: 0.00041
[epoch  95: 220/307] 	 train loss: 0.160000 	 lr: 0.00041
[epoch  95: 240/307] 	 train loss: 0.045022 	 lr: 0.00041
[epoch  95: 260/307] 	 train loss: 0.072747 	 lr: 0.00041

val loss: 0.319363 	 acc: 0.916532

[epoch  95: 280/307] 	 train loss: 0.049055 	 lr: 0.00041
[epoch  95: 300/307] 	 train loss: 0.187349 	 lr: 0.00041
[epoch  96:   0/307] 	 train loss: 0.306804 	 lr: 0.00041
[epoch  96:  20/307] 	 train loss: 0.136587 	 lr: 0.00041
[epoch  96:  40/307] 	 train loss: 0.133425 	 lr: 0.00041
[epoch  96:  60/307] 	 train loss: 0.166893 	 lr: 0.00041
[epoch  96:  80/307] 	 train loss: 0.079466 	 lr: 0.00041
[epoch  96: 100/307] 	 train loss: 0.041328 	 lr: 0.00041

val loss: 0.312294 	 acc: 0.914100

[epoch  96: 120/307] 	 train loss: 0.088349 	 lr: 0.00041
[epoch  96: 140/307] 	 train loss: 0.313542 	 lr: 0.00041
[epoch  96: 160/307] 	 train loss: 0.122458 	 lr: 0.00041
[epoch  96: 180/307] 	 train loss: 0.189657 	 lr: 0.00041
[epoch  96: 200/307] 	 train loss: 0.104256 	 lr: 0.00041
[epoch  96: 220/307] 	 train loss: 0.288287 	 lr: 0.00041
[epoch  96: 240/307] 	 train loss: 0.115275 	 lr: 0.00041
[epoch  96: 260/307] 	 train loss: 0.060280 	 lr: 0.00041

val loss: 0.320983 	 acc: 0.910859

[epoch  96: 280/307] 	 train loss: 0.143875 	 lr: 0.00041
[epoch  96: 300/307] 	 train loss: 0.147816 	 lr: 0.00041
[epoch  97:   0/307] 	 train loss: 0.200189 	 lr: 0.00041
[epoch  97:  20/307] 	 train loss: 0.261083 	 lr: 0.00041
[epoch  97:  40/307] 	 train loss: 0.087498 	 lr: 0.00041
[epoch  97:  60/307] 	 train loss: 0.397535 	 lr: 0.00041
[epoch  97:  80/307] 	 train loss: 0.217970 	 lr: 0.00041
[epoch  97: 100/307] 	 train loss: 0.073321 	 lr: 0.00041

val loss: 0.318382 	 acc: 0.911669

[epoch  97: 120/307] 	 train loss: 0.116745 	 lr: 0.00041
[epoch  97: 140/307] 	 train loss: 0.048062 	 lr: 0.00041
[epoch  97: 160/307] 	 train loss: 0.158811 	 lr: 0.00041
[epoch  97: 180/307] 	 train loss: 0.179388 	 lr: 0.00041
[epoch  97: 200/307] 	 train loss: 0.165823 	 lr: 0.00041
[epoch  97: 220/307] 	 train loss: 0.157077 	 lr: 0.00041
[epoch  97: 240/307] 	 train loss: 0.323299 	 lr: 0.00041
[epoch  97: 260/307] 	 train loss: 0.171884 	 lr: 0.00041

val loss: 0.315197 	 acc: 0.910859

[epoch  97: 280/307] 	 train loss: 0.236332 	 lr: 0.00041
[epoch  97: 300/307] 	 train loss: 0.199710 	 lr: 0.00041
[epoch  98:   0/307] 	 train loss: 0.318279 	 lr: 0.00041
[epoch  98:  20/307] 	 train loss: 0.065150 	 lr: 0.00041
[epoch  98:  40/307] 	 train loss: 0.135544 	 lr: 0.00041
[epoch  98:  60/307] 	 train loss: 0.085825 	 lr: 0.00041
[epoch  98:  80/307] 	 train loss: 0.119341 	 lr: 0.00041
[epoch  98: 100/307] 	 train loss: 0.295019 	 lr: 0.00041

val loss: 0.323480 	 acc: 0.914506

[epoch  98: 120/307] 	 train loss: 0.027448 	 lr: 0.00041
[epoch  98: 140/307] 	 train loss: 0.234543 	 lr: 0.00041
[epoch  98: 160/307] 	 train loss: 0.205717 	 lr: 0.00041
[epoch  98: 180/307] 	 train loss: 0.134822 	 lr: 0.00041
[epoch  98: 200/307] 	 train loss: 0.162850 	 lr: 0.00041
[epoch  98: 220/307] 	 train loss: 0.116259 	 lr: 0.00041
[epoch  98: 240/307] 	 train loss: 0.224218 	 lr: 0.00041
[epoch  98: 260/307] 	 train loss: 0.058179 	 lr: 0.00041

val loss: 0.326232 	 acc: 0.910454

[epoch  98: 280/307] 	 train loss: 0.094786 	 lr: 0.00041
[epoch  98: 300/307] 	 train loss: 0.136845 	 lr: 0.00041
[epoch  99:   0/307] 	 train loss: 0.342105 	 lr: 0.00041
[epoch  99:  20/307] 	 train loss: 0.124647 	 lr: 0.00041
[epoch  99:  40/307] 	 train loss: 0.200207 	 lr: 0.00041
[epoch  99:  60/307] 	 train loss: 0.154394 	 lr: 0.00041
[epoch  99:  80/307] 	 train loss: 0.177873 	 lr: 0.00041
[epoch  99: 100/307] 	 train loss: 0.200654 	 lr: 0.00041

val loss: 0.317491 	 acc: 0.916126

[epoch  99: 120/307] 	 train loss: 0.127150 	 lr: 0.00041
[epoch  99: 140/307] 	 train loss: 0.302780 	 lr: 0.00041
[epoch  99: 160/307] 	 train loss: 0.035510 	 lr: 0.00041
[epoch  99: 180/307] 	 train loss: 0.177056 	 lr: 0.00041
[epoch  99: 200/307] 	 train loss: 0.360633 	 lr: 0.00041
[epoch  99: 220/307] 	 train loss: 0.082887 	 lr: 0.00041
[epoch  99: 240/307] 	 train loss: 0.153076 	 lr: 0.00041
[epoch  99: 260/307] 	 train loss: 0.263402 	 lr: 0.00041

val loss: 0.308773 	 acc: 0.911264

[epoch  99: 280/307] 	 train loss: 0.007777 	 lr: 0.00041
[epoch  99: 300/307] 	 train loss: 0.319270 	 lr: 0.00041
[epoch 100:   0/307] 	 train loss: 0.234632 	 lr: 0.00041
[epoch 100:  20/307] 	 train loss: 0.063098 	 lr: 0.00041
[epoch 100:  40/307] 	 train loss: 0.129551 	 lr: 0.00041
[epoch 100:  60/307] 	 train loss: 0.064531 	 lr: 0.00041
[epoch 100:  80/307] 	 train loss: 0.129280 	 lr: 0.00041
[epoch 100: 100/307] 	 train loss: 0.362349 	 lr: 0.00041

val loss: 0.304205 	 acc: 0.912075

[epoch 100: 120/307] 	 train loss: 0.428594 	 lr: 0.00041
[epoch 100: 140/307] 	 train loss: 0.224905 	 lr: 0.00041
[epoch 100: 160/307] 	 train loss: 0.185293 	 lr: 0.00041
[epoch 100: 180/307] 	 train loss: 0.107295 	 lr: 0.00041
[epoch 100: 200/307] 	 train loss: 0.117158 	 lr: 0.00041
[epoch 100: 220/307] 	 train loss: 0.152191 	 lr: 0.00041
[epoch 100: 240/307] 	 train loss: 0.147523 	 lr: 0.00041
[epoch 100: 260/307] 	 train loss: 0.256375 	 lr: 0.00041

val loss: 0.302790 	 acc: 0.912075

[epoch 100: 280/307] 	 train loss: 0.199521 	 lr: 0.00041
[epoch 100: 300/307] 	 train loss: 0.054948 	 lr: 0.00041
[epoch 101:   0/307] 	 train loss: 0.162453 	 lr: 0.00041
[epoch 101:  20/307] 	 train loss: 0.280680 	 lr: 0.00041
[epoch 101:  40/307] 	 train loss: 0.132333 	 lr: 0.00041
[epoch 101:  60/307] 	 train loss: 0.215408 	 lr: 0.00041
[epoch 101:  80/307] 	 train loss: 0.234879 	 lr: 0.00041
[epoch 101: 100/307] 	 train loss: 0.144952 	 lr: 0.00041

val loss: 0.323721 	 acc: 0.909238

[epoch 101: 120/307] 	 train loss: 0.100514 	 lr: 0.00041
[epoch 101: 140/307] 	 train loss: 0.114758 	 lr: 0.00041
[epoch 101: 160/307] 	 train loss: 0.102181 	 lr: 0.00041
[epoch 101: 180/307] 	 train loss: 0.266902 	 lr: 0.00041
[epoch 101: 200/307] 	 train loss: 0.032956 	 lr: 0.00041
[epoch 101: 220/307] 	 train loss: 0.069809 	 lr: 0.00041
[epoch 101: 240/307] 	 train loss: 0.199121 	 lr: 0.00041

val loss: 0.315831 	 acc: 0.911264

[epoch 101: 260/307] 	 train loss: 0.358183 	 lr: 0.00041
[epoch 101: 280/307] 	 train loss: 0.084524 	 lr: 0.00041
[epoch 101: 300/307] 	 train loss: 0.138207 	 lr: 0.00041
[epoch 102:   0/307] 	 train loss: 0.203135 	 lr: 0.00041
[epoch 102:  20/307] 	 train loss: 0.333170 	 lr: 0.00041
[epoch 102:  40/307] 	 train loss: 0.140508 	 lr: 0.00041
[epoch 102:  60/307] 	 train loss: 0.193753 	 lr: 0.00041
[epoch 102:  80/307] 	 train loss: 0.097821 	 lr: 0.00041
[epoch 102: 100/307] 	 train loss: 0.492078 	 lr: 0.00041

val loss: 0.320131 	 acc: 0.911669

[epoch 102: 120/307] 	 train loss: 0.148135 	 lr: 0.00041
[epoch 102: 140/307] 	 train loss: 0.148594 	 lr: 0.00041
[epoch 102: 160/307] 	 train loss: 0.059312 	 lr: 0.00041
[epoch 102: 180/307] 	 train loss: 0.256610 	 lr: 0.00041
[epoch 102: 200/307] 	 train loss: 0.029936 	 lr: 0.00041
[epoch 102: 220/307] 	 train loss: 0.100871 	 lr: 0.00041
[epoch 102: 240/307] 	 train loss: 0.130858 	 lr: 0.00041

val loss: 0.308570 	 acc: 0.914506

[epoch 102: 260/307] 	 train loss: 0.136562 	 lr: 0.00041
[epoch 102: 280/307] 	 train loss: 0.213616 	 lr: 0.00041
[epoch 102: 300/307] 	 train loss: 0.380805 	 lr: 0.00041
[epoch 103:   0/307] 	 train loss: 0.205560 	 lr: 0.00041
[epoch 103:  20/307] 	 train loss: 0.134576 	 lr: 0.00041
[epoch 103:  40/307] 	 train loss: 0.247744 	 lr: 0.00041
[epoch 103:  60/307] 	 train loss: 0.178469 	 lr: 0.00041
[epoch 103:  80/307] 	 train loss: 0.221482 	 lr: 0.00041
[epoch 103: 100/307] 	 train loss: 0.142334 	 lr: 0.00041

val loss: 0.312717 	 acc: 0.912075

[epoch 103: 120/307] 	 train loss: 0.072532 	 lr: 0.00041
[epoch 103: 140/307] 	 train loss: 0.149320 	 lr: 0.00041
[epoch 103: 160/307] 	 train loss: 0.109059 	 lr: 0.00041
[epoch 103: 180/307] 	 train loss: 0.242002 	 lr: 0.00041
[epoch 103: 200/307] 	 train loss: 0.247506 	 lr: 0.00041
[epoch 103: 220/307] 	 train loss: 0.120087 	 lr: 0.00041
[epoch 103: 240/307] 	 train loss: 0.136195 	 lr: 0.00041

val loss: 0.316511 	 acc: 0.907618

[epoch 103: 260/307] 	 train loss: 0.084726 	 lr: 0.00041
[epoch 103: 280/307] 	 train loss: 0.204700 	 lr: 0.00041
[epoch 103: 300/307] 	 train loss: 0.151623 	 lr: 0.00041
[epoch 104:   0/307] 	 train loss: 0.129863 	 lr: 0.00041
[epoch 104:  20/307] 	 train loss: 0.124932 	 lr: 0.00041
[epoch 104:  40/307] 	 train loss: 0.102700 	 lr: 0.00041
[epoch 104:  60/307] 	 train loss: 0.051478 	 lr: 0.00041
[epoch 104:  80/307] 	 train loss: 0.322036 	 lr: 0.00041

val loss: 0.307215 	 acc: 0.916532

[epoch 104: 100/307] 	 train loss: 0.214021 	 lr: 0.00041
[epoch 104: 120/307] 	 train loss: 0.063307 	 lr: 0.00041
[epoch 104: 140/307] 	 train loss: 0.234987 	 lr: 0.00041
[epoch 104: 160/307] 	 train loss: 0.435922 	 lr: 0.00041
[epoch 104: 180/307] 	 train loss: 0.204984 	 lr: 0.00041
[epoch 104: 200/307] 	 train loss: 0.125472 	 lr: 0.00041
[epoch 104: 220/307] 	 train loss: 0.214735 	 lr: 0.00041
[epoch 104: 240/307] 	 train loss: 0.147478 	 lr: 0.00041

val loss: 0.306382 	 acc: 0.914911

[epoch 104: 260/307] 	 train loss: 0.302711 	 lr: 0.00041
[epoch 104: 280/307] 	 train loss: 0.185712 	 lr: 0.00041
[epoch 104: 300/307] 	 train loss: 0.292891 	 lr: 0.00041
[epoch 105:   0/307] 	 train loss: 0.262601 	 lr: 0.00041
[epoch 105:  20/307] 	 train loss: 0.112007 	 lr: 0.00041
[epoch 105:  40/307] 	 train loss: 0.098036 	 lr: 0.00041
[epoch 105:  60/307] 	 train loss: 0.116356 	 lr: 0.00041
[epoch 105:  80/307] 	 train loss: 0.235112 	 lr: 0.00041

val loss: 0.322486 	 acc: 0.910454

[epoch 105: 100/307] 	 train loss: 0.200652 	 lr: 0.00041
[epoch 105: 120/307] 	 train loss: 0.050900 	 lr: 0.00041
[epoch 105: 140/307] 	 train loss: 0.140954 	 lr: 0.00041
[epoch 105: 160/307] 	 train loss: 0.151154 	 lr: 0.00041
[epoch 105: 180/307] 	 train loss: 0.146553 	 lr: 0.00041
[epoch 105: 200/307] 	 train loss: 0.101043 	 lr: 0.00041
[epoch 105: 220/307] 	 train loss: 0.228093 	 lr: 0.00041
[epoch 105: 240/307] 	 train loss: 0.066841 	 lr: 0.00041

val loss: 0.315310 	 acc: 0.913695

[epoch 105: 260/307] 	 train loss: 0.080631 	 lr: 0.00041
[epoch 105: 280/307] 	 train loss: 0.039898 	 lr: 0.00041
[epoch 105: 300/307] 	 train loss: 0.277045 	 lr: 0.00041
[epoch 106:   0/307] 	 train loss: 0.013651 	 lr: 0.00033
[epoch 106:  20/307] 	 train loss: 0.029469 	 lr: 0.00033
[epoch 106:  40/307] 	 train loss: 0.208513 	 lr: 0.00033
[epoch 106:  60/307] 	 train loss: 0.205748 	 lr: 0.00033
[epoch 106:  80/307] 	 train loss: 0.088277 	 lr: 0.00033

val loss: 0.303390 	 acc: 0.916937

[epoch 106: 100/307] 	 train loss: 0.530923 	 lr: 0.00033
[epoch 106: 120/307] 	 train loss: 0.253987 	 lr: 0.00033
[epoch 106: 140/307] 	 train loss: 0.031061 	 lr: 0.00033
[epoch 106: 160/307] 	 train loss: 0.033452 	 lr: 0.00033
[epoch 106: 180/307] 	 train loss: 0.048877 	 lr: 0.00033
[epoch 106: 200/307] 	 train loss: 0.484496 	 lr: 0.00033
[epoch 106: 220/307] 	 train loss: 0.236436 	 lr: 0.00033
[epoch 106: 240/307] 	 train loss: 0.264501 	 lr: 0.00033

val loss: 0.316209 	 acc: 0.912075

[epoch 106: 260/307] 	 train loss: 0.866845 	 lr: 0.00033
[epoch 106: 280/307] 	 train loss: 0.102984 	 lr: 0.00033
[epoch 106: 300/307] 	 train loss: 0.237338 	 lr: 0.00033
[epoch 107:   0/307] 	 train loss: 0.106360 	 lr: 0.00033
[epoch 107:  20/307] 	 train loss: 0.157573 	 lr: 0.00033
[epoch 107:  40/307] 	 train loss: 0.102786 	 lr: 0.00033
[epoch 107:  60/307] 	 train loss: 0.134492 	 lr: 0.00033
[epoch 107:  80/307] 	 train loss: 0.394604 	 lr: 0.00033

val loss: 0.320147 	 acc: 0.910454

[epoch 107: 100/307] 	 train loss: 0.129318 	 lr: 0.00033
[epoch 107: 120/307] 	 train loss: 0.187041 	 lr: 0.00033
[epoch 107: 140/307] 	 train loss: 0.135195 	 lr: 0.00033
[epoch 107: 160/307] 	 train loss: 0.040289 	 lr: 0.00033
[epoch 107: 180/307] 	 train loss: 0.323814 	 lr: 0.00033
[epoch 107: 200/307] 	 train loss: 0.135288 	 lr: 0.00033
[epoch 107: 220/307] 	 train loss: 0.273570 	 lr: 0.00033
[epoch 107: 240/307] 	 train loss: 0.071243 	 lr: 0.00033

val loss: 0.332824 	 acc: 0.914100

[epoch 107: 260/307] 	 train loss: 0.055454 	 lr: 0.00033
[epoch 107: 280/307] 	 train loss: 0.108812 	 lr: 0.00033
[epoch 107: 300/307] 	 train loss: 0.170009 	 lr: 0.00033
[epoch 108:   0/307] 	 train loss: 0.301449 	 lr: 0.00033
[epoch 108:  20/307] 	 train loss: 0.099826 	 lr: 0.00033
[epoch 108:  40/307] 	 train loss: 0.128590 	 lr: 0.00033
[epoch 108:  60/307] 	 train loss: 0.084286 	 lr: 0.00033
[epoch 108:  80/307] 	 train loss: 0.114001 	 lr: 0.00033

val loss: 0.336408 	 acc: 0.905186

[epoch 108: 100/307] 	 train loss: 0.047705 	 lr: 0.00033
[epoch 108: 120/307] 	 train loss: 0.156165 	 lr: 0.00033
[epoch 108: 140/307] 	 train loss: 0.098214 	 lr: 0.00033
[epoch 108: 160/307] 	 train loss: 0.029006 	 lr: 0.00033
[epoch 108: 180/307] 	 train loss: 0.105016 	 lr: 0.00033
[epoch 108: 200/307] 	 train loss: 0.171894 	 lr: 0.00033
[epoch 108: 220/307] 	 train loss: 0.292647 	 lr: 0.00033
[epoch 108: 240/307] 	 train loss: 0.051400 	 lr: 0.00033

val loss: 0.333855 	 acc: 0.909238

[epoch 108: 260/307] 	 train loss: 0.102332 	 lr: 0.00033
[epoch 108: 280/307] 	 train loss: 0.255271 	 lr: 0.00033
[epoch 108: 300/307] 	 train loss: 0.027624 	 lr: 0.00033
[epoch 109:   0/307] 	 train loss: 0.222070 	 lr: 0.00033
[epoch 109:  20/307] 	 train loss: 0.119738 	 lr: 0.00033
[epoch 109:  40/307] 	 train loss: 0.046590 	 lr: 0.00033
[epoch 109:  60/307] 	 train loss: 0.124807 	 lr: 0.00033
[epoch 109:  80/307] 	 train loss: 0.166698 	 lr: 0.00033

val loss: 0.324401 	 acc: 0.910454

[epoch 109: 100/307] 	 train loss: 0.115034 	 lr: 0.00033
[epoch 109: 120/307] 	 train loss: 0.292779 	 lr: 0.00033
[epoch 109: 140/307] 	 train loss: 0.106906 	 lr: 0.00033
[epoch 109: 160/307] 	 train loss: 0.032986 	 lr: 0.00033
[epoch 109: 180/307] 	 train loss: 0.144252 	 lr: 0.00033
[epoch 109: 200/307] 	 train loss: 0.132163 	 lr: 0.00033
[epoch 109: 220/307] 	 train loss: 0.012513 	 lr: 0.00033
[epoch 109: 240/307] 	 train loss: 0.238154 	 lr: 0.00033

val loss: 0.305197 	 acc: 0.914100

[epoch 109: 260/307] 	 train loss: 0.104464 	 lr: 0.00033
[epoch 109: 280/307] 	 train loss: 0.320731 	 lr: 0.00033
[epoch 109: 300/307] 	 train loss: 0.219788 	 lr: 0.00033
[epoch 110:   0/307] 	 train loss: 0.051533 	 lr: 0.00033
[epoch 110:  20/307] 	 train loss: 0.227055 	 lr: 0.00033
[epoch 110:  40/307] 	 train loss: 0.079422 	 lr: 0.00033
[epoch 110:  60/307] 	 train loss: 0.082708 	 lr: 0.00033
[epoch 110:  80/307] 	 train loss: 0.109289 	 lr: 0.00033

val loss: 0.311850 	 acc: 0.914506

[epoch 110: 100/307] 	 train loss: 0.259735 	 lr: 0.00033
[epoch 110: 120/307] 	 train loss: 0.088757 	 lr: 0.00033
[epoch 110: 140/307] 	 train loss: 0.095150 	 lr: 0.00033
[epoch 110: 160/307] 	 train loss: 0.064173 	 lr: 0.00033
[epoch 110: 180/307] 	 train loss: 0.304595 	 lr: 0.00033
[epoch 110: 200/307] 	 train loss: 0.073861 	 lr: 0.00033
[epoch 110: 220/307] 	 train loss: 0.032098 	 lr: 0.00033
[epoch 110: 240/307] 	 train loss: 0.093745 	 lr: 0.00033

val loss: 0.304769 	 acc: 0.913290

[epoch 110: 260/307] 	 train loss: 0.082166 	 lr: 0.00033
[epoch 110: 280/307] 	 train loss: 0.009774 	 lr: 0.00033
[epoch 110: 300/307] 	 train loss: 0.105466 	 lr: 0.00033
[epoch 111:   0/307] 	 train loss: 0.318848 	 lr: 0.00033
[epoch 111:  20/307] 	 train loss: 0.032632 	 lr: 0.00033
[epoch 111:  40/307] 	 train loss: 0.090114 	 lr: 0.00033
[epoch 111:  60/307] 	 train loss: 0.030892 	 lr: 0.00033
[epoch 111:  80/307] 	 train loss: 0.193413 	 lr: 0.00033

val loss: 0.312267 	 acc: 0.914506

[epoch 111: 100/307] 	 train loss: 0.110671 	 lr: 0.00033
[epoch 111: 120/307] 	 train loss: 0.112074 	 lr: 0.00033
[epoch 111: 140/307] 	 train loss: 0.254731 	 lr: 0.00033
[epoch 111: 160/307] 	 train loss: 0.142202 	 lr: 0.00033
[epoch 111: 180/307] 	 train loss: 0.244201 	 lr: 0.00033
[epoch 111: 200/307] 	 train loss: 0.054995 	 lr: 0.00033
[epoch 111: 220/307] 	 train loss: 0.086017 	 lr: 0.00033

val loss: 0.305334 	 acc: 0.910454

[epoch 111: 240/307] 	 train loss: 0.079981 	 lr: 0.00033
[epoch 111: 260/307] 	 train loss: 0.196775 	 lr: 0.00033
[epoch 111: 280/307] 	 train loss: 0.134918 	 lr: 0.00033
[epoch 111: 300/307] 	 train loss: 0.282232 	 lr: 0.00033
[epoch 112:   0/307] 	 train loss: 0.261825 	 lr: 0.00033
[epoch 112:  20/307] 	 train loss: 0.074301 	 lr: 0.00033
[epoch 112:  40/307] 	 train loss: 0.183287 	 lr: 0.00033
[epoch 112:  60/307] 	 train loss: 0.049739 	 lr: 0.00033
[epoch 112:  80/307] 	 train loss: 0.229664 	 lr: 0.00033

val loss: 0.325522 	 acc: 0.906402

[epoch 112: 100/307] 	 train loss: 0.062232 	 lr: 0.00033
[epoch 112: 120/307] 	 train loss: 0.200597 	 lr: 0.00033
[epoch 112: 140/307] 	 train loss: 0.119887 	 lr: 0.00033
[epoch 112: 160/307] 	 train loss: 0.088252 	 lr: 0.00033
[epoch 112: 180/307] 	 train loss: 0.242181 	 lr: 0.00033
[epoch 112: 200/307] 	 train loss: 0.091159 	 lr: 0.00033
[epoch 112: 220/307] 	 train loss: 0.104295 	 lr: 0.00033

val loss: 0.304170 	 acc: 0.916126

[epoch 112: 240/307] 	 train loss: 0.270004 	 lr: 0.00033
[epoch 112: 260/307] 	 train loss: 0.248373 	 lr: 0.00033
[epoch 112: 280/307] 	 train loss: 0.068916 	 lr: 0.00033
[epoch 112: 300/307] 	 train loss: 0.116579 	 lr: 0.00033
[epoch 113:   0/307] 	 train loss: 0.131544 	 lr: 0.00033
[epoch 113:  20/307] 	 train loss: 0.240125 	 lr: 0.00033
[epoch 113:  40/307] 	 train loss: 0.364226 	 lr: 0.00033
[epoch 113:  60/307] 	 train loss: 0.064217 	 lr: 0.00033
[epoch 113:  80/307] 	 train loss: 0.050164 	 lr: 0.00033

val loss: 0.299666 	 acc: 0.915316

[epoch 113: 100/307] 	 train loss: 0.221492 	 lr: 0.00033
[epoch 113: 120/307] 	 train loss: 0.036219 	 lr: 0.00033
[epoch 113: 140/307] 	 train loss: 0.095127 	 lr: 0.00033
[epoch 113: 160/307] 	 train loss: 0.347693 	 lr: 0.00033
[epoch 113: 180/307] 	 train loss: 0.147999 	 lr: 0.00033
[epoch 113: 200/307] 	 train loss: 0.135739 	 lr: 0.00033
[epoch 113: 220/307] 	 train loss: 0.204040 	 lr: 0.00033

val loss: 0.299488 	 acc: 0.911264

[epoch 113: 240/307] 	 train loss: 0.217957 	 lr: 0.00033
[epoch 113: 260/307] 	 train loss: 0.024421 	 lr: 0.00033
[epoch 113: 280/307] 	 train loss: 0.119253 	 lr: 0.00033
[epoch 113: 300/307] 	 train loss: 0.313255 	 lr: 0.00033
[epoch 114:   0/307] 	 train loss: 0.353849 	 lr: 0.00033
[epoch 114:  20/307] 	 train loss: 0.196202 	 lr: 0.00033
[epoch 114:  40/307] 	 train loss: 0.167278 	 lr: 0.00033
[epoch 114:  60/307] 	 train loss: 0.257901 	 lr: 0.00033

val loss: 0.305422 	 acc: 0.916937

[epoch 114:  80/307] 	 train loss: 0.051568 	 lr: 0.00033
[epoch 114: 100/307] 	 train loss: 0.026174 	 lr: 0.00033
[epoch 114: 120/307] 	 train loss: 0.167308 	 lr: 0.00033
[epoch 114: 140/307] 	 train loss: 0.076741 	 lr: 0.00033
[epoch 114: 160/307] 	 train loss: 0.100233 	 lr: 0.00033
[epoch 114: 180/307] 	 train loss: 0.107512 	 lr: 0.00033
[epoch 114: 200/307] 	 train loss: 0.188244 	 lr: 0.00033
[epoch 114: 220/307] 	 train loss: 0.113607 	 lr: 0.00033

val loss: 0.309170 	 acc: 0.917342

[epoch 114: 240/307] 	 train loss: 0.097703 	 lr: 0.00033
[epoch 114: 260/307] 	 train loss: 0.215235 	 lr: 0.00033
[epoch 114: 280/307] 	 train loss: 0.089694 	 lr: 0.00033
[epoch 114: 300/307] 	 train loss: 0.176217 	 lr: 0.00033
[epoch 115:   0/307] 	 train loss: 0.170100 	 lr: 0.00033
[epoch 115:  20/307] 	 train loss: 0.117696 	 lr: 0.00033
[epoch 115:  40/307] 	 train loss: 0.090985 	 lr: 0.00033
[epoch 115:  60/307] 	 train loss: 0.119133 	 lr: 0.00033

val loss: 0.308722 	 acc: 0.917342

[epoch 115:  80/307] 	 train loss: 0.114387 	 lr: 0.00033
[epoch 115: 100/307] 	 train loss: 0.068382 	 lr: 0.00033
[epoch 115: 120/307] 	 train loss: 0.172747 	 lr: 0.00033
[epoch 115: 140/307] 	 train loss: 0.265119 	 lr: 0.00033
[epoch 115: 160/307] 	 train loss: 0.128799 	 lr: 0.00033
[epoch 115: 180/307] 	 train loss: 0.248203 	 lr: 0.00033
[epoch 115: 200/307] 	 train loss: 0.454260 	 lr: 0.00033
[epoch 115: 220/307] 	 train loss: 0.449252 	 lr: 0.00033

val loss: 0.306431 	 acc: 0.913290

[epoch 115: 240/307] 	 train loss: 0.290809 	 lr: 0.00033
[epoch 115: 260/307] 	 train loss: 0.136747 	 lr: 0.00033
[epoch 115: 280/307] 	 train loss: 0.029843 	 lr: 0.00033
[epoch 115: 300/307] 	 train loss: 0.009932 	 lr: 0.00033
[epoch 116:   0/307] 	 train loss: 0.099032 	 lr: 0.00033
[epoch 116:  20/307] 	 train loss: 0.254887 	 lr: 0.00033
[epoch 116:  40/307] 	 train loss: 0.247616 	 lr: 0.00033
[epoch 116:  60/307] 	 train loss: 0.086262 	 lr: 0.00033

val loss: 0.320986 	 acc: 0.913695

[epoch 116:  80/307] 	 train loss: 0.461339 	 lr: 0.00033
[epoch 116: 100/307] 	 train loss: 0.205225 	 lr: 0.00033
[epoch 116: 120/307] 	 train loss: 0.079317 	 lr: 0.00033
[epoch 116: 140/307] 	 train loss: 0.217360 	 lr: 0.00033
[epoch 116: 160/307] 	 train loss: 0.282969 	 lr: 0.00033
[epoch 116: 180/307] 	 train loss: 0.190360 	 lr: 0.00033
[epoch 116: 200/307] 	 train loss: 0.180687 	 lr: 0.00033
[epoch 116: 220/307] 	 train loss: 0.592339 	 lr: 0.00033

val loss: 0.293749 	 acc: 0.917747

[epoch 116: 240/307] 	 train loss: 0.203989 	 lr: 0.00033
[epoch 116: 260/307] 	 train loss: 0.362260 	 lr: 0.00033
[epoch 116: 280/307] 	 train loss: 0.184424 	 lr: 0.00033
[epoch 116: 300/307] 	 train loss: 0.152089 	 lr: 0.00033
[epoch 117:   0/307] 	 train loss: 0.080750 	 lr: 0.00033
[epoch 117:  20/307] 	 train loss: 0.225403 	 lr: 0.00033
[epoch 117:  40/307] 	 train loss: 0.074655 	 lr: 0.00033
[epoch 117:  60/307] 	 train loss: 0.230744 	 lr: 0.00033

val loss: 0.320089 	 acc: 0.912480

[epoch 117:  80/307] 	 train loss: 0.031240 	 lr: 0.00033
[epoch 117: 100/307] 	 train loss: 0.041784 	 lr: 0.00033
[epoch 117: 120/307] 	 train loss: 0.061769 	 lr: 0.00033
[epoch 117: 140/307] 	 train loss: 0.055265 	 lr: 0.00033
[epoch 117: 160/307] 	 train loss: 0.101630 	 lr: 0.00033
[epoch 117: 180/307] 	 train loss: 0.076373 	 lr: 0.00033
[epoch 117: 200/307] 	 train loss: 0.257156 	 lr: 0.00033
[epoch 117: 220/307] 	 train loss: 0.117117 	 lr: 0.00033

val loss: 0.321060 	 acc: 0.913695

[epoch 117: 240/307] 	 train loss: 0.098847 	 lr: 0.00033
[epoch 117: 260/307] 	 train loss: 0.167413 	 lr: 0.00033
[epoch 117: 280/307] 	 train loss: 0.145007 	 lr: 0.00033
[epoch 117: 300/307] 	 train loss: 0.018597 	 lr: 0.00033
[epoch 118:   0/307] 	 train loss: 0.083612 	 lr: 0.00033
[epoch 118:  20/307] 	 train loss: 0.067301 	 lr: 0.00033
[epoch 118:  40/307] 	 train loss: 0.110869 	 lr: 0.00033
[epoch 118:  60/307] 	 train loss: 0.060153 	 lr: 0.00033

val loss: 0.328767 	 acc: 0.915316

[epoch 118:  80/307] 	 train loss: 0.055842 	 lr: 0.00033
[epoch 118: 100/307] 	 train loss: 0.136832 	 lr: 0.00033
[epoch 118: 120/307] 	 train loss: 0.297813 	 lr: 0.00033
[epoch 118: 140/307] 	 train loss: 0.052847 	 lr: 0.00033
[epoch 118: 160/307] 	 train loss: 0.195168 	 lr: 0.00033
[epoch 118: 180/307] 	 train loss: 0.271677 	 lr: 0.00033
[epoch 118: 200/307] 	 train loss: 0.404597 	 lr: 0.00033
[epoch 118: 220/307] 	 train loss: 0.241215 	 lr: 0.00033

val loss: 0.323261 	 acc: 0.916937

[epoch 118: 240/307] 	 train loss: 0.154923 	 lr: 0.00033
[epoch 118: 260/307] 	 train loss: 0.232139 	 lr: 0.00033
[epoch 118: 280/307] 	 train loss: 0.093296 	 lr: 0.00033
[epoch 118: 300/307] 	 train loss: 0.224669 	 lr: 0.00033
[epoch 119:   0/307] 	 train loss: 0.224148 	 lr: 0.00033
[epoch 119:  20/307] 	 train loss: 0.345541 	 lr: 0.00033
[epoch 119:  40/307] 	 train loss: 0.057850 	 lr: 0.00033
[epoch 119:  60/307] 	 train loss: 0.109650 	 lr: 0.00033

val loss: 0.322269 	 acc: 0.914911

[epoch 119:  80/307] 	 train loss: 0.102042 	 lr: 0.00033
[epoch 119: 100/307] 	 train loss: 0.205539 	 lr: 0.00033
[epoch 119: 120/307] 	 train loss: 0.312045 	 lr: 0.00033
[epoch 119: 140/307] 	 train loss: 0.232985 	 lr: 0.00033
[epoch 119: 160/307] 	 train loss: 0.028632 	 lr: 0.00033
[epoch 119: 180/307] 	 train loss: 0.224917 	 lr: 0.00033
[epoch 119: 200/307] 	 train loss: 0.258969 	 lr: 0.00033
[epoch 119: 220/307] 	 train loss: 0.025404 	 lr: 0.00033

val loss: 0.327275 	 acc: 0.916532

[epoch 119: 240/307] 	 train loss: 0.052385 	 lr: 0.00033
[epoch 119: 260/307] 	 train loss: 0.051774 	 lr: 0.00033
[epoch 119: 280/307] 	 train loss: 0.055380 	 lr: 0.00033
[epoch 119: 300/307] 	 train loss: 0.152830 	 lr: 0.00033
[epoch 120:   0/307] 	 train loss: 0.371465 	 lr: 0.00033
[epoch 120:  20/307] 	 train loss: 0.054797 	 lr: 0.00033
[epoch 120:  40/307] 	 train loss: 0.135209 	 lr: 0.00033
[epoch 120:  60/307] 	 train loss: 0.044871 	 lr: 0.00033

val loss: 0.325933 	 acc: 0.912480

[epoch 120:  80/307] 	 train loss: 0.131547 	 lr: 0.00033
[epoch 120: 100/307] 	 train loss: 0.174314 	 lr: 0.00033
[epoch 120: 120/307] 	 train loss: 0.099737 	 lr: 0.00033
[epoch 120: 140/307] 	 train loss: 0.219310 	 lr: 0.00033
[epoch 120: 160/307] 	 train loss: 0.350040 	 lr: 0.00033
[epoch 120: 180/307] 	 train loss: 0.056429 	 lr: 0.00033
[epoch 120: 200/307] 	 train loss: 0.188178 	 lr: 0.00033
[epoch 120: 220/307] 	 train loss: 0.178475 	 lr: 0.00033

val loss: 0.346547 	 acc: 0.912885

[epoch 120: 240/307] 	 train loss: 0.176234 	 lr: 0.00033
[epoch 120: 260/307] 	 train loss: 0.023099 	 lr: 0.00033
[epoch 120: 280/307] 	 train loss: 0.100274 	 lr: 0.00033
[epoch 120: 300/307] 	 train loss: 0.447578 	 lr: 0.00033
[epoch 121:   0/307] 	 train loss: 0.311484 	 lr: 0.00033
[epoch 121:  20/307] 	 train loss: 0.135707 	 lr: 0.00033
[epoch 121:  40/307] 	 train loss: 0.295477 	 lr: 0.00033
[epoch 121:  60/307] 	 train loss: 0.190976 	 lr: 0.00033

val loss: 0.311371 	 acc: 0.914506

[epoch 121:  80/307] 	 train loss: 0.109679 	 lr: 0.00033
[epoch 121: 100/307] 	 train loss: 0.157625 	 lr: 0.00033
[epoch 121: 120/307] 	 train loss: 0.206509 	 lr: 0.00033
[epoch 121: 140/307] 	 train loss: 0.178910 	 lr: 0.00033
[epoch 121: 160/307] 	 train loss: 0.100089 	 lr: 0.00033
[epoch 121: 180/307] 	 train loss: 0.095383 	 lr: 0.00033
[epoch 121: 200/307] 	 train loss: 0.172454 	 lr: 0.00033

val loss: 0.318000 	 acc: 0.920583

[epoch 121: 220/307] 	 train loss: 0.149503 	 lr: 0.00033
[epoch 121: 240/307] 	 train loss: 0.060428 	 lr: 0.00033
[epoch 121: 260/307] 	 train loss: 0.066484 	 lr: 0.00033
[epoch 121: 280/307] 	 train loss: 0.252989 	 lr: 0.00033
[epoch 121: 300/307] 	 train loss: 0.167956 	 lr: 0.00033
[epoch 122:   0/307] 	 train loss: 0.055021 	 lr: 0.00033
[epoch 122:  20/307] 	 train loss: 0.111603 	 lr: 0.00033
[epoch 122:  40/307] 	 train loss: 0.304232 	 lr: 0.00033
[epoch 122:  60/307] 	 train loss: 0.082951 	 lr: 0.00033

val loss: 0.312685 	 acc: 0.921799

[epoch 122:  80/307] 	 train loss: 0.113597 	 lr: 0.00033
[epoch 122: 100/307] 	 train loss: 0.074135 	 lr: 0.00033
[epoch 122: 120/307] 	 train loss: 0.154997 	 lr: 0.00033
[epoch 122: 140/307] 	 train loss: 0.213167 	 lr: 0.00033
[epoch 122: 160/307] 	 train loss: 0.087907 	 lr: 0.00033
[epoch 122: 180/307] 	 train loss: 0.066536 	 lr: 0.00033
[epoch 122: 200/307] 	 train loss: 0.072883 	 lr: 0.00033

val loss: 0.320534 	 acc: 0.913290

[epoch 122: 220/307] 	 train loss: 0.245233 	 lr: 0.00033
[epoch 122: 240/307] 	 train loss: 0.123096 	 lr: 0.00033
[epoch 122: 260/307] 	 train loss: 0.080738 	 lr: 0.00033
[epoch 122: 280/307] 	 train loss: 0.118589 	 lr: 0.00033
[epoch 122: 300/307] 	 train loss: 0.051790 	 lr: 0.00033
[epoch 123:   0/307] 	 train loss: 0.303010 	 lr: 0.00033
[epoch 123:  20/307] 	 train loss: 0.091693 	 lr: 0.00033
[epoch 123:  40/307] 	 train loss: 0.226344 	 lr: 0.00033
[epoch 123:  60/307] 	 train loss: 0.059678 	 lr: 0.00033

val loss: 0.320688 	 acc: 0.915721

[epoch 123:  80/307] 	 train loss: 0.264967 	 lr: 0.00033
[epoch 123: 100/307] 	 train loss: 0.219263 	 lr: 0.00033
[epoch 123: 120/307] 	 train loss: 0.075143 	 lr: 0.00033
[epoch 123: 140/307] 	 train loss: 0.326868 	 lr: 0.00033
[epoch 123: 160/307] 	 train loss: 0.078526 	 lr: 0.00033
[epoch 123: 180/307] 	 train loss: 0.170576 	 lr: 0.00033
[epoch 123: 200/307] 	 train loss: 0.033220 	 lr: 0.00033

val loss: 0.339361 	 acc: 0.915721

[epoch 123: 220/307] 	 train loss: 0.131588 	 lr: 0.00033
[epoch 123: 240/307] 	 train loss: 0.056512 	 lr: 0.00033
[epoch 123: 260/307] 	 train loss: 0.355373 	 lr: 0.00033
[epoch 123: 280/307] 	 train loss: 0.061740 	 lr: 0.00033
[epoch 123: 300/307] 	 train loss: 0.334152 	 lr: 0.00033
[epoch 124:   0/307] 	 train loss: 0.127500 	 lr: 0.00033
[epoch 124:  20/307] 	 train loss: 0.094332 	 lr: 0.00033
[epoch 124:  40/307] 	 train loss: 0.091545 	 lr: 0.00033

val loss: 0.320806 	 acc: 0.910454

[epoch 124:  60/307] 	 train loss: 0.078808 	 lr: 0.00033
[epoch 124:  80/307] 	 train loss: 0.060483 	 lr: 0.00033
[epoch 124: 100/307] 	 train loss: 0.089585 	 lr: 0.00033
[epoch 124: 120/307] 	 train loss: 0.179052 	 lr: 0.00033
[epoch 124: 140/307] 	 train loss: 0.051294 	 lr: 0.00033
[epoch 124: 160/307] 	 train loss: 0.406834 	 lr: 0.00033
[epoch 124: 180/307] 	 train loss: 0.261245 	 lr: 0.00033
[epoch 124: 200/307] 	 train loss: 0.215022 	 lr: 0.00033

val loss: 0.311402 	 acc: 0.915721

[epoch 124: 220/307] 	 train loss: 0.078106 	 lr: 0.00033
[epoch 124: 240/307] 	 train loss: 0.099468 	 lr: 0.00033
[epoch 124: 260/307] 	 train loss: 0.252542 	 lr: 0.00033
[epoch 124: 280/307] 	 train loss: 0.126114 	 lr: 0.00033
[epoch 124: 300/307] 	 train loss: 0.192215 	 lr: 0.00033
[epoch 125:   0/307] 	 train loss: 0.150163 	 lr: 0.00033
[epoch 125:  20/307] 	 train loss: 0.172144 	 lr: 0.00033
[epoch 125:  40/307] 	 train loss: 0.047632 	 lr: 0.00033

val loss: 0.296921 	 acc: 0.922609

saved model with accuracy %0.6f:  0.9226094003241491
[epoch 125:  60/307] 	 train loss: 0.057863 	 lr: 0.00033
[epoch 125:  80/307] 	 train loss: 0.092928 	 lr: 0.00033
[epoch 125: 100/307] 	 train loss: 0.102001 	 lr: 0.00033
[epoch 125: 120/307] 	 train loss: 0.157077 	 lr: 0.00033
[epoch 125: 140/307] 	 train loss: 0.126564 	 lr: 0.00033
[epoch 125: 160/307] 	 train loss: 0.051405 	 lr: 0.00033
[epoch 125: 180/307] 	 train loss: 0.114971 	 lr: 0.00033
[epoch 125: 200/307] 	 train loss: 0.068616 	 lr: 0.00033

val loss: 0.333437 	 acc: 0.909643

[epoch 125: 220/307] 	 train loss: 0.264936 	 lr: 0.00033
[epoch 125: 240/307] 	 train loss: 0.122064 	 lr: 0.00033
[epoch 125: 260/307] 	 train loss: 0.079541 	 lr: 0.00033
[epoch 125: 280/307] 	 train loss: 0.020335 	 lr: 0.00033
[epoch 125: 300/307] 	 train loss: 0.111222 	 lr: 0.00033
[epoch 126:   0/307] 	 train loss: 0.140398 	 lr: 0.00033
[epoch 126:  20/307] 	 train loss: 0.647845 	 lr: 0.00033
[epoch 126:  40/307] 	 train loss: 0.263287 	 lr: 0.00033

val loss: 0.325513 	 acc: 0.916532

[epoch 126:  60/307] 	 train loss: 0.193025 	 lr: 0.00033
[epoch 126:  80/307] 	 train loss: 0.352100 	 lr: 0.00033
[epoch 126: 100/307] 	 train loss: 0.493559 	 lr: 0.00033
[epoch 126: 120/307] 	 train loss: 0.274979 	 lr: 0.00033
[epoch 126: 140/307] 	 train loss: 0.213399 	 lr: 0.00033
[epoch 126: 160/307] 	 train loss: 0.381909 	 lr: 0.00033
[epoch 126: 180/307] 	 train loss: 0.186160 	 lr: 0.00033
[epoch 126: 200/307] 	 train loss: 0.080141 	 lr: 0.00033

val loss: 0.321667 	 acc: 0.915316

[epoch 126: 220/307] 	 train loss: 0.131732 	 lr: 0.00033
[epoch 126: 240/307] 	 train loss: 0.121361 	 lr: 0.00033
[epoch 126: 260/307] 	 train loss: 0.082384 	 lr: 0.00033
[epoch 126: 280/307] 	 train loss: 0.042316 	 lr: 0.00033
[epoch 126: 300/307] 	 train loss: 0.122900 	 lr: 0.00033
[epoch 127:   0/307] 	 train loss: 0.230121 	 lr: 0.00026
[epoch 127:  20/307] 	 train loss: 0.130303 	 lr: 0.00026
[epoch 127:  40/307] 	 train loss: 0.182365 	 lr: 0.00026

val loss: 0.309760 	 acc: 0.918558

[epoch 127:  60/307] 	 train loss: 0.153640 	 lr: 0.00026
[epoch 127:  80/307] 	 train loss: 0.070272 	 lr: 0.00026
[epoch 127: 100/307] 	 train loss: 0.096029 	 lr: 0.00026
[epoch 127: 120/307] 	 train loss: 0.115798 	 lr: 0.00026
[epoch 127: 140/307] 	 train loss: 0.031199 	 lr: 0.00026
[epoch 127: 160/307] 	 train loss: 0.133879 	 lr: 0.00026
[epoch 127: 180/307] 	 train loss: 0.216761 	 lr: 0.00026
[epoch 127: 200/307] 	 train loss: 0.127133 	 lr: 0.00026

val loss: 0.311853 	 acc: 0.916532

[epoch 127: 220/307] 	 train loss: 0.022492 	 lr: 0.00026
[epoch 127: 240/307] 	 train loss: 0.215862 	 lr: 0.00026
[epoch 127: 260/307] 	 train loss: 0.062135 	 lr: 0.00026
[epoch 127: 280/307] 	 train loss: 0.246875 	 lr: 0.00026
[epoch 127: 300/307] 	 train loss: 0.034896 	 lr: 0.00026
[epoch 128:   0/307] 	 train loss: 0.145977 	 lr: 0.00026
[epoch 128:  20/307] 	 train loss: 0.062037 	 lr: 0.00026
[epoch 128:  40/307] 	 train loss: 0.203490 	 lr: 0.00026

val loss: 0.309200 	 acc: 0.920583

[epoch 128:  60/307] 	 train loss: 0.015497 	 lr: 0.00026
[epoch 128:  80/307] 	 train loss: 0.212932 	 lr: 0.00026
[epoch 128: 100/307] 	 train loss: 0.169343 	 lr: 0.00026
[epoch 128: 120/307] 	 train loss: 0.064713 	 lr: 0.00026
[epoch 128: 140/307] 	 train loss: 0.177727 	 lr: 0.00026
[epoch 128: 160/307] 	 train loss: 0.158870 	 lr: 0.00026
[epoch 128: 180/307] 	 train loss: 0.097207 	 lr: 0.00026
[epoch 128: 200/307] 	 train loss: 0.171773 	 lr: 0.00026

val loss: 0.316670 	 acc: 0.911669

[epoch 128: 220/307] 	 train loss: 0.032780 	 lr: 0.00026
[epoch 128: 240/307] 	 train loss: 0.073750 	 lr: 0.00026
[epoch 128: 260/307] 	 train loss: 0.088291 	 lr: 0.00026
[epoch 128: 280/307] 	 train loss: 0.093043 	 lr: 0.00026
[epoch 128: 300/307] 	 train loss: 0.109294 	 lr: 0.00026
[epoch 129:   0/307] 	 train loss: 0.093956 	 lr: 0.00026
[epoch 129:  20/307] 	 train loss: 0.143920 	 lr: 0.00026
[epoch 129:  40/307] 	 train loss: 0.061286 	 lr: 0.00026

val loss: 0.299731 	 acc: 0.916126

[epoch 129:  60/307] 	 train loss: 0.090356 	 lr: 0.00026
[epoch 129:  80/307] 	 train loss: 0.096004 	 lr: 0.00026
[epoch 129: 100/307] 	 train loss: 0.163037 	 lr: 0.00026
[epoch 129: 120/307] 	 train loss: 0.022892 	 lr: 0.00026
[epoch 129: 140/307] 	 train loss: 0.230291 	 lr: 0.00026
[epoch 129: 160/307] 	 train loss: 0.165783 	 lr: 0.00026
[epoch 129: 180/307] 	 train loss: 0.239336 	 lr: 0.00026
[epoch 129: 200/307] 	 train loss: 0.123818 	 lr: 0.00026

val loss: 0.300059 	 acc: 0.916937

[epoch 129: 220/307] 	 train loss: 0.409329 	 lr: 0.00026
[epoch 129: 240/307] 	 train loss: 0.105401 	 lr: 0.00026
[epoch 129: 260/307] 	 train loss: 0.073985 	 lr: 0.00026
[epoch 129: 280/307] 	 train loss: 0.089232 	 lr: 0.00026
[epoch 129: 300/307] 	 train loss: 0.169651 	 lr: 0.00026
[epoch 130:   0/307] 	 train loss: 0.118151 	 lr: 0.00026
[epoch 130:  20/307] 	 train loss: 0.389911 	 lr: 0.00026
[epoch 130:  40/307] 	 train loss: 0.251335 	 lr: 0.00026

val loss: 0.299295 	 acc: 0.919773

[epoch 130:  60/307] 	 train loss: 0.074014 	 lr: 0.00026
[epoch 130:  80/307] 	 train loss: 0.058029 	 lr: 0.00026
[epoch 130: 100/307] 	 train loss: 0.277926 	 lr: 0.00026
[epoch 130: 120/307] 	 train loss: 0.029087 	 lr: 0.00026
[epoch 130: 140/307] 	 train loss: 0.234359 	 lr: 0.00026
[epoch 130: 160/307] 	 train loss: 0.286736 	 lr: 0.00026
[epoch 130: 180/307] 	 train loss: 0.126475 	 lr: 0.00026
[epoch 130: 200/307] 	 train loss: 0.266952 	 lr: 0.00026

val loss: 0.293041 	 acc: 0.914100

[epoch 130: 220/307] 	 train loss: 0.056633 	 lr: 0.00026
[epoch 130: 240/307] 	 train loss: 0.088053 	 lr: 0.00026
[epoch 130: 260/307] 	 train loss: 0.162051 	 lr: 0.00026
[epoch 130: 280/307] 	 train loss: 0.265079 	 lr: 0.00026
[epoch 130: 300/307] 	 train loss: 0.093819 	 lr: 0.00026
[epoch 131:   0/307] 	 train loss: 0.185326 	 lr: 0.00026
[epoch 131:  20/307] 	 train loss: 0.066179 	 lr: 0.00026
[epoch 131:  40/307] 	 train loss: 0.194069 	 lr: 0.00026

val loss: 0.327147 	 acc: 0.921394

[epoch 131:  60/307] 	 train loss: 0.089056 	 lr: 0.00026
[epoch 131:  80/307] 	 train loss: 0.149820 	 lr: 0.00026
[epoch 131: 100/307] 	 train loss: 0.314513 	 lr: 0.00026
[epoch 131: 120/307] 	 train loss: 0.102194 	 lr: 0.00026
[epoch 131: 140/307] 	 train loss: 0.040651 	 lr: 0.00026
[epoch 131: 160/307] 	 train loss: 0.069666 	 lr: 0.00026
[epoch 131: 180/307] 	 train loss: 0.223298 	 lr: 0.00026

val loss: 0.316003 	 acc: 0.917342

[epoch 131: 200/307] 	 train loss: 0.413662 	 lr: 0.00026
[epoch 131: 220/307] 	 train loss: 0.093016 	 lr: 0.00026
[epoch 131: 240/307] 	 train loss: 0.138234 	 lr: 0.00026
[epoch 131: 260/307] 	 train loss: 0.007475 	 lr: 0.00026
[epoch 131: 280/307] 	 train loss: 0.167232 	 lr: 0.00026
[epoch 131: 300/307] 	 train loss: 0.099295 	 lr: 0.00026
[epoch 132:   0/307] 	 train loss: 0.163842 	 lr: 0.00026
[epoch 132:  20/307] 	 train loss: 0.241957 	 lr: 0.00026
[epoch 132:  40/307] 	 train loss: 0.284060 	 lr: 0.00026

val loss: 0.322926 	 acc: 0.916532

[epoch 132:  60/307] 	 train loss: 0.107569 	 lr: 0.00026
[epoch 132:  80/307] 	 train loss: 0.022468 	 lr: 0.00026
[epoch 132: 100/307] 	 train loss: 0.234865 	 lr: 0.00026
[epoch 132: 120/307] 	 train loss: 0.175768 	 lr: 0.00026
[epoch 132: 140/307] 	 train loss: 0.155768 	 lr: 0.00026
[epoch 132: 160/307] 	 train loss: 0.122915 	 lr: 0.00026
[epoch 132: 180/307] 	 train loss: 0.064102 	 lr: 0.00026

val loss: 0.323529 	 acc: 0.915721

[epoch 132: 200/307] 	 train loss: 0.292239 	 lr: 0.00026
[epoch 132: 220/307] 	 train loss: 0.020467 	 lr: 0.00026
[epoch 132: 240/307] 	 train loss: 0.365099 	 lr: 0.00026
[epoch 132: 260/307] 	 train loss: 0.110215 	 lr: 0.00026
[epoch 132: 280/307] 	 train loss: 0.144870 	 lr: 0.00026
[epoch 132: 300/307] 	 train loss: 0.069712 	 lr: 0.00026
[epoch 133:   0/307] 	 train loss: 0.222236 	 lr: 0.00026
[epoch 133:  20/307] 	 train loss: 0.141948 	 lr: 0.00026
[epoch 133:  40/307] 	 train loss: 0.021539 	 lr: 0.00026

val loss: 0.327988 	 acc: 0.915721

[epoch 133:  60/307] 	 train loss: 0.061814 	 lr: 0.00026
[epoch 133:  80/307] 	 train loss: 0.050268 	 lr: 0.00026
[epoch 133: 100/307] 	 train loss: 0.019401 	 lr: 0.00026
[epoch 133: 120/307] 	 train loss: 0.205407 	 lr: 0.00026
[epoch 133: 140/307] 	 train loss: 0.075491 	 lr: 0.00026
[epoch 133: 160/307] 	 train loss: 0.177776 	 lr: 0.00026
[epoch 133: 180/307] 	 train loss: 0.025049 	 lr: 0.00026

val loss: 0.311485 	 acc: 0.923420

saved model with accuracy %0.6f:  0.923419773095624
[epoch 133: 200/307] 	 train loss: 0.209995 	 lr: 0.00026
[epoch 133: 220/307] 	 train loss: 0.134604 	 lr: 0.00026
[epoch 133: 240/307] 	 train loss: 0.075675 	 lr: 0.00026
[epoch 133: 260/307] 	 train loss: 0.092915 	 lr: 0.00026
[epoch 133: 280/307] 	 train loss: 0.056614 	 lr: 0.00026
[epoch 133: 300/307] 	 train loss: 0.156819 	 lr: 0.00026
[epoch 134:   0/307] 	 train loss: 0.088133 	 lr: 0.00026
[epoch 134:  20/307] 	 train loss: 0.194842 	 lr: 0.00026

val loss: 0.318207 	 acc: 0.907618

[epoch 134:  40/307] 	 train loss: 0.053368 	 lr: 0.00026
[epoch 134:  60/307] 	 train loss: 0.062658 	 lr: 0.00026
[epoch 134:  80/307] 	 train loss: 0.060118 	 lr: 0.00026
[epoch 134: 100/307] 	 train loss: 0.128127 	 lr: 0.00026
[epoch 134: 120/307] 	 train loss: 0.027141 	 lr: 0.00026
[epoch 134: 140/307] 	 train loss: 0.020347 	 lr: 0.00026
[epoch 134: 160/307] 	 train loss: 0.270870 	 lr: 0.00026
[epoch 134: 180/307] 	 train loss: 0.267227 	 lr: 0.00026

val loss: 0.317629 	 acc: 0.916937

[epoch 134: 200/307] 	 train loss: 0.243952 	 lr: 0.00026
[epoch 134: 220/307] 	 train loss: 0.096768 	 lr: 0.00026
[epoch 134: 240/307] 	 train loss: 0.400023 	 lr: 0.00026
[epoch 134: 260/307] 	 train loss: 0.034657 	 lr: 0.00026
[epoch 134: 280/307] 	 train loss: 0.153759 	 lr: 0.00026
[epoch 134: 300/307] 	 train loss: 0.129206 	 lr: 0.00026
[epoch 135:   0/307] 	 train loss: 0.200333 	 lr: 0.00026
[epoch 135:  20/307] 	 train loss: 0.144079 	 lr: 0.00026

val loss: 0.300771 	 acc: 0.920583

[epoch 135:  40/307] 	 train loss: 0.208068 	 lr: 0.00026
[epoch 135:  60/307] 	 train loss: 0.088353 	 lr: 0.00026
[epoch 135:  80/307] 	 train loss: 0.133804 	 lr: 0.00026
[epoch 135: 100/307] 	 train loss: 0.024122 	 lr: 0.00026
[epoch 135: 120/307] 	 train loss: 0.058198 	 lr: 0.00026
[epoch 135: 140/307] 	 train loss: 0.065419 	 lr: 0.00026
[epoch 135: 160/307] 	 train loss: 0.163713 	 lr: 0.00026
[epoch 135: 180/307] 	 train loss: 0.084255 	 lr: 0.00026

val loss: 0.326803 	 acc: 0.913290

[epoch 135: 200/307] 	 train loss: 0.129588 	 lr: 0.00026
[epoch 135: 220/307] 	 train loss: 0.013698 	 lr: 0.00026
[epoch 135: 240/307] 	 train loss: 0.058401 	 lr: 0.00026
[epoch 135: 260/307] 	 train loss: 0.154640 	 lr: 0.00026
[epoch 135: 280/307] 	 train loss: 0.127275 	 lr: 0.00026
[epoch 135: 300/307] 	 train loss: 0.119071 	 lr: 0.00026
[epoch 136:   0/307] 	 train loss: 0.139954 	 lr: 0.00026
[epoch 136:  20/307] 	 train loss: 0.139727 	 lr: 0.00026

val loss: 0.317198 	 acc: 0.910049

[epoch 136:  40/307] 	 train loss: 0.178946 	 lr: 0.00026
[epoch 136:  60/307] 	 train loss: 0.194997 	 lr: 0.00026
[epoch 136:  80/307] 	 train loss: 0.142473 	 lr: 0.00026
[epoch 136: 100/307] 	 train loss: 0.261258 	 lr: 0.00026
[epoch 136: 120/307] 	 train loss: 0.122172 	 lr: 0.00026
[epoch 136: 140/307] 	 train loss: 0.230655 	 lr: 0.00026
[epoch 136: 160/307] 	 train loss: 0.025190 	 lr: 0.00026
[epoch 136: 180/307] 	 train loss: 0.025550 	 lr: 0.00026

val loss: 0.298074 	 acc: 0.914100

[epoch 136: 200/307] 	 train loss: 0.099611 	 lr: 0.00026
[epoch 136: 220/307] 	 train loss: 0.019844 	 lr: 0.00026
[epoch 136: 240/307] 	 train loss: 0.201576 	 lr: 0.00026
[epoch 136: 260/307] 	 train loss: 0.089243 	 lr: 0.00026
[epoch 136: 280/307] 	 train loss: 0.144226 	 lr: 0.00026
[epoch 136: 300/307] 	 train loss: 0.062144 	 lr: 0.00026
[epoch 137:   0/307] 	 train loss: 0.044629 	 lr: 0.00026
[epoch 137:  20/307] 	 train loss: 0.072700 	 lr: 0.00026

val loss: 0.300626 	 acc: 0.914911

[epoch 137:  40/307] 	 train loss: 0.021127 	 lr: 0.00026
[epoch 137:  60/307] 	 train loss: 0.213218 	 lr: 0.00026
[epoch 137:  80/307] 	 train loss: 0.127797 	 lr: 0.00026
[epoch 137: 100/307] 	 train loss: 0.029320 	 lr: 0.00026
[epoch 137: 120/307] 	 train loss: 0.128568 	 lr: 0.00026
[epoch 137: 140/307] 	 train loss: 0.038930 	 lr: 0.00026
[epoch 137: 160/307] 	 train loss: 0.055386 	 lr: 0.00026
[epoch 137: 180/307] 	 train loss: 0.158325 	 lr: 0.00026

val loss: 0.300769 	 acc: 0.914506

[epoch 137: 200/307] 	 train loss: 0.273108 	 lr: 0.00026
[epoch 137: 220/307] 	 train loss: 0.039600 	 lr: 0.00026
[epoch 137: 240/307] 	 train loss: 0.116702 	 lr: 0.00026
[epoch 137: 260/307] 	 train loss: 0.261033 	 lr: 0.00026
[epoch 137: 280/307] 	 train loss: 0.223925 	 lr: 0.00026
[epoch 137: 300/307] 	 train loss: 0.136618 	 lr: 0.00026
[epoch 138:   0/307] 	 train loss: 0.073325 	 lr: 0.00026
[epoch 138:  20/307] 	 train loss: 0.154050 	 lr: 0.00026

val loss: 0.300372 	 acc: 0.916126

[epoch 138:  40/307] 	 train loss: 0.101323 	 lr: 0.00026
[epoch 138:  60/307] 	 train loss: 0.182944 	 lr: 0.00026
[epoch 138:  80/307] 	 train loss: 0.084464 	 lr: 0.00026
[epoch 138: 100/307] 	 train loss: 0.147863 	 lr: 0.00026
[epoch 138: 120/307] 	 train loss: 0.327325 	 lr: 0.00026
[epoch 138: 140/307] 	 train loss: 0.082076 	 lr: 0.00026
[epoch 138: 160/307] 	 train loss: 0.051897 	 lr: 0.00026
[epoch 138: 180/307] 	 train loss: 0.086888 	 lr: 0.00026

val loss: 0.307918 	 acc: 0.914911

[epoch 138: 200/307] 	 train loss: 0.321354 	 lr: 0.00026
[epoch 138: 220/307] 	 train loss: 0.150816 	 lr: 0.00026
[epoch 138: 240/307] 	 train loss: 0.096479 	 lr: 0.00026
[epoch 138: 260/307] 	 train loss: 0.135346 	 lr: 0.00026
[epoch 138: 280/307] 	 train loss: 0.013915 	 lr: 0.00026
[epoch 138: 300/307] 	 train loss: 0.114485 	 lr: 0.00026
[epoch 139:   0/307] 	 train loss: 0.239258 	 lr: 0.00026
[epoch 139:  20/307] 	 train loss: 0.340405 	 lr: 0.00026

val loss: 0.324070 	 acc: 0.915316

[epoch 139:  40/307] 	 train loss: 0.212197 	 lr: 0.00026
[epoch 139:  60/307] 	 train loss: 0.044213 	 lr: 0.00026
[epoch 139:  80/307] 	 train loss: 0.059802 	 lr: 0.00026
[epoch 139: 100/307] 	 train loss: 0.154533 	 lr: 0.00026
[epoch 139: 120/307] 	 train loss: 0.098560 	 lr: 0.00026
[epoch 139: 140/307] 	 train loss: 0.354016 	 lr: 0.00026
[epoch 139: 160/307] 	 train loss: 0.193596 	 lr: 0.00026
[epoch 139: 180/307] 	 train loss: 0.272427 	 lr: 0.00026

val loss: 0.320552 	 acc: 0.914100

[epoch 139: 200/307] 	 train loss: 0.091968 	 lr: 0.00026
[epoch 139: 220/307] 	 train loss: 0.326302 	 lr: 0.00026
[epoch 139: 240/307] 	 train loss: 0.044014 	 lr: 0.00026
[epoch 139: 260/307] 	 train loss: 0.265858 	 lr: 0.00026
[epoch 139: 280/307] 	 train loss: 0.183675 	 lr: 0.00026
[epoch 139: 300/307] 	 train loss: 0.169751 	 lr: 0.00026
[epoch 140:   0/307] 	 train loss: 0.171745 	 lr: 0.00026
[epoch 140:  20/307] 	 train loss: 0.048650 	 lr: 0.00026

val loss: 0.325431 	 acc: 0.914506

[epoch 140:  40/307] 	 train loss: 0.073823 	 lr: 0.00026
[epoch 140:  60/307] 	 train loss: 0.186673 	 lr: 0.00026
[epoch 140:  80/307] 	 train loss: 0.129966 	 lr: 0.00026
[epoch 140: 100/307] 	 train loss: 0.116171 	 lr: 0.00026
[epoch 140: 120/307] 	 train loss: 0.163456 	 lr: 0.00026
[epoch 140: 140/307] 	 train loss: 0.066627 	 lr: 0.00026
[epoch 140: 160/307] 	 train loss: 0.140784 	 lr: 0.00026
[epoch 140: 180/307] 	 train loss: 0.041287 	 lr: 0.00026

val loss: 0.300674 	 acc: 0.921799

[epoch 140: 200/307] 	 train loss: 0.021001 	 lr: 0.00026
[epoch 140: 220/307] 	 train loss: 0.119743 	 lr: 0.00026
[epoch 140: 240/307] 	 train loss: 0.257881 	 lr: 0.00026
[epoch 140: 260/307] 	 train loss: 0.020926 	 lr: 0.00026
[epoch 140: 280/307] 	 train loss: 0.081360 	 lr: 0.00026
[epoch 140: 300/307] 	 train loss: 0.170067 	 lr: 0.00026
[epoch 141:   0/307] 	 train loss: 0.156897 	 lr: 0.00026
[epoch 141:  20/307] 	 train loss: 0.076302 	 lr: 0.00026

val loss: 0.331089 	 acc: 0.913290

[epoch 141:  40/307] 	 train loss: 0.079505 	 lr: 0.00026
[epoch 141:  60/307] 	 train loss: 0.177237 	 lr: 0.00026
[epoch 141:  80/307] 	 train loss: 0.278056 	 lr: 0.00026
[epoch 141: 100/307] 	 train loss: 0.163195 	 lr: 0.00026
[epoch 141: 120/307] 	 train loss: 0.033868 	 lr: 0.00026
[epoch 141: 140/307] 	 train loss: 0.319624 	 lr: 0.00026
[epoch 141: 160/307] 	 train loss: 0.128022 	 lr: 0.00026

val loss: 0.314283 	 acc: 0.912885

[epoch 141: 180/307] 	 train loss: 0.028601 	 lr: 0.00026
[epoch 141: 200/307] 	 train loss: 0.211237 	 lr: 0.00026
[epoch 141: 220/307] 	 train loss: 0.075115 	 lr: 0.00026
[epoch 141: 240/307] 	 train loss: 0.110317 	 lr: 0.00026
[epoch 141: 260/307] 	 train loss: 0.017015 	 lr: 0.00026
[epoch 141: 280/307] 	 train loss: 0.169261 	 lr: 0.00026
[epoch 141: 300/307] 	 train loss: 0.101355 	 lr: 0.00026
[epoch 142:   0/307] 	 train loss: 0.131498 	 lr: 0.00026
[epoch 142:  20/307] 	 train loss: 0.132495 	 lr: 0.00026

val loss: 0.319129 	 acc: 0.916126

[epoch 142:  40/307] 	 train loss: 0.074124 	 lr: 0.00026
[epoch 142:  60/307] 	 train loss: 0.050919 	 lr: 0.00026
[epoch 142:  80/307] 	 train loss: 0.023268 	 lr: 0.00026
[epoch 142: 100/307] 	 train loss: 0.136844 	 lr: 0.00026
[epoch 142: 120/307] 	 train loss: 0.148718 	 lr: 0.00026
[epoch 142: 140/307] 	 train loss: 0.231494 	 lr: 0.00026
[epoch 142: 160/307] 	 train loss: 0.175594 	 lr: 0.00026

val loss: 0.302756 	 acc: 0.920583

[epoch 142: 180/307] 	 train loss: 0.194030 	 lr: 0.00026
[epoch 142: 200/307] 	 train loss: 0.106797 	 lr: 0.00026
[epoch 142: 220/307] 	 train loss: 0.120228 	 lr: 0.00026
[epoch 142: 240/307] 	 train loss: 0.022335 	 lr: 0.00026
[epoch 142: 260/307] 	 train loss: 0.124881 	 lr: 0.00026
[epoch 142: 280/307] 	 train loss: 0.106868 	 lr: 0.00026
[epoch 142: 300/307] 	 train loss: 0.119836 	 lr: 0.00026
[epoch 143:   0/307] 	 train loss: 0.079462 	 lr: 0.00026
[epoch 143:  20/307] 	 train loss: 0.100877 	 lr: 0.00026

val loss: 0.321575 	 acc: 0.911669

[epoch 143:  40/307] 	 train loss: 0.062197 	 lr: 0.00026
[epoch 143:  60/307] 	 train loss: 0.128175 	 lr: 0.00026
[epoch 143:  80/307] 	 train loss: 0.356860 	 lr: 0.00026
[epoch 143: 100/307] 	 train loss: 0.147007 	 lr: 0.00026
[epoch 143: 120/307] 	 train loss: 0.073842 	 lr: 0.00026
[epoch 143: 140/307] 	 train loss: 0.066733 	 lr: 0.00026
[epoch 143: 160/307] 	 train loss: 0.184103 	 lr: 0.00026

val loss: 0.309231 	 acc: 0.914911

[epoch 143: 180/307] 	 train loss: 0.018219 	 lr: 0.00026
[epoch 143: 200/307] 	 train loss: 0.089356 	 lr: 0.00026
[epoch 143: 220/307] 	 train loss: 0.101680 	 lr: 0.00026
[epoch 143: 240/307] 	 train loss: 0.211703 	 lr: 0.00026
[epoch 143: 260/307] 	 train loss: 0.108802 	 lr: 0.00026
[epoch 143: 280/307] 	 train loss: 0.100866 	 lr: 0.00026
[epoch 143: 300/307] 	 train loss: 0.101048 	 lr: 0.00026
[epoch 144:   0/307] 	 train loss: 0.014938 	 lr: 0.00026

val loss: 0.321765 	 acc: 0.912885

[epoch 144:  20/307] 	 train loss: 0.078287 	 lr: 0.00026
[epoch 144:  40/307] 	 train loss: 0.214786 	 lr: 0.00026
[epoch 144:  60/307] 	 train loss: 0.115090 	 lr: 0.00026
[epoch 144:  80/307] 	 train loss: 0.251393 	 lr: 0.00026
[epoch 144: 100/307] 	 train loss: 0.118881 	 lr: 0.00026
[epoch 144: 120/307] 	 train loss: 0.233213 	 lr: 0.00026
[epoch 144: 140/307] 	 train loss: 0.189370 	 lr: 0.00026
[epoch 144: 160/307] 	 train loss: 0.047662 	 lr: 0.00026

val loss: 0.343930 	 acc: 0.908833

[epoch 144: 180/307] 	 train loss: 0.105939 	 lr: 0.00026
[epoch 144: 200/307] 	 train loss: 0.183143 	 lr: 0.00026
[epoch 144: 220/307] 	 train loss: 0.207793 	 lr: 0.00026
[epoch 144: 240/307] 	 train loss: 0.068373 	 lr: 0.00026
[epoch 144: 260/307] 	 train loss: 0.089926 	 lr: 0.00026
[epoch 144: 280/307] 	 train loss: 0.184633 	 lr: 0.00026
[epoch 144: 300/307] 	 train loss: 0.378486 	 lr: 0.00026
[epoch 145:   0/307] 	 train loss: 0.102372 	 lr: 0.00026

val loss: 0.308186 	 acc: 0.913290

[epoch 145:  20/307] 	 train loss: 0.078217 	 lr: 0.00026
[epoch 145:  40/307] 	 train loss: 0.072493 	 lr: 0.00026
[epoch 145:  60/307] 	 train loss: 0.183099 	 lr: 0.00026
[epoch 145:  80/307] 	 train loss: 0.133456 	 lr: 0.00026
[epoch 145: 100/307] 	 train loss: 0.104341 	 lr: 0.00026
[epoch 145: 120/307] 	 train loss: 0.204357 	 lr: 0.00026
[epoch 145: 140/307] 	 train loss: 0.039803 	 lr: 0.00026
[epoch 145: 160/307] 	 train loss: 0.111261 	 lr: 0.00026

val loss: 0.300355 	 acc: 0.916126

[epoch 145: 180/307] 	 train loss: 0.310290 	 lr: 0.00026
[epoch 145: 200/307] 	 train loss: 0.082786 	 lr: 0.00026
[epoch 145: 220/307] 	 train loss: 0.121075 	 lr: 0.00026
[epoch 145: 240/307] 	 train loss: 0.088948 	 lr: 0.00026
[epoch 145: 260/307] 	 train loss: 0.141781 	 lr: 0.00026
[epoch 145: 280/307] 	 train loss: 0.041727 	 lr: 0.00026
[epoch 145: 300/307] 	 train loss: 0.151935 	 lr: 0.00026
[epoch 146:   0/307] 	 train loss: 0.202335 	 lr: 0.00026

val loss: 0.308130 	 acc: 0.914506

[epoch 146:  20/307] 	 train loss: 0.120077 	 lr: 0.00026
[epoch 146:  40/307] 	 train loss: 0.079671 	 lr: 0.00026
[epoch 146:  60/307] 	 train loss: 0.153424 	 lr: 0.00026
[epoch 146:  80/307] 	 train loss: 0.018864 	 lr: 0.00026
[epoch 146: 100/307] 	 train loss: 0.297821 	 lr: 0.00026
[epoch 146: 120/307] 	 train loss: 0.112625 	 lr: 0.00026
[epoch 146: 140/307] 	 train loss: 0.060243 	 lr: 0.00026
[epoch 146: 160/307] 	 train loss: 0.038788 	 lr: 0.00026

val loss: 0.312516 	 acc: 0.912885

[epoch 146: 180/307] 	 train loss: 0.050463 	 lr: 0.00026
[epoch 146: 200/307] 	 train loss: 0.035002 	 lr: 0.00026
[epoch 146: 220/307] 	 train loss: 0.047051 	 lr: 0.00026
[epoch 146: 240/307] 	 train loss: 0.059380 	 lr: 0.00026
[epoch 146: 260/307] 	 train loss: 0.103312 	 lr: 0.00026
[epoch 146: 280/307] 	 train loss: 0.062302 	 lr: 0.00026
[epoch 146: 300/307] 	 train loss: 0.051926 	 lr: 0.00026
[epoch 147:   0/307] 	 train loss: 0.077072 	 lr: 0.00026

val loss: 0.318528 	 acc: 0.913695

[epoch 147:  20/307] 	 train loss: 0.090976 	 lr: 0.00026
[epoch 147:  40/307] 	 train loss: 0.361308 	 lr: 0.00026
[epoch 147:  60/307] 	 train loss: 0.236467 	 lr: 0.00026
[epoch 147:  80/307] 	 train loss: 0.091395 	 lr: 0.00026
[epoch 147: 100/307] 	 train loss: 0.107292 	 lr: 0.00026
[epoch 147: 120/307] 	 train loss: 0.111888 	 lr: 0.00026
[epoch 147: 140/307] 	 train loss: 0.373026 	 lr: 0.00026
[epoch 147: 160/307] 	 train loss: 0.084738 	 lr: 0.00026

val loss: 0.315001 	 acc: 0.917747

[epoch 147: 180/307] 	 train loss: 0.078700 	 lr: 0.00026
[epoch 147: 200/307] 	 train loss: 0.019095 	 lr: 0.00026
[epoch 147: 220/307] 	 train loss: 0.188401 	 lr: 0.00026
[epoch 147: 240/307] 	 train loss: 0.167292 	 lr: 0.00026
[epoch 147: 260/307] 	 train loss: 0.114648 	 lr: 0.00026
[epoch 147: 280/307] 	 train loss: 0.010053 	 lr: 0.00026
[epoch 147: 300/307] 	 train loss: 0.131895 	 lr: 0.00026
[epoch 148:   0/307] 	 train loss: 0.236815 	 lr: 0.00021

val loss: 0.327399 	 acc: 0.914100

[epoch 148:  20/307] 	 train loss: 0.061353 	 lr: 0.00021
[epoch 148:  40/307] 	 train loss: 0.214348 	 lr: 0.00021
[epoch 148:  60/307] 	 train loss: 0.116656 	 lr: 0.00021
[epoch 148:  80/307] 	 train loss: 0.218213 	 lr: 0.00021
[epoch 148: 100/307] 	 train loss: 0.253169 	 lr: 0.00021
[epoch 148: 120/307] 	 train loss: 0.094166 	 lr: 0.00021
[epoch 148: 140/307] 	 train loss: 0.249792 	 lr: 0.00021
[epoch 148: 160/307] 	 train loss: 0.124611 	 lr: 0.00021

val loss: 0.303310 	 acc: 0.923015

[epoch 148: 180/307] 	 train loss: 0.192873 	 lr: 0.00021
[epoch 148: 200/307] 	 train loss: 0.177757 	 lr: 0.00021
[epoch 148: 220/307] 	 train loss: 0.220958 	 lr: 0.00021
[epoch 148: 240/307] 	 train loss: 0.281010 	 lr: 0.00021
[epoch 148: 260/307] 	 train loss: 0.072155 	 lr: 0.00021
[epoch 148: 280/307] 	 train loss: 0.147945 	 lr: 0.00021
[epoch 148: 300/307] 	 train loss: 0.022429 	 lr: 0.00021
[epoch 149:   0/307] 	 train loss: 0.081499 	 lr: 0.00021

val loss: 0.314346 	 acc: 0.916126

[epoch 149:  20/307] 	 train loss: 0.018589 	 lr: 0.00021
[epoch 149:  40/307] 	 train loss: 0.021710 	 lr: 0.00021
[epoch 149:  60/307] 	 train loss: 0.029078 	 lr: 0.00021
[epoch 149:  80/307] 	 train loss: 0.205053 	 lr: 0.00021
[epoch 149: 100/307] 	 train loss: 0.116325 	 lr: 0.00021
[epoch 149: 120/307] 	 train loss: 0.084821 	 lr: 0.00021
[epoch 149: 140/307] 	 train loss: 0.038953 	 lr: 0.00021
[epoch 149: 160/307] 	 train loss: 0.445542 	 lr: 0.00021

val loss: 0.316193 	 acc: 0.914100

[epoch 149: 180/307] 	 train loss: 0.077361 	 lr: 0.00021
[epoch 149: 200/307] 	 train loss: 0.125980 	 lr: 0.00021
[epoch 149: 220/307] 	 train loss: 0.092467 	 lr: 0.00021
[epoch 149: 240/307] 	 train loss: 0.051733 	 lr: 0.00021
[epoch 149: 260/307] 	 train loss: 0.043540 	 lr: 0.00021
[epoch 149: 280/307] 	 train loss: 0.140247 	 lr: 0.00021
[epoch 149: 300/307] 	 train loss: 0.019673 	 lr: 0.00021
[epoch 150:   0/307] 	 train loss: 0.050501 	 lr: 0.00021

val loss: 0.325540 	 acc: 0.913290

[epoch 150:  20/307] 	 train loss: 0.098186 	 lr: 0.00021
[epoch 150:  40/307] 	 train loss: 0.058795 	 lr: 0.00021
[epoch 150:  60/307] 	 train loss: 0.030516 	 lr: 0.00021
[epoch 150:  80/307] 	 train loss: 0.024625 	 lr: 0.00021
[epoch 150: 100/307] 	 train loss: 0.197353 	 lr: 0.00021
[epoch 150: 120/307] 	 train loss: 0.474702 	 lr: 0.00021
[epoch 150: 140/307] 	 train loss: 0.047359 	 lr: 0.00021
[epoch 150: 160/307] 	 train loss: 0.253817 	 lr: 0.00021

val loss: 0.314981 	 acc: 0.912885

[epoch 150: 180/307] 	 train loss: 0.153147 	 lr: 0.00021
[epoch 150: 200/307] 	 train loss: 0.296536 	 lr: 0.00021
[epoch 150: 220/307] 	 train loss: 0.031672 	 lr: 0.00021
[epoch 150: 240/307] 	 train loss: 0.311915 	 lr: 0.00021
[epoch 150: 260/307] 	 train loss: 0.125853 	 lr: 0.00021
[epoch 150: 280/307] 	 train loss: 0.121637 	 lr: 0.00021
[epoch 150: 300/307] 	 train loss: 0.085810 	 lr: 0.00021
[epoch 151:   0/307] 	 train loss: 0.012167 	 lr: 0.00021

val loss: 0.335007 	 acc: 0.913290

[epoch 151:  20/307] 	 train loss: 0.090730 	 lr: 0.00021
[epoch 151:  40/307] 	 train loss: 0.077732 	 lr: 0.00021
[epoch 151:  60/307] 	 train loss: 0.216651 	 lr: 0.00021
[epoch 151:  80/307] 	 train loss: 0.084169 	 lr: 0.00021
[epoch 151: 100/307] 	 train loss: 0.068859 	 lr: 0.00021
[epoch 151: 120/307] 	 train loss: 0.187644 	 lr: 0.00021
[epoch 151: 140/307] 	 train loss: 0.096738 	 lr: 0.00021

val loss: 0.335151 	 acc: 0.913290

[epoch 151: 160/307] 	 train loss: 0.187496 	 lr: 0.00021
[epoch 151: 180/307] 	 train loss: 0.053394 	 lr: 0.00021
[epoch 151: 200/307] 	 train loss: 0.323408 	 lr: 0.00021
[epoch 151: 220/307] 	 train loss: 0.034369 	 lr: 0.00021
[epoch 151: 240/307] 	 train loss: 0.118324 	 lr: 0.00021
[epoch 151: 260/307] 	 train loss: 0.167413 	 lr: 0.00021
[epoch 151: 280/307] 	 train loss: 0.233727 	 lr: 0.00021
[epoch 151: 300/307] 	 train loss: 0.228210 	 lr: 0.00021
[epoch 152:   0/307] 	 train loss: 0.046436 	 lr: 0.00021

val loss: 0.340096 	 acc: 0.911669

[epoch 152:  20/307] 	 train loss: 0.167190 	 lr: 0.00021
[epoch 152:  40/307] 	 train loss: 0.216675 	 lr: 0.00021
[epoch 152:  60/307] 	 train loss: 0.243346 	 lr: 0.00021
[epoch 152:  80/307] 	 train loss: 0.031643 	 lr: 0.00021
[epoch 152: 100/307] 	 train loss: 0.259476 	 lr: 0.00021
[epoch 152: 120/307] 	 train loss: 0.141638 	 lr: 0.00021
[epoch 152: 140/307] 	 train loss: 0.151273 	 lr: 0.00021

val loss: 0.349419 	 acc: 0.912075

[epoch 152: 160/307] 	 train loss: 0.052305 	 lr: 0.00021
[epoch 152: 180/307] 	 train loss: 0.090735 	 lr: 0.00021
[epoch 152: 200/307] 	 train loss: 0.262506 	 lr: 0.00021
[epoch 152: 220/307] 	 train loss: 0.146087 	 lr: 0.00021
[epoch 152: 240/307] 	 train loss: 0.149876 	 lr: 0.00021
[epoch 152: 260/307] 	 train loss: 0.193727 	 lr: 0.00021
[epoch 152: 280/307] 	 train loss: 0.015640 	 lr: 0.00021
[epoch 152: 300/307] 	 train loss: 0.194623 	 lr: 0.00021
[epoch 153:   0/307] 	 train loss: 0.159906 	 lr: 0.00021

val loss: 0.329795 	 acc: 0.914506

[epoch 153:  20/307] 	 train loss: 0.053452 	 lr: 0.00021
[epoch 153:  40/307] 	 train loss: 0.328260 	 lr: 0.00021
[epoch 153:  60/307] 	 train loss: 0.070215 	 lr: 0.00021
[epoch 153:  80/307] 	 train loss: 0.588361 	 lr: 0.00021
[epoch 153: 100/307] 	 train loss: 0.019676 	 lr: 0.00021
[epoch 153: 120/307] 	 train loss: 0.082903 	 lr: 0.00021
[epoch 153: 140/307] 	 train loss: 0.125377 	 lr: 0.00021

val loss: 0.329456 	 acc: 0.916937

[epoch 153: 160/307] 	 train loss: 0.222250 	 lr: 0.00021
[epoch 153: 180/307] 	 train loss: 0.072872 	 lr: 0.00021
[epoch 153: 200/307] 	 train loss: 0.121389 	 lr: 0.00021
[epoch 153: 220/307] 	 train loss: 0.083594 	 lr: 0.00021
[epoch 153: 240/307] 	 train loss: 0.304118 	 lr: 0.00021
[epoch 153: 260/307] 	 train loss: 0.270875 	 lr: 0.00021
[epoch 153: 280/307] 	 train loss: 0.058474 	 lr: 0.00021
[epoch 153: 300/307] 	 train loss: 0.262979 	 lr: 0.00021

val loss: 0.326102 	 acc: 0.912480

[epoch 154:   0/307] 	 train loss: 0.050607 	 lr: 0.00021
[epoch 154:  20/307] 	 train loss: 0.217290 	 lr: 0.00021
[epoch 154:  40/307] 	 train loss: 0.073796 	 lr: 0.00021
[epoch 154:  60/307] 	 train loss: 0.121593 	 lr: 0.00021
[epoch 154:  80/307] 	 train loss: 0.184118 	 lr: 0.00021
[epoch 154: 100/307] 	 train loss: 0.031951 	 lr: 0.00021
[epoch 154: 120/307] 	 train loss: 0.124056 	 lr: 0.00021
[epoch 154: 140/307] 	 train loss: 0.200493 	 lr: 0.00021

val loss: 0.310546 	 acc: 0.917342

[epoch 154: 160/307] 	 train loss: 0.204662 	 lr: 0.00021
[epoch 154: 180/307] 	 train loss: 0.114182 	 lr: 0.00021
[epoch 154: 200/307] 	 train loss: 0.054375 	 lr: 0.00021
[epoch 154: 220/307] 	 train loss: 0.138535 	 lr: 0.00021
[epoch 154: 240/307] 	 train loss: 0.034459 	 lr: 0.00021
[epoch 154: 260/307] 	 train loss: 0.242693 	 lr: 0.00021
[epoch 154: 280/307] 	 train loss: 0.122258 	 lr: 0.00021
[epoch 154: 300/307] 	 train loss: 0.017462 	 lr: 0.00021

val loss: 0.318041 	 acc: 0.922204

[epoch 155:   0/307] 	 train loss: 0.210730 	 lr: 0.00021
[epoch 155:  20/307] 	 train loss: 0.094998 	 lr: 0.00021
[epoch 155:  40/307] 	 train loss: 0.037605 	 lr: 0.00021
[epoch 155:  60/307] 	 train loss: 0.094047 	 lr: 0.00021
[epoch 155:  80/307] 	 train loss: 0.020611 	 lr: 0.00021
[epoch 155: 100/307] 	 train loss: 0.228810 	 lr: 0.00021
[epoch 155: 120/307] 	 train loss: 0.188376 	 lr: 0.00021
[epoch 155: 140/307] 	 train loss: 0.090277 	 lr: 0.00021

val loss: 0.312886 	 acc: 0.920989

[epoch 155: 160/307] 	 train loss: 0.150372 	 lr: 0.00021
[epoch 155: 180/307] 	 train loss: 0.126867 	 lr: 0.00021
[epoch 155: 200/307] 	 train loss: 0.096258 	 lr: 0.00021
[epoch 155: 220/307] 	 train loss: 0.250151 	 lr: 0.00021
[epoch 155: 240/307] 	 train loss: 0.096606 	 lr: 0.00021
[epoch 155: 260/307] 	 train loss: 0.043110 	 lr: 0.00021
[epoch 155: 280/307] 	 train loss: 0.240001 	 lr: 0.00021
[epoch 155: 300/307] 	 train loss: 0.040114 	 lr: 0.00021

val loss: 0.309327 	 acc: 0.918152

[epoch 156:   0/307] 	 train loss: 0.053351 	 lr: 0.00021
[epoch 156:  20/307] 	 train loss: 0.031700 	 lr: 0.00021
[epoch 156:  40/307] 	 train loss: 0.163646 	 lr: 0.00021
[epoch 156:  60/307] 	 train loss: 0.087166 	 lr: 0.00021
[epoch 156:  80/307] 	 train loss: 0.148043 	 lr: 0.00021
[epoch 156: 100/307] 	 train loss: 0.143354 	 lr: 0.00021
[epoch 156: 120/307] 	 train loss: 0.098753 	 lr: 0.00021
[epoch 156: 140/307] 	 train loss: 0.285339 	 lr: 0.00021

val loss: 0.298954 	 acc: 0.924230

saved model with accuracy %0.6f:  0.9242301458670988
[epoch 156: 160/307] 	 train loss: 0.039319 	 lr: 0.00021
[epoch 156: 180/307] 	 train loss: 0.199186 	 lr: 0.00021
[epoch 156: 200/307] 	 train loss: 0.293897 	 lr: 0.00021
[epoch 156: 220/307] 	 train loss: 0.067160 	 lr: 0.00021
[epoch 156: 240/307] 	 train loss: 0.040760 	 lr: 0.00021
[epoch 156: 260/307] 	 train loss: 0.118672 	 lr: 0.00021
[epoch 156: 280/307] 	 train loss: 0.204998 	 lr: 0.00021
[epoch 156: 300/307] 	 train loss: 0.116437 	 lr: 0.00021

val loss: 0.301950 	 acc: 0.924635

saved model with accuracy %0.6f:  0.9246353322528363
[epoch 157:   0/307] 	 train loss: 0.047227 	 lr: 0.00021
[epoch 157:  20/307] 	 train loss: 0.126906 	 lr: 0.00021
[epoch 157:  40/307] 	 train loss: 0.120797 	 lr: 0.00021
[epoch 157:  60/307] 	 train loss: 0.206388 	 lr: 0.00021
[epoch 157:  80/307] 	 train loss: 0.137379 	 lr: 0.00021
[epoch 157: 100/307] 	 train loss: 0.299820 	 lr: 0.00021
[epoch 157: 120/307] 	 train loss: 0.090818 	 lr: 0.00021
[epoch 157: 140/307] 	 train loss: 0.098932 	 lr: 0.00021

val loss: 0.316667 	 acc: 0.922204

[epoch 157: 160/307] 	 train loss: 0.096403 	 lr: 0.00021
[epoch 157: 180/307] 	 train loss: 0.021668 	 lr: 0.00021
[epoch 157: 200/307] 	 train loss: 0.157086 	 lr: 0.00021
[epoch 157: 220/307] 	 train loss: 0.013139 	 lr: 0.00021
[epoch 157: 240/307] 	 train loss: 0.121833 	 lr: 0.00021
[epoch 157: 260/307] 	 train loss: 0.072618 	 lr: 0.00021
[epoch 157: 280/307] 	 train loss: 0.127511 	 lr: 0.00021

val loss: 0.310509 	 acc: 0.916937

[epoch 157: 300/307] 	 train loss: 0.254623 	 lr: 0.00021
[epoch 158:   0/307] 	 train loss: 0.030798 	 lr: 0.00021
[epoch 158:  20/307] 	 train loss: 0.092644 	 lr: 0.00021
[epoch 158:  40/307] 	 train loss: 0.033105 	 lr: 0.00021
[epoch 158:  60/307] 	 train loss: 0.226327 	 lr: 0.00021
[epoch 158:  80/307] 	 train loss: 0.266324 	 lr: 0.00021
[epoch 158: 100/307] 	 train loss: 0.080196 	 lr: 0.00021
[epoch 158: 120/307] 	 train loss: 0.072240 	 lr: 0.00021
[epoch 158: 140/307] 	 train loss: 0.046979 	 lr: 0.00021

val loss: 0.305507 	 acc: 0.919773

[epoch 158: 160/307] 	 train loss: 0.152501 	 lr: 0.00021
[epoch 158: 180/307] 	 train loss: 0.178843 	 lr: 0.00021
[epoch 158: 200/307] 	 train loss: 0.159396 	 lr: 0.00021
[epoch 158: 220/307] 	 train loss: 0.107932 	 lr: 0.00021
[epoch 158: 240/307] 	 train loss: 0.058567 	 lr: 0.00021
[epoch 158: 260/307] 	 train loss: 0.087609 	 lr: 0.00021
[epoch 158: 280/307] 	 train loss: 0.127887 	 lr: 0.00021

val loss: 0.307821 	 acc: 0.920583

[epoch 158: 300/307] 	 train loss: 0.155566 	 lr: 0.00021
[epoch 159:   0/307] 	 train loss: 0.058103 	 lr: 0.00021
[epoch 159:  20/307] 	 train loss: 0.216843 	 lr: 0.00021
[epoch 159:  40/307] 	 train loss: 0.024197 	 lr: 0.00021
[epoch 159:  60/307] 	 train loss: 0.011531 	 lr: 0.00021
[epoch 159:  80/307] 	 train loss: 0.044344 	 lr: 0.00021
[epoch 159: 100/307] 	 train loss: 0.054217 	 lr: 0.00021
[epoch 159: 120/307] 	 train loss: 0.157347 	 lr: 0.00021
[epoch 159: 140/307] 	 train loss: 0.023338 	 lr: 0.00021

val loss: 0.319286 	 acc: 0.920178

[epoch 159: 160/307] 	 train loss: 0.028814 	 lr: 0.00021
[epoch 159: 180/307] 	 train loss: 0.154931 	 lr: 0.00021
[epoch 159: 200/307] 	 train loss: 0.144743 	 lr: 0.00021
[epoch 159: 220/307] 	 train loss: 0.058168 	 lr: 0.00021
[epoch 159: 240/307] 	 train loss: 0.130673 	 lr: 0.00021
[epoch 159: 260/307] 	 train loss: 0.056539 	 lr: 0.00021
[epoch 159: 280/307] 	 train loss: 0.039261 	 lr: 0.00021

val loss: 0.319889 	 acc: 0.922609

[epoch 159: 300/307] 	 train loss: 0.082881 	 lr: 0.00021
[epoch 160:   0/307] 	 train loss: 0.039437 	 lr: 0.00021
[epoch 160:  20/307] 	 train loss: 0.207784 	 lr: 0.00021
[epoch 160:  40/307] 	 train loss: 0.062104 	 lr: 0.00021
[epoch 160:  60/307] 	 train loss: 0.166470 	 lr: 0.00021
[epoch 160:  80/307] 	 train loss: 0.131251 	 lr: 0.00021
[epoch 160: 100/307] 	 train loss: 0.045868 	 lr: 0.00021
[epoch 160: 120/307] 	 train loss: 0.076126 	 lr: 0.00021
[epoch 160: 140/307] 	 train loss: 0.022296 	 lr: 0.00021

val loss: 0.310310 	 acc: 0.923825

[epoch 160: 160/307] 	 train loss: 0.064915 	 lr: 0.00021
[epoch 160: 180/307] 	 train loss: 0.128998 	 lr: 0.00021
[epoch 160: 200/307] 	 train loss: 0.121337 	 lr: 0.00021
[epoch 160: 220/307] 	 train loss: 0.249702 	 lr: 0.00021
[epoch 160: 240/307] 	 train loss: 0.112782 	 lr: 0.00021
[epoch 160: 260/307] 	 train loss: 0.102116 	 lr: 0.00021
[epoch 160: 280/307] 	 train loss: 0.227771 	 lr: 0.00021

val loss: 0.319894 	 acc: 0.916937

[epoch 160: 300/307] 	 train loss: 0.147690 	 lr: 0.00021
[epoch 161:   0/307] 	 train loss: 0.190687 	 lr: 0.00021
[epoch 161:  20/307] 	 train loss: 0.024301 	 lr: 0.00021
[epoch 161:  40/307] 	 train loss: 0.043223 	 lr: 0.00021
[epoch 161:  60/307] 	 train loss: 0.057591 	 lr: 0.00021
[epoch 161:  80/307] 	 train loss: 0.025961 	 lr: 0.00021
[epoch 161: 100/307] 	 train loss: 0.809933 	 lr: 0.00021
[epoch 161: 120/307] 	 train loss: 0.081952 	 lr: 0.00021

val loss: 0.334100 	 acc: 0.915721

[epoch 161: 140/307] 	 train loss: 0.086238 	 lr: 0.00021
[epoch 161: 160/307] 	 train loss: 0.198445 	 lr: 0.00021
[epoch 161: 180/307] 	 train loss: 0.067520 	 lr: 0.00021
[epoch 161: 200/307] 	 train loss: 0.044643 	 lr: 0.00021
[epoch 161: 220/307] 	 train loss: 0.180293 	 lr: 0.00021
[epoch 161: 240/307] 	 train loss: 0.035263 	 lr: 0.00021
[epoch 161: 260/307] 	 train loss: 0.017909 	 lr: 0.00021
[epoch 161: 280/307] 	 train loss: 0.040748 	 lr: 0.00021

val loss: 0.340786 	 acc: 0.919773

[epoch 161: 300/307] 	 train loss: 0.135349 	 lr: 0.00021
[epoch 162:   0/307] 	 train loss: 0.083992 	 lr: 0.00021
[epoch 162:  20/307] 	 train loss: 0.160109 	 lr: 0.00021
[epoch 162:  40/307] 	 train loss: 0.233742 	 lr: 0.00021
[epoch 162:  60/307] 	 train loss: 0.164659 	 lr: 0.00021
[epoch 162:  80/307] 	 train loss: 0.035964 	 lr: 0.00021
[epoch 162: 100/307] 	 train loss: 0.042702 	 lr: 0.00021
[epoch 162: 120/307] 	 train loss: 0.158250 	 lr: 0.00021

val loss: 0.332652 	 acc: 0.918963

[epoch 162: 140/307] 	 train loss: 0.204353 	 lr: 0.00021
[epoch 162: 160/307] 	 train loss: 0.084932 	 lr: 0.00021
[epoch 162: 180/307] 	 train loss: 0.140541 	 lr: 0.00021
[epoch 162: 200/307] 	 train loss: 0.133286 	 lr: 0.00021
[epoch 162: 220/307] 	 train loss: 0.132551 	 lr: 0.00021
[epoch 162: 240/307] 	 train loss: 0.172421 	 lr: 0.00021
[epoch 162: 260/307] 	 train loss: 0.529577 	 lr: 0.00021
[epoch 162: 280/307] 	 train loss: 0.115402 	 lr: 0.00021

val loss: 0.343803 	 acc: 0.918963

[epoch 162: 300/307] 	 train loss: 0.122922 	 lr: 0.00021
[epoch 163:   0/307] 	 train loss: 0.314942 	 lr: 0.00021
[epoch 163:  20/307] 	 train loss: 0.151126 	 lr: 0.00021
[epoch 163:  40/307] 	 train loss: 0.008877 	 lr: 0.00021
[epoch 163:  60/307] 	 train loss: 0.114401 	 lr: 0.00021
[epoch 163:  80/307] 	 train loss: 0.148334 	 lr: 0.00021
[epoch 163: 100/307] 	 train loss: 0.277379 	 lr: 0.00021
[epoch 163: 120/307] 	 train loss: 0.035897 	 lr: 0.00021

val loss: 0.322838 	 acc: 0.913695

[epoch 163: 140/307] 	 train loss: 0.040232 	 lr: 0.00021
[epoch 163: 160/307] 	 train loss: 0.159893 	 lr: 0.00021
[epoch 163: 180/307] 	 train loss: 0.045098 	 lr: 0.00021
[epoch 163: 200/307] 	 train loss: 0.146372 	 lr: 0.00021
[epoch 163: 220/307] 	 train loss: 0.069202 	 lr: 0.00021
[epoch 163: 240/307] 	 train loss: 0.049769 	 lr: 0.00021
[epoch 163: 260/307] 	 train loss: 0.137958 	 lr: 0.00021
[epoch 163: 280/307] 	 train loss: 0.086853 	 lr: 0.00021

val loss: 0.322894 	 acc: 0.916532

[epoch 163: 300/307] 	 train loss: 0.190280 	 lr: 0.00021
[epoch 164:   0/307] 	 train loss: 0.140039 	 lr: 0.00021
[epoch 164:  20/307] 	 train loss: 0.394946 	 lr: 0.00021
[epoch 164:  40/307] 	 train loss: 0.111968 	 lr: 0.00021
[epoch 164:  60/307] 	 train loss: 0.163523 	 lr: 0.00021
[epoch 164:  80/307] 	 train loss: 0.094593 	 lr: 0.00021
[epoch 164: 100/307] 	 train loss: 0.228558 	 lr: 0.00021
[epoch 164: 120/307] 	 train loss: 0.212717 	 lr: 0.00021

val loss: 0.318659 	 acc: 0.914911

[epoch 164: 140/307] 	 train loss: 0.072244 	 lr: 0.00021
[epoch 164: 160/307] 	 train loss: 0.097523 	 lr: 0.00021
[epoch 164: 180/307] 	 train loss: 0.135322 	 lr: 0.00021
[epoch 164: 200/307] 	 train loss: 0.290544 	 lr: 0.00021
[epoch 164: 220/307] 	 train loss: 0.063001 	 lr: 0.00021
[epoch 164: 240/307] 	 train loss: 0.207282 	 lr: 0.00021
[epoch 164: 260/307] 	 train loss: 0.066859 	 lr: 0.00021
[epoch 164: 280/307] 	 train loss: 0.053323 	 lr: 0.00021

val loss: 0.319059 	 acc: 0.916126

[epoch 164: 300/307] 	 train loss: 0.098647 	 lr: 0.00021
[epoch 165:   0/307] 	 train loss: 0.023255 	 lr: 0.00021
[epoch 165:  20/307] 	 train loss: 0.178837 	 lr: 0.00021
[epoch 165:  40/307] 	 train loss: 0.133259 	 lr: 0.00021
[epoch 165:  60/307] 	 train loss: 0.121758 	 lr: 0.00021
[epoch 165:  80/307] 	 train loss: 0.189589 	 lr: 0.00021
[epoch 165: 100/307] 	 train loss: 0.161579 	 lr: 0.00021
[epoch 165: 120/307] 	 train loss: 0.056940 	 lr: 0.00021

val loss: 0.333203 	 acc: 0.916937

[epoch 165: 140/307] 	 train loss: 0.239808 	 lr: 0.00021
[epoch 165: 160/307] 	 train loss: 0.174169 	 lr: 0.00021
[epoch 165: 180/307] 	 train loss: 0.074029 	 lr: 0.00021
[epoch 165: 200/307] 	 train loss: 0.023235 	 lr: 0.00021
[epoch 165: 220/307] 	 train loss: 0.233293 	 lr: 0.00021
[epoch 165: 240/307] 	 train loss: 0.058401 	 lr: 0.00021
[epoch 165: 260/307] 	 train loss: 0.135283 	 lr: 0.00021
[epoch 165: 280/307] 	 train loss: 0.177727 	 lr: 0.00021

val loss: 0.326649 	 acc: 0.916937

[epoch 165: 300/307] 	 train loss: 0.039284 	 lr: 0.00021
[epoch 166:   0/307] 	 train loss: 0.195460 	 lr: 0.00021
[epoch 166:  20/307] 	 train loss: 0.067381 	 lr: 0.00021
[epoch 166:  40/307] 	 train loss: 0.424457 	 lr: 0.00021
[epoch 166:  60/307] 	 train loss: 0.099602 	 lr: 0.00021
[epoch 166:  80/307] 	 train loss: 0.167541 	 lr: 0.00021
[epoch 166: 100/307] 	 train loss: 0.094056 	 lr: 0.00021
[epoch 166: 120/307] 	 train loss: 0.397737 	 lr: 0.00021

val loss: 0.323673 	 acc: 0.919773

[epoch 166: 140/307] 	 train loss: 0.041048 	 lr: 0.00021
[epoch 166: 160/307] 	 train loss: 0.203552 	 lr: 0.00021
[epoch 166: 180/307] 	 train loss: 0.277128 	 lr: 0.00021
[epoch 166: 200/307] 	 train loss: 0.064532 	 lr: 0.00021
[epoch 166: 220/307] 	 train loss: 0.155081 	 lr: 0.00021
[epoch 166: 240/307] 	 train loss: 0.335975 	 lr: 0.00021
[epoch 166: 260/307] 	 train loss: 0.072581 	 lr: 0.00021
[epoch 166: 280/307] 	 train loss: 0.204215 	 lr: 0.00021

val loss: 0.329657 	 acc: 0.911669

[epoch 166: 300/307] 	 train loss: 0.173164 	 lr: 0.00021
[epoch 167:   0/307] 	 train loss: 0.038802 	 lr: 0.00021
[epoch 167:  20/307] 	 train loss: 0.124672 	 lr: 0.00021
[epoch 167:  40/307] 	 train loss: 0.203289 	 lr: 0.00021
[epoch 167:  60/307] 	 train loss: 0.176016 	 lr: 0.00021
[epoch 167:  80/307] 	 train loss: 0.210317 	 lr: 0.00021
[epoch 167: 100/307] 	 train loss: 0.051167 	 lr: 0.00021
[epoch 167: 120/307] 	 train loss: 0.028453 	 lr: 0.00021

val loss: 0.323133 	 acc: 0.913695

[epoch 167: 140/307] 	 train loss: 0.116049 	 lr: 0.00021
[epoch 167: 160/307] 	 train loss: 0.077957 	 lr: 0.00021
[epoch 167: 180/307] 	 train loss: 0.236445 	 lr: 0.00021
[epoch 167: 200/307] 	 train loss: 0.095831 	 lr: 0.00021
[epoch 167: 220/307] 	 train loss: 0.041074 	 lr: 0.00021
[epoch 167: 240/307] 	 train loss: 0.251969 	 lr: 0.00021
[epoch 167: 260/307] 	 train loss: 0.023688 	 lr: 0.00021

val loss: 0.322400 	 acc: 0.914506

[epoch 167: 280/307] 	 train loss: 0.197408 	 lr: 0.00021
[epoch 167: 300/307] 	 train loss: 0.101485 	 lr: 0.00021
[epoch 168:   0/307] 	 train loss: 0.064732 	 lr: 0.00021
[epoch 168:  20/307] 	 train loss: 0.104710 	 lr: 0.00021
[epoch 168:  40/307] 	 train loss: 0.146711 	 lr: 0.00021
[epoch 168:  60/307] 	 train loss: 0.125328 	 lr: 0.00021
[epoch 168:  80/307] 	 train loss: 0.047475 	 lr: 0.00021
[epoch 168: 100/307] 	 train loss: 0.040208 	 lr: 0.00021
[epoch 168: 120/307] 	 train loss: 0.060427 	 lr: 0.00021

val loss: 0.319475 	 acc: 0.917342

[epoch 168: 140/307] 	 train loss: 0.208314 	 lr: 0.00021
[epoch 168: 160/307] 	 train loss: 0.045971 	 lr: 0.00021
[epoch 168: 180/307] 	 train loss: 0.045345 	 lr: 0.00021
[epoch 168: 200/307] 	 train loss: 0.053125 	 lr: 0.00021
[epoch 168: 220/307] 	 train loss: 0.054748 	 lr: 0.00021
[epoch 168: 240/307] 	 train loss: 0.125649 	 lr: 0.00021
[epoch 168: 260/307] 	 train loss: 0.069746 	 lr: 0.00021

val loss: 0.321652 	 acc: 0.913290

[epoch 168: 280/307] 	 train loss: 0.049223 	 lr: 0.00021
[epoch 168: 300/307] 	 train loss: 0.105110 	 lr: 0.00021
[epoch 169:   0/307] 	 train loss: 0.125774 	 lr: 0.00017
[epoch 169:  20/307] 	 train loss: 0.051546 	 lr: 0.00017
[epoch 169:  40/307] 	 train loss: 0.028636 	 lr: 0.00017
[epoch 169:  60/307] 	 train loss: 0.060336 	 lr: 0.00017
[epoch 169:  80/307] 	 train loss: 0.150762 	 lr: 0.00017
[epoch 169: 100/307] 	 train loss: 0.056677 	 lr: 0.00017
[epoch 169: 120/307] 	 train loss: 0.183216 	 lr: 0.00017

val loss: 0.320591 	 acc: 0.918963

[epoch 169: 140/307] 	 train loss: 0.053667 	 lr: 0.00017
[epoch 169: 160/307] 	 train loss: 0.046951 	 lr: 0.00017
[epoch 169: 180/307] 	 train loss: 0.395937 	 lr: 0.00017
[epoch 169: 200/307] 	 train loss: 0.112238 	 lr: 0.00017
[epoch 169: 220/307] 	 train loss: 0.161656 	 lr: 0.00017
[epoch 169: 240/307] 	 train loss: 0.283102 	 lr: 0.00017
[epoch 169: 260/307] 	 train loss: 0.164125 	 lr: 0.00017

val loss: 0.332391 	 acc: 0.917747

[epoch 169: 280/307] 	 train loss: 0.124806 	 lr: 0.00017
[epoch 169: 300/307] 	 train loss: 0.099591 	 lr: 0.00017
[epoch 170:   0/307] 	 train loss: 0.483746 	 lr: 0.00017
[epoch 170:  20/307] 	 train loss: 0.295364 	 lr: 0.00017
[epoch 170:  40/307] 	 train loss: 0.187362 	 lr: 0.00017
[epoch 170:  60/307] 	 train loss: 0.020219 	 lr: 0.00017
[epoch 170:  80/307] 	 train loss: 0.240087 	 lr: 0.00017
[epoch 170: 100/307] 	 train loss: 0.212957 	 lr: 0.00017
[epoch 170: 120/307] 	 train loss: 0.117868 	 lr: 0.00017

val loss: 0.307715 	 acc: 0.919773

[epoch 170: 140/307] 	 train loss: 0.281689 	 lr: 0.00017
[epoch 170: 160/307] 	 train loss: 0.126090 	 lr: 0.00017
[epoch 170: 180/307] 	 train loss: 0.017292 	 lr: 0.00017
[epoch 170: 200/307] 	 train loss: 0.350703 	 lr: 0.00017
[epoch 170: 220/307] 	 train loss: 0.078628 	 lr: 0.00017
[epoch 170: 240/307] 	 train loss: 0.189798 	 lr: 0.00017
[epoch 170: 260/307] 	 train loss: 0.053086 	 lr: 0.00017

val loss: 0.323737 	 acc: 0.918963

[epoch 170: 280/307] 	 train loss: 0.156941 	 lr: 0.00017
[epoch 170: 300/307] 	 train loss: 0.156137 	 lr: 0.00017
[epoch 171:   0/307] 	 train loss: 0.147131 	 lr: 0.00017
[epoch 171:  20/307] 	 train loss: 0.033167 	 lr: 0.00017
[epoch 171:  40/307] 	 train loss: 0.134710 	 lr: 0.00017
[epoch 171:  60/307] 	 train loss: 0.206142 	 lr: 0.00017
[epoch 171:  80/307] 	 train loss: 0.103121 	 lr: 0.00017
[epoch 171: 100/307] 	 train loss: 0.485040 	 lr: 0.00017

val loss: 0.327376 	 acc: 0.916532

[epoch 171: 120/307] 	 train loss: 0.120147 	 lr: 0.00017
[epoch 171: 140/307] 	 train loss: 0.199471 	 lr: 0.00017
[epoch 171: 160/307] 	 train loss: 0.040589 	 lr: 0.00017
[epoch 171: 180/307] 	 train loss: 0.144609 	 lr: 0.00017
[epoch 171: 200/307] 	 train loss: 0.116161 	 lr: 0.00017
[epoch 171: 220/307] 	 train loss: 0.080684 	 lr: 0.00017
[epoch 171: 240/307] 	 train loss: 0.264463 	 lr: 0.00017
[epoch 171: 260/307] 	 train loss: 0.097909 	 lr: 0.00017

val loss: 0.323437 	 acc: 0.916126

[epoch 171: 280/307] 	 train loss: 0.113026 	 lr: 0.00017
[epoch 171: 300/307] 	 train loss: 0.296694 	 lr: 0.00017
[epoch 172:   0/307] 	 train loss: 0.131348 	 lr: 0.00017
[epoch 172:  20/307] 	 train loss: 0.071582 	 lr: 0.00017
[epoch 172:  40/307] 	 train loss: 0.104536 	 lr: 0.00017
[epoch 172:  60/307] 	 train loss: 0.222560 	 lr: 0.00017
[epoch 172:  80/307] 	 train loss: 0.086211 	 lr: 0.00017
[epoch 172: 100/307] 	 train loss: 0.082920 	 lr: 0.00017

val loss: 0.333039 	 acc: 0.918963

[epoch 172: 120/307] 	 train loss: 0.167055 	 lr: 0.00017
[epoch 172: 140/307] 	 train loss: 0.202266 	 lr: 0.00017
[epoch 172: 160/307] 	 train loss: 0.219688 	 lr: 0.00017
[epoch 172: 180/307] 	 train loss: 0.066337 	 lr: 0.00017
[epoch 172: 200/307] 	 train loss: 0.040782 	 lr: 0.00017
[epoch 172: 220/307] 	 train loss: 0.038940 	 lr: 0.00017
[epoch 172: 240/307] 	 train loss: 0.058463 	 lr: 0.00017
[epoch 172: 260/307] 	 train loss: 0.038359 	 lr: 0.00017

val loss: 0.317807 	 acc: 0.921799

[epoch 172: 280/307] 	 train loss: 0.028972 	 lr: 0.00017
[epoch 172: 300/307] 	 train loss: 0.044355 	 lr: 0.00017
[epoch 173:   0/307] 	 train loss: 0.156171 	 lr: 0.00017
[epoch 173:  20/307] 	 train loss: 0.076659 	 lr: 0.00017
[epoch 173:  40/307] 	 train loss: 0.141608 	 lr: 0.00017
[epoch 173:  60/307] 	 train loss: 0.163224 	 lr: 0.00017
[epoch 173:  80/307] 	 train loss: 0.022515 	 lr: 0.00017
[epoch 173: 100/307] 	 train loss: 0.014724 	 lr: 0.00017

val loss: 0.325374 	 acc: 0.920178

[epoch 173: 120/307] 	 train loss: 0.100970 	 lr: 0.00017
[epoch 173: 140/307] 	 train loss: 0.056099 	 lr: 0.00017
[epoch 173: 160/307] 	 train loss: 0.322326 	 lr: 0.00017
[epoch 173: 180/307] 	 train loss: 0.040722 	 lr: 0.00017
[epoch 173: 200/307] 	 train loss: 0.485131 	 lr: 0.00017
[epoch 173: 220/307] 	 train loss: 0.097399 	 lr: 0.00017
[epoch 173: 240/307] 	 train loss: 0.060275 	 lr: 0.00017
[epoch 173: 260/307] 	 train loss: 0.042850 	 lr: 0.00017

val loss: 0.315336 	 acc: 0.919368

[epoch 173: 280/307] 	 train loss: 0.072000 	 lr: 0.00017
[epoch 173: 300/307] 	 train loss: 0.040529 	 lr: 0.00017
[epoch 174:   0/307] 	 train loss: 0.230159 	 lr: 0.00017
[epoch 174:  20/307] 	 train loss: 0.047697 	 lr: 0.00017
[epoch 174:  40/307] 	 train loss: 0.156101 	 lr: 0.00017
[epoch 174:  60/307] 	 train loss: 0.155060 	 lr: 0.00017
[epoch 174:  80/307] 	 train loss: 0.046534 	 lr: 0.00017
[epoch 174: 100/307] 	 train loss: 0.032862 	 lr: 0.00017

val loss: 0.323100 	 acc: 0.915316

[epoch 174: 120/307] 	 train loss: 0.160500 	 lr: 0.00017
[epoch 174: 140/307] 	 train loss: 0.147338 	 lr: 0.00017
[epoch 174: 160/307] 	 train loss: 0.212977 	 lr: 0.00017
[epoch 174: 180/307] 	 train loss: 0.016208 	 lr: 0.00017
[epoch 174: 200/307] 	 train loss: 0.006258 	 lr: 0.00017
[epoch 174: 220/307] 	 train loss: 0.065820 	 lr: 0.00017
[epoch 174: 240/307] 	 train loss: 0.011906 	 lr: 0.00017
[epoch 174: 260/307] 	 train loss: 0.194422 	 lr: 0.00017

val loss: 0.321156 	 acc: 0.914506

[epoch 174: 280/307] 	 train loss: 0.013074 	 lr: 0.00017
[epoch 174: 300/307] 	 train loss: 0.058490 	 lr: 0.00017
[epoch 175:   0/307] 	 train loss: 0.060432 	 lr: 0.00017
[epoch 175:  20/307] 	 train loss: 0.093302 	 lr: 0.00017
[epoch 175:  40/307] 	 train loss: 0.034337 	 lr: 0.00017
[epoch 175:  60/307] 	 train loss: 0.280975 	 lr: 0.00017
[epoch 175:  80/307] 	 train loss: 0.054041 	 lr: 0.00017
[epoch 175: 100/307] 	 train loss: 0.223329 	 lr: 0.00017

val loss: 0.340067 	 acc: 0.909238

[epoch 175: 120/307] 	 train loss: 0.175641 	 lr: 0.00017
[epoch 175: 140/307] 	 train loss: 0.157729 	 lr: 0.00017
[epoch 175: 160/307] 	 train loss: 0.235935 	 lr: 0.00017
[epoch 175: 180/307] 	 train loss: 0.153010 	 lr: 0.00017
[epoch 175: 200/307] 	 train loss: 0.021063 	 lr: 0.00017
[epoch 175: 220/307] 	 train loss: 0.162488 	 lr: 0.00017
[epoch 175: 240/307] 	 train loss: 0.216458 	 lr: 0.00017
[epoch 175: 260/307] 	 train loss: 0.154086 	 lr: 0.00017

val loss: 0.346887 	 acc: 0.910859

[epoch 175: 280/307] 	 train loss: 0.126148 	 lr: 0.00017
[epoch 175: 300/307] 	 train loss: 0.081066 	 lr: 0.00017
[epoch 176:   0/307] 	 train loss: 0.022741 	 lr: 0.00017
[epoch 176:  20/307] 	 train loss: 0.019358 	 lr: 0.00017
[epoch 176:  40/307] 	 train loss: 0.186329 	 lr: 0.00017
[epoch 176:  60/307] 	 train loss: 0.135045 	 lr: 0.00017
[epoch 176:  80/307] 	 train loss: 0.039245 	 lr: 0.00017
[epoch 176: 100/307] 	 train loss: 0.063435 	 lr: 0.00017

val loss: 0.337453 	 acc: 0.913695

[epoch 176: 120/307] 	 train loss: 0.063582 	 lr: 0.00017
[epoch 176: 140/307] 	 train loss: 0.139530 	 lr: 0.00017
[epoch 176: 160/307] 	 train loss: 0.047028 	 lr: 0.00017
[epoch 176: 180/307] 	 train loss: 0.044404 	 lr: 0.00017
[epoch 176: 200/307] 	 train loss: 0.017686 	 lr: 0.00017
[epoch 176: 220/307] 	 train loss: 0.024488 	 lr: 0.00017
[epoch 176: 240/307] 	 train loss: 0.051841 	 lr: 0.00017
[epoch 176: 260/307] 	 train loss: 0.028658 	 lr: 0.00017

val loss: 0.323073 	 acc: 0.912885

[epoch 176: 280/307] 	 train loss: 0.258292 	 lr: 0.00017
[epoch 176: 300/307] 	 train loss: 0.189229 	 lr: 0.00017
[epoch 177:   0/307] 	 train loss: 0.038071 	 lr: 0.00017
[epoch 177:  20/307] 	 train loss: 0.071139 	 lr: 0.00017
[epoch 177:  40/307] 	 train loss: 0.078358 	 lr: 0.00017
[epoch 177:  60/307] 	 train loss: 0.063619 	 lr: 0.00017
[epoch 177:  80/307] 	 train loss: 0.062518 	 lr: 0.00017
[epoch 177: 100/307] 	 train loss: 0.250395 	 lr: 0.00017

val loss: 0.315075 	 acc: 0.918558

[epoch 177: 120/307] 	 train loss: 0.165841 	 lr: 0.00017
[epoch 177: 140/307] 	 train loss: 0.045971 	 lr: 0.00017
[epoch 177: 160/307] 	 train loss: 0.083209 	 lr: 0.00017
[epoch 177: 180/307] 	 train loss: 0.130162 	 lr: 0.00017
[epoch 177: 200/307] 	 train loss: 0.044766 	 lr: 0.00017
[epoch 177: 220/307] 	 train loss: 0.091495 	 lr: 0.00017
[epoch 177: 240/307] 	 train loss: 0.015744 	 lr: 0.00017

val loss: 0.322217 	 acc: 0.917747

[epoch 177: 260/307] 	 train loss: 0.182312 	 lr: 0.00017
[epoch 177: 280/307] 	 train loss: 0.040469 	 lr: 0.00017
[epoch 177: 300/307] 	 train loss: 0.074403 	 lr: 0.00017
[epoch 178:   0/307] 	 train loss: 0.076262 	 lr: 0.00017
[epoch 178:  20/307] 	 train loss: 0.112894 	 lr: 0.00017
[epoch 178:  40/307] 	 train loss: 0.163110 	 lr: 0.00017
[epoch 178:  60/307] 	 train loss: 0.030942 	 lr: 0.00017
[epoch 178:  80/307] 	 train loss: 0.151635 	 lr: 0.00017
[epoch 178: 100/307] 	 train loss: 0.073797 	 lr: 0.00017

val loss: 0.324088 	 acc: 0.917342

[epoch 178: 120/307] 	 train loss: 0.090460 	 lr: 0.00017
[epoch 178: 140/307] 	 train loss: 0.111380 	 lr: 0.00017
[epoch 178: 160/307] 	 train loss: 0.154291 	 lr: 0.00017
[epoch 178: 180/307] 	 train loss: 0.055318 	 lr: 0.00017
[epoch 178: 200/307] 	 train loss: 0.090563 	 lr: 0.00017
[epoch 178: 220/307] 	 train loss: 0.073156 	 lr: 0.00017
[epoch 178: 240/307] 	 train loss: 0.147805 	 lr: 0.00017

val loss: 0.332848 	 acc: 0.918558

[epoch 178: 260/307] 	 train loss: 0.054269 	 lr: 0.00017
[epoch 178: 280/307] 	 train loss: 0.052429 	 lr: 0.00017
[epoch 178: 300/307] 	 train loss: 0.010129 	 lr: 0.00017
[epoch 179:   0/307] 	 train loss: 0.016606 	 lr: 0.00017
[epoch 179:  20/307] 	 train loss: 0.105958 	 lr: 0.00017
[epoch 179:  40/307] 	 train loss: 0.150018 	 lr: 0.00017
[epoch 179:  60/307] 	 train loss: 0.069002 	 lr: 0.00017
[epoch 179:  80/307] 	 train loss: 0.018026 	 lr: 0.00017
[epoch 179: 100/307] 	 train loss: 0.232345 	 lr: 0.00017

val loss: 0.327960 	 acc: 0.917747

[epoch 179: 120/307] 	 train loss: 0.126228 	 lr: 0.00017
[epoch 179: 140/307] 	 train loss: 0.046535 	 lr: 0.00017
[epoch 179: 160/307] 	 train loss: 0.238576 	 lr: 0.00017
[epoch 179: 180/307] 	 train loss: 0.023867 	 lr: 0.00017
[epoch 179: 200/307] 	 train loss: 0.362803 	 lr: 0.00017
[epoch 179: 220/307] 	 train loss: 0.210235 	 lr: 0.00017
[epoch 179: 240/307] 	 train loss: 0.047780 	 lr: 0.00017

val loss: 0.331600 	 acc: 0.915721

[epoch 179: 260/307] 	 train loss: 0.080234 	 lr: 0.00017
[epoch 179: 280/307] 	 train loss: 0.053573 	 lr: 0.00017
[epoch 179: 300/307] 	 train loss: 0.114107 	 lr: 0.00017
[epoch 180:   0/307] 	 train loss: 0.147079 	 lr: 0.00017
[epoch 180:  20/307] 	 train loss: 0.071885 	 lr: 0.00017
[epoch 180:  40/307] 	 train loss: 0.258531 	 lr: 0.00017
[epoch 180:  60/307] 	 train loss: 0.047937 	 lr: 0.00017
[epoch 180:  80/307] 	 train loss: 0.640935 	 lr: 0.00017
[epoch 180: 100/307] 	 train loss: 0.065219 	 lr: 0.00017

val loss: 0.334416 	 acc: 0.918963

[epoch 180: 120/307] 	 train loss: 0.042479 	 lr: 0.00017
[epoch 180: 140/307] 	 train loss: 0.101659 	 lr: 0.00017
[epoch 180: 160/307] 	 train loss: 0.145665 	 lr: 0.00017
[epoch 180: 180/307] 	 train loss: 0.150876 	 lr: 0.00017
[epoch 180: 200/307] 	 train loss: 0.092280 	 lr: 0.00017
[epoch 180: 220/307] 	 train loss: 0.052816 	 lr: 0.00017
[epoch 180: 240/307] 	 train loss: 0.075543 	 lr: 0.00017

val loss: 0.327204 	 acc: 0.917747

[epoch 180: 260/307] 	 train loss: 0.058816 	 lr: 0.00017
[epoch 180: 280/307] 	 train loss: 0.143274 	 lr: 0.00017
[epoch 180: 300/307] 	 train loss: 0.273726 	 lr: 0.00017
[epoch 181:   0/307] 	 train loss: 0.038205 	 lr: 0.00017
[epoch 181:  20/307] 	 train loss: 0.056720 	 lr: 0.00017
[epoch 181:  40/307] 	 train loss: 0.110898 	 lr: 0.00017
[epoch 181:  60/307] 	 train loss: 0.125964 	 lr: 0.00017
[epoch 181:  80/307] 	 train loss: 0.248583 	 lr: 0.00017

val loss: 0.332628 	 acc: 0.915721

[epoch 181: 100/307] 	 train loss: 0.341462 	 lr: 0.00017
[epoch 181: 120/307] 	 train loss: 0.082485 	 lr: 0.00017
[epoch 181: 140/307] 	 train loss: 0.145642 	 lr: 0.00017
[epoch 181: 160/307] 	 train loss: 0.117982 	 lr: 0.00017
[epoch 181: 180/307] 	 train loss: 0.075156 	 lr: 0.00017
[epoch 181: 200/307] 	 train loss: 0.071608 	 lr: 0.00017
[epoch 181: 220/307] 	 train loss: 0.279410 	 lr: 0.00017
[epoch 181: 240/307] 	 train loss: 0.083343 	 lr: 0.00017

val loss: 0.335000 	 acc: 0.917747

[epoch 181: 260/307] 	 train loss: 0.154291 	 lr: 0.00017
[epoch 181: 280/307] 	 train loss: 0.359314 	 lr: 0.00017
[epoch 181: 300/307] 	 train loss: 0.079826 	 lr: 0.00017
[epoch 182:   0/307] 	 train loss: 0.019936 	 lr: 0.00017
[epoch 182:  20/307] 	 train loss: 0.073684 	 lr: 0.00017
[epoch 182:  40/307] 	 train loss: 0.198279 	 lr: 0.00017
[epoch 182:  60/307] 	 train loss: 0.228719 	 lr: 0.00017
[epoch 182:  80/307] 	 train loss: 0.219449 	 lr: 0.00017

val loss: 0.333356 	 acc: 0.917342

[epoch 182: 100/307] 	 train loss: 0.066448 	 lr: 0.00017
[epoch 182: 120/307] 	 train loss: 0.131332 	 lr: 0.00017
[epoch 182: 140/307] 	 train loss: 0.156003 	 lr: 0.00017
[epoch 182: 160/307] 	 train loss: 0.144128 	 lr: 0.00017
[epoch 182: 180/307] 	 train loss: 0.050249 	 lr: 0.00017
[epoch 182: 200/307] 	 train loss: 0.061020 	 lr: 0.00017
[epoch 182: 220/307] 	 train loss: 0.037211 	 lr: 0.00017
[epoch 182: 240/307] 	 train loss: 0.086985 	 lr: 0.00017

val loss: 0.338140 	 acc: 0.916937

[epoch 182: 260/307] 	 train loss: 0.004390 	 lr: 0.00017
[epoch 182: 280/307] 	 train loss: 0.137859 	 lr: 0.00017
[epoch 182: 300/307] 	 train loss: 0.033547 	 lr: 0.00017
[epoch 183:   0/307] 	 train loss: 0.072815 	 lr: 0.00017
[epoch 183:  20/307] 	 train loss: 0.029440 	 lr: 0.00017
[epoch 183:  40/307] 	 train loss: 0.156819 	 lr: 0.00017
[epoch 183:  60/307] 	 train loss: 0.172529 	 lr: 0.00017
[epoch 183:  80/307] 	 train loss: 0.116770 	 lr: 0.00017

val loss: 0.328165 	 acc: 0.917342

[epoch 183: 100/307] 	 train loss: 0.181843 	 lr: 0.00017
[epoch 183: 120/307] 	 train loss: 0.072790 	 lr: 0.00017
[epoch 183: 140/307] 	 train loss: 0.185244 	 lr: 0.00017
[epoch 183: 160/307] 	 train loss: 0.136244 	 lr: 0.00017
[epoch 183: 180/307] 	 train loss: 0.054557 	 lr: 0.00017
[epoch 183: 200/307] 	 train loss: 0.264657 	 lr: 0.00017
[epoch 183: 220/307] 	 train loss: 0.035310 	 lr: 0.00017
[epoch 183: 240/307] 	 train loss: 0.133986 	 lr: 0.00017

val loss: 0.334284 	 acc: 0.912480

[epoch 183: 260/307] 	 train loss: 0.085339 	 lr: 0.00017
[epoch 183: 280/307] 	 train loss: 0.177049 	 lr: 0.00017
[epoch 183: 300/307] 	 train loss: 0.248711 	 lr: 0.00017
[epoch 184:   0/307] 	 train loss: 0.079678 	 lr: 0.00017
[epoch 184:  20/307] 	 train loss: 0.038757 	 lr: 0.00017
[epoch 184:  40/307] 	 train loss: 0.183971 	 lr: 0.00017
[epoch 184:  60/307] 	 train loss: 0.176932 	 lr: 0.00017
[epoch 184:  80/307] 	 train loss: 0.167986 	 lr: 0.00017

val loss: 0.333110 	 acc: 0.912885

[epoch 184: 100/307] 	 train loss: 0.050256 	 lr: 0.00017
[epoch 184: 120/307] 	 train loss: 0.059897 	 lr: 0.00017
[epoch 184: 140/307] 	 train loss: 0.258842 	 lr: 0.00017
[epoch 184: 160/307] 	 train loss: 0.117406 	 lr: 0.00017
[epoch 184: 180/307] 	 train loss: 0.072710 	 lr: 0.00017
[epoch 184: 200/307] 	 train loss: 0.020206 	 lr: 0.00017
[epoch 184: 220/307] 	 train loss: 0.067214 	 lr: 0.00017
[epoch 184: 240/307] 	 train loss: 0.275632 	 lr: 0.00017

val loss: 0.325678 	 acc: 0.915721

[epoch 184: 260/307] 	 train loss: 0.097588 	 lr: 0.00017
[epoch 184: 280/307] 	 train loss: 0.089757 	 lr: 0.00017
[epoch 184: 300/307] 	 train loss: 0.091995 	 lr: 0.00017
[epoch 185:   0/307] 	 train loss: 0.107219 	 lr: 0.00017
[epoch 185:  20/307] 	 train loss: 0.057422 	 lr: 0.00017
[epoch 185:  40/307] 	 train loss: 0.323692 	 lr: 0.00017
[epoch 185:  60/307] 	 train loss: 0.004755 	 lr: 0.00017
[epoch 185:  80/307] 	 train loss: 0.240427 	 lr: 0.00017

val loss: 0.330975 	 acc: 0.914506

[epoch 185: 100/307] 	 train loss: 0.227047 	 lr: 0.00017
[epoch 185: 120/307] 	 train loss: 0.093775 	 lr: 0.00017
[epoch 185: 140/307] 	 train loss: 0.020764 	 lr: 0.00017
[epoch 185: 160/307] 	 train loss: 0.043442 	 lr: 0.00017
[epoch 185: 180/307] 	 train loss: 0.088916 	 lr: 0.00017
[epoch 185: 200/307] 	 train loss: 0.100452 	 lr: 0.00017
[epoch 185: 220/307] 	 train loss: 0.112598 	 lr: 0.00017
[epoch 185: 240/307] 	 train loss: 0.131063 	 lr: 0.00017

val loss: 0.342485 	 acc: 0.913695

[epoch 185: 260/307] 	 train loss: 0.120974 	 lr: 0.00017
[epoch 185: 280/307] 	 train loss: 0.069537 	 lr: 0.00017
[epoch 185: 300/307] 	 train loss: 0.052755 	 lr: 0.00017
[epoch 186:   0/307] 	 train loss: 0.289838 	 lr: 0.00017
[epoch 186:  20/307] 	 train loss: 0.083028 	 lr: 0.00017
[epoch 186:  40/307] 	 train loss: 0.002552 	 lr: 0.00017
[epoch 186:  60/307] 	 train loss: 0.052207 	 lr: 0.00017
[epoch 186:  80/307] 	 train loss: 0.096195 	 lr: 0.00017

val loss: 0.341618 	 acc: 0.912480

[epoch 186: 100/307] 	 train loss: 0.111296 	 lr: 0.00017
[epoch 186: 120/307] 	 train loss: 0.228582 	 lr: 0.00017
[epoch 186: 140/307] 	 train loss: 0.205721 	 lr: 0.00017
[epoch 186: 160/307] 	 train loss: 0.079447 	 lr: 0.00017
[epoch 186: 180/307] 	 train loss: 0.144286 	 lr: 0.00017
[epoch 186: 200/307] 	 train loss: 0.054606 	 lr: 0.00017
[epoch 186: 220/307] 	 train loss: 0.050630 	 lr: 0.00017
[epoch 186: 240/307] 	 train loss: 0.146319 	 lr: 0.00017

val loss: 0.346447 	 acc: 0.911264

[epoch 186: 260/307] 	 train loss: 0.026790 	 lr: 0.00017
[epoch 186: 280/307] 	 train loss: 0.070707 	 lr: 0.00017
[epoch 186: 300/307] 	 train loss: 0.020512 	 lr: 0.00017
[epoch 187:   0/307] 	 train loss: 0.086716 	 lr: 0.00017
[epoch 187:  20/307] 	 train loss: 0.078652 	 lr: 0.00017
[epoch 187:  40/307] 	 train loss: 0.153283 	 lr: 0.00017
[epoch 187:  60/307] 	 train loss: 0.135854 	 lr: 0.00017
[epoch 187:  80/307] 	 train loss: 0.261667 	 lr: 0.00017

val loss: 0.346249 	 acc: 0.911669

[epoch 187: 100/307] 	 train loss: 0.218410 	 lr: 0.00017
[epoch 187: 120/307] 	 train loss: 0.096236 	 lr: 0.00017
[epoch 187: 140/307] 	 train loss: 0.083500 	 lr: 0.00017
[epoch 187: 160/307] 	 train loss: 0.034334 	 lr: 0.00017
[epoch 187: 180/307] 	 train loss: 0.231793 	 lr: 0.00017
[epoch 187: 200/307] 	 train loss: 0.155830 	 lr: 0.00017
[epoch 187: 220/307] 	 train loss: 0.128085 	 lr: 0.00017

val loss: 0.355567 	 acc: 0.913290

[epoch 187: 240/307] 	 train loss: 0.041130 	 lr: 0.00017
[epoch 187: 260/307] 	 train loss: 0.125122 	 lr: 0.00017
[epoch 187: 280/307] 	 train loss: 0.168339 	 lr: 0.00017
[epoch 187: 300/307] 	 train loss: 0.038973 	 lr: 0.00017
[epoch 188:   0/307] 	 train loss: 0.040673 	 lr: 0.00017
[epoch 188:  20/307] 	 train loss: 0.066072 	 lr: 0.00017
[epoch 188:  40/307] 	 train loss: 0.129415 	 lr: 0.00017
[epoch 188:  60/307] 	 train loss: 0.064232 	 lr: 0.00017
[epoch 188:  80/307] 	 train loss: 0.111642 	 lr: 0.00017

val loss: 0.344271 	 acc: 0.911669

[epoch 188: 100/307] 	 train loss: 0.096186 	 lr: 0.00017
[epoch 188: 120/307] 	 train loss: 0.045988 	 lr: 0.00017
[epoch 188: 140/307] 	 train loss: 0.118050 	 lr: 0.00017
[epoch 188: 160/307] 	 train loss: 0.069105 	 lr: 0.00017
[epoch 188: 180/307] 	 train loss: 0.358964 	 lr: 0.00017
[epoch 188: 200/307] 	 train loss: 0.035032 	 lr: 0.00017
[epoch 188: 220/307] 	 train loss: 0.136943 	 lr: 0.00017

val loss: 0.366248 	 acc: 0.910859

[epoch 188: 240/307] 	 train loss: 0.036920 	 lr: 0.00017
[epoch 188: 260/307] 	 train loss: 0.198989 	 lr: 0.00017
[epoch 188: 280/307] 	 train loss: 0.034960 	 lr: 0.00017
[epoch 188: 300/307] 	 train loss: 0.193169 	 lr: 0.00017
[epoch 189:   0/307] 	 train loss: 0.060588 	 lr: 0.00017
[epoch 189:  20/307] 	 train loss: 0.252819 	 lr: 0.00017
[epoch 189:  40/307] 	 train loss: 0.106598 	 lr: 0.00017
[epoch 189:  60/307] 	 train loss: 0.317393 	 lr: 0.00017
[epoch 189:  80/307] 	 train loss: 0.051569 	 lr: 0.00017

val loss: 0.328048 	 acc: 0.917747

[epoch 189: 100/307] 	 train loss: 0.056033 	 lr: 0.00017
[epoch 189: 120/307] 	 train loss: 0.273340 	 lr: 0.00017
[epoch 189: 140/307] 	 train loss: 0.100937 	 lr: 0.00017
[epoch 189: 160/307] 	 train loss: 0.062584 	 lr: 0.00017
[epoch 189: 180/307] 	 train loss: 0.026570 	 lr: 0.00017
[epoch 189: 200/307] 	 train loss: 0.091163 	 lr: 0.00017
[epoch 189: 220/307] 	 train loss: 0.148471 	 lr: 0.00017

val loss: 0.321086 	 acc: 0.917747

[epoch 189: 240/307] 	 train loss: 0.186916 	 lr: 0.00017
[epoch 189: 260/307] 	 train loss: 0.128858 	 lr: 0.00017
[epoch 189: 280/307] 	 train loss: 0.088271 	 lr: 0.00017
[epoch 189: 300/307] 	 train loss: 0.165833 	 lr: 0.00017
[epoch 190:   0/307] 	 train loss: 0.300283 	 lr: 0.00013
[epoch 190:  20/307] 	 train loss: 0.238063 	 lr: 0.00013
[epoch 190:  40/307] 	 train loss: 0.166565 	 lr: 0.00013
[epoch 190:  60/307] 	 train loss: 0.180934 	 lr: 0.00013
[epoch 190:  80/307] 	 train loss: 0.013797 	 lr: 0.00013

val loss: 0.318770 	 acc: 0.916532

[epoch 190: 100/307] 	 train loss: 0.126794 	 lr: 0.00013
[epoch 190: 120/307] 	 train loss: 0.085751 	 lr: 0.00013
[epoch 190: 140/307] 	 train loss: 0.198495 	 lr: 0.00013
[epoch 190: 160/307] 	 train loss: 0.101263 	 lr: 0.00013
[epoch 190: 180/307] 	 train loss: 0.063072 	 lr: 0.00013
[epoch 190: 200/307] 	 train loss: 0.009565 	 lr: 0.00013
[epoch 190: 220/307] 	 train loss: 0.261892 	 lr: 0.00013

val loss: 0.330776 	 acc: 0.915316

[epoch 190: 240/307] 	 train loss: 0.133328 	 lr: 0.00013
[epoch 190: 260/307] 	 train loss: 0.277303 	 lr: 0.00013
[epoch 190: 280/307] 	 train loss: 0.182228 	 lr: 0.00013
[epoch 190: 300/307] 	 train loss: 0.185058 	 lr: 0.00013
[epoch 191:   0/307] 	 train loss: 0.153253 	 lr: 0.00013
[epoch 191:  20/307] 	 train loss: 0.252124 	 lr: 0.00013
[epoch 191:  40/307] 	 train loss: 0.239864 	 lr: 0.00013
[epoch 191:  60/307] 	 train loss: 0.189959 	 lr: 0.00013

val loss: 0.316692 	 acc: 0.917342

[epoch 191:  80/307] 	 train loss: 0.022695 	 lr: 0.00013
[epoch 191: 100/307] 	 train loss: 0.011364 	 lr: 0.00013
[epoch 191: 120/307] 	 train loss: 0.113813 	 lr: 0.00013
[epoch 191: 140/307] 	 train loss: 0.034174 	 lr: 0.00013
[epoch 191: 160/307] 	 train loss: 0.121161 	 lr: 0.00013
[epoch 191: 180/307] 	 train loss: 0.118091 	 lr: 0.00013
[epoch 191: 200/307] 	 train loss: 0.042363 	 lr: 0.00013
[epoch 191: 220/307] 	 train loss: 0.051168 	 lr: 0.00013

val loss: 0.314950 	 acc: 0.918558

[epoch 191: 240/307] 	 train loss: 0.034358 	 lr: 0.00013
[epoch 191: 260/307] 	 train loss: 0.242658 	 lr: 0.00013
[epoch 191: 280/307] 	 train loss: 0.111964 	 lr: 0.00013
[epoch 191: 300/307] 	 train loss: 0.123903 	 lr: 0.00013
[epoch 192:   0/307] 	 train loss: 0.205289 	 lr: 0.00013
[epoch 192:  20/307] 	 train loss: 0.036830 	 lr: 0.00013
[epoch 192:  40/307] 	 train loss: 0.015146 	 lr: 0.00013
[epoch 192:  60/307] 	 train loss: 0.177192 	 lr: 0.00013

val loss: 0.310462 	 acc: 0.916532

[epoch 192:  80/307] 	 train loss: 0.043506 	 lr: 0.00013
[epoch 192: 100/307] 	 train loss: 0.130797 	 lr: 0.00013
[epoch 192: 120/307] 	 train loss: 0.032112 	 lr: 0.00013
[epoch 192: 140/307] 	 train loss: 0.012055 	 lr: 0.00013
[epoch 192: 160/307] 	 train loss: 0.020763 	 lr: 0.00013
[epoch 192: 180/307] 	 train loss: 0.039650 	 lr: 0.00013
[epoch 192: 200/307] 	 train loss: 0.148673 	 lr: 0.00013
[epoch 192: 220/307] 	 train loss: 0.241601 	 lr: 0.00013

val loss: 0.324817 	 acc: 0.917342

[epoch 192: 240/307] 	 train loss: 0.032106 	 lr: 0.00013
[epoch 192: 260/307] 	 train loss: 0.033154 	 lr: 0.00013
[epoch 192: 280/307] 	 train loss: 0.115483 	 lr: 0.00013
[epoch 192: 300/307] 	 train loss: 0.061110 	 lr: 0.00013
[epoch 193:   0/307] 	 train loss: 0.185275 	 lr: 0.00013
[epoch 193:  20/307] 	 train loss: 0.168013 	 lr: 0.00013
[epoch 193:  40/307] 	 train loss: 0.086844 	 lr: 0.00013
[epoch 193:  60/307] 	 train loss: 0.135238 	 lr: 0.00013

val loss: 0.319276 	 acc: 0.915721

[epoch 193:  80/307] 	 train loss: 0.085061 	 lr: 0.00013
[epoch 193: 100/307] 	 train loss: 0.138008 	 lr: 0.00013
[epoch 193: 120/307] 	 train loss: 0.018976 	 lr: 0.00013
[epoch 193: 140/307] 	 train loss: 0.191339 	 lr: 0.00013
[epoch 193: 160/307] 	 train loss: 0.064775 	 lr: 0.00013
[epoch 193: 180/307] 	 train loss: 0.013530 	 lr: 0.00013
[epoch 193: 200/307] 	 train loss: 0.109905 	 lr: 0.00013
[epoch 193: 220/307] 	 train loss: 0.037215 	 lr: 0.00013

val loss: 0.323529 	 acc: 0.915721

[epoch 193: 240/307] 	 train loss: 0.123403 	 lr: 0.00013
[epoch 193: 260/307] 	 train loss: 0.051522 	 lr: 0.00013
[epoch 193: 280/307] 	 train loss: 0.042716 	 lr: 0.00013
[epoch 193: 300/307] 	 train loss: 0.198756 	 lr: 0.00013
[epoch 194:   0/307] 	 train loss: 0.209306 	 lr: 0.00013
[epoch 194:  20/307] 	 train loss: 0.103385 	 lr: 0.00013
[epoch 194:  40/307] 	 train loss: 0.146025 	 lr: 0.00013
[epoch 194:  60/307] 	 train loss: 0.053293 	 lr: 0.00013

val loss: 0.335995 	 acc: 0.915316

[epoch 194:  80/307] 	 train loss: 0.017542 	 lr: 0.00013
[epoch 194: 100/307] 	 train loss: 0.090341 	 lr: 0.00013
[epoch 194: 120/307] 	 train loss: 0.050011 	 lr: 0.00013
[epoch 194: 140/307] 	 train loss: 0.022649 	 lr: 0.00013
[epoch 194: 160/307] 	 train loss: 0.104516 	 lr: 0.00013
[epoch 194: 180/307] 	 train loss: 0.032504 	 lr: 0.00013
[epoch 194: 200/307] 	 train loss: 0.040216 	 lr: 0.00013
[epoch 194: 220/307] 	 train loss: 0.036229 	 lr: 0.00013

val loss: 0.323586 	 acc: 0.920178

[epoch 194: 240/307] 	 train loss: 0.053693 	 lr: 0.00013
[epoch 194: 260/307] 	 train loss: 0.168413 	 lr: 0.00013
[epoch 194: 280/307] 	 train loss: 0.208388 	 lr: 0.00013
[epoch 194: 300/307] 	 train loss: 0.242528 	 lr: 0.00013
[epoch 195:   0/307] 	 train loss: 0.124714 	 lr: 0.00013
[epoch 195:  20/307] 	 train loss: 0.023539 	 lr: 0.00013
[epoch 195:  40/307] 	 train loss: 0.090874 	 lr: 0.00013
[epoch 195:  60/307] 	 train loss: 0.277182 	 lr: 0.00013

val loss: 0.338811 	 acc: 0.912075

[epoch 195:  80/307] 	 train loss: 0.068429 	 lr: 0.00013
[epoch 195: 100/307] 	 train loss: 0.038262 	 lr: 0.00013
[epoch 195: 120/307] 	 train loss: 0.032084 	 lr: 0.00013
[epoch 195: 140/307] 	 train loss: 0.052356 	 lr: 0.00013
[epoch 195: 160/307] 	 train loss: 0.044000 	 lr: 0.00013
[epoch 195: 180/307] 	 train loss: 0.119279 	 lr: 0.00013
[epoch 195: 200/307] 	 train loss: 0.109327 	 lr: 0.00013
[epoch 195: 220/307] 	 train loss: 0.225225 	 lr: 0.00013

val loss: 0.326565 	 acc: 0.914506

[epoch 195: 240/307] 	 train loss: 0.128529 	 lr: 0.00013
[epoch 195: 260/307] 	 train loss: 0.087929 	 lr: 0.00013
[epoch 195: 280/307] 	 train loss: 0.077898 	 lr: 0.00013
[epoch 195: 300/307] 	 train loss: 0.084962 	 lr: 0.00013
[epoch 196:   0/307] 	 train loss: 0.042544 	 lr: 0.00013
[epoch 196:  20/307] 	 train loss: 0.177572 	 lr: 0.00013
[epoch 196:  40/307] 	 train loss: 0.051292 	 lr: 0.00013
[epoch 196:  60/307] 	 train loss: 0.097133 	 lr: 0.00013

val loss: 0.320800 	 acc: 0.918963

[epoch 196:  80/307] 	 train loss: 0.290208 	 lr: 0.00013
[epoch 196: 100/307] 	 train loss: 0.087260 	 lr: 0.00013
[epoch 196: 120/307] 	 train loss: 0.065269 	 lr: 0.00013
[epoch 196: 140/307] 	 train loss: 0.141755 	 lr: 0.00013
[epoch 196: 160/307] 	 train loss: 0.125784 	 lr: 0.00013
[epoch 196: 180/307] 	 train loss: 0.072018 	 lr: 0.00013
[epoch 196: 200/307] 	 train loss: 0.117047 	 lr: 0.00013
[epoch 196: 220/307] 	 train loss: 0.303159 	 lr: 0.00013

val loss: 0.334949 	 acc: 0.917342

[epoch 196: 240/307] 	 train loss: 0.183540 	 lr: 0.00013
[epoch 196: 260/307] 	 train loss: 0.126732 	 lr: 0.00013
[epoch 196: 280/307] 	 train loss: 0.005982 	 lr: 0.00013
[epoch 196: 300/307] 	 train loss: 0.100705 	 lr: 0.00013
[epoch 197:   0/307] 	 train loss: 0.050150 	 lr: 0.00013
[epoch 197:  20/307] 	 train loss: 0.025537 	 lr: 0.00013
[epoch 197:  40/307] 	 train loss: 0.038353 	 lr: 0.00013
[epoch 197:  60/307] 	 train loss: 0.112753 	 lr: 0.00013

val loss: 0.329245 	 acc: 0.914911

[epoch 197:  80/307] 	 train loss: 0.020304 	 lr: 0.00013
[epoch 197: 100/307] 	 train loss: 0.139846 	 lr: 0.00013
[epoch 197: 120/307] 	 train loss: 0.067676 	 lr: 0.00013
[epoch 197: 140/307] 	 train loss: 0.083342 	 lr: 0.00013
[epoch 197: 160/307] 	 train loss: 0.222180 	 lr: 0.00013
[epoch 197: 180/307] 	 train loss: 0.077749 	 lr: 0.00013
[epoch 197: 200/307] 	 train loss: 0.059515 	 lr: 0.00013

val loss: 0.335059 	 acc: 0.912885

[epoch 197: 220/307] 	 train loss: 0.238976 	 lr: 0.00013
[epoch 197: 240/307] 	 train loss: 0.005962 	 lr: 0.00013
[epoch 197: 260/307] 	 train loss: 0.048916 	 lr: 0.00013
[epoch 197: 280/307] 	 train loss: 0.053294 	 lr: 0.00013
[epoch 197: 300/307] 	 train loss: 0.079049 	 lr: 0.00013
[epoch 198:   0/307] 	 train loss: 0.069737 	 lr: 0.00013
[epoch 198:  20/307] 	 train loss: 0.048465 	 lr: 0.00013
[epoch 198:  40/307] 	 train loss: 0.141033 	 lr: 0.00013
[epoch 198:  60/307] 	 train loss: 0.132279 	 lr: 0.00013

val loss: 0.323023 	 acc: 0.915316

[epoch 198:  80/307] 	 train loss: 0.280027 	 lr: 0.00013
[epoch 198: 100/307] 	 train loss: 0.184772 	 lr: 0.00013
[epoch 198: 120/307] 	 train loss: 0.094554 	 lr: 0.00013
[epoch 198: 140/307] 	 train loss: 0.111956 	 lr: 0.00013
[epoch 198: 160/307] 	 train loss: 0.086738 	 lr: 0.00013
[epoch 198: 180/307] 	 train loss: 0.144778 	 lr: 0.00013
[epoch 198: 200/307] 	 train loss: 0.184105 	 lr: 0.00013

val loss: 0.334747 	 acc: 0.916937

[epoch 198: 220/307] 	 train loss: 0.044842 	 lr: 0.00013
[epoch 198: 240/307] 	 train loss: 0.295526 	 lr: 0.00013
[epoch 198: 260/307] 	 train loss: 0.027786 	 lr: 0.00013
[epoch 198: 280/307] 	 train loss: 0.206694 	 lr: 0.00013
[epoch 198: 300/307] 	 train loss: 0.106383 	 lr: 0.00013
[epoch 199:   0/307] 	 train loss: 0.141945 	 lr: 0.00013
[epoch 199:  20/307] 	 train loss: 0.022951 	 lr: 0.00013
[epoch 199:  40/307] 	 train loss: 0.169675 	 lr: 0.00013
[epoch 199:  60/307] 	 train loss: 0.027472 	 lr: 0.00013

val loss: 0.336705 	 acc: 0.911669

[epoch 199:  80/307] 	 train loss: 0.199291 	 lr: 0.00013
[epoch 199: 100/307] 	 train loss: 0.104755 	 lr: 0.00013
[epoch 199: 120/307] 	 train loss: 0.045944 	 lr: 0.00013
[epoch 199: 140/307] 	 train loss: 0.040395 	 lr: 0.00013
[epoch 199: 160/307] 	 train loss: 0.062851 	 lr: 0.00013
[epoch 199: 180/307] 	 train loss: 0.055579 	 lr: 0.00013
[epoch 199: 200/307] 	 train loss: 0.056184 	 lr: 0.00013

val loss: 0.334245 	 acc: 0.913290

[epoch 199: 220/307] 	 train loss: 0.413986 	 lr: 0.00013
[epoch 199: 240/307] 	 train loss: 0.426880 	 lr: 0.00013
[epoch 199: 260/307] 	 train loss: 0.085540 	 lr: 0.00013
[epoch 199: 280/307] 	 train loss: 0.066843 	 lr: 0.00013
[epoch 199: 300/307] 	 train loss: 0.125080 	 lr: 0.00013
[epoch 200:   0/307] 	 train loss: 0.045525 	 lr: 0.00013
[epoch 200:  20/307] 	 train loss: 0.055703 	 lr: 0.00013
[epoch 200:  40/307] 	 train loss: 0.176522 	 lr: 0.00013
[epoch 200:  60/307] 	 train loss: 0.016947 	 lr: 0.00013

val loss: 0.343660 	 acc: 0.912885

[epoch 200:  80/307] 	 train loss: 0.033988 	 lr: 0.00013
[epoch 200: 100/307] 	 train loss: 0.180007 	 lr: 0.00013
[epoch 200: 120/307] 	 train loss: 0.071913 	 lr: 0.00013
[epoch 200: 140/307] 	 train loss: 0.178078 	 lr: 0.00013
[epoch 200: 160/307] 	 train loss: 0.023533 	 lr: 0.00013
[epoch 200: 180/307] 	 train loss: 0.040283 	 lr: 0.00013
[epoch 200: 200/307] 	 train loss: 0.041205 	 lr: 0.00013

val loss: 0.344405 	 acc: 0.910049

[epoch 200: 220/307] 	 train loss: 0.301010 	 lr: 0.00013
[epoch 200: 240/307] 	 train loss: 0.069336 	 lr: 0.00013
[epoch 200: 260/307] 	 train loss: 0.063900 	 lr: 0.00013
[epoch 200: 280/307] 	 train loss: 0.056574 	 lr: 0.00013
[epoch 200: 300/307] 	 train loss: 0.037246 	 lr: 0.00013
[epoch 201:   0/307] 	 train loss: 0.189568 	 lr: 0.00013
[epoch 201:  20/307] 	 train loss: 0.023103 	 lr: 0.00013
[epoch 201:  40/307] 	 train loss: 0.153224 	 lr: 0.00013

val loss: 0.334601 	 acc: 0.916937

[epoch 201:  60/307] 	 train loss: 0.078068 	 lr: 0.00013
[epoch 201:  80/307] 	 train loss: 0.050662 	 lr: 0.00013
[epoch 201: 100/307] 	 train loss: 0.061658 	 lr: 0.00013
[epoch 201: 120/307] 	 train loss: 0.033708 	 lr: 0.00013
[epoch 201: 140/307] 	 train loss: 0.100430 	 lr: 0.00013
[epoch 201: 160/307] 	 train loss: 0.075746 	 lr: 0.00013
[epoch 201: 180/307] 	 train loss: 0.033651 	 lr: 0.00013
[epoch 201: 200/307] 	 train loss: 0.095193 	 lr: 0.00013

val loss: 0.344781 	 acc: 0.912075

[epoch 201: 220/307] 	 train loss: 0.162738 	 lr: 0.00013
[epoch 201: 240/307] 	 train loss: 0.093763 	 lr: 0.00013
[epoch 201: 260/307] 	 train loss: 0.252305 	 lr: 0.00013
[epoch 201: 280/307] 	 train loss: 0.109119 	 lr: 0.00013
[epoch 201: 300/307] 	 train loss: 0.023983 	 lr: 0.00013
[epoch 202:   0/307] 	 train loss: 0.188051 	 lr: 0.00013
[epoch 202:  20/307] 	 train loss: 0.124755 	 lr: 0.00013
[epoch 202:  40/307] 	 train loss: 0.026557 	 lr: 0.00013

val loss: 0.338793 	 acc: 0.916937

[epoch 202:  60/307] 	 train loss: 0.088973 	 lr: 0.00013
[epoch 202:  80/307] 	 train loss: 0.079071 	 lr: 0.00013
[epoch 202: 100/307] 	 train loss: 0.194585 	 lr: 0.00013
[epoch 202: 120/307] 	 train loss: 0.016018 	 lr: 0.00013
[epoch 202: 140/307] 	 train loss: 0.057444 	 lr: 0.00013
[epoch 202: 160/307] 	 train loss: 0.100122 	 lr: 0.00013
[epoch 202: 180/307] 	 train loss: 0.180413 	 lr: 0.00013
[epoch 202: 200/307] 	 train loss: 0.026410 	 lr: 0.00013

val loss: 0.343367 	 acc: 0.914911

[epoch 202: 220/307] 	 train loss: 0.274201 	 lr: 0.00013
[epoch 202: 240/307] 	 train loss: 0.177678 	 lr: 0.00013
[epoch 202: 260/307] 	 train loss: 0.039441 	 lr: 0.00013
[epoch 202: 280/307] 	 train loss: 0.383714 	 lr: 0.00013
[epoch 202: 300/307] 	 train loss: 0.066636 	 lr: 0.00013
[epoch 203:   0/307] 	 train loss: 0.195377 	 lr: 0.00013
[epoch 203:  20/307] 	 train loss: 0.047639 	 lr: 0.00013
[epoch 203:  40/307] 	 train loss: 0.376693 	 lr: 0.00013

val loss: 0.336947 	 acc: 0.918963

[epoch 203:  60/307] 	 train loss: 0.336425 	 lr: 0.00013
[epoch 203:  80/307] 	 train loss: 0.296039 	 lr: 0.00013
[epoch 203: 100/307] 	 train loss: 0.061337 	 lr: 0.00013
[epoch 203: 120/307] 	 train loss: 0.188027 	 lr: 0.00013
[epoch 203: 140/307] 	 train loss: 0.064503 	 lr: 0.00013
[epoch 203: 160/307] 	 train loss: 0.045062 	 lr: 0.00013
[epoch 203: 180/307] 	 train loss: 0.422355 	 lr: 0.00013
[epoch 203: 200/307] 	 train loss: 0.143750 	 lr: 0.00013

val loss: 0.348936 	 acc: 0.914506

[epoch 203: 220/307] 	 train loss: 0.098779 	 lr: 0.00013
[epoch 203: 240/307] 	 train loss: 0.001238 	 lr: 0.00013
[epoch 203: 260/307] 	 train loss: 0.039188 	 lr: 0.00013
[epoch 203: 280/307] 	 train loss: 0.075649 	 lr: 0.00013
[epoch 203: 300/307] 	 train loss: 0.043010 	 lr: 0.00013
[epoch 204:   0/307] 	 train loss: 0.051875 	 lr: 0.00013
[epoch 204:  20/307] 	 train loss: 0.135558 	 lr: 0.00013
[epoch 204:  40/307] 	 train loss: 0.227876 	 lr: 0.00013

val loss: 0.356634 	 acc: 0.910049

[epoch 204:  60/307] 	 train loss: 0.056489 	 lr: 0.00013
[epoch 204:  80/307] 	 train loss: 0.230522 	 lr: 0.00013
[epoch 204: 100/307] 	 train loss: 0.129486 	 lr: 0.00013
[epoch 204: 120/307] 	 train loss: 0.210546 	 lr: 0.00013
[epoch 204: 140/307] 	 train loss: 0.210228 	 lr: 0.00013
[epoch 204: 160/307] 	 train loss: 0.067889 	 lr: 0.00013
[epoch 204: 180/307] 	 train loss: 0.260984 	 lr: 0.00013
[epoch 204: 200/307] 	 train loss: 0.084651 	 lr: 0.00013

val loss: 0.328703 	 acc: 0.916937

[epoch 204: 220/307] 	 train loss: 0.083760 	 lr: 0.00013
[epoch 204: 240/307] 	 train loss: 0.255909 	 lr: 0.00013
[epoch 204: 260/307] 	 train loss: 0.103400 	 lr: 0.00013
[epoch 204: 280/307] 	 train loss: 0.174805 	 lr: 0.00013
[epoch 204: 300/307] 	 train loss: 0.155603 	 lr: 0.00013
[epoch 205:   0/307] 	 train loss: 0.259277 	 lr: 0.00013
[epoch 205:  20/307] 	 train loss: 0.105968 	 lr: 0.00013
[epoch 205:  40/307] 	 train loss: 0.170097 	 lr: 0.00013

val loss: 0.339351 	 acc: 0.916126

[epoch 205:  60/307] 	 train loss: 0.057095 	 lr: 0.00013
[epoch 205:  80/307] 	 train loss: 0.060866 	 lr: 0.00013
[epoch 205: 100/307] 	 train loss: 0.109016 	 lr: 0.00013
[epoch 205: 120/307] 	 train loss: 0.077114 	 lr: 0.00013
[epoch 205: 140/307] 	 train loss: 0.057336 	 lr: 0.00013
[epoch 205: 160/307] 	 train loss: 0.046715 	 lr: 0.00013
[epoch 205: 180/307] 	 train loss: 0.171053 	 lr: 0.00013
[epoch 205: 200/307] 	 train loss: 0.088278 	 lr: 0.00013

val loss: 0.334602 	 acc: 0.912885

[epoch 205: 220/307] 	 train loss: 0.235766 	 lr: 0.00013
[epoch 205: 240/307] 	 train loss: 0.114455 	 lr: 0.00013
[epoch 205: 260/307] 	 train loss: 0.045462 	 lr: 0.00013
[epoch 205: 280/307] 	 train loss: 0.101411 	 lr: 0.00013
[epoch 205: 300/307] 	 train loss: 0.049935 	 lr: 0.00013
[epoch 206:   0/307] 	 train loss: 0.269985 	 lr: 0.00013
[epoch 206:  20/307] 	 train loss: 0.047984 	 lr: 0.00013
[epoch 206:  40/307] 	 train loss: 0.132175 	 lr: 0.00013

val loss: 0.334624 	 acc: 0.915316

[epoch 206:  60/307] 	 train loss: 0.066120 	 lr: 0.00013
[epoch 206:  80/307] 	 train loss: 0.060690 	 lr: 0.00013
[epoch 206: 100/307] 	 train loss: 0.071792 	 lr: 0.00013
[epoch 206: 120/307] 	 train loss: 0.057146 	 lr: 0.00013
[epoch 206: 140/307] 	 train loss: 0.030772 	 lr: 0.00013
[epoch 206: 160/307] 	 train loss: 0.104706 	 lr: 0.00013
[epoch 206: 180/307] 	 train loss: 0.075289 	 lr: 0.00013
[epoch 206: 200/307] 	 train loss: 0.040007 	 lr: 0.00013

val loss: 0.336187 	 acc: 0.918963

[epoch 206: 220/307] 	 train loss: 0.084604 	 lr: 0.00013
[epoch 206: 240/307] 	 train loss: 0.028568 	 lr: 0.00013
[epoch 206: 260/307] 	 train loss: 0.140179 	 lr: 0.00013
[epoch 206: 280/307] 	 train loss: 0.192957 	 lr: 0.00013
[epoch 206: 300/307] 	 train loss: 0.052225 	 lr: 0.00013
[epoch 207:   0/307] 	 train loss: 0.038563 	 lr: 0.00013
[epoch 207:  20/307] 	 train loss: 0.048560 	 lr: 0.00013
[epoch 207:  40/307] 	 train loss: 0.079924 	 lr: 0.00013

val loss: 0.339659 	 acc: 0.915316

[epoch 207:  60/307] 	 train loss: 0.086902 	 lr: 0.00013
[epoch 207:  80/307] 	 train loss: 0.284890 	 lr: 0.00013
[epoch 207: 100/307] 	 train loss: 0.244552 	 lr: 0.00013
[epoch 207: 120/307] 	 train loss: 0.060856 	 lr: 0.00013
[epoch 207: 140/307] 	 train loss: 0.082398 	 lr: 0.00013
[epoch 207: 160/307] 	 train loss: 0.373054 	 lr: 0.00013
[epoch 207: 180/307] 	 train loss: 0.185559 	 lr: 0.00013

val loss: 0.346322 	 acc: 0.917342

[epoch 207: 200/307] 	 train loss: 0.117340 	 lr: 0.00013
[epoch 207: 220/307] 	 train loss: 0.105388 	 lr: 0.00013
[epoch 207: 240/307] 	 train loss: 0.091057 	 lr: 0.00013
[epoch 207: 260/307] 	 train loss: 0.080025 	 lr: 0.00013
[epoch 207: 280/307] 	 train loss: 0.007969 	 lr: 0.00013
[epoch 207: 300/307] 	 train loss: 0.042031 	 lr: 0.00013
[epoch 208:   0/307] 	 train loss: 0.022284 	 lr: 0.00013
[epoch 208:  20/307] 	 train loss: 0.061581 	 lr: 0.00013
[epoch 208:  40/307] 	 train loss: 0.035134 	 lr: 0.00013

val loss: 0.347982 	 acc: 0.912480

[epoch 208:  60/307] 	 train loss: 0.041761 	 lr: 0.00013
[epoch 208:  80/307] 	 train loss: 0.288867 	 lr: 0.00013
[epoch 208: 100/307] 	 train loss: 0.330609 	 lr: 0.00013
[epoch 208: 120/307] 	 train loss: 0.150219 	 lr: 0.00013
[epoch 208: 140/307] 	 train loss: 0.036708 	 lr: 0.00013
[epoch 208: 160/307] 	 train loss: 0.065338 	 lr: 0.00013
[epoch 208: 180/307] 	 train loss: 0.053819 	 lr: 0.00013

val loss: 0.346387 	 acc: 0.912885

[epoch 208: 200/307] 	 train loss: 0.023583 	 lr: 0.00013
[epoch 208: 220/307] 	 train loss: 0.042196 	 lr: 0.00013
[epoch 208: 240/307] 	 train loss: 0.138168 	 lr: 0.00013
[epoch 208: 260/307] 	 train loss: 0.025147 	 lr: 0.00013
[epoch 208: 280/307] 	 train loss: 0.144266 	 lr: 0.00013
[epoch 208: 300/307] 	 train loss: 0.050737 	 lr: 0.00013
[epoch 209:   0/307] 	 train loss: 0.015874 	 lr: 0.00013
[epoch 209:  20/307] 	 train loss: 0.010159 	 lr: 0.00013
[epoch 209:  40/307] 	 train loss: 0.006108 	 lr: 0.00013

val loss: 0.339401 	 acc: 0.913695

[epoch 209:  60/307] 	 train loss: 0.160721 	 lr: 0.00013
[epoch 209:  80/307] 	 train loss: 0.058257 	 lr: 0.00013
[epoch 209: 100/307] 	 train loss: 0.200512 	 lr: 0.00013
[epoch 209: 120/307] 	 train loss: 0.203541 	 lr: 0.00013
[epoch 209: 140/307] 	 train loss: 0.226323 	 lr: 0.00013
[epoch 209: 160/307] 	 train loss: 0.123047 	 lr: 0.00013
[epoch 209: 180/307] 	 train loss: 0.095919 	 lr: 0.00013

val loss: 0.360768 	 acc: 0.909643

[epoch 209: 200/307] 	 train loss: 0.168770 	 lr: 0.00013
[epoch 209: 220/307] 	 train loss: 0.059627 	 lr: 0.00013
[epoch 209: 240/307] 	 train loss: 0.044102 	 lr: 0.00013
[epoch 209: 260/307] 	 train loss: 0.332296 	 lr: 0.00013
[epoch 209: 280/307] 	 train loss: 0.047612 	 lr: 0.00013
[epoch 209: 300/307] 	 train loss: 0.025119 	 lr: 0.00013
[epoch 210:   0/307] 	 train loss: 0.323688 	 lr: 0.00013
[epoch 210:  20/307] 	 train loss: 0.016854 	 lr: 0.00013
[epoch 210:  40/307] 	 train loss: 0.064223 	 lr: 0.00013

val loss: 0.341837 	 acc: 0.918963

[epoch 210:  60/307] 	 train loss: 0.110490 	 lr: 0.00013
[epoch 210:  80/307] 	 train loss: 0.095864 	 lr: 0.00013
[epoch 210: 100/307] 	 train loss: 0.122686 	 lr: 0.00013
[epoch 210: 120/307] 	 train loss: 0.111549 	 lr: 0.00013
[epoch 210: 140/307] 	 train loss: 0.080144 	 lr: 0.00013
[epoch 210: 160/307] 	 train loss: 0.027575 	 lr: 0.00013
[epoch 210: 180/307] 	 train loss: 0.181220 	 lr: 0.00013

val loss: 0.347376 	 acc: 0.914100

[epoch 210: 200/307] 	 train loss: 0.148215 	 lr: 0.00013
[epoch 210: 220/307] 	 train loss: 0.194516 	 lr: 0.00013
[epoch 210: 240/307] 	 train loss: 0.135186 	 lr: 0.00013
[epoch 210: 260/307] 	 train loss: 0.020864 	 lr: 0.00013
[epoch 210: 280/307] 	 train loss: 0.091315 	 lr: 0.00013
[epoch 210: 300/307] 	 train loss: 0.079657 	 lr: 0.00013
[epoch 211:   0/307] 	 train loss: 0.100149 	 lr: 0.00011
[epoch 211:  20/307] 	 train loss: 0.178850 	 lr: 0.00011

val loss: 0.337799 	 acc: 0.914506

[epoch 211:  40/307] 	 train loss: 0.211376 	 lr: 0.00011
[epoch 211:  60/307] 	 train loss: 0.042772 	 lr: 0.00011
[epoch 211:  80/307] 	 train loss: 0.125188 	 lr: 0.00011
[epoch 211: 100/307] 	 train loss: 0.112559 	 lr: 0.00011
[epoch 211: 120/307] 	 train loss: 0.016074 	 lr: 0.00011
[epoch 211: 140/307] 	 train loss: 0.072047 	 lr: 0.00011
[epoch 211: 160/307] 	 train loss: 0.041678 	 lr: 0.00011
[epoch 211: 180/307] 	 train loss: 0.026108 	 lr: 0.00011

val loss: 0.335035 	 acc: 0.916532

[epoch 211: 200/307] 	 train loss: 0.112772 	 lr: 0.00011
[epoch 211: 220/307] 	 train loss: 0.101682 	 lr: 0.00011
[epoch 211: 240/307] 	 train loss: 0.036289 	 lr: 0.00011
[epoch 211: 260/307] 	 train loss: 0.211772 	 lr: 0.00011
[epoch 211: 280/307] 	 train loss: 0.094664 	 lr: 0.00011
[epoch 211: 300/307] 	 train loss: 0.076904 	 lr: 0.00011
[epoch 212:   0/307] 	 train loss: 0.008738 	 lr: 0.00011
[epoch 212:  20/307] 	 train loss: 0.061075 	 lr: 0.00011

val loss: 0.342548 	 acc: 0.916126

[epoch 212:  40/307] 	 train loss: 0.187550 	 lr: 0.00011
[epoch 212:  60/307] 	 train loss: 0.053877 	 lr: 0.00011
[epoch 212:  80/307] 	 train loss: 0.118737 	 lr: 0.00011
[epoch 212: 100/307] 	 train loss: 0.053479 	 lr: 0.00011
[epoch 212: 120/307] 	 train loss: 0.083861 	 lr: 0.00011
[epoch 212: 140/307] 	 train loss: 0.071444 	 lr: 0.00011
[epoch 212: 160/307] 	 train loss: 0.103341 	 lr: 0.00011
[epoch 212: 180/307] 	 train loss: 0.099183 	 lr: 0.00011

val loss: 0.341208 	 acc: 0.913290

[epoch 212: 200/307] 	 train loss: 0.025430 	 lr: 0.00011
[epoch 212: 220/307] 	 train loss: 0.248859 	 lr: 0.00011
[epoch 212: 240/307] 	 train loss: 0.052159 	 lr: 0.00011
[epoch 212: 260/307] 	 train loss: 0.183261 	 lr: 0.00011
[epoch 212: 280/307] 	 train loss: 0.087911 	 lr: 0.00011
[epoch 212: 300/307] 	 train loss: 0.038212 	 lr: 0.00011
[epoch 213:   0/307] 	 train loss: 0.165964 	 lr: 0.00011
[epoch 213:  20/307] 	 train loss: 0.017035 	 lr: 0.00011

val loss: 0.334996 	 acc: 0.914506

[epoch 213:  40/307] 	 train loss: 0.010208 	 lr: 0.00011
[epoch 213:  60/307] 	 train loss: 0.022110 	 lr: 0.00011
[epoch 213:  80/307] 	 train loss: 0.019058 	 lr: 0.00011
[epoch 213: 100/307] 	 train loss: 0.163815 	 lr: 0.00011
[epoch 213: 120/307] 	 train loss: 0.060424 	 lr: 0.00011
[epoch 213: 140/307] 	 train loss: 0.235200 	 lr: 0.00011
[epoch 213: 160/307] 	 train loss: 0.131912 	 lr: 0.00011
[epoch 213: 180/307] 	 train loss: 0.142916 	 lr: 0.00011

val loss: 0.341451 	 acc: 0.911669

[epoch 213: 200/307] 	 train loss: 0.101686 	 lr: 0.00011
[epoch 213: 220/307] 	 train loss: 0.126558 	 lr: 0.00011
[epoch 213: 240/307] 	 train loss: 0.028606 	 lr: 0.00011
[epoch 213: 260/307] 	 train loss: 0.049303 	 lr: 0.00011
[epoch 213: 280/307] 	 train loss: 0.135311 	 lr: 0.00011
[epoch 213: 300/307] 	 train loss: 0.133893 	 lr: 0.00011
[epoch 214:   0/307] 	 train loss: 0.025411 	 lr: 0.00011
[epoch 214:  20/307] 	 train loss: 0.167268 	 lr: 0.00011

val loss: 0.332415 	 acc: 0.915316

[epoch 214:  40/307] 	 train loss: 0.082301 	 lr: 0.00011
[epoch 214:  60/307] 	 train loss: 0.007697 	 lr: 0.00011
[epoch 214:  80/307] 	 train loss: 0.077772 	 lr: 0.00011
[epoch 214: 100/307] 	 train loss: 0.081328 	 lr: 0.00011
[epoch 214: 120/307] 	 train loss: 0.250030 	 lr: 0.00011
[epoch 214: 140/307] 	 train loss: 0.097599 	 lr: 0.00011
[epoch 214: 160/307] 	 train loss: 0.104398 	 lr: 0.00011
[epoch 214: 180/307] 	 train loss: 0.157591 	 lr: 0.00011

val loss: 0.333606 	 acc: 0.916532

[epoch 214: 200/307] 	 train loss: 0.084821 	 lr: 0.00011
[epoch 214: 220/307] 	 train loss: 0.178690 	 lr: 0.00011
[epoch 214: 240/307] 	 train loss: 0.074229 	 lr: 0.00011
[epoch 214: 260/307] 	 train loss: 0.184785 	 lr: 0.00011
[epoch 214: 280/307] 	 train loss: 0.299514 	 lr: 0.00011
[epoch 214: 300/307] 	 train loss: 0.099646 	 lr: 0.00011
[epoch 215:   0/307] 	 train loss: 0.039939 	 lr: 0.00011
[epoch 215:  20/307] 	 train loss: 0.157155 	 lr: 0.00011

val loss: 0.335261 	 acc: 0.916126

[epoch 215:  40/307] 	 train loss: 0.170038 	 lr: 0.00011
[epoch 215:  60/307] 	 train loss: 0.062228 	 lr: 0.00011
[epoch 215:  80/307] 	 train loss: 0.061416 	 lr: 0.00011
[epoch 215: 100/307] 	 train loss: 0.174756 	 lr: 0.00011
[epoch 215: 120/307] 	 train loss: 0.017177 	 lr: 0.00011
[epoch 215: 140/307] 	 train loss: 0.133855 	 lr: 0.00011
[epoch 215: 160/307] 	 train loss: 0.015055 	 lr: 0.00011
[epoch 215: 180/307] 	 train loss: 0.178981 	 lr: 0.00011

val loss: 0.338849 	 acc: 0.917342

[epoch 215: 200/307] 	 train loss: 0.244627 	 lr: 0.00011
[epoch 215: 220/307] 	 train loss: 0.057311 	 lr: 0.00011
[epoch 215: 240/307] 	 train loss: 0.022903 	 lr: 0.00011
[epoch 215: 260/307] 	 train loss: 0.059852 	 lr: 0.00011
[epoch 215: 280/307] 	 train loss: 0.035486 	 lr: 0.00011
[epoch 215: 300/307] 	 train loss: 0.040848 	 lr: 0.00011
[epoch 216:   0/307] 	 train loss: 0.064134 	 lr: 0.00011
[epoch 216:  20/307] 	 train loss: 0.104161 	 lr: 0.00011

val loss: 0.327011 	 acc: 0.920178

[epoch 216:  40/307] 	 train loss: 0.046182 	 lr: 0.00011
[epoch 216:  60/307] 	 train loss: 0.019016 	 lr: 0.00011
[epoch 216:  80/307] 	 train loss: 0.056895 	 lr: 0.00011
[epoch 216: 100/307] 	 train loss: 0.092891 	 lr: 0.00011
[epoch 216: 120/307] 	 train loss: 0.043387 	 lr: 0.00011
[epoch 216: 140/307] 	 train loss: 0.203691 	 lr: 0.00011
[epoch 216: 160/307] 	 train loss: 0.109406 	 lr: 0.00011
[epoch 216: 180/307] 	 train loss: 0.036790 	 lr: 0.00011

val loss: 0.338149 	 acc: 0.914506

[epoch 216: 200/307] 	 train loss: 0.113385 	 lr: 0.00011
[epoch 216: 220/307] 	 train loss: 0.121709 	 lr: 0.00011
[epoch 216: 240/307] 	 train loss: 0.060974 	 lr: 0.00011
[epoch 216: 260/307] 	 train loss: 0.062069 	 lr: 0.00011
[epoch 216: 280/307] 	 train loss: 0.035036 	 lr: 0.00011
[epoch 216: 300/307] 	 train loss: 0.165329 	 lr: 0.00011
[epoch 217:   0/307] 	 train loss: 0.110764 	 lr: 0.00011
[epoch 217:  20/307] 	 train loss: 0.052645 	 lr: 0.00011

val loss: 0.328789 	 acc: 0.912480

[epoch 217:  40/307] 	 train loss: 0.060549 	 lr: 0.00011
[epoch 217:  60/307] 	 train loss: 0.184945 	 lr: 0.00011
[epoch 217:  80/307] 	 train loss: 0.045304 	 lr: 0.00011
[epoch 217: 100/307] 	 train loss: 0.081868 	 lr: 0.00011
[epoch 217: 120/307] 	 train loss: 0.122694 	 lr: 0.00011
[epoch 217: 140/307] 	 train loss: 0.050202 	 lr: 0.00011
[epoch 217: 160/307] 	 train loss: 0.113294 	 lr: 0.00011

val loss: 0.333028 	 acc: 0.915721

[epoch 217: 180/307] 	 train loss: 0.227935 	 lr: 0.00011
[epoch 217: 200/307] 	 train loss: 0.052873 	 lr: 0.00011
[epoch 217: 220/307] 	 train loss: 0.138312 	 lr: 0.00011
[epoch 217: 240/307] 	 train loss: 0.014251 	 lr: 0.00011
[epoch 217: 260/307] 	 train loss: 0.111627 	 lr: 0.00011
[epoch 217: 280/307] 	 train loss: 0.063655 	 lr: 0.00011
[epoch 217: 300/307] 	 train loss: 0.130881 	 lr: 0.00011
[epoch 218:   0/307] 	 train loss: 0.044655 	 lr: 0.00011
[epoch 218:  20/307] 	 train loss: 0.123393 	 lr: 0.00011

val loss: 0.339860 	 acc: 0.919773

[epoch 218:  40/307] 	 train loss: 0.094073 	 lr: 0.00011
[epoch 218:  60/307] 	 train loss: 0.036944 	 lr: 0.00011
[epoch 218:  80/307] 	 train loss: 0.025010 	 lr: 0.00011
[epoch 218: 100/307] 	 train loss: 0.058813 	 lr: 0.00011
[epoch 218: 120/307] 	 train loss: 0.060835 	 lr: 0.00011
[epoch 218: 140/307] 	 train loss: 0.220812 	 lr: 0.00011
[epoch 218: 160/307] 	 train loss: 0.168709 	 lr: 0.00011

val loss: 0.331944 	 acc: 0.916937

[epoch 218: 180/307] 	 train loss: 0.116720 	 lr: 0.00011
[epoch 218: 200/307] 	 train loss: 0.051536 	 lr: 0.00011
[epoch 218: 220/307] 	 train loss: 0.096641 	 lr: 0.00011
[epoch 218: 240/307] 	 train loss: 0.212058 	 lr: 0.00011
[epoch 218: 260/307] 	 train loss: 0.065460 	 lr: 0.00011
[epoch 218: 280/307] 	 train loss: 0.093885 	 lr: 0.00011
[epoch 218: 300/307] 	 train loss: 0.041050 	 lr: 0.00011
[epoch 219:   0/307] 	 train loss: 0.169031 	 lr: 0.00011
[epoch 219:  20/307] 	 train loss: 0.199417 	 lr: 0.00011

val loss: 0.334277 	 acc: 0.917747

[epoch 219:  40/307] 	 train loss: 0.116580 	 lr: 0.00011
[epoch 219:  60/307] 	 train loss: 0.022334 	 lr: 0.00011
[epoch 219:  80/307] 	 train loss: 0.329471 	 lr: 0.00011
[epoch 219: 100/307] 	 train loss: 0.054428 	 lr: 0.00011
[epoch 219: 120/307] 	 train loss: 0.282052 	 lr: 0.00011
[epoch 219: 140/307] 	 train loss: 0.155953 	 lr: 0.00011
[epoch 219: 160/307] 	 train loss: 0.200981 	 lr: 0.00011

val loss: 0.333161 	 acc: 0.920178

[epoch 219: 180/307] 	 train loss: 0.075726 	 lr: 0.00011
[epoch 219: 200/307] 	 train loss: 0.107362 	 lr: 0.00011
[epoch 219: 220/307] 	 train loss: 0.044603 	 lr: 0.00011
[epoch 219: 240/307] 	 train loss: 0.200595 	 lr: 0.00011
[epoch 219: 260/307] 	 train loss: 0.128819 	 lr: 0.00011
[epoch 219: 280/307] 	 train loss: 0.027570 	 lr: 0.00011
[epoch 219: 300/307] 	 train loss: 0.037211 	 lr: 0.00011
[epoch 220:   0/307] 	 train loss: 0.034744 	 lr: 0.00011
[epoch 220:  20/307] 	 train loss: 0.132194 	 lr: 0.00011

val loss: 0.340382 	 acc: 0.916126

[epoch 220:  40/307] 	 train loss: 0.102503 	 lr: 0.00011
[epoch 220:  60/307] 	 train loss: 0.037241 	 lr: 0.00011
[epoch 220:  80/307] 	 train loss: 0.179804 	 lr: 0.00011
[epoch 220: 100/307] 	 train loss: 0.263726 	 lr: 0.00011
[epoch 220: 120/307] 	 train loss: 0.232241 	 lr: 0.00011
[epoch 220: 140/307] 	 train loss: 0.191617 	 lr: 0.00011
[epoch 220: 160/307] 	 train loss: 0.280209 	 lr: 0.00011

val loss: 0.338281 	 acc: 0.912480

[epoch 220: 180/307] 	 train loss: 0.097703 	 lr: 0.00011
[epoch 220: 200/307] 	 train loss: 0.100219 	 lr: 0.00011
[epoch 220: 220/307] 	 train loss: 0.103166 	 lr: 0.00011
[epoch 220: 240/307] 	 train loss: 0.098892 	 lr: 0.00011
[epoch 220: 260/307] 	 train loss: 0.151679 	 lr: 0.00011
[epoch 220: 280/307] 	 train loss: 0.170393 	 lr: 0.00011
[epoch 220: 300/307] 	 train loss: 0.123640 	 lr: 0.00011
[epoch 221:   0/307] 	 train loss: 0.094360 	 lr: 0.00011

val loss: 0.340024 	 acc: 0.916532

[epoch 221:  20/307] 	 train loss: 0.115445 	 lr: 0.00011
[epoch 221:  40/307] 	 train loss: 0.231729 	 lr: 0.00011
[epoch 221:  60/307] 	 train loss: 0.082491 	 lr: 0.00011
[epoch 221:  80/307] 	 train loss: 0.238744 	 lr: 0.00011
[epoch 221: 100/307] 	 train loss: 0.269282 	 lr: 0.00011
[epoch 221: 120/307] 	 train loss: 0.163189 	 lr: 0.00011
[epoch 221: 140/307] 	 train loss: 0.092059 	 lr: 0.00011
[epoch 221: 160/307] 	 train loss: 0.088389 	 lr: 0.00011

val loss: 0.344493 	 acc: 0.915316

[epoch 221: 180/307] 	 train loss: 0.070241 	 lr: 0.00011
[epoch 221: 200/307] 	 train loss: 0.166776 	 lr: 0.00011
[epoch 221: 220/307] 	 train loss: 0.003713 	 lr: 0.00011
[epoch 221: 240/307] 	 train loss: 0.117700 	 lr: 0.00011
[epoch 221: 260/307] 	 train loss: 0.070330 	 lr: 0.00011
[epoch 221: 280/307] 	 train loss: 0.015997 	 lr: 0.00011
[epoch 221: 300/307] 	 train loss: 0.362126 	 lr: 0.00011
[epoch 222:   0/307] 	 train loss: 0.144454 	 lr: 0.00011

val loss: 0.334981 	 acc: 0.917747

[epoch 222:  20/307] 	 train loss: 0.067403 	 lr: 0.00011
[epoch 222:  40/307] 	 train loss: 0.108837 	 lr: 0.00011
[epoch 222:  60/307] 	 train loss: 0.036258 	 lr: 0.00011
[epoch 222:  80/307] 	 train loss: 0.159400 	 lr: 0.00011
[epoch 222: 100/307] 	 train loss: 0.147877 	 lr: 0.00011
[epoch 222: 120/307] 	 train loss: 0.222202 	 lr: 0.00011
[epoch 222: 140/307] 	 train loss: 0.276060 	 lr: 0.00011
[epoch 222: 160/307] 	 train loss: 0.199243 	 lr: 0.00011

val loss: 0.337867 	 acc: 0.917747

[epoch 222: 180/307] 	 train loss: 0.099842 	 lr: 0.00011
[epoch 222: 200/307] 	 train loss: 0.026919 	 lr: 0.00011
[epoch 222: 220/307] 	 train loss: 0.014949 	 lr: 0.00011
[epoch 222: 240/307] 	 train loss: 0.165865 	 lr: 0.00011
[epoch 222: 260/307] 	 train loss: 0.076450 	 lr: 0.00011
[epoch 222: 280/307] 	 train loss: 0.166018 	 lr: 0.00011
[epoch 222: 300/307] 	 train loss: 0.102988 	 lr: 0.00011
[epoch 223:   0/307] 	 train loss: 0.276483 	 lr: 0.00011

val loss: 0.335242 	 acc: 0.916937

[epoch 223:  20/307] 	 train loss: 0.064194 	 lr: 0.00011
[epoch 223:  40/307] 	 train loss: 0.017494 	 lr: 0.00011
[epoch 223:  60/307] 	 train loss: 0.034792 	 lr: 0.00011
[epoch 223:  80/307] 	 train loss: 0.059192 	 lr: 0.00011
[epoch 223: 100/307] 	 train loss: 0.042432 	 lr: 0.00011
[epoch 223: 120/307] 	 train loss: 0.097984 	 lr: 0.00011
[epoch 223: 140/307] 	 train loss: 0.043284 	 lr: 0.00011
[epoch 223: 160/307] 	 train loss: 0.041805 	 lr: 0.00011

val loss: 0.336877 	 acc: 0.917747

[epoch 223: 180/307] 	 train loss: 0.027571 	 lr: 0.00011
[epoch 223: 200/307] 	 train loss: 0.050948 	 lr: 0.00011
[epoch 223: 220/307] 	 train loss: 0.088859 	 lr: 0.00011
[epoch 223: 240/307] 	 train loss: 0.022458 	 lr: 0.00011
[epoch 223: 260/307] 	 train loss: 0.141085 	 lr: 0.00011
[epoch 223: 280/307] 	 train loss: 0.108008 	 lr: 0.00011
[epoch 223: 300/307] 	 train loss: 0.113290 	 lr: 0.00011
[epoch 224:   0/307] 	 train loss: 0.129302 	 lr: 0.00011

val loss: 0.328660 	 acc: 0.916937

[epoch 224:  20/307] 	 train loss: 0.067631 	 lr: 0.00011
[epoch 224:  40/307] 	 train loss: 0.050160 	 lr: 0.00011
[epoch 224:  60/307] 	 train loss: 0.048446 	 lr: 0.00011
[epoch 224:  80/307] 	 train loss: 0.041182 	 lr: 0.00011
[epoch 224: 100/307] 	 train loss: 0.087157 	 lr: 0.00011
[epoch 224: 120/307] 	 train loss: 0.088319 	 lr: 0.00011
[epoch 224: 140/307] 	 train loss: 0.152660 	 lr: 0.00011
[epoch 224: 160/307] 	 train loss: 0.015072 	 lr: 0.00011

val loss: 0.333529 	 acc: 0.917342

[epoch 224: 180/307] 	 train loss: 0.075883 	 lr: 0.00011
[epoch 224: 200/307] 	 train loss: 0.066616 	 lr: 0.00011
[epoch 224: 220/307] 	 train loss: 0.127998 	 lr: 0.00011
[epoch 224: 240/307] 	 train loss: 0.219538 	 lr: 0.00011
[epoch 224: 260/307] 	 train loss: 0.188304 	 lr: 0.00011
[epoch 224: 280/307] 	 train loss: 0.160127 	 lr: 0.00011
[epoch 224: 300/307] 	 train loss: 0.188843 	 lr: 0.00011
[epoch 225:   0/307] 	 train loss: 0.283107 	 lr: 0.00011

val loss: 0.332242 	 acc: 0.919368

[epoch 225:  20/307] 	 train loss: 0.048266 	 lr: 0.00011
[epoch 225:  40/307] 	 train loss: 0.021768 	 lr: 0.00011
[epoch 225:  60/307] 	 train loss: 0.096757 	 lr: 0.00011
[epoch 225:  80/307] 	 train loss: 0.031136 	 lr: 0.00011
[epoch 225: 100/307] 	 train loss: 0.156773 	 lr: 0.00011
[epoch 225: 120/307] 	 train loss: 0.115899 	 lr: 0.00011
[epoch 225: 140/307] 	 train loss: 0.024087 	 lr: 0.00011
[epoch 225: 160/307] 	 train loss: 0.066271 	 lr: 0.00011

val loss: 0.329249 	 acc: 0.918558

[epoch 225: 180/307] 	 train loss: 0.060776 	 lr: 0.00011
[epoch 225: 200/307] 	 train loss: 0.058127 	 lr: 0.00011
[epoch 225: 220/307] 	 train loss: 0.179407 	 lr: 0.00011
[epoch 225: 240/307] 	 train loss: 0.061524 	 lr: 0.00011
[epoch 225: 260/307] 	 train loss: 0.052017 	 lr: 0.00011
[epoch 225: 280/307] 	 train loss: 0.027366 	 lr: 0.00011
[epoch 225: 300/307] 	 train loss: 0.088911 	 lr: 0.00011
[epoch 226:   0/307] 	 train loss: 0.189887 	 lr: 0.00011

val loss: 0.333035 	 acc: 0.916532

[epoch 226:  20/307] 	 train loss: 0.103768 	 lr: 0.00011
[epoch 226:  40/307] 	 train loss: 0.053000 	 lr: 0.00011
[epoch 226:  60/307] 	 train loss: 0.023514 	 lr: 0.00011
[epoch 226:  80/307] 	 train loss: 0.107185 	 lr: 0.00011
[epoch 226: 100/307] 	 train loss: 0.054503 	 lr: 0.00011
[epoch 226: 120/307] 	 train loss: 0.021642 	 lr: 0.00011
[epoch 226: 140/307] 	 train loss: 0.033959 	 lr: 0.00011
[epoch 226: 160/307] 	 train loss: 0.128731 	 lr: 0.00011

val loss: 0.343326 	 acc: 0.914100

[epoch 226: 180/307] 	 train loss: 0.095171 	 lr: 0.00011
[epoch 226: 200/307] 	 train loss: 0.067788 	 lr: 0.00011
[epoch 226: 220/307] 	 train loss: 0.020847 	 lr: 0.00011
[epoch 226: 240/307] 	 train loss: 0.124247 	 lr: 0.00011
[epoch 226: 260/307] 	 train loss: 0.374753 	 lr: 0.00011
[epoch 226: 280/307] 	 train loss: 0.137629 	 lr: 0.00011
[epoch 226: 300/307] 	 train loss: 0.061641 	 lr: 0.00011
[epoch 227:   0/307] 	 train loss: 0.241916 	 lr: 0.00011

val loss: 0.334227 	 acc: 0.914506

[epoch 227:  20/307] 	 train loss: 0.071963 	 lr: 0.00011
[epoch 227:  40/307] 	 train loss: 0.186185 	 lr: 0.00011
[epoch 227:  60/307] 	 train loss: 0.136641 	 lr: 0.00011
[epoch 227:  80/307] 	 train loss: 0.108486 	 lr: 0.00011
[epoch 227: 100/307] 	 train loss: 0.048048 	 lr: 0.00011
[epoch 227: 120/307] 	 train loss: 0.085667 	 lr: 0.00011
[epoch 227: 140/307] 	 train loss: 0.092271 	 lr: 0.00011

val loss: 0.328879 	 acc: 0.918963

[epoch 227: 160/307] 	 train loss: 0.113779 	 lr: 0.00011
[epoch 227: 180/307] 	 train loss: 0.009369 	 lr: 0.00011
[epoch 227: 200/307] 	 train loss: 0.078156 	 lr: 0.00011
[epoch 227: 220/307] 	 train loss: 0.117595 	 lr: 0.00011
[epoch 227: 240/307] 	 train loss: 0.045973 	 lr: 0.00011
[epoch 227: 260/307] 	 train loss: 0.120841 	 lr: 0.00011
[epoch 227: 280/307] 	 train loss: 0.087254 	 lr: 0.00011
[epoch 227: 300/307] 	 train loss: 0.162451 	 lr: 0.00011
[epoch 228:   0/307] 	 train loss: 0.052448 	 lr: 0.00011

val loss: 0.335653 	 acc: 0.911669

[epoch 228:  20/307] 	 train loss: 0.204420 	 lr: 0.00011
[epoch 228:  40/307] 	 train loss: 0.020639 	 lr: 0.00011
[epoch 228:  60/307] 	 train loss: 0.039095 	 lr: 0.00011
[epoch 228:  80/307] 	 train loss: 0.073119 	 lr: 0.00011
[epoch 228: 100/307] 	 train loss: 0.242220 	 lr: 0.00011
[epoch 228: 120/307] 	 train loss: 0.060947 	 lr: 0.00011
[epoch 228: 140/307] 	 train loss: 0.034630 	 lr: 0.00011

val loss: 0.336860 	 acc: 0.917342

[epoch 228: 160/307] 	 train loss: 0.104989 	 lr: 0.00011
[epoch 228: 180/307] 	 train loss: 0.087817 	 lr: 0.00011
[epoch 228: 200/307] 	 train loss: 0.106666 	 lr: 0.00011
[epoch 228: 220/307] 	 train loss: 0.140331 	 lr: 0.00011
[epoch 228: 240/307] 	 train loss: 0.134677 	 lr: 0.00011
[epoch 228: 260/307] 	 train loss: 0.122368 	 lr: 0.00011
[epoch 228: 280/307] 	 train loss: 0.002949 	 lr: 0.00011
[epoch 228: 300/307] 	 train loss: 0.123246 	 lr: 0.00011
[epoch 229:   0/307] 	 train loss: 0.050298 	 lr: 0.00011

val loss: 0.334283 	 acc: 0.920989

[epoch 229:  20/307] 	 train loss: 0.146963 	 lr: 0.00011
[epoch 229:  40/307] 	 train loss: 0.096309 	 lr: 0.00011
[epoch 229:  60/307] 	 train loss: 0.100246 	 lr: 0.00011
[epoch 229:  80/307] 	 train loss: 0.085780 	 lr: 0.00011
[epoch 229: 100/307] 	 train loss: 0.019866 	 lr: 0.00011
[epoch 229: 120/307] 	 train loss: 0.074402 	 lr: 0.00011
[epoch 229: 140/307] 	 train loss: 0.197310 	 lr: 0.00011

val loss: 0.335880 	 acc: 0.919368

[epoch 229: 160/307] 	 train loss: 0.139114 	 lr: 0.00011
[epoch 229: 180/307] 	 train loss: 0.025774 	 lr: 0.00011
[epoch 229: 200/307] 	 train loss: 0.153158 	 lr: 0.00011
[epoch 229: 220/307] 	 train loss: 0.030683 	 lr: 0.00011
[epoch 229: 240/307] 	 train loss: 0.092902 	 lr: 0.00011
[epoch 229: 260/307] 	 train loss: 0.029468 	 lr: 0.00011
[epoch 229: 280/307] 	 train loss: 0.032657 	 lr: 0.00011
[epoch 229: 300/307] 	 train loss: 0.016319 	 lr: 0.00011
[epoch 230:   0/307] 	 train loss: 0.199500 	 lr: 0.00011

val loss: 0.337622 	 acc: 0.914100

[epoch 230:  20/307] 	 train loss: 0.032139 	 lr: 0.00011
[epoch 230:  40/307] 	 train loss: 0.155417 	 lr: 0.00011
[epoch 230:  60/307] 	 train loss: 0.079972 	 lr: 0.00011
[epoch 230:  80/307] 	 train loss: 0.039935 	 lr: 0.00011
[epoch 230: 100/307] 	 train loss: 0.284889 	 lr: 0.00011
[epoch 230: 120/307] 	 train loss: 0.094782 	 lr: 0.00011
[epoch 230: 140/307] 	 train loss: 0.079011 	 lr: 0.00011

val loss: 0.329003 	 acc: 0.916937

[epoch 230: 160/307] 	 train loss: 0.094579 	 lr: 0.00011
[epoch 230: 180/307] 	 train loss: 0.110956 	 lr: 0.00011
[epoch 230: 200/307] 	 train loss: 0.140245 	 lr: 0.00011
[epoch 230: 220/307] 	 train loss: 0.076720 	 lr: 0.00011
[epoch 230: 240/307] 	 train loss: 0.138246 	 lr: 0.00011
[epoch 230: 260/307] 	 train loss: 0.163134 	 lr: 0.00011
[epoch 230: 280/307] 	 train loss: 0.089139 	 lr: 0.00011
[epoch 230: 300/307] 	 train loss: 0.150163 	 lr: 0.00011

val loss: 0.332123 	 acc: 0.915316

[epoch 231:   0/307] 	 train loss: 0.185337 	 lr: 0.00011
[epoch 231:  20/307] 	 train loss: 0.123272 	 lr: 0.00011
[epoch 231:  40/307] 	 train loss: 0.116054 	 lr: 0.00011
[epoch 231:  60/307] 	 train loss: 0.073339 	 lr: 0.00011
[epoch 231:  80/307] 	 train loss: 0.062331 	 lr: 0.00011
[epoch 231: 100/307] 	 train loss: 0.077772 	 lr: 0.00011
[epoch 231: 120/307] 	 train loss: 0.098434 	 lr: 0.00011
[epoch 231: 140/307] 	 train loss: 0.123868 	 lr: 0.00011

val loss: 0.329409 	 acc: 0.918558

[epoch 231: 160/307] 	 train loss: 0.013599 	 lr: 0.00011
[epoch 231: 180/307] 	 train loss: 0.065896 	 lr: 0.00011
[epoch 231: 200/307] 	 train loss: 0.035923 	 lr: 0.00011
[epoch 231: 220/307] 	 train loss: 0.057090 	 lr: 0.00011
[epoch 231: 240/307] 	 train loss: 0.172319 	 lr: 0.00011
[epoch 231: 260/307] 	 train loss: 0.128174 	 lr: 0.00011
[epoch 231: 280/307] 	 train loss: 0.223551 	 lr: 0.00011
[epoch 231: 300/307] 	 train loss: 0.044927 	 lr: 0.00011

val loss: 0.341767 	 acc: 0.917342

[epoch 232:   0/307] 	 train loss: 0.188845 	 lr: 0.00009
[epoch 232:  20/307] 	 train loss: 0.082169 	 lr: 0.00009
[epoch 232:  40/307] 	 train loss: 0.020245 	 lr: 0.00009
[epoch 232:  60/307] 	 train loss: 0.097427 	 lr: 0.00009
[epoch 232:  80/307] 	 train loss: 0.022496 	 lr: 0.00009
[epoch 232: 100/307] 	 train loss: 0.233120 	 lr: 0.00009
[epoch 232: 120/307] 	 train loss: 0.081669 	 lr: 0.00009
[epoch 232: 140/307] 	 train loss: 0.160344 	 lr: 0.00009

val loss: 0.332854 	 acc: 0.916937

[epoch 232: 160/307] 	 train loss: 0.013857 	 lr: 0.00009
[epoch 232: 180/307] 	 train loss: 0.062494 	 lr: 0.00009
[epoch 232: 200/307] 	 train loss: 0.075818 	 lr: 0.00009
[epoch 232: 220/307] 	 train loss: 0.090125 	 lr: 0.00009
[epoch 232: 240/307] 	 train loss: 0.028632 	 lr: 0.00009
[epoch 232: 260/307] 	 train loss: 0.003773 	 lr: 0.00009
[epoch 232: 280/307] 	 train loss: 0.212509 	 lr: 0.00009
[epoch 232: 300/307] 	 train loss: 0.007700 	 lr: 0.00009

val loss: 0.331329 	 acc: 0.917747

[epoch 233:   0/307] 	 train loss: 0.110207 	 lr: 0.00009
[epoch 233:  20/307] 	 train loss: 0.059448 	 lr: 0.00009
[epoch 233:  40/307] 	 train loss: 0.139212 	 lr: 0.00009
[epoch 233:  60/307] 	 train loss: 0.141873 	 lr: 0.00009
[epoch 233:  80/307] 	 train loss: 0.012906 	 lr: 0.00009
[epoch 233: 100/307] 	 train loss: 0.085526 	 lr: 0.00009
[epoch 233: 120/307] 	 train loss: 0.038226 	 lr: 0.00009
[epoch 233: 140/307] 	 train loss: 0.374986 	 lr: 0.00009

val loss: 0.338272 	 acc: 0.918963

[epoch 233: 160/307] 	 train loss: 0.267505 	 lr: 0.00009
[epoch 233: 180/307] 	 train loss: 0.023117 	 lr: 0.00009
[epoch 233: 200/307] 	 train loss: 0.251593 	 lr: 0.00009
[epoch 233: 220/307] 	 train loss: 0.251826 	 lr: 0.00009
[epoch 233: 240/307] 	 train loss: 0.084876 	 lr: 0.00009
[epoch 233: 260/307] 	 train loss: 0.047066 	 lr: 0.00009
[epoch 233: 280/307] 	 train loss: 0.294382 	 lr: 0.00009
[epoch 233: 300/307] 	 train loss: 0.388079 	 lr: 0.00009

val loss: 0.334889 	 acc: 0.914911

[epoch 234:   0/307] 	 train loss: 0.057818 	 lr: 0.00009
[epoch 234:  20/307] 	 train loss: 0.009879 	 lr: 0.00009
[epoch 234:  40/307] 	 train loss: 0.068172 	 lr: 0.00009
[epoch 234:  60/307] 	 train loss: 0.045927 	 lr: 0.00009
[epoch 234:  80/307] 	 train loss: 0.050716 	 lr: 0.00009
[epoch 234: 100/307] 	 train loss: 0.122292 	 lr: 0.00009
[epoch 234: 120/307] 	 train loss: 0.079166 	 lr: 0.00009
[epoch 234: 140/307] 	 train loss: 0.052514 	 lr: 0.00009

val loss: 0.328805 	 acc: 0.918963

[epoch 234: 160/307] 	 train loss: 0.321853 	 lr: 0.00009
[epoch 234: 180/307] 	 train loss: 0.056427 	 lr: 0.00009
[epoch 234: 200/307] 	 train loss: 0.049518 	 lr: 0.00009
[epoch 234: 220/307] 	 train loss: 0.033049 	 lr: 0.00009
[epoch 234: 240/307] 	 train loss: 0.033318 	 lr: 0.00009
[epoch 234: 260/307] 	 train loss: 0.058263 	 lr: 0.00009
[epoch 234: 280/307] 	 train loss: 0.143296 	 lr: 0.00009

val loss: 0.326416 	 acc: 0.919773

[epoch 234: 300/307] 	 train loss: 0.130245 	 lr: 0.00009
[epoch 235:   0/307] 	 train loss: 0.004999 	 lr: 0.00009
[epoch 235:  20/307] 	 train loss: 0.050086 	 lr: 0.00009
[epoch 235:  40/307] 	 train loss: 0.046981 	 lr: 0.00009
[epoch 235:  60/307] 	 train loss: 0.175813 	 lr: 0.00009
[epoch 235:  80/307] 	 train loss: 0.008862 	 lr: 0.00009
[epoch 235: 100/307] 	 train loss: 0.264049 	 lr: 0.00009
[epoch 235: 120/307] 	 train loss: 0.136353 	 lr: 0.00009
[epoch 235: 140/307] 	 train loss: 0.091494 	 lr: 0.00009

val loss: 0.329199 	 acc: 0.917342

[epoch 235: 160/307] 	 train loss: 0.024164 	 lr: 0.00009
[epoch 235: 180/307] 	 train loss: 0.101135 	 lr: 0.00009
[epoch 235: 200/307] 	 train loss: 0.046149 	 lr: 0.00009
[epoch 235: 220/307] 	 train loss: 0.133262 	 lr: 0.00009
[epoch 235: 240/307] 	 train loss: 0.430226 	 lr: 0.00009
[epoch 235: 260/307] 	 train loss: 0.190942 	 lr: 0.00009
[epoch 235: 280/307] 	 train loss: 0.195516 	 lr: 0.00009

val loss: 0.339547 	 acc: 0.916532

[epoch 235: 300/307] 	 train loss: 0.167272 	 lr: 0.00009
[epoch 236:   0/307] 	 train loss: 0.020908 	 lr: 0.00009
[epoch 236:  20/307] 	 train loss: 0.143902 	 lr: 0.00009
[epoch 236:  40/307] 	 train loss: 0.088188 	 lr: 0.00009
[epoch 236:  60/307] 	 train loss: 0.026065 	 lr: 0.00009
[epoch 236:  80/307] 	 train loss: 0.050670 	 lr: 0.00009
[epoch 236: 100/307] 	 train loss: 0.020635 	 lr: 0.00009
[epoch 236: 120/307] 	 train loss: 0.109479 	 lr: 0.00009
[epoch 236: 140/307] 	 train loss: 0.142229 	 lr: 0.00009

val loss: 0.328709 	 acc: 0.918558

[epoch 236: 160/307] 	 train loss: 0.046535 	 lr: 0.00009
[epoch 236: 180/307] 	 train loss: 0.310864 	 lr: 0.00009
[epoch 236: 200/307] 	 train loss: 0.143359 	 lr: 0.00009
[epoch 236: 220/307] 	 train loss: 0.020343 	 lr: 0.00009
[epoch 236: 240/307] 	 train loss: 0.287673 	 lr: 0.00009
[epoch 236: 260/307] 	 train loss: 0.050988 	 lr: 0.00009
[epoch 236: 280/307] 	 train loss: 0.183961 	 lr: 0.00009

val loss: 0.333059 	 acc: 0.918152

[epoch 236: 300/307] 	 train loss: 0.127411 	 lr: 0.00009
[epoch 237:   0/307] 	 train loss: 0.076717 	 lr: 0.00009
[epoch 237:  20/307] 	 train loss: 0.011665 	 lr: 0.00009
[epoch 237:  40/307] 	 train loss: 0.133559 	 lr: 0.00009
[epoch 237:  60/307] 	 train loss: 0.033204 	 lr: 0.00009
[epoch 237:  80/307] 	 train loss: 0.130251 	 lr: 0.00009
[epoch 237: 100/307] 	 train loss: 0.037279 	 lr: 0.00009
[epoch 237: 120/307] 	 train loss: 0.265477 	 lr: 0.00009

val loss: 0.333831 	 acc: 0.918963

[epoch 237: 140/307] 	 train loss: 0.015431 	 lr: 0.00009
[epoch 237: 160/307] 	 train loss: 0.036356 	 lr: 0.00009
[epoch 237: 180/307] 	 train loss: 0.176459 	 lr: 0.00009
[epoch 237: 200/307] 	 train loss: 0.027237 	 lr: 0.00009
[epoch 237: 220/307] 	 train loss: 0.111369 	 lr: 0.00009
[epoch 237: 240/307] 	 train loss: 0.302369 	 lr: 0.00009
[epoch 237: 260/307] 	 train loss: 0.109876 	 lr: 0.00009
[epoch 237: 280/307] 	 train loss: 0.123655 	 lr: 0.00009

val loss: 0.341299 	 acc: 0.915316

[epoch 237: 300/307] 	 train loss: 0.257914 	 lr: 0.00009
[epoch 238:   0/307] 	 train loss: 0.294774 	 lr: 0.00009
[epoch 238:  20/307] 	 train loss: 0.144547 	 lr: 0.00009
[epoch 238:  40/307] 	 train loss: 0.156602 	 lr: 0.00009
[epoch 238:  60/307] 	 train loss: 0.152445 	 lr: 0.00009
[epoch 238:  80/307] 	 train loss: 0.064263 	 lr: 0.00009
[epoch 238: 100/307] 	 train loss: 0.147001 	 lr: 0.00009
[epoch 238: 120/307] 	 train loss: 0.046981 	 lr: 0.00009

val loss: 0.346358 	 acc: 0.917342

[epoch 238: 140/307] 	 train loss: 0.096076 	 lr: 0.00009
[epoch 238: 160/307] 	 train loss: 0.036410 	 lr: 0.00009
[epoch 238: 180/307] 	 train loss: 0.103782 	 lr: 0.00009
[epoch 238: 200/307] 	 train loss: 0.018829 	 lr: 0.00009
[epoch 238: 220/307] 	 train loss: 0.092802 	 lr: 0.00009
[epoch 238: 240/307] 	 train loss: 0.021942 	 lr: 0.00009
[epoch 238: 260/307] 	 train loss: 0.090026 	 lr: 0.00009
[epoch 238: 280/307] 	 train loss: 0.010368 	 lr: 0.00009

val loss: 0.338174 	 acc: 0.919368

[epoch 238: 300/307] 	 train loss: 0.043596 	 lr: 0.00009
[epoch 239:   0/307] 	 train loss: 0.052659 	 lr: 0.00009
[epoch 239:  20/307] 	 train loss: 0.115558 	 lr: 0.00009
[epoch 239:  40/307] 	 train loss: 0.385595 	 lr: 0.00009
[epoch 239:  60/307] 	 train loss: 0.197708 	 lr: 0.00009
[epoch 239:  80/307] 	 train loss: 0.028168 	 lr: 0.00009
[epoch 239: 100/307] 	 train loss: 0.152200 	 lr: 0.00009
[epoch 239: 120/307] 	 train loss: 0.017375 	 lr: 0.00009

val loss: 0.342466 	 acc: 0.918152

[epoch 239: 140/307] 	 train loss: 0.100547 	 lr: 0.00009
[epoch 239: 160/307] 	 train loss: 0.070821 	 lr: 0.00009
[epoch 239: 180/307] 	 train loss: 0.124210 	 lr: 0.00009
[epoch 239: 200/307] 	 train loss: 0.037423 	 lr: 0.00009
[epoch 239: 220/307] 	 train loss: 0.153589 	 lr: 0.00009
[epoch 239: 240/307] 	 train loss: 0.217377 	 lr: 0.00009
[epoch 239: 260/307] 	 train loss: 0.014783 	 lr: 0.00009
[epoch 239: 280/307] 	 train loss: 0.020076 	 lr: 0.00009

val loss: 0.334554 	 acc: 0.917342

[epoch 239: 300/307] 	 train loss: 0.078039 	 lr: 0.00009
[epoch 240:   0/307] 	 train loss: 0.315378 	 lr: 0.00009
[epoch 240:  20/307] 	 train loss: 0.010738 	 lr: 0.00009
[epoch 240:  40/307] 	 train loss: 0.040819 	 lr: 0.00009
[epoch 240:  60/307] 	 train loss: 0.084061 	 lr: 0.00009
[epoch 240:  80/307] 	 train loss: 0.112512 	 lr: 0.00009
[epoch 240: 100/307] 	 train loss: 0.084723 	 lr: 0.00009
[epoch 240: 120/307] 	 train loss: 0.065137 	 lr: 0.00009

val loss: 0.334618 	 acc: 0.921394

[epoch 240: 140/307] 	 train loss: 0.079576 	 lr: 0.00009
[epoch 240: 160/307] 	 train loss: 0.054969 	 lr: 0.00009
[epoch 240: 180/307] 	 train loss: 0.017606 	 lr: 0.00009
[epoch 240: 200/307] 	 train loss: 0.027424 	 lr: 0.00009
[epoch 240: 220/307] 	 train loss: 0.071922 	 lr: 0.00009
[epoch 240: 240/307] 	 train loss: 0.163998 	 lr: 0.00009
[epoch 240: 260/307] 	 train loss: 0.046687 	 lr: 0.00009
[epoch 240: 280/307] 	 train loss: 0.009526 	 lr: 0.00009

val loss: 0.334310 	 acc: 0.917342

[epoch 240: 300/307] 	 train loss: 0.095874 	 lr: 0.00009
[epoch 241:   0/307] 	 train loss: 0.017613 	 lr: 0.00009
[epoch 241:  20/307] 	 train loss: 0.046437 	 lr: 0.00009
[epoch 241:  40/307] 	 train loss: 0.015683 	 lr: 0.00009
[epoch 241:  60/307] 	 train loss: 0.176053 	 lr: 0.00009
[epoch 241:  80/307] 	 train loss: 0.115825 	 lr: 0.00009
[epoch 241: 100/307] 	 train loss: 0.040497 	 lr: 0.00009
[epoch 241: 120/307] 	 train loss: 0.019327 	 lr: 0.00009

val loss: 0.341114 	 acc: 0.917747

[epoch 241: 140/307] 	 train loss: 0.029475 	 lr: 0.00009
[epoch 241: 160/307] 	 train loss: 0.059299 	 lr: 0.00009
[epoch 241: 180/307] 	 train loss: 0.117855 	 lr: 0.00009
[epoch 241: 200/307] 	 train loss: 0.020082 	 lr: 0.00009
[epoch 241: 220/307] 	 train loss: 0.191766 	 lr: 0.00009
[epoch 241: 240/307] 	 train loss: 0.100528 	 lr: 0.00009
[epoch 241: 260/307] 	 train loss: 0.036158 	 lr: 0.00009
[epoch 241: 280/307] 	 train loss: 0.162125 	 lr: 0.00009

val loss: 0.336485 	 acc: 0.916937

[epoch 241: 300/307] 	 train loss: 0.108052 	 lr: 0.00009
[epoch 242:   0/307] 	 train loss: 0.099643 	 lr: 0.00009
[epoch 242:  20/307] 	 train loss: 0.126858 	 lr: 0.00009
[epoch 242:  40/307] 	 train loss: 0.052048 	 lr: 0.00009
[epoch 242:  60/307] 	 train loss: 0.068444 	 lr: 0.00009
[epoch 242:  80/307] 	 train loss: 0.087727 	 lr: 0.00009
[epoch 242: 100/307] 	 train loss: 0.037650 	 lr: 0.00009
[epoch 242: 120/307] 	 train loss: 0.053388 	 lr: 0.00009

val loss: 0.332530 	 acc: 0.917342

[epoch 242: 140/307] 	 train loss: 0.121634 	 lr: 0.00009
[epoch 242: 160/307] 	 train loss: 0.102864 	 lr: 0.00009
[epoch 242: 180/307] 	 train loss: 0.065425 	 lr: 0.00009
[epoch 242: 200/307] 	 train loss: 0.064012 	 lr: 0.00009
[epoch 242: 220/307] 	 train loss: 0.030274 	 lr: 0.00009
[epoch 242: 240/307] 	 train loss: 0.003497 	 lr: 0.00009
[epoch 242: 260/307] 	 train loss: 0.072837 	 lr: 0.00009
[epoch 242: 280/307] 	 train loss: 0.043660 	 lr: 0.00009

val loss: 0.334433 	 acc: 0.918963

[epoch 242: 300/307] 	 train loss: 0.027412 	 lr: 0.00009
[epoch 243:   0/307] 	 train loss: 0.092263 	 lr: 0.00009
[epoch 243:  20/307] 	 train loss: 0.066536 	 lr: 0.00009
[epoch 243:  40/307] 	 train loss: 0.024765 	 lr: 0.00009
[epoch 243:  60/307] 	 train loss: 0.269924 	 lr: 0.00009
[epoch 243:  80/307] 	 train loss: 0.122054 	 lr: 0.00009
[epoch 243: 100/307] 	 train loss: 0.100544 	 lr: 0.00009
[epoch 243: 120/307] 	 train loss: 0.234401 	 lr: 0.00009

val loss: 0.335482 	 acc: 0.920583

[epoch 243: 140/307] 	 train loss: 0.083061 	 lr: 0.00009
[epoch 243: 160/307] 	 train loss: 0.059640 	 lr: 0.00009
[epoch 243: 180/307] 	 train loss: 0.044395 	 lr: 0.00009
[epoch 243: 200/307] 	 train loss: 0.201698 	 lr: 0.00009
[epoch 243: 220/307] 	 train loss: 0.044579 	 lr: 0.00009
[epoch 243: 240/307] 	 train loss: 0.057228 	 lr: 0.00009
[epoch 243: 260/307] 	 train loss: 0.068657 	 lr: 0.00009
[epoch 243: 280/307] 	 train loss: 0.108238 	 lr: 0.00009

val loss: 0.337647 	 acc: 0.919368

[epoch 243: 300/307] 	 train loss: 0.230140 	 lr: 0.00009
[epoch 244:   0/307] 	 train loss: 0.153700 	 lr: 0.00009
[epoch 244:  20/307] 	 train loss: 0.145767 	 lr: 0.00009
[epoch 244:  40/307] 	 train loss: 0.251314 	 lr: 0.00009
[epoch 244:  60/307] 	 train loss: 0.044278 	 lr: 0.00009
[epoch 244:  80/307] 	 train loss: 0.154368 	 lr: 0.00009
[epoch 244: 100/307] 	 train loss: 0.064381 	 lr: 0.00009
[epoch 244: 120/307] 	 train loss: 0.323932 	 lr: 0.00009

val loss: 0.338546 	 acc: 0.914911

[epoch 244: 140/307] 	 train loss: 0.132101 	 lr: 0.00009
[epoch 244: 160/307] 	 train loss: 0.027660 	 lr: 0.00009
[epoch 244: 180/307] 	 train loss: 0.033577 	 lr: 0.00009
[epoch 244: 200/307] 	 train loss: 0.208146 	 lr: 0.00009
[epoch 244: 220/307] 	 train loss: 0.154945 	 lr: 0.00009
[epoch 244: 240/307] 	 train loss: 0.113611 	 lr: 0.00009
[epoch 244: 260/307] 	 train loss: 0.124616 	 lr: 0.00009

val loss: 0.338835 	 acc: 0.916126

[epoch 244: 280/307] 	 train loss: 0.036824 	 lr: 0.00009
[epoch 244: 300/307] 	 train loss: 0.060071 	 lr: 0.00009
[epoch 245:   0/307] 	 train loss: 0.214601 	 lr: 0.00009
[epoch 245:  20/307] 	 train loss: 0.025067 	 lr: 0.00009
[epoch 245:  40/307] 	 train loss: 0.116708 	 lr: 0.00009
[epoch 245:  60/307] 	 train loss: 0.051690 	 lr: 0.00009
[epoch 245:  80/307] 	 train loss: 0.079805 	 lr: 0.00009
[epoch 245: 100/307] 	 train loss: 0.031589 	 lr: 0.00009
[epoch 245: 120/307] 	 train loss: 0.159640 	 lr: 0.00009

val loss: 0.341499 	 acc: 0.915316

[epoch 245: 140/307] 	 train loss: 0.024581 	 lr: 0.00009
[epoch 245: 160/307] 	 train loss: 0.151897 	 lr: 0.00009
[epoch 245: 180/307] 	 train loss: 0.171894 	 lr: 0.00009
[epoch 245: 200/307] 	 train loss: 0.231914 	 lr: 0.00009
[epoch 245: 220/307] 	 train loss: 0.009036 	 lr: 0.00009
[epoch 245: 240/307] 	 train loss: 0.139044 	 lr: 0.00009
[epoch 245: 260/307] 	 train loss: 0.116627 	 lr: 0.00009

val loss: 0.339607 	 acc: 0.917342

[epoch 245: 280/307] 	 train loss: 0.064608 	 lr: 0.00009
[epoch 245: 300/307] 	 train loss: 0.109790 	 lr: 0.00009
[epoch 246:   0/307] 	 train loss: 0.135193 	 lr: 0.00009
[epoch 246:  20/307] 	 train loss: 0.057681 	 lr: 0.00009
[epoch 246:  40/307] 	 train loss: 0.103449 	 lr: 0.00009
[epoch 246:  60/307] 	 train loss: 0.035023 	 lr: 0.00009
[epoch 246:  80/307] 	 train loss: 0.019686 	 lr: 0.00009
[epoch 246: 100/307] 	 train loss: 0.091384 	 lr: 0.00009
[epoch 246: 120/307] 	 train loss: 0.129120 	 lr: 0.00009

val loss: 0.335520 	 acc: 0.918963

[epoch 246: 140/307] 	 train loss: 0.112688 	 lr: 0.00009
[epoch 246: 160/307] 	 train loss: 0.114537 	 lr: 0.00009
[epoch 246: 180/307] 	 train loss: 0.076020 	 lr: 0.00009
[epoch 246: 200/307] 	 train loss: 0.115136 	 lr: 0.00009
[epoch 246: 220/307] 	 train loss: 0.281537 	 lr: 0.00009
[epoch 246: 240/307] 	 train loss: 0.137992 	 lr: 0.00009
[epoch 246: 260/307] 	 train loss: 0.170373 	 lr: 0.00009

val loss: 0.332598 	 acc: 0.918152

[epoch 246: 280/307] 	 train loss: 0.105844 	 lr: 0.00009
[epoch 246: 300/307] 	 train loss: 0.108746 	 lr: 0.00009
[epoch 247:   0/307] 	 train loss: 0.249168 	 lr: 0.00009
[epoch 247:  20/307] 	 train loss: 0.048634 	 lr: 0.00009
[epoch 247:  40/307] 	 train loss: 0.117230 	 lr: 0.00009
[epoch 247:  60/307] 	 train loss: 0.058669 	 lr: 0.00009
[epoch 247:  80/307] 	 train loss: 0.074625 	 lr: 0.00009
[epoch 247: 100/307] 	 train loss: 0.143758 	 lr: 0.00009

val loss: 0.332445 	 acc: 0.921394

[epoch 247: 120/307] 	 train loss: 0.078813 	 lr: 0.00009
[epoch 247: 140/307] 	 train loss: 0.056811 	 lr: 0.00009
[epoch 247: 160/307] 	 train loss: 0.065730 	 lr: 0.00009
[epoch 247: 180/307] 	 train loss: 0.105088 	 lr: 0.00009
[epoch 247: 200/307] 	 train loss: 0.149440 	 lr: 0.00009
[epoch 247: 220/307] 	 train loss: 0.084531 	 lr: 0.00009
[epoch 247: 240/307] 	 train loss: 0.126616 	 lr: 0.00009
[epoch 247: 260/307] 	 train loss: 0.164666 	 lr: 0.00009

val loss: 0.340664 	 acc: 0.915316

[epoch 247: 280/307] 	 train loss: 0.068984 	 lr: 0.00009
[epoch 247: 300/307] 	 train loss: 0.114267 	 lr: 0.00009
[epoch 248:   0/307] 	 train loss: 0.030733 	 lr: 0.00009
[epoch 248:  20/307] 	 train loss: 0.017045 	 lr: 0.00009
[epoch 248:  40/307] 	 train loss: 0.076250 	 lr: 0.00009
[epoch 248:  60/307] 	 train loss: 0.087547 	 lr: 0.00009
[epoch 248:  80/307] 	 train loss: 0.036287 	 lr: 0.00009
[epoch 248: 100/307] 	 train loss: 0.065135 	 lr: 0.00009

val loss: 0.338047 	 acc: 0.915721

[epoch 248: 120/307] 	 train loss: 0.144949 	 lr: 0.00009
[epoch 248: 140/307] 	 train loss: 0.031941 	 lr: 0.00009
[epoch 248: 160/307] 	 train loss: 0.068930 	 lr: 0.00009
[epoch 248: 180/307] 	 train loss: 0.073920 	 lr: 0.00009
[epoch 248: 200/307] 	 train loss: 0.043716 	 lr: 0.00009
[epoch 248: 220/307] 	 train loss: 0.273005 	 lr: 0.00009
[epoch 248: 240/307] 	 train loss: 0.032455 	 lr: 0.00009
[epoch 248: 260/307] 	 train loss: 0.076744 	 lr: 0.00009

val loss: 0.336694 	 acc: 0.918558

[epoch 248: 280/307] 	 train loss: 0.071767 	 lr: 0.00009
[epoch 248: 300/307] 	 train loss: 0.042626 	 lr: 0.00009
[epoch 249:   0/307] 	 train loss: 0.152006 	 lr: 0.00009
[epoch 249:  20/307] 	 train loss: 0.011558 	 lr: 0.00009
[epoch 249:  40/307] 	 train loss: 0.041859 	 lr: 0.00009
[epoch 249:  60/307] 	 train loss: 0.022210 	 lr: 0.00009
[epoch 249:  80/307] 	 train loss: 0.145088 	 lr: 0.00009
[epoch 249: 100/307] 	 train loss: 0.184305 	 lr: 0.00009

val loss: 0.337716 	 acc: 0.917342

[epoch 249: 120/307] 	 train loss: 0.346966 	 lr: 0.00009
[epoch 249: 140/307] 	 train loss: 0.060275 	 lr: 0.00009
[epoch 249: 160/307] 	 train loss: 0.123445 	 lr: 0.00009
[epoch 249: 180/307] 	 train loss: 0.162410 	 lr: 0.00009
[epoch 249: 200/307] 	 train loss: 0.042337 	 lr: 0.00009
[epoch 249: 220/307] 	 train loss: 0.296030 	 lr: 0.00009
[epoch 249: 240/307] 	 train loss: 0.066554 	 lr: 0.00009
[epoch 249: 260/307] 	 train loss: 0.155993 	 lr: 0.00009

val loss: 0.328337 	 acc: 0.916126

[epoch 249: 280/307] 	 train loss: 0.011111 	 lr: 0.00009
[epoch 249: 300/307] 	 train loss: 0.114117 	 lr: 0.00009
[epoch 250:   0/307] 	 train loss: 0.069023 	 lr: 0.00009
[epoch 250:  20/307] 	 train loss: 0.081565 	 lr: 0.00009
[epoch 250:  40/307] 	 train loss: 0.088851 	 lr: 0.00009
[epoch 250:  60/307] 	 train loss: 0.056974 	 lr: 0.00009
[epoch 250:  80/307] 	 train loss: 0.064845 	 lr: 0.00009
[epoch 250: 100/307] 	 train loss: 0.131428 	 lr: 0.00009

val loss: 0.338398 	 acc: 0.915721

[epoch 250: 120/307] 	 train loss: 0.059464 	 lr: 0.00009
[epoch 250: 140/307] 	 train loss: 0.062198 	 lr: 0.00009
[epoch 250: 160/307] 	 train loss: 0.249797 	 lr: 0.00009
[epoch 250: 180/307] 	 train loss: 0.040674 	 lr: 0.00009
[epoch 250: 200/307] 	 train loss: 0.135146 	 lr: 0.00009
[epoch 250: 220/307] 	 train loss: 0.057619 	 lr: 0.00009
[epoch 250: 240/307] 	 train loss: 0.064400 	 lr: 0.00009
[epoch 250: 260/307] 	 train loss: 0.071512 	 lr: 0.00009

val loss: 0.347311 	 acc: 0.915721

[epoch 250: 280/307] 	 train loss: 0.065358 	 lr: 0.00009
[epoch 250: 300/307] 	 train loss: 0.036376 	 lr: 0.00009
[epoch 251:   0/307] 	 train loss: 0.093092 	 lr: 0.00009
[epoch 251:  20/307] 	 train loss: 0.073967 	 lr: 0.00009
[epoch 251:  40/307] 	 train loss: 0.331200 	 lr: 0.00009
[epoch 251:  60/307] 	 train loss: 0.075730 	 lr: 0.00009
[epoch 251:  80/307] 	 train loss: 0.038725 	 lr: 0.00009
[epoch 251: 100/307] 	 train loss: 0.140034 	 lr: 0.00009

val loss: 0.338702 	 acc: 0.914506

[epoch 251: 120/307] 	 train loss: 0.035702 	 lr: 0.00009
[epoch 251: 140/307] 	 train loss: 0.112537 	 lr: 0.00009
[epoch 251: 160/307] 	 train loss: 0.047269 	 lr: 0.00009
[epoch 251: 180/307] 	 train loss: 0.116221 	 lr: 0.00009
[epoch 251: 200/307] 	 train loss: 0.045050 	 lr: 0.00009
[epoch 251: 220/307] 	 train loss: 0.015540 	 lr: 0.00009
[epoch 251: 240/307] 	 train loss: 0.101210 	 lr: 0.00009
[epoch 251: 260/307] 	 train loss: 0.078022 	 lr: 0.00009

val loss: 0.328310 	 acc: 0.918558

[epoch 251: 280/307] 	 train loss: 0.055925 	 lr: 0.00009
[epoch 251: 300/307] 	 train loss: 0.014600 	 lr: 0.00009
[epoch 252:   0/307] 	 train loss: 0.055409 	 lr: 0.00009
[epoch 252:  20/307] 	 train loss: 0.164853 	 lr: 0.00009
[epoch 252:  40/307] 	 train loss: 0.062764 	 lr: 0.00009
[epoch 252:  60/307] 	 train loss: 0.075429 	 lr: 0.00009
[epoch 252:  80/307] 	 train loss: 0.141797 	 lr: 0.00009
[epoch 252: 100/307] 	 train loss: 0.074072 	 lr: 0.00009

val loss: 0.331114 	 acc: 0.916532

[epoch 252: 120/307] 	 train loss: 0.120486 	 lr: 0.00009
[epoch 252: 140/307] 	 train loss: 0.113741 	 lr: 0.00009
[epoch 252: 160/307] 	 train loss: 0.123155 	 lr: 0.00009
[epoch 252: 180/307] 	 train loss: 0.086105 	 lr: 0.00009
[epoch 252: 200/307] 	 train loss: 0.123267 	 lr: 0.00009
[epoch 252: 220/307] 	 train loss: 0.050530 	 lr: 0.00009
[epoch 252: 240/307] 	 train loss: 0.116440 	 lr: 0.00009
[epoch 252: 260/307] 	 train loss: 0.072700 	 lr: 0.00009

val loss: 0.327013 	 acc: 0.917747

[epoch 252: 280/307] 	 train loss: 0.124216 	 lr: 0.00009
[epoch 252: 300/307] 	 train loss: 0.119320 	 lr: 0.00009
[epoch 253:   0/307] 	 train loss: 0.050191 	 lr: 0.00007
[epoch 253:  20/307] 	 train loss: 0.092804 	 lr: 0.00007
[epoch 253:  40/307] 	 train loss: 0.142873 	 lr: 0.00007
[epoch 253:  60/307] 	 train loss: 0.046777 	 lr: 0.00007
[epoch 253:  80/307] 	 train loss: 0.143833 	 lr: 0.00007
[epoch 253: 100/307] 	 train loss: 0.153579 	 lr: 0.00007

val loss: 0.330504 	 acc: 0.915721

[epoch 253: 120/307] 	 train loss: 0.066555 	 lr: 0.00007
[epoch 253: 140/307] 	 train loss: 0.035097 	 lr: 0.00007
[epoch 253: 160/307] 	 train loss: 0.004267 	 lr: 0.00007
[epoch 253: 180/307] 	 train loss: 0.024042 	 lr: 0.00007
[epoch 253: 200/307] 	 train loss: 0.207892 	 lr: 0.00007
[epoch 253: 220/307] 	 train loss: 0.120245 	 lr: 0.00007
[epoch 253: 240/307] 	 train loss: 0.050159 	 lr: 0.00007
[epoch 253: 260/307] 	 train loss: 0.073188 	 lr: 0.00007

val loss: 0.336913 	 acc: 0.915316

[epoch 253: 280/307] 	 train loss: 0.051644 	 lr: 0.00007
[epoch 253: 300/307] 	 train loss: 0.073710 	 lr: 0.00007
[epoch 254:   0/307] 	 train loss: 0.062171 	 lr: 0.00007
[epoch 254:  20/307] 	 train loss: 0.006378 	 lr: 0.00007
[epoch 254:  40/307] 	 train loss: 0.088019 	 lr: 0.00007
[epoch 254:  60/307] 	 train loss: 0.080595 	 lr: 0.00007
[epoch 254:  80/307] 	 train loss: 0.020628 	 lr: 0.00007
[epoch 254: 100/307] 	 train loss: 0.046247 	 lr: 0.00007

val loss: 0.337008 	 acc: 0.917342

[epoch 254: 120/307] 	 train loss: 0.037559 	 lr: 0.00007
[epoch 254: 140/307] 	 train loss: 0.061252 	 lr: 0.00007
[epoch 254: 160/307] 	 train loss: 0.112768 	 lr: 0.00007
[epoch 254: 180/307] 	 train loss: 0.191091 	 lr: 0.00007
[epoch 254: 200/307] 	 train loss: 0.044400 	 lr: 0.00007
[epoch 254: 220/307] 	 train loss: 0.030488 	 lr: 0.00007
[epoch 254: 240/307] 	 train loss: 0.037274 	 lr: 0.00007

val loss: 0.333490 	 acc: 0.920178

[epoch 254: 260/307] 	 train loss: 0.043830 	 lr: 0.00007
[epoch 254: 280/307] 	 train loss: 0.149013 	 lr: 0.00007
[epoch 254: 300/307] 	 train loss: 0.034028 	 lr: 0.00007
[epoch 255:   0/307] 	 train loss: 0.041082 	 lr: 0.00007
[epoch 255:  20/307] 	 train loss: 0.030937 	 lr: 0.00007
[epoch 255:  40/307] 	 train loss: 0.034824 	 lr: 0.00007
[epoch 255:  60/307] 	 train loss: 0.050024 	 lr: 0.00007
[epoch 255:  80/307] 	 train loss: 0.032593 	 lr: 0.00007
[epoch 255: 100/307] 	 train loss: 0.033670 	 lr: 0.00007

val loss: 0.330077 	 acc: 0.917342

[epoch 255: 120/307] 	 train loss: 0.023330 	 lr: 0.00007
[epoch 255: 140/307] 	 train loss: 0.187712 	 lr: 0.00007
[epoch 255: 160/307] 	 train loss: 0.013037 	 lr: 0.00007
[epoch 255: 180/307] 	 train loss: 0.096647 	 lr: 0.00007
[epoch 255: 200/307] 	 train loss: 0.151088 	 lr: 0.00007
[epoch 255: 220/307] 	 train loss: 0.246330 	 lr: 0.00007
[epoch 255: 240/307] 	 train loss: 0.063425 	 lr: 0.00007

val loss: 0.328503 	 acc: 0.917747

[epoch 255: 260/307] 	 train loss: 0.034534 	 lr: 0.00007
[epoch 255: 280/307] 	 train loss: 0.100644 	 lr: 0.00007
[epoch 255: 300/307] 	 train loss: 0.086211 	 lr: 0.00007
[epoch 256:   0/307] 	 train loss: 0.095972 	 lr: 0.00007
[epoch 256:  20/307] 	 train loss: 0.110109 	 lr: 0.00007
[epoch 256:  40/307] 	 train loss: 0.115308 	 lr: 0.00007
[epoch 256:  60/307] 	 train loss: 0.384627 	 lr: 0.00007
[epoch 256:  80/307] 	 train loss: 0.166098 	 lr: 0.00007
[epoch 256: 100/307] 	 train loss: 0.031314 	 lr: 0.00007

val loss: 0.330250 	 acc: 0.918152

[epoch 256: 120/307] 	 train loss: 0.067699 	 lr: 0.00007
[epoch 256: 140/307] 	 train loss: 0.076048 	 lr: 0.00007
[epoch 256: 160/307] 	 train loss: 0.059230 	 lr: 0.00007
[epoch 256: 180/307] 	 train loss: 0.154119 	 lr: 0.00007
[epoch 256: 200/307] 	 train loss: 0.043066 	 lr: 0.00007
[epoch 256: 220/307] 	 train loss: 0.155519 	 lr: 0.00007
[epoch 256: 240/307] 	 train loss: 0.123160 	 lr: 0.00007

val loss: 0.333977 	 acc: 0.917342

[epoch 256: 260/307] 	 train loss: 0.355843 	 lr: 0.00007
[epoch 256: 280/307] 	 train loss: 0.050972 	 lr: 0.00007
[epoch 256: 300/307] 	 train loss: 0.078133 	 lr: 0.00007
[epoch 257:   0/307] 	 train loss: 0.027410 	 lr: 0.00007
[epoch 257:  20/307] 	 train loss: 0.079677 	 lr: 0.00007
[epoch 257:  40/307] 	 train loss: 0.113999 	 lr: 0.00007
[epoch 257:  60/307] 	 train loss: 0.044676 	 lr: 0.00007
[epoch 257:  80/307] 	 train loss: 0.093369 	 lr: 0.00007

val loss: 0.330367 	 acc: 0.916937

[epoch 257: 100/307] 	 train loss: 0.039835 	 lr: 0.00007
[epoch 257: 120/307] 	 train loss: 0.267306 	 lr: 0.00007
[epoch 257: 140/307] 	 train loss: 0.089123 	 lr: 0.00007
[epoch 257: 160/307] 	 train loss: 0.013592 	 lr: 0.00007
[epoch 257: 180/307] 	 train loss: 0.165626 	 lr: 0.00007
[epoch 257: 200/307] 	 train loss: 0.069338 	 lr: 0.00007
[epoch 257: 220/307] 	 train loss: 0.177389 	 lr: 0.00007
[epoch 257: 240/307] 	 train loss: 0.063929 	 lr: 0.00007

val loss: 0.332057 	 acc: 0.916532

[epoch 257: 260/307] 	 train loss: 0.146053 	 lr: 0.00007
[epoch 257: 280/307] 	 train loss: 0.110562 	 lr: 0.00007
[epoch 257: 300/307] 	 train loss: 0.074626 	 lr: 0.00007
[epoch 258:   0/307] 	 train loss: 0.081049 	 lr: 0.00007
[epoch 258:  20/307] 	 train loss: 0.020314 	 lr: 0.00007
[epoch 258:  40/307] 	 train loss: 0.027893 	 lr: 0.00007
[epoch 258:  60/307] 	 train loss: 0.156336 	 lr: 0.00007
[epoch 258:  80/307] 	 train loss: 0.054034 	 lr: 0.00007

val loss: 0.333939 	 acc: 0.917747

[epoch 258: 100/307] 	 train loss: 0.033439 	 lr: 0.00007
[epoch 258: 120/307] 	 train loss: 0.130061 	 lr: 0.00007
[epoch 258: 140/307] 	 train loss: 0.055734 	 lr: 0.00007
[epoch 258: 160/307] 	 train loss: 0.115786 	 lr: 0.00007
[epoch 258: 180/307] 	 train loss: 0.056557 	 lr: 0.00007
[epoch 258: 200/307] 	 train loss: 0.041577 	 lr: 0.00007
[epoch 258: 220/307] 	 train loss: 0.037900 	 lr: 0.00007
[epoch 258: 240/307] 	 train loss: 0.083446 	 lr: 0.00007

val loss: 0.330917 	 acc: 0.915316

[epoch 258: 260/307] 	 train loss: 0.057839 	 lr: 0.00007
[epoch 258: 280/307] 	 train loss: 0.203995 	 lr: 0.00007
[epoch 258: 300/307] 	 train loss: 0.332257 	 lr: 0.00007
[epoch 259:   0/307] 	 train loss: 0.200661 	 lr: 0.00007
[epoch 259:  20/307] 	 train loss: 0.140735 	 lr: 0.00007
[epoch 259:  40/307] 	 train loss: 0.102982 	 lr: 0.00007
[epoch 259:  60/307] 	 train loss: 0.118083 	 lr: 0.00007
[epoch 259:  80/307] 	 train loss: 0.024616 	 lr: 0.00007

val loss: 0.334549 	 acc: 0.916126

[epoch 259: 100/307] 	 train loss: 0.017505 	 lr: 0.00007
[epoch 259: 120/307] 	 train loss: 0.136977 	 lr: 0.00007
[epoch 259: 140/307] 	 train loss: 0.094067 	 lr: 0.00007
[epoch 259: 160/307] 	 train loss: 0.078355 	 lr: 0.00007
[epoch 259: 180/307] 	 train loss: 0.088538 	 lr: 0.00007
[epoch 259: 200/307] 	 train loss: 0.193362 	 lr: 0.00007
[epoch 259: 220/307] 	 train loss: 0.065742 	 lr: 0.00007
[epoch 259: 240/307] 	 train loss: 0.104200 	 lr: 0.00007

val loss: 0.325501 	 acc: 0.918963

[epoch 259: 260/307] 	 train loss: 0.051487 	 lr: 0.00007
[epoch 259: 280/307] 	 train loss: 0.025683 	 lr: 0.00007
[epoch 259: 300/307] 	 train loss: 0.087972 	 lr: 0.00007
[epoch 260:   0/307] 	 train loss: 0.093764 	 lr: 0.00007
[epoch 260:  20/307] 	 train loss: 0.083924 	 lr: 0.00007
[epoch 260:  40/307] 	 train loss: 0.130431 	 lr: 0.00007
[epoch 260:  60/307] 	 train loss: 0.048473 	 lr: 0.00007
[epoch 260:  80/307] 	 train loss: 0.043266 	 lr: 0.00007

val loss: 0.333966 	 acc: 0.917342

[epoch 260: 100/307] 	 train loss: 0.069592 	 lr: 0.00007
[epoch 260: 120/307] 	 train loss: 0.068258 	 lr: 0.00007
[epoch 260: 140/307] 	 train loss: 0.091384 	 lr: 0.00007
[epoch 260: 160/307] 	 train loss: 0.050012 	 lr: 0.00007
[epoch 260: 180/307] 	 train loss: 0.356667 	 lr: 0.00007
[epoch 260: 200/307] 	 train loss: 0.106491 	 lr: 0.00007
[epoch 260: 220/307] 	 train loss: 0.093566 	 lr: 0.00007
[epoch 260: 240/307] 	 train loss: 0.027098 	 lr: 0.00007

val loss: 0.329241 	 acc: 0.916937

[epoch 260: 260/307] 	 train loss: 0.063186 	 lr: 0.00007
[epoch 260: 280/307] 	 train loss: 0.155528 	 lr: 0.00007
[epoch 260: 300/307] 	 train loss: 0.103405 	 lr: 0.00007
[epoch 261:   0/307] 	 train loss: 0.028616 	 lr: 0.00007
[epoch 261:  20/307] 	 train loss: 0.059452 	 lr: 0.00007
[epoch 261:  40/307] 	 train loss: 0.118786 	 lr: 0.00007
[epoch 261:  60/307] 	 train loss: 0.123252 	 lr: 0.00007
[epoch 261:  80/307] 	 train loss: 0.123892 	 lr: 0.00007

val loss: 0.329765 	 acc: 0.918963

[epoch 261: 100/307] 	 train loss: 0.048610 	 lr: 0.00007
[epoch 261: 120/307] 	 train loss: 0.107850 	 lr: 0.00007
[epoch 261: 140/307] 	 train loss: 0.046294 	 lr: 0.00007
[epoch 261: 160/307] 	 train loss: 0.142834 	 lr: 0.00007
[epoch 261: 180/307] 	 train loss: 0.022596 	 lr: 0.00007
[epoch 261: 200/307] 	 train loss: 0.061121 	 lr: 0.00007
[epoch 261: 220/307] 	 train loss: 0.087575 	 lr: 0.00007
[epoch 261: 240/307] 	 train loss: 0.051835 	 lr: 0.00007

val loss: 0.331513 	 acc: 0.915721

[epoch 261: 260/307] 	 train loss: 0.026217 	 lr: 0.00007
[epoch 261: 280/307] 	 train loss: 0.035984 	 lr: 0.00007
[epoch 261: 300/307] 	 train loss: 0.067030 	 lr: 0.00007
[epoch 262:   0/307] 	 train loss: 0.047147 	 lr: 0.00007
[epoch 262:  20/307] 	 train loss: 0.101381 	 lr: 0.00007
[epoch 262:  40/307] 	 train loss: 0.084735 	 lr: 0.00007
[epoch 262:  60/307] 	 train loss: 0.212448 	 lr: 0.00007
[epoch 262:  80/307] 	 train loss: 0.005208 	 lr: 0.00007

val loss: 0.338158 	 acc: 0.916126

[epoch 262: 100/307] 	 train loss: 0.045491 	 lr: 0.00007
[epoch 262: 120/307] 	 train loss: 0.018203 	 lr: 0.00007
[epoch 262: 140/307] 	 train loss: 0.083958 	 lr: 0.00007
[epoch 262: 160/307] 	 train loss: 0.043696 	 lr: 0.00007
[epoch 262: 180/307] 	 train loss: 0.035013 	 lr: 0.00007
[epoch 262: 200/307] 	 train loss: 0.162790 	 lr: 0.00007
[epoch 262: 220/307] 	 train loss: 0.011211 	 lr: 0.00007
[epoch 262: 240/307] 	 train loss: 0.106882 	 lr: 0.00007

val loss: 0.331660 	 acc: 0.917747

[epoch 262: 260/307] 	 train loss: 0.119054 	 lr: 0.00007
[epoch 262: 280/307] 	 train loss: 0.411856 	 lr: 0.00007
[epoch 262: 300/307] 	 train loss: 0.266830 	 lr: 0.00007
[epoch 263:   0/307] 	 train loss: 0.120416 	 lr: 0.00007
[epoch 263:  20/307] 	 train loss: 0.039488 	 lr: 0.00007
[epoch 263:  40/307] 	 train loss: 0.128495 	 lr: 0.00007
[epoch 263:  60/307] 	 train loss: 0.009984 	 lr: 0.00007
[epoch 263:  80/307] 	 train loss: 0.195139 	 lr: 0.00007

val loss: 0.325414 	 acc: 0.919773

[epoch 263: 100/307] 	 train loss: 0.065754 	 lr: 0.00007
[epoch 263: 120/307] 	 train loss: 0.221945 	 lr: 0.00007
[epoch 263: 140/307] 	 train loss: 0.128414 	 lr: 0.00007
[epoch 263: 160/307] 	 train loss: 0.022239 	 lr: 0.00007
[epoch 263: 180/307] 	 train loss: 0.032358 	 lr: 0.00007
[epoch 263: 200/307] 	 train loss: 0.175250 	 lr: 0.00007
[epoch 263: 220/307] 	 train loss: 0.124286 	 lr: 0.00007
[epoch 263: 240/307] 	 train loss: 0.021980 	 lr: 0.00007

val loss: 0.323811 	 acc: 0.918558

[epoch 263: 260/307] 	 train loss: 0.160589 	 lr: 0.00007
[epoch 263: 280/307] 	 train loss: 0.028057 	 lr: 0.00007
[epoch 263: 300/307] 	 train loss: 0.134020 	 lr: 0.00007
[epoch 264:   0/307] 	 train loss: 0.033985 	 lr: 0.00007
[epoch 264:  20/307] 	 train loss: 0.043641 	 lr: 0.00007
[epoch 264:  40/307] 	 train loss: 0.218290 	 lr: 0.00007
[epoch 264:  60/307] 	 train loss: 0.124065 	 lr: 0.00007
[epoch 264:  80/307] 	 train loss: 0.171695 	 lr: 0.00007

val loss: 0.329258 	 acc: 0.917342

[epoch 264: 100/307] 	 train loss: 0.111688 	 lr: 0.00007
[epoch 264: 120/307] 	 train loss: 0.049004 	 lr: 0.00007
[epoch 264: 140/307] 	 train loss: 0.060905 	 lr: 0.00007
[epoch 264: 160/307] 	 train loss: 0.042119 	 lr: 0.00007
[epoch 264: 180/307] 	 train loss: 0.247113 	 lr: 0.00007
[epoch 264: 200/307] 	 train loss: 0.061364 	 lr: 0.00007
[epoch 264: 220/307] 	 train loss: 0.056532 	 lr: 0.00007

val loss: 0.332105 	 acc: 0.919368

[epoch 264: 240/307] 	 train loss: 0.073029 	 lr: 0.00007
[epoch 264: 260/307] 	 train loss: 0.051344 	 lr: 0.00007
[epoch 264: 280/307] 	 train loss: 0.011460 	 lr: 0.00007
[epoch 264: 300/307] 	 train loss: 0.078997 	 lr: 0.00007
[epoch 265:   0/307] 	 train loss: 0.301477 	 lr: 0.00007
[epoch 265:  20/307] 	 train loss: 0.052142 	 lr: 0.00007
[epoch 265:  40/307] 	 train loss: 0.144361 	 lr: 0.00007
[epoch 265:  60/307] 	 train loss: 0.167190 	 lr: 0.00007
[epoch 265:  80/307] 	 train loss: 0.183811 	 lr: 0.00007

val loss: 0.332993 	 acc: 0.916126

[epoch 265: 100/307] 	 train loss: 0.051437 	 lr: 0.00007
[epoch 265: 120/307] 	 train loss: 0.082209 	 lr: 0.00007
[epoch 265: 140/307] 	 train loss: 0.266085 	 lr: 0.00007
[epoch 265: 160/307] 	 train loss: 0.133558 	 lr: 0.00007
[epoch 265: 180/307] 	 train loss: 0.115643 	 lr: 0.00007
[epoch 265: 200/307] 	 train loss: 0.093027 	 lr: 0.00007
[epoch 265: 220/307] 	 train loss: 0.266753 	 lr: 0.00007

val loss: 0.334079 	 acc: 0.916937

[epoch 265: 240/307] 	 train loss: 0.113334 	 lr: 0.00007
[epoch 265: 260/307] 	 train loss: 0.004336 	 lr: 0.00007
[epoch 265: 280/307] 	 train loss: 0.176203 	 lr: 0.00007
[epoch 265: 300/307] 	 train loss: 0.032873 	 lr: 0.00007
[epoch 266:   0/307] 	 train loss: 0.087967 	 lr: 0.00007
[epoch 266:  20/307] 	 train loss: 0.014310 	 lr: 0.00007
[epoch 266:  40/307] 	 train loss: 0.066360 	 lr: 0.00007
[epoch 266:  60/307] 	 train loss: 0.075762 	 lr: 0.00007
[epoch 266:  80/307] 	 train loss: 0.066599 	 lr: 0.00007

val loss: 0.332856 	 acc: 0.916532

[epoch 266: 100/307] 	 train loss: 0.206226 	 lr: 0.00007
[epoch 266: 120/307] 	 train loss: 0.091439 	 lr: 0.00007
[epoch 266: 140/307] 	 train loss: 0.193994 	 lr: 0.00007
[epoch 266: 160/307] 	 train loss: 0.288923 	 lr: 0.00007
[epoch 266: 180/307] 	 train loss: 0.014926 	 lr: 0.00007
[epoch 266: 200/307] 	 train loss: 0.116472 	 lr: 0.00007
[epoch 266: 220/307] 	 train loss: 0.055266 	 lr: 0.00007

val loss: 0.336167 	 acc: 0.915316

[epoch 266: 240/307] 	 train loss: 0.045937 	 lr: 0.00007
[epoch 266: 260/307] 	 train loss: 0.071418 	 lr: 0.00007
[epoch 266: 280/307] 	 train loss: 0.102482 	 lr: 0.00007
[epoch 266: 300/307] 	 train loss: 0.083315 	 lr: 0.00007
[epoch 267:   0/307] 	 train loss: 0.007233 	 lr: 0.00007
[epoch 267:  20/307] 	 train loss: 0.277930 	 lr: 0.00007
[epoch 267:  40/307] 	 train loss: 0.089763 	 lr: 0.00007
[epoch 267:  60/307] 	 train loss: 0.086837 	 lr: 0.00007

val loss: 0.332489 	 acc: 0.918152

[epoch 267:  80/307] 	 train loss: 0.044780 	 lr: 0.00007
[epoch 267: 100/307] 	 train loss: 0.037231 	 lr: 0.00007
[epoch 267: 120/307] 	 train loss: 0.066872 	 lr: 0.00007
[epoch 267: 140/307] 	 train loss: 0.066523 	 lr: 0.00007
[epoch 267: 160/307] 	 train loss: 0.054058 	 lr: 0.00007
[epoch 267: 180/307] 	 train loss: 0.024556 	 lr: 0.00007
[epoch 267: 200/307] 	 train loss: 0.168904 	 lr: 0.00007
[epoch 267: 220/307] 	 train loss: 0.041940 	 lr: 0.00007

val loss: 0.337400 	 acc: 0.915721

[epoch 267: 240/307] 	 train loss: 0.173642 	 lr: 0.00007
[epoch 267: 260/307] 	 train loss: 0.069737 	 lr: 0.00007
[epoch 267: 280/307] 	 train loss: 0.091887 	 lr: 0.00007
[epoch 267: 300/307] 	 train loss: 0.035275 	 lr: 0.00007
[epoch 268:   0/307] 	 train loss: 0.049893 	 lr: 0.00007
[epoch 268:  20/307] 	 train loss: 0.126904 	 lr: 0.00007
[epoch 268:  40/307] 	 train loss: 0.024740 	 lr: 0.00007
[epoch 268:  60/307] 	 train loss: 0.109824 	 lr: 0.00007

val loss: 0.333323 	 acc: 0.918152

[epoch 268:  80/307] 	 train loss: 0.038694 	 lr: 0.00007
[epoch 268: 100/307] 	 train loss: 0.172555 	 lr: 0.00007
[epoch 268: 120/307] 	 train loss: 0.088817 	 lr: 0.00007
[epoch 268: 140/307] 	 train loss: 0.023514 	 lr: 0.00007
[epoch 268: 160/307] 	 train loss: 0.151033 	 lr: 0.00007
[epoch 268: 180/307] 	 train loss: 0.182175 	 lr: 0.00007
[epoch 268: 200/307] 	 train loss: 0.165642 	 lr: 0.00007
[epoch 268: 220/307] 	 train loss: 0.015011 	 lr: 0.00007

val loss: 0.337044 	 acc: 0.916126

[epoch 268: 240/307] 	 train loss: 0.054628 	 lr: 0.00007
[epoch 268: 260/307] 	 train loss: 0.129785 	 lr: 0.00007
[epoch 268: 280/307] 	 train loss: 0.041976 	 lr: 0.00007
[epoch 268: 300/307] 	 train loss: 0.307327 	 lr: 0.00007
[epoch 269:   0/307] 	 train loss: 0.112773 	 lr: 0.00007
[epoch 269:  20/307] 	 train loss: 0.090463 	 lr: 0.00007
[epoch 269:  40/307] 	 train loss: 0.038995 	 lr: 0.00007
[epoch 269:  60/307] 	 train loss: 0.096747 	 lr: 0.00007

val loss: 0.335386 	 acc: 0.916937

[epoch 269:  80/307] 	 train loss: 0.417373 	 lr: 0.00007
[epoch 269: 100/307] 	 train loss: 0.081619 	 lr: 0.00007
[epoch 269: 120/307] 	 train loss: 0.102347 	 lr: 0.00007
[epoch 269: 140/307] 	 train loss: 0.025066 	 lr: 0.00007
[epoch 269: 160/307] 	 train loss: 0.059880 	 lr: 0.00007
[epoch 269: 180/307] 	 train loss: 0.255582 	 lr: 0.00007
[epoch 269: 200/307] 	 train loss: 0.120941 	 lr: 0.00007
[epoch 269: 220/307] 	 train loss: 0.037630 	 lr: 0.00007

val loss: 0.335104 	 acc: 0.914100

[epoch 269: 240/307] 	 train loss: 0.056412 	 lr: 0.00007
[epoch 269: 260/307] 	 train loss: 0.095109 	 lr: 0.00007
[epoch 269: 280/307] 	 train loss: 0.050624 	 lr: 0.00007
[epoch 269: 300/307] 	 train loss: 0.112066 	 lr: 0.00007
[epoch 270:   0/307] 	 train loss: 0.083472 	 lr: 0.00007
[epoch 270:  20/307] 	 train loss: 0.060949 	 lr: 0.00007
[epoch 270:  40/307] 	 train loss: 0.041964 	 lr: 0.00007
[epoch 270:  60/307] 	 train loss: 0.137114 	 lr: 0.00007

val loss: 0.337491 	 acc: 0.915316

[epoch 270:  80/307] 	 train loss: 0.045547 	 lr: 0.00007
[epoch 270: 100/307] 	 train loss: 0.048836 	 lr: 0.00007
[epoch 270: 120/307] 	 train loss: 0.069052 	 lr: 0.00007
[epoch 270: 140/307] 	 train loss: 0.123590 	 lr: 0.00007
[epoch 270: 160/307] 	 train loss: 0.013579 	 lr: 0.00007
[epoch 270: 180/307] 	 train loss: 0.029538 	 lr: 0.00007
[epoch 270: 200/307] 	 train loss: 0.463871 	 lr: 0.00007
[epoch 270: 220/307] 	 train loss: 0.216372 	 lr: 0.00007

val loss: 0.332441 	 acc: 0.916937

[epoch 270: 240/307] 	 train loss: 0.015541 	 lr: 0.00007
[epoch 270: 260/307] 	 train loss: 0.025404 	 lr: 0.00007
[epoch 270: 280/307] 	 train loss: 0.059179 	 lr: 0.00007
[epoch 270: 300/307] 	 train loss: 0.027512 	 lr: 0.00007
[epoch 271:   0/307] 	 train loss: 0.036764 	 lr: 0.00007
[epoch 271:  20/307] 	 train loss: 0.040477 	 lr: 0.00007
[epoch 271:  40/307] 	 train loss: 0.165452 	 lr: 0.00007
[epoch 271:  60/307] 	 train loss: 0.123626 	 lr: 0.00007

val loss: 0.342173 	 acc: 0.913290

[epoch 271:  80/307] 	 train loss: 0.036876 	 lr: 0.00007
[epoch 271: 100/307] 	 train loss: 0.008676 	 lr: 0.00007
[epoch 271: 120/307] 	 train loss: 0.197364 	 lr: 0.00007
[epoch 271: 140/307] 	 train loss: 0.043569 	 lr: 0.00007
[epoch 271: 160/307] 	 train loss: 0.399275 	 lr: 0.00007
[epoch 271: 180/307] 	 train loss: 0.094984 	 lr: 0.00007
[epoch 271: 200/307] 	 train loss: 0.070606 	 lr: 0.00007
[epoch 271: 220/307] 	 train loss: 0.047592 	 lr: 0.00007

val loss: 0.342434 	 acc: 0.912885

[epoch 271: 240/307] 	 train loss: 0.007778 	 lr: 0.00007
[epoch 271: 260/307] 	 train loss: 0.180759 	 lr: 0.00007
[epoch 271: 280/307] 	 train loss: 0.144910 	 lr: 0.00007
[epoch 271: 300/307] 	 train loss: 0.023851 	 lr: 0.00007
[epoch 272:   0/307] 	 train loss: 0.018192 	 lr: 0.00007
[epoch 272:  20/307] 	 train loss: 0.094700 	 lr: 0.00007
[epoch 272:  40/307] 	 train loss: 0.253902 	 lr: 0.00007
[epoch 272:  60/307] 	 train loss: 0.088385 	 lr: 0.00007

val loss: 0.342017 	 acc: 0.916937

[epoch 272:  80/307] 	 train loss: 0.203951 	 lr: 0.00007
[epoch 272: 100/307] 	 train loss: 0.151133 	 lr: 0.00007
[epoch 272: 120/307] 	 train loss: 0.058459 	 lr: 0.00007
[epoch 272: 140/307] 	 train loss: 0.060804 	 lr: 0.00007
[epoch 272: 160/307] 	 train loss: 0.201425 	 lr: 0.00007
[epoch 272: 180/307] 	 train loss: 0.077254 	 lr: 0.00007
[epoch 272: 200/307] 	 train loss: 0.096774 	 lr: 0.00007
[epoch 272: 220/307] 	 train loss: 0.107417 	 lr: 0.00007

val loss: 0.335798 	 acc: 0.918152

[epoch 272: 240/307] 	 train loss: 0.062129 	 lr: 0.00007
[epoch 272: 260/307] 	 train loss: 0.143254 	 lr: 0.00007
[epoch 272: 280/307] 	 train loss: 0.014772 	 lr: 0.00007
[epoch 272: 300/307] 	 train loss: 0.180405 	 lr: 0.00007
[epoch 273:   0/307] 	 train loss: 0.149116 	 lr: 0.00007
[epoch 273:  20/307] 	 train loss: 0.045224 	 lr: 0.00007
[epoch 273:  40/307] 	 train loss: 0.139689 	 lr: 0.00007
[epoch 273:  60/307] 	 train loss: 0.066082 	 lr: 0.00007

val loss: 0.336363 	 acc: 0.914911

[epoch 273:  80/307] 	 train loss: 0.085843 	 lr: 0.00007
[epoch 273: 100/307] 	 train loss: 0.179060 	 lr: 0.00007
[epoch 273: 120/307] 	 train loss: 0.104207 	 lr: 0.00007
[epoch 273: 140/307] 	 train loss: 0.042151 	 lr: 0.00007
[epoch 273: 160/307] 	 train loss: 0.160553 	 lr: 0.00007
[epoch 273: 180/307] 	 train loss: 0.106290 	 lr: 0.00007
[epoch 273: 200/307] 	 train loss: 0.038112 	 lr: 0.00007
[epoch 273: 220/307] 	 train loss: 0.269151 	 lr: 0.00007

val loss: 0.335016 	 acc: 0.917747

[epoch 273: 240/307] 	 train loss: 0.068401 	 lr: 0.00007
[epoch 273: 260/307] 	 train loss: 0.116596 	 lr: 0.00007
[epoch 273: 280/307] 	 train loss: 0.116242 	 lr: 0.00007
[epoch 273: 300/307] 	 train loss: 0.014214 	 lr: 0.00007
[epoch 274:   0/307] 	 train loss: 0.134650 	 lr: 0.00005
[epoch 274:  20/307] 	 train loss: 0.180225 	 lr: 0.00005
[epoch 274:  40/307] 	 train loss: 0.107829 	 lr: 0.00005
[epoch 274:  60/307] 	 train loss: 0.166544 	 lr: 0.00005

val loss: 0.336118 	 acc: 0.919773

[epoch 274:  80/307] 	 train loss: 0.159599 	 lr: 0.00005
[epoch 274: 100/307] 	 train loss: 0.113768 	 lr: 0.00005
[epoch 274: 120/307] 	 train loss: 0.062572 	 lr: 0.00005
[epoch 274: 140/307] 	 train loss: 0.045841 	 lr: 0.00005
[epoch 274: 160/307] 	 train loss: 0.123459 	 lr: 0.00005
[epoch 274: 180/307] 	 train loss: 0.181353 	 lr: 0.00005
[epoch 274: 200/307] 	 train loss: 0.112864 	 lr: 0.00005

val loss: 0.335955 	 acc: 0.917342

[epoch 274: 220/307] 	 train loss: 0.142644 	 lr: 0.00005
[epoch 274: 240/307] 	 train loss: 0.046835 	 lr: 0.00005
[epoch 274: 260/307] 	 train loss: 0.017492 	 lr: 0.00005
[epoch 274: 280/307] 	 train loss: 0.058889 	 lr: 0.00005
[epoch 274: 300/307] 	 train loss: 0.203540 	 lr: 0.00005
[epoch 275:   0/307] 	 train loss: 0.027572 	 lr: 0.00005
[epoch 275:  20/307] 	 train loss: 0.186515 	 lr: 0.00005
[epoch 275:  40/307] 	 train loss: 0.051084 	 lr: 0.00005
[epoch 275:  60/307] 	 train loss: 0.014156 	 lr: 0.00005

val loss: 0.339548 	 acc: 0.918152

[epoch 275:  80/307] 	 train loss: 0.157069 	 lr: 0.00005
[epoch 275: 100/307] 	 train loss: 0.088241 	 lr: 0.00005
[epoch 275: 120/307] 	 train loss: 0.067325 	 lr: 0.00005
[epoch 275: 140/307] 	 train loss: 0.193986 	 lr: 0.00005
[epoch 275: 160/307] 	 train loss: 0.057370 	 lr: 0.00005
[epoch 275: 180/307] 	 train loss: 0.022610 	 lr: 0.00005
[epoch 275: 200/307] 	 train loss: 0.031111 	 lr: 0.00005

val loss: 0.333254 	 acc: 0.920583

[epoch 275: 220/307] 	 train loss: 0.131727 	 lr: 0.00005
[epoch 275: 240/307] 	 train loss: 0.253585 	 lr: 0.00005
[epoch 275: 260/307] 	 train loss: 0.106868 	 lr: 0.00005
[epoch 275: 280/307] 	 train loss: 0.221148 	 lr: 0.00005
[epoch 275: 300/307] 	 train loss: 0.168576 	 lr: 0.00005
[epoch 276:   0/307] 	 train loss: 0.105691 	 lr: 0.00005
[epoch 276:  20/307] 	 train loss: 0.250130 	 lr: 0.00005
[epoch 276:  40/307] 	 train loss: 0.013184 	 lr: 0.00005
[epoch 276:  60/307] 	 train loss: 0.037321 	 lr: 0.00005

val loss: 0.331696 	 acc: 0.922609

[epoch 276:  80/307] 	 train loss: 0.300109 	 lr: 0.00005
[epoch 276: 100/307] 	 train loss: 0.003552 	 lr: 0.00005
[epoch 276: 120/307] 	 train loss: 0.044006 	 lr: 0.00005
[epoch 276: 140/307] 	 train loss: 0.183917 	 lr: 0.00005
[epoch 276: 160/307] 	 train loss: 0.065536 	 lr: 0.00005
[epoch 276: 180/307] 	 train loss: 0.028931 	 lr: 0.00005
[epoch 276: 200/307] 	 train loss: 0.007123 	 lr: 0.00005

val loss: 0.336994 	 acc: 0.916937

[epoch 276: 220/307] 	 train loss: 0.121347 	 lr: 0.00005
[epoch 276: 240/307] 	 train loss: 0.090706 	 lr: 0.00005
[epoch 276: 260/307] 	 train loss: 0.092384 	 lr: 0.00005
[epoch 276: 280/307] 	 train loss: 0.082134 	 lr: 0.00005
[epoch 276: 300/307] 	 train loss: 0.037647 	 lr: 0.00005
[epoch 277:   0/307] 	 train loss: 0.138027 	 lr: 0.00005
[epoch 277:  20/307] 	 train loss: 0.156131 	 lr: 0.00005
[epoch 277:  40/307] 	 train loss: 0.097315 	 lr: 0.00005

val loss: 0.338472 	 acc: 0.918558

[epoch 277:  60/307] 	 train loss: 0.007839 	 lr: 0.00005
[epoch 277:  80/307] 	 train loss: 0.057902 	 lr: 0.00005
[epoch 277: 100/307] 	 train loss: 0.211198 	 lr: 0.00005
[epoch 277: 120/307] 	 train loss: 0.239705 	 lr: 0.00005
[epoch 277: 140/307] 	 train loss: 0.098450 	 lr: 0.00005
[epoch 277: 160/307] 	 train loss: 0.088300 	 lr: 0.00005
[epoch 277: 180/307] 	 train loss: 0.205771 	 lr: 0.00005
[epoch 277: 200/307] 	 train loss: 0.080167 	 lr: 0.00005

val loss: 0.336515 	 acc: 0.919368

[epoch 277: 220/307] 	 train loss: 0.053126 	 lr: 0.00005
[epoch 277: 240/307] 	 train loss: 0.083979 	 lr: 0.00005
[epoch 277: 260/307] 	 train loss: 0.069324 	 lr: 0.00005
[epoch 277: 280/307] 	 train loss: 0.035303 	 lr: 0.00005
[epoch 277: 300/307] 	 train loss: 0.167995 	 lr: 0.00005
[epoch 278:   0/307] 	 train loss: 0.088051 	 lr: 0.00005
[epoch 278:  20/307] 	 train loss: 0.111480 	 lr: 0.00005
[epoch 278:  40/307] 	 train loss: 0.138926 	 lr: 0.00005

val loss: 0.336616 	 acc: 0.918963

[epoch 278:  60/307] 	 train loss: 0.033410 	 lr: 0.00005
[epoch 278:  80/307] 	 train loss: 0.031635 	 lr: 0.00005
[epoch 278: 100/307] 	 train loss: 0.101920 	 lr: 0.00005
[epoch 278: 120/307] 	 train loss: 0.031517 	 lr: 0.00005
[epoch 278: 140/307] 	 train loss: 0.094484 	 lr: 0.00005
[epoch 278: 160/307] 	 train loss: 0.016397 	 lr: 0.00005
[epoch 278: 180/307] 	 train loss: 0.096038 	 lr: 0.00005
[epoch 278: 200/307] 	 train loss: 0.011213 	 lr: 0.00005

val loss: 0.337936 	 acc: 0.919368

[epoch 278: 220/307] 	 train loss: 0.068682 	 lr: 0.00005
[epoch 278: 240/307] 	 train loss: 0.010145 	 lr: 0.00005
[epoch 278: 260/307] 	 train loss: 0.096654 	 lr: 0.00005
[epoch 278: 280/307] 	 train loss: 0.023252 	 lr: 0.00005
[epoch 278: 300/307] 	 train loss: 0.003497 	 lr: 0.00005
[epoch 279:   0/307] 	 train loss: 0.058693 	 lr: 0.00005
[epoch 279:  20/307] 	 train loss: 0.017579 	 lr: 0.00005
[epoch 279:  40/307] 	 train loss: 0.032453 	 lr: 0.00005

val loss: 0.332486 	 acc: 0.919368

[epoch 279:  60/307] 	 train loss: 0.021448 	 lr: 0.00005
[epoch 279:  80/307] 	 train loss: 0.132338 	 lr: 0.00005
[epoch 279: 100/307] 	 train loss: 0.192341 	 lr: 0.00005
[epoch 279: 120/307] 	 train loss: 0.072299 	 lr: 0.00005
[epoch 279: 140/307] 	 train loss: 0.062735 	 lr: 0.00005
[epoch 279: 160/307] 	 train loss: 0.186826 	 lr: 0.00005
[epoch 279: 180/307] 	 train loss: 0.033289 	 lr: 0.00005
[epoch 279: 200/307] 	 train loss: 0.088306 	 lr: 0.00005

val loss: 0.340774 	 acc: 0.919368

[epoch 279: 220/307] 	 train loss: 0.115057 	 lr: 0.00005
[epoch 279: 240/307] 	 train loss: 0.080168 	 lr: 0.00005
[epoch 279: 260/307] 	 train loss: 0.131602 	 lr: 0.00005
[epoch 279: 280/307] 	 train loss: 0.065262 	 lr: 0.00005
[epoch 279: 300/307] 	 train loss: 0.091586 	 lr: 0.00005
[epoch 280:   0/307] 	 train loss: 0.040342 	 lr: 0.00005
[epoch 280:  20/307] 	 train loss: 0.065892 	 lr: 0.00005
[epoch 280:  40/307] 	 train loss: 0.133658 	 lr: 0.00005

val loss: 0.340226 	 acc: 0.914911

[epoch 280:  60/307] 	 train loss: 0.095285 	 lr: 0.00005
[epoch 280:  80/307] 	 train loss: 0.229312 	 lr: 0.00005
[epoch 280: 100/307] 	 train loss: 0.031594 	 lr: 0.00005
[epoch 280: 120/307] 	 train loss: 0.408208 	 lr: 0.00005
[epoch 280: 140/307] 	 train loss: 0.010162 	 lr: 0.00005
[epoch 280: 160/307] 	 train loss: 0.101502 	 lr: 0.00005
[epoch 280: 180/307] 	 train loss: 0.089786 	 lr: 0.00005
[epoch 280: 200/307] 	 train loss: 0.059477 	 lr: 0.00005

val loss: 0.342209 	 acc: 0.916937

[epoch 280: 220/307] 	 train loss: 0.061554 	 lr: 0.00005
[epoch 280: 240/307] 	 train loss: 0.114770 	 lr: 0.00005
[epoch 280: 260/307] 	 train loss: 0.233917 	 lr: 0.00005
[epoch 280: 280/307] 	 train loss: 0.322805 	 lr: 0.00005
[epoch 280: 300/307] 	 train loss: 0.156142 	 lr: 0.00005
[epoch 281:   0/307] 	 train loss: 0.084100 	 lr: 0.00005
[epoch 281:  20/307] 	 train loss: 0.117531 	 lr: 0.00005
[epoch 281:  40/307] 	 train loss: 0.068965 	 lr: 0.00005

val loss: 0.347710 	 acc: 0.915316

[epoch 281:  60/307] 	 train loss: 0.041331 	 lr: 0.00005
[epoch 281:  80/307] 	 train loss: 0.131549 	 lr: 0.00005
[epoch 281: 100/307] 	 train loss: 0.098133 	 lr: 0.00005
[epoch 281: 120/307] 	 train loss: 0.102773 	 lr: 0.00005
[epoch 281: 140/307] 	 train loss: 0.051900 	 lr: 0.00005
[epoch 281: 160/307] 	 train loss: 0.071520 	 lr: 0.00005
[epoch 281: 180/307] 	 train loss: 0.155419 	 lr: 0.00005
[epoch 281: 200/307] 	 train loss: 0.007400 	 lr: 0.00005

val loss: 0.343410 	 acc: 0.914911

[epoch 281: 220/307] 	 train loss: 0.128611 	 lr: 0.00005
[epoch 281: 240/307] 	 train loss: 0.013229 	 lr: 0.00005
[epoch 281: 260/307] 	 train loss: 0.062804 	 lr: 0.00005
[epoch 281: 280/307] 	 train loss: 0.130094 	 lr: 0.00005
[epoch 281: 300/307] 	 train loss: 0.078726 	 lr: 0.00005
[epoch 282:   0/307] 	 train loss: 0.011405 	 lr: 0.00005
[epoch 282:  20/307] 	 train loss: 0.235725 	 lr: 0.00005
[epoch 282:  40/307] 	 train loss: 0.027010 	 lr: 0.00005

val loss: 0.342110 	 acc: 0.918152

[epoch 282:  60/307] 	 train loss: 0.080001 	 lr: 0.00005
[epoch 282:  80/307] 	 train loss: 0.109937 	 lr: 0.00005
[epoch 282: 100/307] 	 train loss: 0.167688 	 lr: 0.00005
[epoch 282: 120/307] 	 train loss: 0.013884 	 lr: 0.00005
[epoch 282: 140/307] 	 train loss: 0.052734 	 lr: 0.00005
[epoch 282: 160/307] 	 train loss: 0.315216 	 lr: 0.00005
[epoch 282: 180/307] 	 train loss: 0.002448 	 lr: 0.00005
[epoch 282: 200/307] 	 train loss: 0.110335 	 lr: 0.00005

val loss: 0.344942 	 acc: 0.916126

[epoch 282: 220/307] 	 train loss: 0.076515 	 lr: 0.00005
[epoch 282: 240/307] 	 train loss: 0.209207 	 lr: 0.00005
[epoch 282: 260/307] 	 train loss: 0.113592 	 lr: 0.00005
[epoch 282: 280/307] 	 train loss: 0.066721 	 lr: 0.00005
[epoch 282: 300/307] 	 train loss: 0.105677 	 lr: 0.00005
[epoch 283:   0/307] 	 train loss: 0.063677 	 lr: 0.00005
[epoch 283:  20/307] 	 train loss: 0.036541 	 lr: 0.00005
[epoch 283:  40/307] 	 train loss: 0.196840 	 lr: 0.00005

val loss: 0.339581 	 acc: 0.917747

[epoch 283:  60/307] 	 train loss: 0.134738 	 lr: 0.00005
[epoch 283:  80/307] 	 train loss: 0.292107 	 lr: 0.00005
[epoch 283: 100/307] 	 train loss: 0.188764 	 lr: 0.00005
[epoch 283: 120/307] 	 train loss: 0.078412 	 lr: 0.00005
[epoch 283: 140/307] 	 train loss: 0.239806 	 lr: 0.00005
[epoch 283: 160/307] 	 train loss: 0.146044 	 lr: 0.00005
[epoch 283: 180/307] 	 train loss: 0.017258 	 lr: 0.00005
[epoch 283: 200/307] 	 train loss: 0.151057 	 lr: 0.00005

val loss: 0.340668 	 acc: 0.917342

[epoch 283: 220/307] 	 train loss: 0.114044 	 lr: 0.00005
[epoch 283: 240/307] 	 train loss: 0.019283 	 lr: 0.00005
[epoch 283: 260/307] 	 train loss: 0.092638 	 lr: 0.00005
[epoch 283: 280/307] 	 train loss: 0.085431 	 lr: 0.00005
[epoch 283: 300/307] 	 train loss: 0.008167 	 lr: 0.00005
[epoch 284:   0/307] 	 train loss: 0.065946 	 lr: 0.00005
[epoch 284:  20/307] 	 train loss: 0.020343 	 lr: 0.00005
[epoch 284:  40/307] 	 train loss: 0.203950 	 lr: 0.00005

val loss: 0.339887 	 acc: 0.914911

[epoch 284:  60/307] 	 train loss: 0.070447 	 lr: 0.00005
[epoch 284:  80/307] 	 train loss: 0.088208 	 lr: 0.00005
[epoch 284: 100/307] 	 train loss: 0.145587 	 lr: 0.00005
[epoch 284: 120/307] 	 train loss: 0.107088 	 lr: 0.00005
[epoch 284: 140/307] 	 train loss: 0.189142 	 lr: 0.00005
[epoch 284: 160/307] 	 train loss: 0.287476 	 lr: 0.00005
[epoch 284: 180/307] 	 train loss: 0.019546 	 lr: 0.00005

val loss: 0.339894 	 acc: 0.917747

[epoch 284: 200/307] 	 train loss: 0.102441 	 lr: 0.00005
[epoch 284: 220/307] 	 train loss: 0.088327 	 lr: 0.00005
[epoch 284: 240/307] 	 train loss: 0.056724 	 lr: 0.00005
[epoch 284: 260/307] 	 train loss: 0.221378 	 lr: 0.00005
[epoch 284: 280/307] 	 train loss: 0.078741 	 lr: 0.00005
[epoch 284: 300/307] 	 train loss: 0.128695 	 lr: 0.00005
[epoch 285:   0/307] 	 train loss: 0.062769 	 lr: 0.00005
[epoch 285:  20/307] 	 train loss: 0.198168 	 lr: 0.00005
[epoch 285:  40/307] 	 train loss: 0.012178 	 lr: 0.00005

val loss: 0.340285 	 acc: 0.916532

[epoch 285:  60/307] 	 train loss: 0.045502 	 lr: 0.00005
[epoch 285:  80/307] 	 train loss: 0.191866 	 lr: 0.00005
[epoch 285: 100/307] 	 train loss: 0.086673 	 lr: 0.00005
[epoch 285: 120/307] 	 train loss: 0.088878 	 lr: 0.00005
[epoch 285: 140/307] 	 train loss: 0.202914 	 lr: 0.00005
[epoch 285: 160/307] 	 train loss: 0.040467 	 lr: 0.00005
[epoch 285: 180/307] 	 train loss: 0.075205 	 lr: 0.00005

val loss: 0.335949 	 acc: 0.919368

[epoch 285: 200/307] 	 train loss: 0.073382 	 lr: 0.00005
[epoch 285: 220/307] 	 train loss: 0.027994 	 lr: 0.00005
[epoch 285: 240/307] 	 train loss: 0.051552 	 lr: 0.00005
[epoch 285: 260/307] 	 train loss: 0.013377 	 lr: 0.00005
[epoch 285: 280/307] 	 train loss: 0.046272 	 lr: 0.00005
[epoch 285: 300/307] 	 train loss: 0.004784 	 lr: 0.00005
[epoch 286:   0/307] 	 train loss: 0.040541 	 lr: 0.00005
[epoch 286:  20/307] 	 train loss: 0.080340 	 lr: 0.00005
[epoch 286:  40/307] 	 train loss: 0.092640 	 lr: 0.00005

val loss: 0.344572 	 acc: 0.915316

[epoch 286:  60/307] 	 train loss: 0.059071 	 lr: 0.00005
[epoch 286:  80/307] 	 train loss: 0.072554 	 lr: 0.00005
[epoch 286: 100/307] 	 train loss: 0.179746 	 lr: 0.00005
[epoch 286: 120/307] 	 train loss: 0.023629 	 lr: 0.00005
[epoch 286: 140/307] 	 train loss: 0.211965 	 lr: 0.00005
[epoch 286: 160/307] 	 train loss: 0.057136 	 lr: 0.00005
[epoch 286: 180/307] 	 train loss: 0.077324 	 lr: 0.00005

val loss: 0.340281 	 acc: 0.915721

[epoch 286: 200/307] 	 train loss: 0.115239 	 lr: 0.00005
[epoch 286: 220/307] 	 train loss: 0.015047 	 lr: 0.00005
[epoch 286: 240/307] 	 train loss: 0.177025 	 lr: 0.00005
[epoch 286: 260/307] 	 train loss: 0.305548 	 lr: 0.00005
[epoch 286: 280/307] 	 train loss: 0.051596 	 lr: 0.00005
[epoch 286: 300/307] 	 train loss: 0.049956 	 lr: 0.00005
[epoch 287:   0/307] 	 train loss: 0.071917 	 lr: 0.00005
[epoch 287:  20/307] 	 train loss: 0.194291 	 lr: 0.00005

val loss: 0.337128 	 acc: 0.915316

[epoch 287:  40/307] 	 train loss: 0.046131 	 lr: 0.00005
[epoch 287:  60/307] 	 train loss: 0.010239 	 lr: 0.00005
[epoch 287:  80/307] 	 train loss: 0.119336 	 lr: 0.00005
[epoch 287: 100/307] 	 train loss: 0.076202 	 lr: 0.00005
[epoch 287: 120/307] 	 train loss: 0.045449 	 lr: 0.00005
[epoch 287: 140/307] 	 train loss: 0.091905 	 lr: 0.00005
[epoch 287: 160/307] 	 train loss: 0.061914 	 lr: 0.00005
[epoch 287: 180/307] 	 train loss: 0.012231 	 lr: 0.00005

val loss: 0.344420 	 acc: 0.914506

[epoch 287: 200/307] 	 train loss: 0.091576 	 lr: 0.00005
[epoch 287: 220/307] 	 train loss: 0.051745 	 lr: 0.00005
[epoch 287: 240/307] 	 train loss: 0.070905 	 lr: 0.00005
[epoch 287: 260/307] 	 train loss: 0.028924 	 lr: 0.00005
[epoch 287: 280/307] 	 train loss: 0.232743 	 lr: 0.00005
[epoch 287: 300/307] 	 train loss: 0.114578 	 lr: 0.00005
[epoch 288:   0/307] 	 train loss: 0.148435 	 lr: 0.00005
[epoch 288:  20/307] 	 train loss: 0.220502 	 lr: 0.00005

val loss: 0.342622 	 acc: 0.914506

[epoch 288:  40/307] 	 train loss: 0.203847 	 lr: 0.00005
[epoch 288:  60/307] 	 train loss: 0.066125 	 lr: 0.00005
[epoch 288:  80/307] 	 train loss: 0.057946 	 lr: 0.00005
[epoch 288: 100/307] 	 train loss: 0.160809 	 lr: 0.00005
[epoch 288: 120/307] 	 train loss: 0.105761 	 lr: 0.00005
[epoch 288: 140/307] 	 train loss: 0.129327 	 lr: 0.00005
[epoch 288: 160/307] 	 train loss: 0.043236 	 lr: 0.00005
[epoch 288: 180/307] 	 train loss: 0.045887 	 lr: 0.00005

val loss: 0.340076 	 acc: 0.916126

[epoch 288: 200/307] 	 train loss: 0.035891 	 lr: 0.00005
[epoch 288: 220/307] 	 train loss: 0.029926 	 lr: 0.00005
[epoch 288: 240/307] 	 train loss: 0.137424 	 lr: 0.00005
[epoch 288: 260/307] 	 train loss: 0.045791 	 lr: 0.00005
[epoch 288: 280/307] 	 train loss: 0.048021 	 lr: 0.00005
[epoch 288: 300/307] 	 train loss: 0.111993 	 lr: 0.00005
[epoch 289:   0/307] 	 train loss: 0.246526 	 lr: 0.00005
[epoch 289:  20/307] 	 train loss: 0.050595 	 lr: 0.00005

val loss: 0.333601 	 acc: 0.918558

[epoch 289:  40/307] 	 train loss: 0.155372 	 lr: 0.00005
[epoch 289:  60/307] 	 train loss: 0.056564 	 lr: 0.00005
[epoch 289:  80/307] 	 train loss: 0.075203 	 lr: 0.00005
[epoch 289: 100/307] 	 train loss: 0.234954 	 lr: 0.00005
[epoch 289: 120/307] 	 train loss: 0.035638 	 lr: 0.00005
[epoch 289: 140/307] 	 train loss: 0.247205 	 lr: 0.00005
[epoch 289: 160/307] 	 train loss: 0.037143 	 lr: 0.00005
[epoch 289: 180/307] 	 train loss: 0.250422 	 lr: 0.00005

val loss: 0.337981 	 acc: 0.917342

[epoch 289: 200/307] 	 train loss: 0.165370 	 lr: 0.00005
[epoch 289: 220/307] 	 train loss: 0.025774 	 lr: 0.00005
[epoch 289: 240/307] 	 train loss: 0.169221 	 lr: 0.00005
[epoch 289: 260/307] 	 train loss: 0.047195 	 lr: 0.00005
[epoch 289: 280/307] 	 train loss: 0.066901 	 lr: 0.00005
[epoch 289: 300/307] 	 train loss: 0.023566 	 lr: 0.00005
[epoch 290:   0/307] 	 train loss: 0.191494 	 lr: 0.00005
[epoch 290:  20/307] 	 train loss: 0.067775 	 lr: 0.00005

val loss: 0.345827 	 acc: 0.917747

[epoch 290:  40/307] 	 train loss: 0.079186 	 lr: 0.00005
[epoch 290:  60/307] 	 train loss: 0.008359 	 lr: 0.00005
[epoch 290:  80/307] 	 train loss: 0.029830 	 lr: 0.00005
[epoch 290: 100/307] 	 train loss: 0.077369 	 lr: 0.00005
[epoch 290: 120/307] 	 train loss: 0.017557 	 lr: 0.00005
[epoch 290: 140/307] 	 train loss: 0.058363 	 lr: 0.00005
[epoch 290: 160/307] 	 train loss: 0.087287 	 lr: 0.00005
[epoch 290: 180/307] 	 train loss: 0.189626 	 lr: 0.00005

val loss: 0.339396 	 acc: 0.917342

[epoch 290: 200/307] 	 train loss: 0.057587 	 lr: 0.00005
[epoch 290: 220/307] 	 train loss: 0.136398 	 lr: 0.00005
[epoch 290: 240/307] 	 train loss: 0.039688 	 lr: 0.00005
[epoch 290: 260/307] 	 train loss: 0.008971 	 lr: 0.00005
[epoch 290: 280/307] 	 train loss: 0.120624 	 lr: 0.00005
[epoch 290: 300/307] 	 train loss: 0.016757 	 lr: 0.00005
[epoch 291:   0/307] 	 train loss: 0.026107 	 lr: 0.00005
[epoch 291:  20/307] 	 train loss: 0.216199 	 lr: 0.00005

val loss: 0.331233 	 acc: 0.920583

[epoch 291:  40/307] 	 train loss: 0.062297 	 lr: 0.00005
[epoch 291:  60/307] 	 train loss: 0.016836 	 lr: 0.00005
[epoch 291:  80/307] 	 train loss: 0.072326 	 lr: 0.00005
[epoch 291: 100/307] 	 train loss: 0.014778 	 lr: 0.00005
[epoch 291: 120/307] 	 train loss: 0.075716 	 lr: 0.00005
[epoch 291: 140/307] 	 train loss: 0.156402 	 lr: 0.00005
[epoch 291: 160/307] 	 train loss: 0.072202 	 lr: 0.00005
[epoch 291: 180/307] 	 train loss: 0.130952 	 lr: 0.00005

val loss: 0.333650 	 acc: 0.920178

[epoch 291: 200/307] 	 train loss: 0.077956 	 lr: 0.00005
[epoch 291: 220/307] 	 train loss: 0.026642 	 lr: 0.00005
[epoch 291: 240/307] 	 train loss: 0.124987 	 lr: 0.00005
[epoch 291: 260/307] 	 train loss: 0.197621 	 lr: 0.00005
[epoch 291: 280/307] 	 train loss: 0.113883 	 lr: 0.00005
[epoch 291: 300/307] 	 train loss: 0.042886 	 lr: 0.00005
[epoch 292:   0/307] 	 train loss: 0.119462 	 lr: 0.00005
[epoch 292:  20/307] 	 train loss: 0.046708 	 lr: 0.00005

val loss: 0.337639 	 acc: 0.918558

[epoch 292:  40/307] 	 train loss: 0.108846 	 lr: 0.00005
[epoch 292:  60/307] 	 train loss: 0.072732 	 lr: 0.00005
[epoch 292:  80/307] 	 train loss: 0.246913 	 lr: 0.00005
[epoch 292: 100/307] 	 train loss: 0.059514 	 lr: 0.00005
[epoch 292: 120/307] 	 train loss: 0.122168 	 lr: 0.00005
[epoch 292: 140/307] 	 train loss: 0.035970 	 lr: 0.00005
[epoch 292: 160/307] 	 train loss: 0.007247 	 lr: 0.00005
[epoch 292: 180/307] 	 train loss: 0.020125 	 lr: 0.00005

val loss: 0.341067 	 acc: 0.918558

[epoch 292: 200/307] 	 train loss: 0.018608 	 lr: 0.00005
[epoch 292: 220/307] 	 train loss: 0.032879 	 lr: 0.00005
[epoch 292: 240/307] 	 train loss: 0.262784 	 lr: 0.00005
[epoch 292: 260/307] 	 train loss: 0.245631 	 lr: 0.00005
[epoch 292: 280/307] 	 train loss: 0.296665 	 lr: 0.00005
[epoch 292: 300/307] 	 train loss: 0.222049 	 lr: 0.00005
[epoch 293:   0/307] 	 train loss: 0.063489 	 lr: 0.00005
[epoch 293:  20/307] 	 train loss: 0.059112 	 lr: 0.00005

val loss: 0.343595 	 acc: 0.916937

[epoch 293:  40/307] 	 train loss: 0.171548 	 lr: 0.00005
[epoch 293:  60/307] 	 train loss: 0.178801 	 lr: 0.00005
[epoch 293:  80/307] 	 train loss: 0.057708 	 lr: 0.00005
[epoch 293: 100/307] 	 train loss: 0.109084 	 lr: 0.00005
[epoch 293: 120/307] 	 train loss: 0.010653 	 lr: 0.00005
[epoch 293: 140/307] 	 train loss: 0.064012 	 lr: 0.00005
[epoch 293: 160/307] 	 train loss: 0.254650 	 lr: 0.00005
[epoch 293: 180/307] 	 train loss: 0.296159 	 lr: 0.00005

val loss: 0.336368 	 acc: 0.916532

[epoch 293: 200/307] 	 train loss: 0.078556 	 lr: 0.00005
[epoch 293: 220/307] 	 train loss: 0.036099 	 lr: 0.00005
[epoch 293: 240/307] 	 train loss: 0.203739 	 lr: 0.00005
[epoch 293: 260/307] 	 train loss: 0.022992 	 lr: 0.00005
[epoch 293: 280/307] 	 train loss: 0.380775 	 lr: 0.00005
[epoch 293: 300/307] 	 train loss: 0.117935 	 lr: 0.00005
[epoch 294:   0/307] 	 train loss: 0.132583 	 lr: 0.00005
[epoch 294:  20/307] 	 train loss: 0.124174 	 lr: 0.00005

val loss: 0.336616 	 acc: 0.917747

[epoch 294:  40/307] 	 train loss: 0.039693 	 lr: 0.00005
[epoch 294:  60/307] 	 train loss: 0.037745 	 lr: 0.00005
[epoch 294:  80/307] 	 train loss: 0.076213 	 lr: 0.00005
[epoch 294: 100/307] 	 train loss: 0.032428 	 lr: 0.00005
[epoch 294: 120/307] 	 train loss: 0.067153 	 lr: 0.00005
[epoch 294: 140/307] 	 train loss: 0.080350 	 lr: 0.00005
[epoch 294: 160/307] 	 train loss: 0.202639 	 lr: 0.00005

val loss: 0.341503 	 acc: 0.918963

[epoch 294: 180/307] 	 train loss: 0.170140 	 lr: 0.00005
[epoch 294: 200/307] 	 train loss: 0.080564 	 lr: 0.00005
[epoch 294: 220/307] 	 train loss: 0.193753 	 lr: 0.00005
[epoch 294: 240/307] 	 train loss: 0.064537 	 lr: 0.00005
[epoch 294: 260/307] 	 train loss: 0.034352 	 lr: 0.00005
[epoch 294: 280/307] 	 train loss: 0.027210 	 lr: 0.00005
[epoch 294: 300/307] 	 train loss: 0.020805 	 lr: 0.00005
[epoch 295:   0/307] 	 train loss: 0.158662 	 lr: 0.00004
[epoch 295:  20/307] 	 train loss: 0.044876 	 lr: 0.00004

val loss: 0.338898 	 acc: 0.916937

[epoch 295:  40/307] 	 train loss: 0.313859 	 lr: 0.00004
[epoch 295:  60/307] 	 train loss: 0.109971 	 lr: 0.00004
[epoch 295:  80/307] 	 train loss: 0.022721 	 lr: 0.00004
[epoch 295: 100/307] 	 train loss: 0.052371 	 lr: 0.00004
[epoch 295: 120/307] 	 train loss: 0.145188 	 lr: 0.00004
[epoch 295: 140/307] 	 train loss: 0.097293 	 lr: 0.00004
[epoch 295: 160/307] 	 train loss: 0.178798 	 lr: 0.00004

val loss: 0.338086 	 acc: 0.917342

[epoch 295: 180/307] 	 train loss: 0.073952 	 lr: 0.00004
[epoch 295: 200/307] 	 train loss: 0.058831 	 lr: 0.00004
[epoch 295: 220/307] 	 train loss: 0.036214 	 lr: 0.00004
[epoch 295: 240/307] 	 train loss: 0.092479 	 lr: 0.00004
[epoch 295: 260/307] 	 train loss: 0.150488 	 lr: 0.00004
[epoch 295: 280/307] 	 train loss: 0.029632 	 lr: 0.00004
[epoch 295: 300/307] 	 train loss: 0.029489 	 lr: 0.00004
[epoch 296:   0/307] 	 train loss: 0.099142 	 lr: 0.00004
[epoch 296:  20/307] 	 train loss: 0.015015 	 lr: 0.00004

val loss: 0.337560 	 acc: 0.914100

[epoch 296:  40/307] 	 train loss: 0.138700 	 lr: 0.00004
[epoch 296:  60/307] 	 train loss: 0.028949 	 lr: 0.00004
[epoch 296:  80/307] 	 train loss: 0.104707 	 lr: 0.00004
[epoch 296: 100/307] 	 train loss: 0.135992 	 lr: 0.00004
[epoch 296: 120/307] 	 train loss: 0.011332 	 lr: 0.00004
[epoch 296: 140/307] 	 train loss: 0.060851 	 lr: 0.00004
[epoch 296: 160/307] 	 train loss: 0.044533 	 lr: 0.00004

val loss: 0.344910 	 acc: 0.914911

[epoch 296: 180/307] 	 train loss: 0.037054 	 lr: 0.00004
[epoch 296: 200/307] 	 train loss: 0.073362 	 lr: 0.00004
[epoch 296: 220/307] 	 train loss: 0.232925 	 lr: 0.00004
[epoch 296: 240/307] 	 train loss: 0.051868 	 lr: 0.00004
[epoch 296: 260/307] 	 train loss: 0.028894 	 lr: 0.00004
[epoch 296: 280/307] 	 train loss: 0.062535 	 lr: 0.00004
[epoch 296: 300/307] 	 train loss: 0.057369 	 lr: 0.00004
[epoch 297:   0/307] 	 train loss: 0.050766 	 lr: 0.00004

val loss: 0.338897 	 acc: 0.916126

[epoch 297:  20/307] 	 train loss: 0.081126 	 lr: 0.00004
[epoch 297:  40/307] 	 train loss: 0.055297 	 lr: 0.00004
[epoch 297:  60/307] 	 train loss: 0.194822 	 lr: 0.00004
[epoch 297:  80/307] 	 train loss: 0.056762 	 lr: 0.00004
[epoch 297: 100/307] 	 train loss: 0.042019 	 lr: 0.00004
[epoch 297: 120/307] 	 train loss: 0.034303 	 lr: 0.00004
[epoch 297: 140/307] 	 train loss: 0.017231 	 lr: 0.00004
[epoch 297: 160/307] 	 train loss: 0.049037 	 lr: 0.00004

val loss: 0.340310 	 acc: 0.918152

[epoch 297: 180/307] 	 train loss: 0.124422 	 lr: 0.00004
[epoch 297: 200/307] 	 train loss: 0.010588 	 lr: 0.00004
[epoch 297: 220/307] 	 train loss: 0.016990 	 lr: 0.00004
[epoch 297: 240/307] 	 train loss: 0.067572 	 lr: 0.00004
[epoch 297: 260/307] 	 train loss: 0.094899 	 lr: 0.00004
[epoch 297: 280/307] 	 train loss: 0.109400 	 lr: 0.00004
[epoch 297: 300/307] 	 train loss: 0.124479 	 lr: 0.00004
[epoch 298:   0/307] 	 train loss: 0.020515 	 lr: 0.00004

val loss: 0.341345 	 acc: 0.916126

[epoch 298:  20/307] 	 train loss: 0.159295 	 lr: 0.00004
[epoch 298:  40/307] 	 train loss: 0.271474 	 lr: 0.00004
[epoch 298:  60/307] 	 train loss: 0.140910 	 lr: 0.00004
[epoch 298:  80/307] 	 train loss: 0.040740 	 lr: 0.00004
[epoch 298: 100/307] 	 train loss: 0.032312 	 lr: 0.00004
[epoch 298: 120/307] 	 train loss: 0.148989 	 lr: 0.00004
[epoch 298: 140/307] 	 train loss: 0.428923 	 lr: 0.00004
[epoch 298: 160/307] 	 train loss: 0.166665 	 lr: 0.00004

val loss: 0.341641 	 acc: 0.916126

[epoch 298: 180/307] 	 train loss: 0.025372 	 lr: 0.00004
[epoch 298: 200/307] 	 train loss: 0.077263 	 lr: 0.00004
[epoch 298: 220/307] 	 train loss: 0.053754 	 lr: 0.00004
[epoch 298: 240/307] 	 train loss: 0.136293 	 lr: 0.00004
[epoch 298: 260/307] 	 train loss: 0.028640 	 lr: 0.00004
[epoch 298: 280/307] 	 train loss: 0.168864 	 lr: 0.00004
[epoch 298: 300/307] 	 train loss: 0.060895 	 lr: 0.00004
[epoch 299:   0/307] 	 train loss: 0.044276 	 lr: 0.00004

val loss: 0.341265 	 acc: 0.917747

[epoch 299:  20/307] 	 train loss: 0.053714 	 lr: 0.00004
[epoch 299:  40/307] 	 train loss: 0.043635 	 lr: 0.00004
[epoch 299:  60/307] 	 train loss: 0.027559 	 lr: 0.00004
[epoch 299:  80/307] 	 train loss: 0.040094 	 lr: 0.00004
[epoch 299: 100/307] 	 train loss: 0.009738 	 lr: 0.00004
[epoch 299: 120/307] 	 train loss: 0.179688 	 lr: 0.00004
[epoch 299: 140/307] 	 train loss: 0.066387 	 lr: 0.00004
[epoch 299: 160/307] 	 train loss: 0.101506 	 lr: 0.00004

val loss: 0.336379 	 acc: 0.916126

[epoch 299: 180/307] 	 train loss: 0.111259 	 lr: 0.00004
[epoch 299: 200/307] 	 train loss: 0.104684 	 lr: 0.00004
[epoch 299: 220/307] 	 train loss: 0.150410 	 lr: 0.00004
[epoch 299: 240/307] 	 train loss: 0.078748 	 lr: 0.00004
[epoch 299: 260/307] 	 train loss: 0.129338 	 lr: 0.00004
[epoch 299: 280/307] 	 train loss: 0.091332 	 lr: 0.00004
[epoch 299: 300/307] 	 train loss: 0.054479 	 lr: 0.00004
[epoch 300:   0/307] 	 train loss: 0.063845 	 lr: 0.00004

val loss: 0.337705 	 acc: 0.920178

[epoch 300:  20/307] 	 train loss: 0.073086 	 lr: 0.00004
[epoch 300:  40/307] 	 train loss: 0.065358 	 lr: 0.00004
[epoch 300:  60/307] 	 train loss: 0.204334 	 lr: 0.00004
[epoch 300:  80/307] 	 train loss: 0.068710 	 lr: 0.00004
[epoch 300: 100/307] 	 train loss: 0.085023 	 lr: 0.00004
[epoch 300: 120/307] 	 train loss: 0.119974 	 lr: 0.00004
[epoch 300: 140/307] 	 train loss: 0.207797 	 lr: 0.00004
[epoch 300: 160/307] 	 train loss: 0.003779 	 lr: 0.00004

val loss: 0.340436 	 acc: 0.917342

[epoch 300: 180/307] 	 train loss: 0.034888 	 lr: 0.00004
[epoch 300: 200/307] 	 train loss: 0.096782 	 lr: 0.00004
[epoch 300: 220/307] 	 train loss: 0.147744 	 lr: 0.00004
[epoch 300: 240/307] 	 train loss: 0.150903 	 lr: 0.00004
[epoch 300: 260/307] 	 train loss: 0.053492 	 lr: 0.00004
[epoch 300: 280/307] 	 train loss: 0.283468 	 lr: 0.00004
[epoch 300: 300/307] 	 train loss: 0.207658 	 lr: 0.00004
[epoch 301:   0/307] 	 train loss: 0.128494 	 lr: 0.00004

val loss: 0.337586 	 acc: 0.917747

[epoch 301:  20/307] 	 train loss: 0.096383 	 lr: 0.00004
[epoch 301:  40/307] 	 train loss: 0.055913 	 lr: 0.00004
[epoch 301:  60/307] 	 train loss: 0.061148 	 lr: 0.00004
[epoch 301:  80/307] 	 train loss: 0.007572 	 lr: 0.00004
[epoch 301: 100/307] 	 train loss: 0.007247 	 lr: 0.00004
[epoch 301: 120/307] 	 train loss: 0.067630 	 lr: 0.00004
[epoch 301: 140/307] 	 train loss: 0.233340 	 lr: 0.00004
[epoch 301: 160/307] 	 train loss: 0.012456 	 lr: 0.00004

val loss: 0.339288 	 acc: 0.918963

[epoch 301: 180/307] 	 train loss: 0.121313 	 lr: 0.00004
[epoch 301: 200/307] 	 train loss: 0.022798 	 lr: 0.00004
[epoch 301: 220/307] 	 train loss: 0.055483 	 lr: 0.00004
[epoch 301: 240/307] 	 train loss: 0.036986 	 lr: 0.00004
[epoch 301: 260/307] 	 train loss: 0.076841 	 lr: 0.00004
[epoch 301: 280/307] 	 train loss: 0.062322 	 lr: 0.00004
[epoch 301: 300/307] 	 train loss: 0.008278 	 lr: 0.00004
[epoch 302:   0/307] 	 train loss: 0.206821 	 lr: 0.00004

val loss: 0.341070 	 acc: 0.918558

[epoch 302:  20/307] 	 train loss: 0.046884 	 lr: 0.00004
[epoch 302:  40/307] 	 train loss: 0.043496 	 lr: 0.00004
[epoch 302:  60/307] 	 train loss: 0.016611 	 lr: 0.00004
[epoch 302:  80/307] 	 train loss: 0.089760 	 lr: 0.00004
[epoch 302: 100/307] 	 train loss: 0.253888 	 lr: 0.00004
[epoch 302: 120/307] 	 train loss: 0.178194 	 lr: 0.00004
[epoch 302: 140/307] 	 train loss: 0.050800 	 lr: 0.00004
[epoch 302: 160/307] 	 train loss: 0.321651 	 lr: 0.00004

val loss: 0.340080 	 acc: 0.919773

[epoch 302: 180/307] 	 train loss: 0.028467 	 lr: 0.00004
[epoch 302: 200/307] 	 train loss: 0.022894 	 lr: 0.00004
[epoch 302: 220/307] 	 train loss: 0.073793 	 lr: 0.00004
[epoch 302: 240/307] 	 train loss: 0.088880 	 lr: 0.00004
[epoch 302: 260/307] 	 train loss: 0.151441 	 lr: 0.00004
[epoch 302: 280/307] 	 train loss: 0.141114 	 lr: 0.00004
[epoch 302: 300/307] 	 train loss: 0.025623 	 lr: 0.00004
[epoch 303:   0/307] 	 train loss: 0.190008 	 lr: 0.00004

val loss: 0.337185 	 acc: 0.916937

[epoch 303:  20/307] 	 train loss: 0.240143 	 lr: 0.00004
[epoch 303:  40/307] 	 train loss: 0.027618 	 lr: 0.00004
[epoch 303:  60/307] 	 train loss: 0.033238 	 lr: 0.00004
[epoch 303:  80/307] 	 train loss: 0.064374 	 lr: 0.00004
[epoch 303: 100/307] 	 train loss: 0.003060 	 lr: 0.00004
[epoch 303: 120/307] 	 train loss: 0.187815 	 lr: 0.00004
[epoch 303: 140/307] 	 train loss: 0.032232 	 lr: 0.00004
[epoch 303: 160/307] 	 train loss: 0.020971 	 lr: 0.00004

val loss: 0.342835 	 acc: 0.919368

[epoch 303: 180/307] 	 train loss: 0.037484 	 lr: 0.00004
[epoch 303: 200/307] 	 train loss: 0.170965 	 lr: 0.00004
[epoch 303: 220/307] 	 train loss: 0.130453 	 lr: 0.00004
[epoch 303: 240/307] 	 train loss: 0.052334 	 lr: 0.00004
[epoch 303: 260/307] 	 train loss: 0.136988 	 lr: 0.00004
[epoch 303: 280/307] 	 train loss: 0.016692 	 lr: 0.00004
[epoch 303: 300/307] 	 train loss: 0.018270 	 lr: 0.00004
[epoch 304:   0/307] 	 train loss: 0.187455 	 lr: 0.00004

val loss: 0.337568 	 acc: 0.919773

[epoch 304:  20/307] 	 train loss: 0.165191 	 lr: 0.00004
[epoch 304:  40/307] 	 train loss: 0.107910 	 lr: 0.00004
[epoch 304:  60/307] 	 train loss: 0.071985 	 lr: 0.00004
[epoch 304:  80/307] 	 train loss: 0.018518 	 lr: 0.00004
[epoch 304: 100/307] 	 train loss: 0.009230 	 lr: 0.00004
[epoch 304: 120/307] 	 train loss: 0.015716 	 lr: 0.00004
[epoch 304: 140/307] 	 train loss: 0.052555 	 lr: 0.00004

val loss: 0.337291 	 acc: 0.920989

[epoch 304: 160/307] 	 train loss: 0.029572 	 lr: 0.00004
[epoch 304: 180/307] 	 train loss: 0.078751 	 lr: 0.00004
[epoch 304: 200/307] 	 train loss: 0.054017 	 lr: 0.00004
[epoch 304: 220/307] 	 train loss: 0.029121 	 lr: 0.00004
[epoch 304: 240/307] 	 train loss: 0.062115 	 lr: 0.00004
[epoch 304: 260/307] 	 train loss: 0.033817 	 lr: 0.00004
[epoch 304: 280/307] 	 train loss: 0.092133 	 lr: 0.00004
[epoch 304: 300/307] 	 train loss: 0.007975 	 lr: 0.00004
[epoch 305:   0/307] 	 train loss: 0.101992 	 lr: 0.00004

val loss: 0.342852 	 acc: 0.919368

[epoch 305:  20/307] 	 train loss: 0.047294 	 lr: 0.00004
[epoch 305:  40/307] 	 train loss: 0.080423 	 lr: 0.00004
[epoch 305:  60/307] 	 train loss: 0.189951 	 lr: 0.00004
[epoch 305:  80/307] 	 train loss: 0.133713 	 lr: 0.00004
[epoch 305: 100/307] 	 train loss: 0.159681 	 lr: 0.00004
[epoch 305: 120/307] 	 train loss: 0.067942 	 lr: 0.00004
[epoch 305: 140/307] 	 train loss: 0.328505 	 lr: 0.00004

val loss: 0.349770 	 acc: 0.916937

[epoch 305: 160/307] 	 train loss: 0.043144 	 lr: 0.00004
[epoch 305: 180/307] 	 train loss: 0.014825 	 lr: 0.00004
[epoch 305: 200/307] 	 train loss: 0.037338 	 lr: 0.00004
[epoch 305: 220/307] 	 train loss: 0.045987 	 lr: 0.00004
[epoch 305: 240/307] 	 train loss: 0.209565 	 lr: 0.00004
[epoch 305: 260/307] 	 train loss: 0.021579 	 lr: 0.00004
[epoch 305: 280/307] 	 train loss: 0.199507 	 lr: 0.00004
[epoch 305: 300/307] 	 train loss: 0.091671 	 lr: 0.00004
[epoch 306:   0/307] 	 train loss: 0.186829 	 lr: 0.00004

val loss: 0.342524 	 acc: 0.917342

[epoch 306:  20/307] 	 train loss: 0.245396 	 lr: 0.00004
[epoch 306:  40/307] 	 train loss: 0.032349 	 lr: 0.00004
[epoch 306:  60/307] 	 train loss: 0.118355 	 lr: 0.00004
[epoch 306:  80/307] 	 train loss: 0.124144 	 lr: 0.00004
[epoch 306: 100/307] 	 train loss: 0.091596 	 lr: 0.00004
[epoch 306: 120/307] 	 train loss: 0.023173 	 lr: 0.00004
[epoch 306: 140/307] 	 train loss: 0.099429 	 lr: 0.00004

val loss: 0.344409 	 acc: 0.918152

[epoch 306: 160/307] 	 train loss: 0.108917 	 lr: 0.00004
[epoch 306: 180/307] 	 train loss: 0.101729 	 lr: 0.00004
[epoch 306: 200/307] 	 train loss: 0.142914 	 lr: 0.00004
[epoch 306: 220/307] 	 train loss: 0.002401 	 lr: 0.00004
[epoch 306: 240/307] 	 train loss: 0.110065 	 lr: 0.00004
[epoch 306: 260/307] 	 train loss: 0.370373 	 lr: 0.00004
[epoch 306: 280/307] 	 train loss: 0.062490 	 lr: 0.00004
[epoch 306: 300/307] 	 train loss: 0.123635 	 lr: 0.00004

val loss: 0.341592 	 acc: 0.917342

[epoch 307:   0/307] 	 train loss: 0.115910 	 lr: 0.00004
[epoch 307:  20/307] 	 train loss: 0.068530 	 lr: 0.00004
[epoch 307:  40/307] 	 train loss: 0.060327 	 lr: 0.00004
[epoch 307:  60/307] 	 train loss: 0.086319 	 lr: 0.00004
[epoch 307:  80/307] 	 train loss: 0.070956 	 lr: 0.00004
[epoch 307: 100/307] 	 train loss: 0.049090 	 lr: 0.00004
[epoch 307: 120/307] 	 train loss: 0.153441 	 lr: 0.00004
[epoch 307: 140/307] 	 train loss: 0.189658 	 lr: 0.00004

val loss: 0.341635 	 acc: 0.918558

[epoch 307: 160/307] 	 train loss: 0.185492 	 lr: 0.00004
[epoch 307: 180/307] 	 train loss: 0.135738 	 lr: 0.00004
[epoch 307: 200/307] 	 train loss: 0.208256 	 lr: 0.00004
[epoch 307: 220/307] 	 train loss: 0.003238 	 lr: 0.00004
[epoch 307: 240/307] 	 train loss: 0.125021 	 lr: 0.00004
[epoch 307: 260/307] 	 train loss: 0.140336 	 lr: 0.00004
[epoch 307: 280/307] 	 train loss: 0.058318 	 lr: 0.00004
[epoch 307: 300/307] 	 train loss: 0.096417 	 lr: 0.00004

val loss: 0.339667 	 acc: 0.918558

[epoch 308:   0/307] 	 train loss: 0.050206 	 lr: 0.00004
[epoch 308:  20/307] 	 train loss: 0.042236 	 lr: 0.00004
[epoch 308:  40/307] 	 train loss: 0.091974 	 lr: 0.00004
[epoch 308:  60/307] 	 train loss: 0.232759 	 lr: 0.00004
[epoch 308:  80/307] 	 train loss: 0.082950 	 lr: 0.00004
[epoch 308: 100/307] 	 train loss: 0.014733 	 lr: 0.00004
[epoch 308: 120/307] 	 train loss: 0.034575 	 lr: 0.00004
[epoch 308: 140/307] 	 train loss: 0.225033 	 lr: 0.00004

val loss: 0.342402 	 acc: 0.919368

[epoch 308: 160/307] 	 train loss: 0.051157 	 lr: 0.00004
[epoch 308: 180/307] 	 train loss: 0.090785 	 lr: 0.00004
[epoch 308: 200/307] 	 train loss: 0.106924 	 lr: 0.00004
[epoch 308: 220/307] 	 train loss: 0.044384 	 lr: 0.00004
[epoch 308: 240/307] 	 train loss: 0.042793 	 lr: 0.00004
[epoch 308: 260/307] 	 train loss: 0.077325 	 lr: 0.00004
[epoch 308: 280/307] 	 train loss: 0.122229 	 lr: 0.00004
[epoch 308: 300/307] 	 train loss: 0.145705 	 lr: 0.00004

val loss: 0.344804 	 acc: 0.916532

[epoch 309:   0/307] 	 train loss: 0.219266 	 lr: 0.00004
[epoch 309:  20/307] 	 train loss: 0.250947 	 lr: 0.00004
[epoch 309:  40/307] 	 train loss: 0.068471 	 lr: 0.00004
[epoch 309:  60/307] 	 train loss: 0.164670 	 lr: 0.00004
[epoch 309:  80/307] 	 train loss: 0.399062 	 lr: 0.00004
[epoch 309: 100/307] 	 train loss: 0.021065 	 lr: 0.00004
[epoch 309: 120/307] 	 train loss: 0.004762 	 lr: 0.00004
[epoch 309: 140/307] 	 train loss: 0.017284 	 lr: 0.00004

val loss: 0.347297 	 acc: 0.916532

[epoch 309: 160/307] 	 train loss: 0.021362 	 lr: 0.00004
[epoch 309: 180/307] 	 train loss: 0.018978 	 lr: 0.00004
[epoch 309: 200/307] 	 train loss: 0.067654 	 lr: 0.00004
[epoch 309: 220/307] 	 train loss: 0.092401 	 lr: 0.00004
[epoch 309: 240/307] 	 train loss: 0.163530 	 lr: 0.00004
[epoch 309: 260/307] 	 train loss: 0.174865 	 lr: 0.00004
[epoch 309: 280/307] 	 train loss: 0.296461 	 lr: 0.00004
[epoch 309: 300/307] 	 train loss: 0.109694 	 lr: 0.00004

val loss: 0.347060 	 acc: 0.914100

[epoch 310:   0/307] 	 train loss: 0.016616 	 lr: 0.00004
[epoch 310:  20/307] 	 train loss: 0.064418 	 lr: 0.00004
[epoch 310:  40/307] 	 train loss: 0.014169 	 lr: 0.00004
[epoch 310:  60/307] 	 train loss: 0.053505 	 lr: 0.00004
[epoch 310:  80/307] 	 train loss: 0.187922 	 lr: 0.00004
[epoch 310: 100/307] 	 train loss: 0.068794 	 lr: 0.00004
[epoch 310: 120/307] 	 train loss: 0.044650 	 lr: 0.00004
[epoch 310: 140/307] 	 train loss: 0.051496 	 lr: 0.00004

val loss: 0.346419 	 acc: 0.915721

[epoch 310: 160/307] 	 train loss: 0.064800 	 lr: 0.00004
[epoch 310: 180/307] 	 train loss: 0.139663 	 lr: 0.00004
[epoch 310: 200/307] 	 train loss: 0.027018 	 lr: 0.00004
[epoch 310: 220/307] 	 train loss: 0.009536 	 lr: 0.00004
[epoch 310: 240/307] 	 train loss: 0.009485 	 lr: 0.00004
[epoch 310: 260/307] 	 train loss: 0.313564 	 lr: 0.00004
[epoch 310: 280/307] 	 train loss: 0.047621 	 lr: 0.00004

val loss: 0.341345 	 acc: 0.916532

[epoch 310: 300/307] 	 train loss: 0.138748 	 lr: 0.00004
[epoch 311:   0/307] 	 train loss: 0.046598 	 lr: 0.00004
[epoch 311:  20/307] 	 train loss: 0.032094 	 lr: 0.00004
[epoch 311:  40/307] 	 train loss: 0.003565 	 lr: 0.00004
[epoch 311:  60/307] 	 train loss: 0.104165 	 lr: 0.00004
[epoch 311:  80/307] 	 train loss: 0.026507 	 lr: 0.00004
[epoch 311: 100/307] 	 train loss: 0.137676 	 lr: 0.00004
[epoch 311: 120/307] 	 train loss: 0.034539 	 lr: 0.00004
[epoch 311: 140/307] 	 train loss: 0.188136 	 lr: 0.00004

val loss: 0.338263 	 acc: 0.916126

[epoch 311: 160/307] 	 train loss: 0.047782 	 lr: 0.00004
[epoch 311: 180/307] 	 train loss: 0.200071 	 lr: 0.00004
[epoch 311: 200/307] 	 train loss: 0.083252 	 lr: 0.00004
[epoch 311: 220/307] 	 train loss: 0.105185 	 lr: 0.00004
[epoch 311: 240/307] 	 train loss: 0.013005 	 lr: 0.00004
[epoch 311: 260/307] 	 train loss: 0.052230 	 lr: 0.00004
[epoch 311: 280/307] 	 train loss: 0.043408 	 lr: 0.00004

val loss: 0.344539 	 acc: 0.917747

[epoch 311: 300/307] 	 train loss: 0.314224 	 lr: 0.00004
[epoch 312:   0/307] 	 train loss: 0.135829 	 lr: 0.00004
[epoch 312:  20/307] 	 train loss: 0.330873 	 lr: 0.00004
[epoch 312:  40/307] 	 train loss: 0.074355 	 lr: 0.00004
[epoch 312:  60/307] 	 train loss: 0.061077 	 lr: 0.00004
[epoch 312:  80/307] 	 train loss: 0.025511 	 lr: 0.00004
[epoch 312: 100/307] 	 train loss: 0.146115 	 lr: 0.00004
[epoch 312: 120/307] 	 train loss: 0.155133 	 lr: 0.00004
[epoch 312: 140/307] 	 train loss: 0.057626 	 lr: 0.00004

val loss: 0.345969 	 acc: 0.916937

[epoch 312: 160/307] 	 train loss: 0.123555 	 lr: 0.00004
[epoch 312: 180/307] 	 train loss: 0.029345 	 lr: 0.00004
[epoch 312: 200/307] 	 train loss: 0.007224 	 lr: 0.00004
[epoch 312: 220/307] 	 train loss: 0.015915 	 lr: 0.00004
[epoch 312: 240/307] 	 train loss: 0.024845 	 lr: 0.00004
[epoch 312: 260/307] 	 train loss: 0.087063 	 lr: 0.00004
[epoch 312: 280/307] 	 train loss: 0.082733 	 lr: 0.00004

val loss: 0.346509 	 acc: 0.914506

[epoch 312: 300/307] 	 train loss: 0.038499 	 lr: 0.00004
[epoch 313:   0/307] 	 train loss: 0.103344 	 lr: 0.00004
[epoch 313:  20/307] 	 train loss: 0.050290 	 lr: 0.00004
[epoch 313:  40/307] 	 train loss: 0.198885 	 lr: 0.00004
[epoch 313:  60/307] 	 train loss: 0.129259 	 lr: 0.00004
[epoch 313:  80/307] 	 train loss: 0.144137 	 lr: 0.00004
[epoch 313: 100/307] 	 train loss: 0.067802 	 lr: 0.00004
[epoch 313: 120/307] 	 train loss: 0.078688 	 lr: 0.00004
[epoch 313: 140/307] 	 train loss: 0.074605 	 lr: 0.00004

val loss: 0.346651 	 acc: 0.914100

[epoch 313: 160/307] 	 train loss: 0.079208 	 lr: 0.00004
[epoch 313: 180/307] 	 train loss: 0.213854 	 lr: 0.00004
[epoch 313: 200/307] 	 train loss: 0.022454 	 lr: 0.00004
[epoch 313: 220/307] 	 train loss: 0.017560 	 lr: 0.00004
[epoch 313: 240/307] 	 train loss: 0.105350 	 lr: 0.00004
[epoch 313: 260/307] 	 train loss: 0.062850 	 lr: 0.00004
[epoch 313: 280/307] 	 train loss: 0.314877 	 lr: 0.00004

val loss: 0.348527 	 acc: 0.915721

[epoch 313: 300/307] 	 train loss: 0.040995 	 lr: 0.00004
[epoch 314:   0/307] 	 train loss: 0.016757 	 lr: 0.00004
[epoch 314:  20/307] 	 train loss: 0.033423 	 lr: 0.00004
[epoch 314:  40/307] 	 train loss: 0.049417 	 lr: 0.00004
[epoch 314:  60/307] 	 train loss: 0.171767 	 lr: 0.00004
[epoch 314:  80/307] 	 train loss: 0.168864 	 lr: 0.00004
[epoch 314: 100/307] 	 train loss: 0.069631 	 lr: 0.00004
[epoch 314: 120/307] 	 train loss: 0.046236 	 lr: 0.00004

val loss: 0.348379 	 acc: 0.914100

[epoch 314: 140/307] 	 train loss: 0.051582 	 lr: 0.00004
[epoch 314: 160/307] 	 train loss: 0.033497 	 lr: 0.00004
[epoch 314: 180/307] 	 train loss: 0.326255 	 lr: 0.00004
[epoch 314: 200/307] 	 train loss: 0.127528 	 lr: 0.00004
[epoch 314: 220/307] 	 train loss: 0.139060 	 lr: 0.00004
[epoch 314: 240/307] 	 train loss: 0.145536 	 lr: 0.00004
[epoch 314: 260/307] 	 train loss: 0.023517 	 lr: 0.00004
[epoch 314: 280/307] 	 train loss: 0.026768 	 lr: 0.00004

val loss: 0.343571 	 acc: 0.915721

[epoch 314: 300/307] 	 train loss: 0.227926 	 lr: 0.00004
[epoch 315:   0/307] 	 train loss: 0.104897 	 lr: 0.00004
[epoch 315:  20/307] 	 train loss: 0.073482 	 lr: 0.00004
[epoch 315:  40/307] 	 train loss: 0.027652 	 lr: 0.00004
[epoch 315:  60/307] 	 train loss: 0.105361 	 lr: 0.00004
[epoch 315:  80/307] 	 train loss: 0.011563 	 lr: 0.00004
[epoch 315: 100/307] 	 train loss: 0.038530 	 lr: 0.00004
[epoch 315: 120/307] 	 train loss: 0.029122 	 lr: 0.00004

val loss: 0.343126 	 acc: 0.917342

[epoch 315: 140/307] 	 train loss: 0.132716 	 lr: 0.00004
[epoch 315: 160/307] 	 train loss: 0.107722 	 lr: 0.00004
[epoch 315: 180/307] 	 train loss: 0.096889 	 lr: 0.00004
[epoch 315: 200/307] 	 train loss: 0.125844 	 lr: 0.00004
[epoch 315: 220/307] 	 train loss: 0.039985 	 lr: 0.00004
[epoch 315: 240/307] 	 train loss: 0.063847 	 lr: 0.00004
[epoch 315: 260/307] 	 train loss: 0.340664 	 lr: 0.00004
[epoch 315: 280/307] 	 train loss: 0.080432 	 lr: 0.00004

val loss: 0.347298 	 acc: 0.915721

[epoch 315: 300/307] 	 train loss: 0.035686 	 lr: 0.00004
[epoch 316:   0/307] 	 train loss: 0.012031 	 lr: 0.00004
[epoch 316:  20/307] 	 train loss: 0.020061 	 lr: 0.00004
[epoch 316:  40/307] 	 train loss: 0.057868 	 lr: 0.00004
[epoch 316:  60/307] 	 train loss: 0.021340 	 lr: 0.00004
[epoch 316:  80/307] 	 train loss: 0.019910 	 lr: 0.00004
[epoch 316: 100/307] 	 train loss: 0.115980 	 lr: 0.00004
[epoch 316: 120/307] 	 train loss: 0.163362 	 lr: 0.00004

val loss: 0.347240 	 acc: 0.915721

[epoch 316: 140/307] 	 train loss: 0.214980 	 lr: 0.00004
[epoch 316: 160/307] 	 train loss: 0.005355 	 lr: 0.00004
[epoch 316: 180/307] 	 train loss: 0.119098 	 lr: 0.00004
[epoch 316: 200/307] 	 train loss: 0.062007 	 lr: 0.00004
[epoch 316: 220/307] 	 train loss: 0.248500 	 lr: 0.00004
[epoch 316: 240/307] 	 train loss: 0.046412 	 lr: 0.00004
[epoch 316: 260/307] 	 train loss: 0.070188 	 lr: 0.00004
[epoch 316: 280/307] 	 train loss: 0.090917 	 lr: 0.00004

val loss: 0.347241 	 acc: 0.915316

[epoch 316: 300/307] 	 train loss: 0.043041 	 lr: 0.00004
[epoch 317:   0/307] 	 train loss: 0.072037 	 lr: 0.00004
[epoch 317:  20/307] 	 train loss: 0.101184 	 lr: 0.00004
[epoch 317:  40/307] 	 train loss: 0.073436 	 lr: 0.00004
[epoch 317:  60/307] 	 train loss: 0.071673 	 lr: 0.00004
[epoch 317:  80/307] 	 train loss: 0.061817 	 lr: 0.00004
[epoch 317: 100/307] 	 train loss: 0.051934 	 lr: 0.00004
[epoch 317: 120/307] 	 train loss: 0.106912 	 lr: 0.00004

val loss: 0.342685 	 acc: 0.916937

[epoch 317: 140/307] 	 train loss: 0.138798 	 lr: 0.00004
[epoch 317: 160/307] 	 train loss: 0.219562 	 lr: 0.00004
[epoch 317: 180/307] 	 train loss: 0.107973 	 lr: 0.00004
[epoch 317: 200/307] 	 train loss: 0.222171 	 lr: 0.00004
[epoch 317: 220/307] 	 train loss: 0.052212 	 lr: 0.00004
[epoch 317: 240/307] 	 train loss: 0.050168 	 lr: 0.00004
[epoch 317: 260/307] 	 train loss: 0.016233 	 lr: 0.00004
[epoch 317: 280/307] 	 train loss: 0.017938 	 lr: 0.00004

val loss: 0.346037 	 acc: 0.914506

[epoch 317: 300/307] 	 train loss: 0.063239 	 lr: 0.00004
[epoch 318:   0/307] 	 train loss: 0.027249 	 lr: 0.00004
[epoch 318:  20/307] 	 train loss: 0.005705 	 lr: 0.00004
[epoch 318:  40/307] 	 train loss: 0.166849 	 lr: 0.00004
[epoch 318:  60/307] 	 train loss: 0.275074 	 lr: 0.00004
[epoch 318:  80/307] 	 train loss: 0.096071 	 lr: 0.00004
[epoch 318: 100/307] 	 train loss: 0.008529 	 lr: 0.00004
[epoch 318: 120/307] 	 train loss: 0.051102 	 lr: 0.00004

val loss: 0.342898 	 acc: 0.917342

[epoch 318: 140/307] 	 train loss: 0.058199 	 lr: 0.00004
[epoch 318: 160/307] 	 train loss: 0.167757 	 lr: 0.00004
[epoch 318: 180/307] 	 train loss: 0.011923 	 lr: 0.00004
[epoch 318: 200/307] 	 train loss: 0.066294 	 lr: 0.00004
[epoch 318: 220/307] 	 train loss: 0.066500 	 lr: 0.00004
[epoch 318: 240/307] 	 train loss: 0.129729 	 lr: 0.00004
[epoch 318: 260/307] 	 train loss: 0.163416 	 lr: 0.00004
[epoch 318: 280/307] 	 train loss: 0.078728 	 lr: 0.00004

val loss: 0.344657 	 acc: 0.916126

[epoch 318: 300/307] 	 train loss: 0.034326 	 lr: 0.00004
[epoch 319:   0/307] 	 train loss: 0.023309 	 lr: 0.00004
[epoch 319:  20/307] 	 train loss: 0.036951 	 lr: 0.00004
[epoch 319:  40/307] 	 train loss: 0.200188 	 lr: 0.00004
[epoch 319:  60/307] 	 train loss: 0.017705 	 lr: 0.00004
[epoch 319:  80/307] 	 train loss: 0.085362 	 lr: 0.00004
[epoch 319: 100/307] 	 train loss: 0.075912 	 lr: 0.00004
[epoch 319: 120/307] 	 train loss: 0.243381 	 lr: 0.00004

val loss: 0.338609 	 acc: 0.917342

[epoch 319: 140/307] 	 train loss: 0.016816 	 lr: 0.00004
[epoch 319: 160/307] 	 train loss: 0.276698 	 lr: 0.00004
[epoch 319: 180/307] 	 train loss: 0.072753 	 lr: 0.00004
[epoch 319: 200/307] 	 train loss: 0.037613 	 lr: 0.00004
[epoch 319: 220/307] 	 train loss: 0.052401 	 lr: 0.00004
[epoch 319: 240/307] 	 train loss: 0.022306 	 lr: 0.00004
[epoch 319: 260/307] 	 train loss: 0.019283 	 lr: 0.00004
[epoch 319: 280/307] 	 train loss: 0.042781 	 lr: 0.00004

val loss: 0.339377 	 acc: 0.919368

[epoch 319: 300/307] 	 train loss: 0.080303 	 lr: 0.00004
[epoch 320:   0/307] 	 train loss: 0.183850 	 lr: 0.00004
[epoch 320:  20/307] 	 train loss: 0.118099 	 lr: 0.00004
[epoch 320:  40/307] 	 train loss: 0.028663 	 lr: 0.00004
[epoch 320:  60/307] 	 train loss: 0.006421 	 lr: 0.00004
[epoch 320:  80/307] 	 train loss: 0.043511 	 lr: 0.00004
[epoch 320: 100/307] 	 train loss: 0.360938 	 lr: 0.00004
[epoch 320: 120/307] 	 train loss: 0.037392 	 lr: 0.00004

val loss: 0.340563 	 acc: 0.918558

[epoch 320: 140/307] 	 train loss: 0.101824 	 lr: 0.00004
[epoch 320: 160/307] 	 train loss: 0.230180 	 lr: 0.00004
[epoch 320: 180/307] 	 train loss: 0.067681 	 lr: 0.00004
[epoch 320: 200/307] 	 train loss: 0.101971 	 lr: 0.00004
[epoch 320: 220/307] 	 train loss: 0.043073 	 lr: 0.00004
[epoch 320: 240/307] 	 train loss: 0.126304 	 lr: 0.00004
[epoch 320: 260/307] 	 train loss: 0.277966 	 lr: 0.00004

val loss: 0.340137 	 acc: 0.918152

[epoch 320: 280/307] 	 train loss: 0.066601 	 lr: 0.00004
[epoch 320: 300/307] 	 train loss: 0.059203 	 lr: 0.00004
[epoch 321:   0/307] 	 train loss: 0.150854 	 lr: 0.00004
[epoch 321:  20/307] 	 train loss: 0.113196 	 lr: 0.00004
[epoch 321:  40/307] 	 train loss: 0.112980 	 lr: 0.00004
[epoch 321:  60/307] 	 train loss: 0.182917 	 lr: 0.00004
[epoch 321:  80/307] 	 train loss: 0.046085 	 lr: 0.00004
[epoch 321: 100/307] 	 train loss: 0.088345 	 lr: 0.00004
[epoch 321: 120/307] 	 train loss: 0.024208 	 lr: 0.00004

val loss: 0.343334 	 acc: 0.916937

[epoch 321: 140/307] 	 train loss: 0.044680 	 lr: 0.00004
[epoch 321: 160/307] 	 train loss: 0.092424 	 lr: 0.00004
[epoch 321: 180/307] 	 train loss: 0.034235 	 lr: 0.00004
[epoch 321: 200/307] 	 train loss: 0.048609 	 lr: 0.00004
[epoch 321: 220/307] 	 train loss: 0.145326 	 lr: 0.00004
[epoch 321: 240/307] 	 train loss: 0.167044 	 lr: 0.00004
[epoch 321: 260/307] 	 train loss: 0.123302 	 lr: 0.00004

val loss: 0.343142 	 acc: 0.918963

[epoch 321: 280/307] 	 train loss: 0.321402 	 lr: 0.00004
[epoch 321: 300/307] 	 train loss: 0.163945 	 lr: 0.00004
[epoch 322:   0/307] 	 train loss: 0.096344 	 lr: 0.00004
[epoch 322:  20/307] 	 train loss: 0.059109 	 lr: 0.00004
[epoch 322:  40/307] 	 train loss: 0.062240 	 lr: 0.00004
[epoch 322:  60/307] 	 train loss: 0.123794 	 lr: 0.00004
[epoch 322:  80/307] 	 train loss: 0.036638 	 lr: 0.00004
[epoch 322: 100/307] 	 train loss: 0.103980 	 lr: 0.00004
[epoch 322: 120/307] 	 train loss: 0.186817 	 lr: 0.00004

val loss: 0.341692 	 acc: 0.919773

[epoch 322: 140/307] 	 train loss: 0.148136 	 lr: 0.00004
[epoch 322: 160/307] 	 train loss: 0.073836 	 lr: 0.00004
[epoch 322: 180/307] 	 train loss: 0.057536 	 lr: 0.00004
[epoch 322: 200/307] 	 train loss: 0.024949 	 lr: 0.00004
[epoch 322: 220/307] 	 train loss: 0.031111 	 lr: 0.00004
[epoch 322: 240/307] 	 train loss: 0.141432 	 lr: 0.00004
[epoch 322: 260/307] 	 train loss: 0.054601 	 lr: 0.00004

val loss: 0.339591 	 acc: 0.919773

[epoch 322: 280/307] 	 train loss: 0.007590 	 lr: 0.00004
[epoch 322: 300/307] 	 train loss: 0.046457 	 lr: 0.00004
[epoch 323:   0/307] 	 train loss: 0.064665 	 lr: 0.00004
[epoch 323:  20/307] 	 train loss: 0.223883 	 lr: 0.00004
[epoch 323:  40/307] 	 train loss: 0.184746 	 lr: 0.00004
[epoch 323:  60/307] 	 train loss: 0.019907 	 lr: 0.00004
[epoch 323:  80/307] 	 train loss: 0.144017 	 lr: 0.00004
[epoch 323: 100/307] 	 train loss: 0.170580 	 lr: 0.00004
[epoch 323: 120/307] 	 train loss: 0.084233 	 lr: 0.00004

val loss: 0.342664 	 acc: 0.918963

[epoch 323: 140/307] 	 train loss: 0.058480 	 lr: 0.00004
[epoch 323: 160/307] 	 train loss: 0.117336 	 lr: 0.00004
[epoch 323: 180/307] 	 train loss: 0.097850 	 lr: 0.00004
[epoch 323: 200/307] 	 train loss: 0.015154 	 lr: 0.00004
[epoch 323: 220/307] 	 train loss: 0.091152 	 lr: 0.00004
[epoch 323: 240/307] 	 train loss: 0.051066 	 lr: 0.00004
[epoch 323: 260/307] 	 train loss: 0.116680 	 lr: 0.00004

val loss: 0.342275 	 acc: 0.916937

[epoch 323: 280/307] 	 train loss: 0.047895 	 lr: 0.00004
[epoch 323: 300/307] 	 train loss: 0.066610 	 lr: 0.00004
[epoch 324:   0/307] 	 train loss: 0.143963 	 lr: 0.00004
[epoch 324:  20/307] 	 train loss: 0.146170 	 lr: 0.00004
[epoch 324:  40/307] 	 train loss: 0.017060 	 lr: 0.00004
[epoch 324:  60/307] 	 train loss: 0.138253 	 lr: 0.00004
[epoch 324:  80/307] 	 train loss: 0.015192 	 lr: 0.00004
[epoch 324: 100/307] 	 train loss: 0.091700 	 lr: 0.00004

val loss: 0.342131 	 acc: 0.918152

[epoch 324: 120/307] 	 train loss: 0.051503 	 lr: 0.00004
[epoch 324: 140/307] 	 train loss: 0.019773 	 lr: 0.00004
[epoch 324: 160/307] 	 train loss: 0.131047 	 lr: 0.00004
[epoch 324: 180/307] 	 train loss: 0.222082 	 lr: 0.00004
[epoch 324: 200/307] 	 train loss: 0.226252 	 lr: 0.00004
[epoch 324: 220/307] 	 train loss: 0.172756 	 lr: 0.00004
[epoch 324: 240/307] 	 train loss: 0.038929 	 lr: 0.00004
[epoch 324: 260/307] 	 train loss: 0.152238 	 lr: 0.00004

val loss: 0.345714 	 acc: 0.918963

[epoch 324: 280/307] 	 train loss: 0.026601 	 lr: 0.00004
[epoch 324: 300/307] 	 train loss: 0.204498 	 lr: 0.00004
[epoch 325:   0/307] 	 train loss: 0.231896 	 lr: 0.00004
[epoch 325:  20/307] 	 train loss: 0.129791 	 lr: 0.00004
[epoch 325:  40/307] 	 train loss: 0.009912 	 lr: 0.00004
[epoch 325:  60/307] 	 train loss: 0.018383 	 lr: 0.00004
[epoch 325:  80/307] 	 train loss: 0.262533 	 lr: 0.00004
[epoch 325: 100/307] 	 train loss: 0.137272 	 lr: 0.00004

val loss: 0.346423 	 acc: 0.917342

[epoch 325: 120/307] 	 train loss: 0.286730 	 lr: 0.00004
[epoch 325: 140/307] 	 train loss: 0.140087 	 lr: 0.00004
[epoch 325: 160/307] 	 train loss: 0.308066 	 lr: 0.00004
[epoch 325: 180/307] 	 train loss: 0.020837 	 lr: 0.00004
[epoch 325: 200/307] 	 train loss: 0.124725 	 lr: 0.00004
[epoch 325: 220/307] 	 train loss: 0.042835 	 lr: 0.00004
[epoch 325: 240/307] 	 train loss: 0.071004 	 lr: 0.00004
[epoch 325: 260/307] 	 train loss: 0.040648 	 lr: 0.00004

val loss: 0.345248 	 acc: 0.916937

[epoch 325: 280/307] 	 train loss: 0.110027 	 lr: 0.00004
[epoch 325: 300/307] 	 train loss: 0.056138 	 lr: 0.00004
[epoch 326:   0/307] 	 train loss: 0.037556 	 lr: 0.00004
[epoch 326:  20/307] 	 train loss: 0.081832 	 lr: 0.00004
[epoch 326:  40/307] 	 train loss: 0.207366 	 lr: 0.00004
[epoch 326:  60/307] 	 train loss: 0.163520 	 lr: 0.00004
[epoch 326:  80/307] 	 train loss: 0.052049 	 lr: 0.00004
[epoch 326: 100/307] 	 train loss: 0.082141 	 lr: 0.00004

val loss: 0.348086 	 acc: 0.915316

[epoch 326: 120/307] 	 train loss: 0.015851 	 lr: 0.00004
[epoch 326: 140/307] 	 train loss: 0.184315 	 lr: 0.00004
[epoch 326: 160/307] 	 train loss: 0.170068 	 lr: 0.00004
[epoch 326: 180/307] 	 train loss: 0.089206 	 lr: 0.00004
[epoch 326: 200/307] 	 train loss: 0.074305 	 lr: 0.00004
[epoch 326: 220/307] 	 train loss: 0.093682 	 lr: 0.00004
[epoch 326: 240/307] 	 train loss: 0.158818 	 lr: 0.00004
[epoch 326: 260/307] 	 train loss: 0.088011 	 lr: 0.00004

val loss: 0.345292 	 acc: 0.918152

[epoch 326: 280/307] 	 train loss: 0.152121 	 lr: 0.00004
[epoch 326: 300/307] 	 train loss: 0.147554 	 lr: 0.00004
[epoch 327:   0/307] 	 train loss: 0.060648 	 lr: 0.00004
[epoch 327:  20/307] 	 train loss: 0.006842 	 lr: 0.00004
[epoch 327:  40/307] 	 train loss: 0.110233 	 lr: 0.00004
[epoch 327:  60/307] 	 train loss: 0.043022 	 lr: 0.00004
[epoch 327:  80/307] 	 train loss: 0.022506 	 lr: 0.00004
[epoch 327: 100/307] 	 train loss: 0.075621 	 lr: 0.00004

val loss: 0.341779 	 acc: 0.918963

[epoch 327: 120/307] 	 train loss: 0.011345 	 lr: 0.00004
[epoch 327: 140/307] 	 train loss: 0.005038 	 lr: 0.00004
[epoch 327: 160/307] 	 train loss: 0.109502 	 lr: 0.00004
[epoch 327: 180/307] 	 train loss: 0.078112 	 lr: 0.00004
[epoch 327: 200/307] 	 train loss: 0.327484 	 lr: 0.00004
[epoch 327: 220/307] 	 train loss: 0.126255 	 lr: 0.00004
[epoch 327: 240/307] 	 train loss: 0.189350 	 lr: 0.00004
[epoch 327: 260/307] 	 train loss: 0.043728 	 lr: 0.00004

val loss: 0.346984 	 acc: 0.912885

[epoch 327: 280/307] 	 train loss: 0.009907 	 lr: 0.00004
[epoch 327: 300/307] 	 train loss: 0.028698 	 lr: 0.00004
[epoch 328:   0/307] 	 train loss: 0.078476 	 lr: 0.00004
[epoch 328:  20/307] 	 train loss: 0.035898 	 lr: 0.00004
[epoch 328:  40/307] 	 train loss: 0.109619 	 lr: 0.00004
[epoch 328:  60/307] 	 train loss: 0.152964 	 lr: 0.00004
[epoch 328:  80/307] 	 train loss: 0.119208 	 lr: 0.00004
[epoch 328: 100/307] 	 train loss: 0.024491 	 lr: 0.00004

val loss: 0.343420 	 acc: 0.916532

[epoch 328: 120/307] 	 train loss: 0.023044 	 lr: 0.00004
[epoch 328: 140/307] 	 train loss: 0.119431 	 lr: 0.00004
[epoch 328: 160/307] 	 train loss: 0.039962 	 lr: 0.00004
[epoch 328: 180/307] 	 train loss: 0.076959 	 lr: 0.00004
[epoch 328: 200/307] 	 train loss: 0.046981 	 lr: 0.00004
[epoch 328: 220/307] 	 train loss: 0.089528 	 lr: 0.00004
[epoch 328: 240/307] 	 train loss: 0.153080 	 lr: 0.00004
[epoch 328: 260/307] 	 train loss: 0.055661 	 lr: 0.00004

val loss: 0.341704 	 acc: 0.917342

[epoch 328: 280/307] 	 train loss: 0.056039 	 lr: 0.00004
[epoch 328: 300/307] 	 train loss: 0.088518 	 lr: 0.00004
[epoch 329:   0/307] 	 train loss: 0.074329 	 lr: 0.00004
[epoch 329:  20/307] 	 train loss: 0.073727 	 lr: 0.00004
[epoch 329:  40/307] 	 train loss: 0.143794 	 lr: 0.00004
[epoch 329:  60/307] 	 train loss: 0.078539 	 lr: 0.00004
[epoch 329:  80/307] 	 train loss: 0.087432 	 lr: 0.00004
[epoch 329: 100/307] 	 train loss: 0.195841 	 lr: 0.00004

val loss: 0.344724 	 acc: 0.914911

[epoch 329: 120/307] 	 train loss: 0.083136 	 lr: 0.00004
[epoch 329: 140/307] 	 train loss: 0.015213 	 lr: 0.00004
[epoch 329: 160/307] 	 train loss: 0.056213 	 lr: 0.00004
[epoch 329: 180/307] 	 train loss: 0.017317 	 lr: 0.00004
[epoch 329: 200/307] 	 train loss: 0.094568 	 lr: 0.00004
[epoch 329: 220/307] 	 train loss: 0.018908 	 lr: 0.00004
[epoch 329: 240/307] 	 train loss: 0.141070 	 lr: 0.00004
[epoch 329: 260/307] 	 train loss: 0.384226 	 lr: 0.00004

val loss: 0.345783 	 acc: 0.914100

[epoch 329: 280/307] 	 train loss: 0.027787 	 lr: 0.00004
[epoch 329: 300/307] 	 train loss: 0.024072 	 lr: 0.00004
[epoch 330:   0/307] 	 train loss: 0.021455 	 lr: 0.00004
[epoch 330:  20/307] 	 train loss: 0.047784 	 lr: 0.00004
[epoch 330:  40/307] 	 train loss: 0.008757 	 lr: 0.00004
[epoch 330:  60/307] 	 train loss: 0.105181 	 lr: 0.00004
[epoch 330:  80/307] 	 train loss: 0.110691 	 lr: 0.00004
[epoch 330: 100/307] 	 train loss: 0.035700 	 lr: 0.00004

val loss: 0.341912 	 acc: 0.916126

[epoch 330: 120/307] 	 train loss: 0.113299 	 lr: 0.00004
[epoch 330: 140/307] 	 train loss: 0.106430 	 lr: 0.00004
[epoch 330: 160/307] 	 train loss: 0.013198 	 lr: 0.00004
[epoch 330: 180/307] 	 train loss: 0.196352 	 lr: 0.00004
[epoch 330: 200/307] 	 train loss: 0.178461 	 lr: 0.00004
[epoch 330: 220/307] 	 train loss: 0.061705 	 lr: 0.00004
[epoch 330: 240/307] 	 train loss: 0.017679 	 lr: 0.00004

val loss: 0.341242 	 acc: 0.914506

[epoch 330: 260/307] 	 train loss: 0.081407 	 lr: 0.00004
[epoch 330: 280/307] 	 train loss: 0.028382 	 lr: 0.00004
[epoch 330: 300/307] 	 train loss: 0.047778 	 lr: 0.00004
[epoch 331:   0/307] 	 train loss: 0.123972 	 lr: 0.00004
[epoch 331:  20/307] 	 train loss: 0.032054 	 lr: 0.00004
[epoch 331:  40/307] 	 train loss: 0.089054 	 lr: 0.00004
[epoch 331:  60/307] 	 train loss: 0.117620 	 lr: 0.00004
[epoch 331:  80/307] 	 train loss: 0.114359 	 lr: 0.00004
[epoch 331: 100/307] 	 train loss: 0.017922 	 lr: 0.00004

val loss: 0.340491 	 acc: 0.914100

[epoch 331: 120/307] 	 train loss: 0.068852 	 lr: 0.00004
[epoch 331: 140/307] 	 train loss: 0.007757 	 lr: 0.00004
[epoch 331: 160/307] 	 train loss: 0.056110 	 lr: 0.00004
[epoch 331: 180/307] 	 train loss: 0.053547 	 lr: 0.00004
[epoch 331: 200/307] 	 train loss: 0.052427 	 lr: 0.00004
[epoch 331: 220/307] 	 train loss: 0.064591 	 lr: 0.00004
[epoch 331: 240/307] 	 train loss: 0.059143 	 lr: 0.00004

val loss: 0.344749 	 acc: 0.914911

[epoch 331: 260/307] 	 train loss: 0.007261 	 lr: 0.00004
[epoch 331: 280/307] 	 train loss: 0.021696 	 lr: 0.00004
[epoch 331: 300/307] 	 train loss: 0.091165 	 lr: 0.00004
[epoch 332:   0/307] 	 train loss: 0.057818 	 lr: 0.00004
[epoch 332:  20/307] 	 train loss: 0.111375 	 lr: 0.00004
[epoch 332:  40/307] 	 train loss: 0.096910 	 lr: 0.00004
[epoch 332:  60/307] 	 train loss: 0.092919 	 lr: 0.00004
[epoch 332:  80/307] 	 train loss: 0.310363 	 lr: 0.00004
[epoch 332: 100/307] 	 train loss: 0.036835 	 lr: 0.00004

val loss: 0.340451 	 acc: 0.915721

[epoch 332: 120/307] 	 train loss: 0.259606 	 lr: 0.00004
[epoch 332: 140/307] 	 train loss: 0.033824 	 lr: 0.00004
[epoch 332: 160/307] 	 train loss: 0.120004 	 lr: 0.00004
[epoch 332: 180/307] 	 train loss: 0.113510 	 lr: 0.00004
[epoch 332: 200/307] 	 train loss: 0.072253 	 lr: 0.00004
[epoch 332: 220/307] 	 train loss: 0.171066 	 lr: 0.00004
[epoch 332: 240/307] 	 train loss: 0.058738 	 lr: 0.00004

val loss: 0.341538 	 acc: 0.916126

[epoch 332: 260/307] 	 train loss: 0.172385 	 lr: 0.00004
[epoch 332: 280/307] 	 train loss: 0.013591 	 lr: 0.00004
[epoch 332: 300/307] 	 train loss: 0.067591 	 lr: 0.00004
[epoch 333:   0/307] 	 train loss: 0.038549 	 lr: 0.00004
[epoch 333:  20/307] 	 train loss: 0.044633 	 lr: 0.00004
[epoch 333:  40/307] 	 train loss: 0.083582 	 lr: 0.00004
[epoch 333:  60/307] 	 train loss: 0.105633 	 lr: 0.00004
[epoch 333:  80/307] 	 train loss: 0.064891 	 lr: 0.00004
[epoch 333: 100/307] 	 train loss: 0.052318 	 lr: 0.00004

val loss: 0.340727 	 acc: 0.916126

[epoch 333: 120/307] 	 train loss: 0.028255 	 lr: 0.00004
[epoch 333: 140/307] 	 train loss: 0.048735 	 lr: 0.00004
[epoch 333: 160/307] 	 train loss: 0.020584 	 lr: 0.00004
[epoch 333: 180/307] 	 train loss: 0.014245 	 lr: 0.00004
[epoch 333: 200/307] 	 train loss: 0.015759 	 lr: 0.00004
[epoch 333: 220/307] 	 train loss: 0.145374 	 lr: 0.00004
[epoch 333: 240/307] 	 train loss: 0.015951 	 lr: 0.00004

val loss: 0.338308 	 acc: 0.917342

[epoch 333: 260/307] 	 train loss: 0.105911 	 lr: 0.00004
[epoch 333: 280/307] 	 train loss: 0.086572 	 lr: 0.00004
[epoch 333: 300/307] 	 train loss: 0.013470 	 lr: 0.00004
[epoch 334:   0/307] 	 train loss: 0.019980 	 lr: 0.00004
[epoch 334:  20/307] 	 train loss: 0.031872 	 lr: 0.00004
[epoch 334:  40/307] 	 train loss: 0.086358 	 lr: 0.00004
[epoch 334:  60/307] 	 train loss: 0.071906 	 lr: 0.00004
[epoch 334:  80/307] 	 train loss: 0.040170 	 lr: 0.00004

val loss: 0.345443 	 acc: 0.914911

[epoch 334: 100/307] 	 train loss: 0.199209 	 lr: 0.00004
[epoch 334: 120/307] 	 train loss: 0.321951 	 lr: 0.00004
[epoch 334: 140/307] 	 train loss: 0.140352 	 lr: 0.00004
[epoch 334: 160/307] 	 train loss: 0.011566 	 lr: 0.00004
[epoch 334: 180/307] 	 train loss: 0.160786 	 lr: 0.00004
[epoch 334: 200/307] 	 train loss: 0.086166 	 lr: 0.00004
[epoch 334: 220/307] 	 train loss: 0.114205 	 lr: 0.00004
[epoch 334: 240/307] 	 train loss: 0.027124 	 lr: 0.00004

val loss: 0.344837 	 acc: 0.916937

[epoch 334: 260/307] 	 train loss: 0.119043 	 lr: 0.00004
[epoch 334: 280/307] 	 train loss: 0.257993 	 lr: 0.00004
[epoch 334: 300/307] 	 train loss: 0.055438 	 lr: 0.00004
[epoch 335:   0/307] 	 train loss: 0.011754 	 lr: 0.00004
[epoch 335:  20/307] 	 train loss: 0.029908 	 lr: 0.00004
[epoch 335:  40/307] 	 train loss: 0.009645 	 lr: 0.00004
[epoch 335:  60/307] 	 train loss: 0.086976 	 lr: 0.00004
[epoch 335:  80/307] 	 train loss: 0.131406 	 lr: 0.00004

val loss: 0.340656 	 acc: 0.915721

[epoch 335: 100/307] 	 train loss: 0.022076 	 lr: 0.00004
[epoch 335: 120/307] 	 train loss: 0.012401 	 lr: 0.00004
[epoch 335: 140/307] 	 train loss: 0.057036 	 lr: 0.00004
[epoch 335: 160/307] 	 train loss: 0.214497 	 lr: 0.00004
[epoch 335: 180/307] 	 train loss: 0.032759 	 lr: 0.00004
[epoch 335: 200/307] 	 train loss: 0.051599 	 lr: 0.00004
[epoch 335: 220/307] 	 train loss: 0.065622 	 lr: 0.00004
[epoch 335: 240/307] 	 train loss: 0.090103 	 lr: 0.00004

val loss: 0.340939 	 acc: 0.916126

[epoch 335: 260/307] 	 train loss: 0.024220 	 lr: 0.00004
[epoch 335: 280/307] 	 train loss: 0.054273 	 lr: 0.00004
[epoch 335: 300/307] 	 train loss: 0.048030 	 lr: 0.00004
[epoch 336:   0/307] 	 train loss: 0.002072 	 lr: 0.00004
[epoch 336:  20/307] 	 train loss: 0.039531 	 lr: 0.00004
[epoch 336:  40/307] 	 train loss: 0.095064 	 lr: 0.00004
[epoch 336:  60/307] 	 train loss: 0.059554 	 lr: 0.00004
[epoch 336:  80/307] 	 train loss: 0.032536 	 lr: 0.00004

val loss: 0.340342 	 acc: 0.917342

[epoch 336: 100/307] 	 train loss: 0.052175 	 lr: 0.00004
[epoch 336: 120/307] 	 train loss: 0.161810 	 lr: 0.00004
[epoch 336: 140/307] 	 train loss: 0.015395 	 lr: 0.00004
[epoch 336: 160/307] 	 train loss: 0.155428 	 lr: 0.00004
[epoch 336: 180/307] 	 train loss: 0.030908 	 lr: 0.00004
[epoch 336: 200/307] 	 train loss: 0.066429 	 lr: 0.00004
[epoch 336: 220/307] 	 train loss: 0.175649 	 lr: 0.00004
[epoch 336: 240/307] 	 train loss: 0.023619 	 lr: 0.00004

val loss: 0.347049 	 acc: 0.915721

[epoch 336: 260/307] 	 train loss: 0.270546 	 lr: 0.00004
[epoch 336: 280/307] 	 train loss: 0.027459 	 lr: 0.00004
[epoch 336: 300/307] 	 train loss: 0.054151 	 lr: 0.00004
[epoch 337:   0/307] 	 train loss: 0.036739 	 lr: 0.00003
[epoch 337:  20/307] 	 train loss: 0.384910 	 lr: 0.00003
[epoch 337:  40/307] 	 train loss: 0.024093 	 lr: 0.00003
[epoch 337:  60/307] 	 train loss: 0.226272 	 lr: 0.00003
[epoch 337:  80/307] 	 train loss: 0.028003 	 lr: 0.00003

val loss: 0.343471 	 acc: 0.915721

[epoch 337: 100/307] 	 train loss: 0.134743 	 lr: 0.00003
[epoch 337: 120/307] 	 train loss: 0.017149 	 lr: 0.00003
[epoch 337: 140/307] 	 train loss: 0.041283 	 lr: 0.00003
[epoch 337: 160/307] 	 train loss: 0.092190 	 lr: 0.00003
[epoch 337: 180/307] 	 train loss: 0.067064 	 lr: 0.00003
[epoch 337: 200/307] 	 train loss: 0.041174 	 lr: 0.00003
[epoch 337: 220/307] 	 train loss: 0.207206 	 lr: 0.00003
[epoch 337: 240/307] 	 train loss: 0.110876 	 lr: 0.00003

val loss: 0.342627 	 acc: 0.917342

[epoch 337: 260/307] 	 train loss: 0.098309 	 lr: 0.00003
[epoch 337: 280/307] 	 train loss: 0.138801 	 lr: 0.00003
[epoch 337: 300/307] 	 train loss: 0.125103 	 lr: 0.00003
[epoch 338:   0/307] 	 train loss: 0.227855 	 lr: 0.00003
[epoch 338:  20/307] 	 train loss: 0.020559 	 lr: 0.00003
[epoch 338:  40/307] 	 train loss: 0.219076 	 lr: 0.00003
[epoch 338:  60/307] 	 train loss: 0.091545 	 lr: 0.00003
[epoch 338:  80/307] 	 train loss: 0.132333 	 lr: 0.00003

val loss: 0.347543 	 acc: 0.914911

[epoch 338: 100/307] 	 train loss: 0.241821 	 lr: 0.00003
[epoch 338: 120/307] 	 train loss: 0.044437 	 lr: 0.00003
[epoch 338: 140/307] 	 train loss: 0.022915 	 lr: 0.00003
[epoch 338: 160/307] 	 train loss: 0.127705 	 lr: 0.00003
[epoch 338: 180/307] 	 train loss: 0.048684 	 lr: 0.00003
[epoch 338: 200/307] 	 train loss: 0.050272 	 lr: 0.00003
[epoch 338: 220/307] 	 train loss: 0.164055 	 lr: 0.00003
[epoch 338: 240/307] 	 train loss: 0.110035 	 lr: 0.00003

val loss: 0.350750 	 acc: 0.915316

[epoch 338: 260/307] 	 train loss: 0.073438 	 lr: 0.00003
[epoch 338: 280/307] 	 train loss: 0.025599 	 lr: 0.00003
[epoch 338: 300/307] 	 train loss: 0.187626 	 lr: 0.00003
[epoch 339:   0/307] 	 train loss: 0.302199 	 lr: 0.00003
[epoch 339:  20/307] 	 train loss: 0.096194 	 lr: 0.00003
[epoch 339:  40/307] 	 train loss: 0.159660 	 lr: 0.00003
[epoch 339:  60/307] 	 train loss: 0.033895 	 lr: 0.00003
[epoch 339:  80/307] 	 train loss: 0.100443 	 lr: 0.00003

val loss: 0.344979 	 acc: 0.914911

[epoch 339: 100/307] 	 train loss: 0.087239 	 lr: 0.00003
[epoch 339: 120/307] 	 train loss: 0.012498 	 lr: 0.00003
[epoch 339: 140/307] 	 train loss: 0.102309 	 lr: 0.00003
[epoch 339: 160/307] 	 train loss: 0.020900 	 lr: 0.00003
[epoch 339: 180/307] 	 train loss: 0.062523 	 lr: 0.00003
[epoch 339: 200/307] 	 train loss: 0.036799 	 lr: 0.00003
[epoch 339: 220/307] 	 train loss: 0.261337 	 lr: 0.00003
[epoch 339: 240/307] 	 train loss: 0.105811 	 lr: 0.00003

val loss: 0.347703 	 acc: 0.915316

[epoch 339: 260/307] 	 train loss: 0.166708 	 lr: 0.00003
[epoch 339: 280/307] 	 train loss: 0.019156 	 lr: 0.00003
[epoch 339: 300/307] 	 train loss: 0.041630 	 lr: 0.00003
[epoch 340:   0/307] 	 train loss: 0.068430 	 lr: 0.00003
[epoch 340:  20/307] 	 train loss: 0.121892 	 lr: 0.00003
[epoch 340:  40/307] 	 train loss: 0.034975 	 lr: 0.00003
[epoch 340:  60/307] 	 train loss: 0.149165 	 lr: 0.00003
[epoch 340:  80/307] 	 train loss: 0.093895 	 lr: 0.00003

val loss: 0.346543 	 acc: 0.914506

[epoch 340: 100/307] 	 train loss: 0.068660 	 lr: 0.00003
[epoch 340: 120/307] 	 train loss: 0.042294 	 lr: 0.00003
[epoch 340: 140/307] 	 train loss: 0.013620 	 lr: 0.00003
[epoch 340: 160/307] 	 train loss: 0.125141 	 lr: 0.00003
[epoch 340: 180/307] 	 train loss: 0.045051 	 lr: 0.00003
[epoch 340: 200/307] 	 train loss: 0.007626 	 lr: 0.00003
[epoch 340: 220/307] 	 train loss: 0.102732 	 lr: 0.00003

val loss: 0.342981 	 acc: 0.916126

[epoch 340: 240/307] 	 train loss: 0.026621 	 lr: 0.00003
[epoch 340: 260/307] 	 train loss: 0.046380 	 lr: 0.00003
[epoch 340: 280/307] 	 train loss: 0.085192 	 lr: 0.00003
[epoch 340: 300/307] 	 train loss: 0.127293 	 lr: 0.00003
[epoch 341:   0/307] 	 train loss: 0.247168 	 lr: 0.00003
[epoch 341:  20/307] 	 train loss: 0.025757 	 lr: 0.00003
[epoch 341:  40/307] 	 train loss: 0.109116 	 lr: 0.00003
[epoch 341:  60/307] 	 train loss: 0.215050 	 lr: 0.00003
[epoch 341:  80/307] 	 train loss: 0.021101 	 lr: 0.00003

val loss: 0.345282 	 acc: 0.915316

[epoch 341: 100/307] 	 train loss: 0.043901 	 lr: 0.00003
[epoch 341: 120/307] 	 train loss: 0.075091 	 lr: 0.00003
[epoch 341: 140/307] 	 train loss: 0.152553 	 lr: 0.00003
[epoch 341: 160/307] 	 train loss: 0.065680 	 lr: 0.00003
[epoch 341: 180/307] 	 train loss: 0.127386 	 lr: 0.00003
[epoch 341: 200/307] 	 train loss: 0.119206 	 lr: 0.00003
[epoch 341: 220/307] 	 train loss: 0.026552 	 lr: 0.00003

val loss: 0.344910 	 acc: 0.915721

[epoch 341: 240/307] 	 train loss: 0.134446 	 lr: 0.00003
[epoch 341: 260/307] 	 train loss: 0.171656 	 lr: 0.00003
[epoch 341: 280/307] 	 train loss: 0.129365 	 lr: 0.00003
[epoch 341: 300/307] 	 train loss: 0.075925 	 lr: 0.00003
[epoch 342:   0/307] 	 train loss: 0.041254 	 lr: 0.00003
[epoch 342:  20/307] 	 train loss: 0.103539 	 lr: 0.00003
[epoch 342:  40/307] 	 train loss: 0.301383 	 lr: 0.00003
[epoch 342:  60/307] 	 train loss: 0.306221 	 lr: 0.00003
[epoch 342:  80/307] 	 train loss: 0.092482 	 lr: 0.00003

val loss: 0.341424 	 acc: 0.917747

[epoch 342: 100/307] 	 train loss: 0.058347 	 lr: 0.00003
[epoch 342: 120/307] 	 train loss: 0.124842 	 lr: 0.00003
[epoch 342: 140/307] 	 train loss: 0.023482 	 lr: 0.00003
[epoch 342: 160/307] 	 train loss: 0.062261 	 lr: 0.00003
[epoch 342: 180/307] 	 train loss: 0.061668 	 lr: 0.00003
[epoch 342: 200/307] 	 train loss: 0.053927 	 lr: 0.00003
[epoch 342: 220/307] 	 train loss: 0.059337 	 lr: 0.00003

val loss: 0.342075 	 acc: 0.914506

[epoch 342: 240/307] 	 train loss: 0.194529 	 lr: 0.00003
[epoch 342: 260/307] 	 train loss: 0.056534 	 lr: 0.00003
[epoch 342: 280/307] 	 train loss: 0.070428 	 lr: 0.00003
[epoch 342: 300/307] 	 train loss: 0.021282 	 lr: 0.00003
[epoch 343:   0/307] 	 train loss: 0.176032 	 lr: 0.00003
[epoch 343:  20/307] 	 train loss: 0.058403 	 lr: 0.00003
[epoch 343:  40/307] 	 train loss: 0.012534 	 lr: 0.00003
[epoch 343:  60/307] 	 train loss: 0.183068 	 lr: 0.00003
[epoch 343:  80/307] 	 train loss: 0.085621 	 lr: 0.00003

val loss: 0.342144 	 acc: 0.919368

[epoch 343: 100/307] 	 train loss: 0.079704 	 lr: 0.00003
[epoch 343: 120/307] 	 train loss: 0.066987 	 lr: 0.00003
[epoch 343: 140/307] 	 train loss: 0.018933 	 lr: 0.00003
[epoch 343: 160/307] 	 train loss: 0.067717 	 lr: 0.00003
[epoch 343: 180/307] 	 train loss: 0.008042 	 lr: 0.00003
[epoch 343: 200/307] 	 train loss: 0.098237 	 lr: 0.00003
[epoch 343: 220/307] 	 train loss: 0.123051 	 lr: 0.00003

val loss: 0.343529 	 acc: 0.916937

[epoch 343: 240/307] 	 train loss: 0.096414 	 lr: 0.00003
[epoch 343: 260/307] 	 train loss: 0.004865 	 lr: 0.00003
[epoch 343: 280/307] 	 train loss: 0.128748 	 lr: 0.00003
[epoch 343: 300/307] 	 train loss: 0.041824 	 lr: 0.00003
[epoch 344:   0/307] 	 train loss: 0.026055 	 lr: 0.00003
[epoch 344:  20/307] 	 train loss: 0.046915 	 lr: 0.00003
[epoch 344:  40/307] 	 train loss: 0.069360 	 lr: 0.00003
[epoch 344:  60/307] 	 train loss: 0.140198 	 lr: 0.00003

val loss: 0.341611 	 acc: 0.917342

[epoch 344:  80/307] 	 train loss: 0.079452 	 lr: 0.00003
[epoch 344: 100/307] 	 train loss: 0.061384 	 lr: 0.00003
[epoch 344: 120/307] 	 train loss: 0.106805 	 lr: 0.00003
[epoch 344: 140/307] 	 train loss: 0.077559 	 lr: 0.00003
[epoch 344: 160/307] 	 train loss: 0.029662 	 lr: 0.00003
[epoch 344: 180/307] 	 train loss: 0.108224 	 lr: 0.00003
[epoch 344: 200/307] 	 train loss: 0.202122 	 lr: 0.00003
[epoch 344: 220/307] 	 train loss: 0.126156 	 lr: 0.00003

val loss: 0.343165 	 acc: 0.918152

[epoch 344: 240/307] 	 train loss: 0.082875 	 lr: 0.00003
[epoch 344: 260/307] 	 train loss: 0.040729 	 lr: 0.00003
[epoch 344: 280/307] 	 train loss: 0.254494 	 lr: 0.00003
[epoch 344: 300/307] 	 train loss: 0.010981 	 lr: 0.00003
[epoch 345:   0/307] 	 train loss: 0.034542 	 lr: 0.00003
[epoch 345:  20/307] 	 train loss: 0.080406 	 lr: 0.00003
[epoch 345:  40/307] 	 train loss: 0.053640 	 lr: 0.00003
[epoch 345:  60/307] 	 train loss: 0.024259 	 lr: 0.00003

val loss: 0.339841 	 acc: 0.919368

[epoch 345:  80/307] 	 train loss: 0.035502 	 lr: 0.00003
[epoch 345: 100/307] 	 train loss: 0.020244 	 lr: 0.00003
[epoch 345: 120/307] 	 train loss: 0.094264 	 lr: 0.00003
[epoch 345: 140/307] 	 train loss: 0.016356 	 lr: 0.00003
[epoch 345: 160/307] 	 train loss: 0.095600 	 lr: 0.00003
[epoch 345: 180/307] 	 train loss: 0.188733 	 lr: 0.00003
[epoch 345: 200/307] 	 train loss: 0.053892 	 lr: 0.00003
[epoch 345: 220/307] 	 train loss: 0.160249 	 lr: 0.00003

val loss: 0.340254 	 acc: 0.917747

[epoch 345: 240/307] 	 train loss: 0.017424 	 lr: 0.00003
[epoch 345: 260/307] 	 train loss: 0.009117 	 lr: 0.00003
[epoch 345: 280/307] 	 train loss: 0.069876 	 lr: 0.00003
[epoch 345: 300/307] 	 train loss: 0.106669 	 lr: 0.00003
[epoch 346:   0/307] 	 train loss: 0.044099 	 lr: 0.00003
[epoch 346:  20/307] 	 train loss: 0.262113 	 lr: 0.00003
[epoch 346:  40/307] 	 train loss: 0.232363 	 lr: 0.00003
[epoch 346:  60/307] 	 train loss: 0.016744 	 lr: 0.00003

val loss: 0.341171 	 acc: 0.917747

[epoch 346:  80/307] 	 train loss: 0.106140 	 lr: 0.00003
[epoch 346: 100/307] 	 train loss: 0.063165 	 lr: 0.00003
[epoch 346: 120/307] 	 train loss: 0.007206 	 lr: 0.00003
[epoch 346: 140/307] 	 train loss: 0.240793 	 lr: 0.00003
[epoch 346: 160/307] 	 train loss: 0.086551 	 lr: 0.00003
[epoch 346: 180/307] 	 train loss: 0.029690 	 lr: 0.00003
[epoch 346: 200/307] 	 train loss: 0.129535 	 lr: 0.00003
[epoch 346: 220/307] 	 train loss: 0.028233 	 lr: 0.00003

val loss: 0.338772 	 acc: 0.918963

[epoch 346: 240/307] 	 train loss: 0.039410 	 lr: 0.00003
[epoch 346: 260/307] 	 train loss: 0.010019 	 lr: 0.00003
[epoch 346: 280/307] 	 train loss: 0.025979 	 lr: 0.00003
[epoch 346: 300/307] 	 train loss: 0.041825 	 lr: 0.00003
[epoch 347:   0/307] 	 train loss: 0.274365 	 lr: 0.00003
[epoch 347:  20/307] 	 train loss: 0.006982 	 lr: 0.00003
[epoch 347:  40/307] 	 train loss: 0.192256 	 lr: 0.00003
[epoch 347:  60/307] 	 train loss: 0.402850 	 lr: 0.00003

val loss: 0.341543 	 acc: 0.917342

[epoch 347:  80/307] 	 train loss: 0.122451 	 lr: 0.00003
[epoch 347: 100/307] 	 train loss: 0.121590 	 lr: 0.00003
[epoch 347: 120/307] 	 train loss: 0.081895 	 lr: 0.00003
[epoch 347: 140/307] 	 train loss: 0.110677 	 lr: 0.00003
[epoch 347: 160/307] 	 train loss: 0.064801 	 lr: 0.00003
[epoch 347: 180/307] 	 train loss: 0.054895 	 lr: 0.00003
[epoch 347: 200/307] 	 train loss: 0.030385 	 lr: 0.00003
[epoch 347: 220/307] 	 train loss: 0.061390 	 lr: 0.00003

val loss: 0.342992 	 acc: 0.917747

[epoch 347: 240/307] 	 train loss: 0.133659 	 lr: 0.00003
[epoch 347: 260/307] 	 train loss: 0.009648 	 lr: 0.00003
[epoch 347: 280/307] 	 train loss: 0.077219 	 lr: 0.00003
[epoch 347: 300/307] 	 train loss: 0.037503 	 lr: 0.00003
[epoch 348:   0/307] 	 train loss: 0.075877 	 lr: 0.00003
[epoch 348:  20/307] 	 train loss: 0.058626 	 lr: 0.00003
[epoch 348:  40/307] 	 train loss: 0.079833 	 lr: 0.00003
[epoch 348:  60/307] 	 train loss: 0.012600 	 lr: 0.00003

val loss: 0.342611 	 acc: 0.918558

[epoch 348:  80/307] 	 train loss: 0.215062 	 lr: 0.00003
[epoch 348: 100/307] 	 train loss: 0.050957 	 lr: 0.00003
[epoch 348: 120/307] 	 train loss: 0.093535 	 lr: 0.00003
[epoch 348: 140/307] 	 train loss: 0.153878 	 lr: 0.00003
[epoch 348: 160/307] 	 train loss: 0.067176 	 lr: 0.00003
[epoch 348: 180/307] 	 train loss: 0.065246 	 lr: 0.00003
[epoch 348: 200/307] 	 train loss: 0.054758 	 lr: 0.00003
[epoch 348: 220/307] 	 train loss: 0.027956 	 lr: 0.00003

val loss: 0.343268 	 acc: 0.916937

[epoch 348: 240/307] 	 train loss: 0.035145 	 lr: 0.00003
[epoch 348: 260/307] 	 train loss: 0.093845 	 lr: 0.00003
[epoch 348: 280/307] 	 train loss: 0.023368 	 lr: 0.00003
[epoch 348: 300/307] 	 train loss: 0.141060 	 lr: 0.00003
[epoch 349:   0/307] 	 train loss: 0.199726 	 lr: 0.00003
[epoch 349:  20/307] 	 train loss: 0.195194 	 lr: 0.00003
[epoch 349:  40/307] 	 train loss: 0.009032 	 lr: 0.00003
[epoch 349:  60/307] 	 train loss: 0.032967 	 lr: 0.00003

val loss: 0.343812 	 acc: 0.918963

[epoch 349:  80/307] 	 train loss: 0.183844 	 lr: 0.00003
[epoch 349: 100/307] 	 train loss: 0.335203 	 lr: 0.00003
[epoch 349: 120/307] 	 train loss: 0.193363 	 lr: 0.00003
[epoch 349: 140/307] 	 train loss: 0.138022 	 lr: 0.00003
[epoch 349: 160/307] 	 train loss: 0.043914 	 lr: 0.00003
[epoch 349: 180/307] 	 train loss: 0.077116 	 lr: 0.00003
[epoch 349: 200/307] 	 train loss: 0.105473 	 lr: 0.00003
[epoch 349: 220/307] 	 train loss: 0.013133 	 lr: 0.00003

val loss: 0.343567 	 acc: 0.917342

[epoch 349: 240/307] 	 train loss: 0.172419 	 lr: 0.00003
[epoch 349: 260/307] 	 train loss: 0.019831 	 lr: 0.00003
[epoch 349: 280/307] 	 train loss: 0.126408 	 lr: 0.00003
[epoch 349: 300/307] 	 train loss: 0.132397 	 lr: 0.00003
[epoch 350:   0/307] 	 train loss: 0.180611 	 lr: 0.00003
[epoch 350:  20/307] 	 train loss: 0.075651 	 lr: 0.00003
[epoch 350:  40/307] 	 train loss: 0.017352 	 lr: 0.00003
[epoch 350:  60/307] 	 train loss: 0.206233 	 lr: 0.00003

val loss: 0.341907 	 acc: 0.918152

[epoch 350:  80/307] 	 train loss: 0.067338 	 lr: 0.00003
[epoch 350: 100/307] 	 train loss: 0.024514 	 lr: 0.00003
[epoch 350: 120/307] 	 train loss: 0.139758 	 lr: 0.00003
[epoch 350: 140/307] 	 train loss: 0.042386 	 lr: 0.00003
[epoch 350: 160/307] 	 train loss: 0.279294 	 lr: 0.00003
[epoch 350: 180/307] 	 train loss: 0.010880 	 lr: 0.00003
[epoch 350: 200/307] 	 train loss: 0.007908 	 lr: 0.00003

val loss: 0.345089 	 acc: 0.918963

[epoch 350: 220/307] 	 train loss: 0.021511 	 lr: 0.00003
[epoch 350: 240/307] 	 train loss: 0.243436 	 lr: 0.00003
[epoch 350: 260/307] 	 train loss: 0.059648 	 lr: 0.00003
[epoch 350: 280/307] 	 train loss: 0.148797 	 lr: 0.00003
[epoch 350: 300/307] 	 train loss: 0.059655 	 lr: 0.00003
[epoch 351:   0/307] 	 train loss: 0.012455 	 lr: 0.00003
[epoch 351:  20/307] 	 train loss: 0.155536 	 lr: 0.00003
[epoch 351:  40/307] 	 train loss: 0.133215 	 lr: 0.00003
[epoch 351:  60/307] 	 train loss: 0.144987 	 lr: 0.00003

val loss: 0.350154 	 acc: 0.918152

[epoch 351:  80/307] 	 train loss: 0.019443 	 lr: 0.00003
[epoch 351: 100/307] 	 train loss: 0.033731 	 lr: 0.00003
[epoch 351: 120/307] 	 train loss: 0.119529 	 lr: 0.00003
[epoch 351: 140/307] 	 train loss: 0.139791 	 lr: 0.00003
[epoch 351: 160/307] 	 train loss: 0.052121 	 lr: 0.00003
[epoch 351: 180/307] 	 train loss: 0.065024 	 lr: 0.00003
[epoch 351: 200/307] 	 train loss: 0.042618 	 lr: 0.00003

val loss: 0.344647 	 acc: 0.918152

[epoch 351: 220/307] 	 train loss: 0.340542 	 lr: 0.00003
[epoch 351: 240/307] 	 train loss: 0.063653 	 lr: 0.00003
[epoch 351: 260/307] 	 train loss: 0.014271 	 lr: 0.00003
[epoch 351: 280/307] 	 train loss: 0.064537 	 lr: 0.00003
[epoch 351: 300/307] 	 train loss: 0.038755 	 lr: 0.00003
[epoch 352:   0/307] 	 train loss: 0.025261 	 lr: 0.00003
[epoch 352:  20/307] 	 train loss: 0.061027 	 lr: 0.00003
[epoch 352:  40/307] 	 train loss: 0.106068 	 lr: 0.00003
[epoch 352:  60/307] 	 train loss: 0.066540 	 lr: 0.00003

val loss: 0.341953 	 acc: 0.918558

[epoch 352:  80/307] 	 train loss: 0.060394 	 lr: 0.00003
[epoch 352: 100/307] 	 train loss: 0.004361 	 lr: 0.00003
[epoch 352: 120/307] 	 train loss: 0.047212 	 lr: 0.00003
[epoch 352: 140/307] 	 train loss: 0.070595 	 lr: 0.00003
[epoch 352: 160/307] 	 train loss: 0.247865 	 lr: 0.00003
[epoch 352: 180/307] 	 train loss: 0.196732 	 lr: 0.00003
[epoch 352: 200/307] 	 train loss: 0.061649 	 lr: 0.00003

val loss: 0.345078 	 acc: 0.916937

[epoch 352: 220/307] 	 train loss: 0.062837 	 lr: 0.00003
[epoch 352: 240/307] 	 train loss: 0.006616 	 lr: 0.00003
[epoch 352: 260/307] 	 train loss: 0.108519 	 lr: 0.00003
[epoch 352: 280/307] 	 train loss: 0.037739 	 lr: 0.00003
[epoch 352: 300/307] 	 train loss: 0.073853 	 lr: 0.00003
[epoch 353:   0/307] 	 train loss: 0.256119 	 lr: 0.00003
[epoch 353:  20/307] 	 train loss: 0.066435 	 lr: 0.00003
[epoch 353:  40/307] 	 train loss: 0.117193 	 lr: 0.00003
[epoch 353:  60/307] 	 train loss: 0.155983 	 lr: 0.00003

val loss: 0.342777 	 acc: 0.918558

[epoch 353:  80/307] 	 train loss: 0.089756 	 lr: 0.00003
[epoch 353: 100/307] 	 train loss: 0.018343 	 lr: 0.00003
[epoch 353: 120/307] 	 train loss: 0.055220 	 lr: 0.00003
[epoch 353: 140/307] 	 train loss: 0.210516 	 lr: 0.00003
[epoch 353: 160/307] 	 train loss: 0.007511 	 lr: 0.00003
[epoch 353: 180/307] 	 train loss: 0.031714 	 lr: 0.00003
[epoch 353: 200/307] 	 train loss: 0.302605 	 lr: 0.00003

val loss: 0.345976 	 acc: 0.916937

[epoch 353: 220/307] 	 train loss: 0.028379 	 lr: 0.00003
[epoch 353: 240/307] 	 train loss: 0.055398 	 lr: 0.00003
[epoch 353: 260/307] 	 train loss: 0.030971 	 lr: 0.00003
[epoch 353: 280/307] 	 train loss: 0.045737 	 lr: 0.00003
[epoch 353: 300/307] 	 train loss: 0.011420 	 lr: 0.00003
[epoch 354:   0/307] 	 train loss: 0.187189 	 lr: 0.00003
[epoch 354:  20/307] 	 train loss: 0.126525 	 lr: 0.00003
[epoch 354:  40/307] 	 train loss: 0.141866 	 lr: 0.00003

val loss: 0.348063 	 acc: 0.913695

[epoch 354:  60/307] 	 train loss: 0.216917 	 lr: 0.00003
[epoch 354:  80/307] 	 train loss: 0.077404 	 lr: 0.00003
[epoch 354: 100/307] 	 train loss: 0.140063 	 lr: 0.00003
[epoch 354: 120/307] 	 train loss: 0.046255 	 lr: 0.00003
[epoch 354: 140/307] 	 train loss: 0.011021 	 lr: 0.00003
[epoch 354: 160/307] 	 train loss: 0.028471 	 lr: 0.00003
[epoch 354: 180/307] 	 train loss: 0.061187 	 lr: 0.00003
[epoch 354: 200/307] 	 train loss: 0.039184 	 lr: 0.00003

val loss: 0.346578 	 acc: 0.916126

[epoch 354: 220/307] 	 train loss: 0.208917 	 lr: 0.00003
[epoch 354: 240/307] 	 train loss: 0.096293 	 lr: 0.00003
[epoch 354: 260/307] 	 train loss: 0.359437 	 lr: 0.00003
[epoch 354: 280/307] 	 train loss: 0.054084 	 lr: 0.00003
[epoch 354: 300/307] 	 train loss: 0.035260 	 lr: 0.00003
[epoch 355:   0/307] 	 train loss: 0.020531 	 lr: 0.00003
[epoch 355:  20/307] 	 train loss: 0.040836 	 lr: 0.00003
[epoch 355:  40/307] 	 train loss: 0.024292 	 lr: 0.00003

val loss: 0.342273 	 acc: 0.917342

[epoch 355:  60/307] 	 train loss: 0.114251 	 lr: 0.00003
[epoch 355:  80/307] 	 train loss: 0.151439 	 lr: 0.00003
[epoch 355: 100/307] 	 train loss: 0.058320 	 lr: 0.00003
[epoch 355: 120/307] 	 train loss: 0.158519 	 lr: 0.00003
[epoch 355: 140/307] 	 train loss: 0.259997 	 lr: 0.00003
[epoch 355: 160/307] 	 train loss: 0.266148 	 lr: 0.00003
[epoch 355: 180/307] 	 train loss: 0.020770 	 lr: 0.00003
[epoch 355: 200/307] 	 train loss: 0.125345 	 lr: 0.00003

val loss: 0.346539 	 acc: 0.914506

[epoch 355: 220/307] 	 train loss: 0.192210 	 lr: 0.00003
[epoch 355: 240/307] 	 train loss: 0.025728 	 lr: 0.00003
[epoch 355: 260/307] 	 train loss: 0.088204 	 lr: 0.00003
[epoch 355: 280/307] 	 train loss: 0.086392 	 lr: 0.00003
[epoch 355: 300/307] 	 train loss: 0.144548 	 lr: 0.00003
[epoch 356:   0/307] 	 train loss: 0.047590 	 lr: 0.00003
[epoch 356:  20/307] 	 train loss: 0.115902 	 lr: 0.00003
[epoch 356:  40/307] 	 train loss: 0.104872 	 lr: 0.00003

val loss: 0.349267 	 acc: 0.916126

[epoch 356:  60/307] 	 train loss: 0.071271 	 lr: 0.00003
[epoch 356:  80/307] 	 train loss: 0.019732 	 lr: 0.00003
[epoch 356: 100/307] 	 train loss: 0.024354 	 lr: 0.00003
[epoch 356: 120/307] 	 train loss: 0.160308 	 lr: 0.00003
[epoch 356: 140/307] 	 train loss: 0.058160 	 lr: 0.00003
[epoch 356: 160/307] 	 train loss: 0.069299 	 lr: 0.00003
[epoch 356: 180/307] 	 train loss: 0.019626 	 lr: 0.00003
[epoch 356: 200/307] 	 train loss: 0.163696 	 lr: 0.00003

val loss: 0.345641 	 acc: 0.916532

[epoch 356: 220/307] 	 train loss: 0.097284 	 lr: 0.00003
[epoch 356: 240/307] 	 train loss: 0.106928 	 lr: 0.00003
[epoch 356: 260/307] 	 train loss: 0.092902 	 lr: 0.00003
[epoch 356: 280/307] 	 train loss: 0.122193 	 lr: 0.00003
[epoch 356: 300/307] 	 train loss: 0.015791 	 lr: 0.00003
[epoch 357:   0/307] 	 train loss: 0.072740 	 lr: 0.00003
[epoch 357:  20/307] 	 train loss: 0.083993 	 lr: 0.00003
[epoch 357:  40/307] 	 train loss: 0.010583 	 lr: 0.00003

val loss: 0.345851 	 acc: 0.916937

[epoch 357:  60/307] 	 train loss: 0.157847 	 lr: 0.00003
[epoch 357:  80/307] 	 train loss: 0.029314 	 lr: 0.00003
[epoch 357: 100/307] 	 train loss: 0.085182 	 lr: 0.00003
[epoch 357: 120/307] 	 train loss: 0.050814 	 lr: 0.00003
[epoch 357: 140/307] 	 train loss: 0.052872 	 lr: 0.00003
[epoch 357: 160/307] 	 train loss: 0.033380 	 lr: 0.00003
[epoch 357: 180/307] 	 train loss: 0.060989 	 lr: 0.00003
[epoch 357: 200/307] 	 train loss: 0.014208 	 lr: 0.00003

val loss: 0.348791 	 acc: 0.916126

[epoch 357: 220/307] 	 train loss: 0.016900 	 lr: 0.00003
[epoch 357: 240/307] 	 train loss: 0.127939 	 lr: 0.00003
[epoch 357: 260/307] 	 train loss: 0.102722 	 lr: 0.00003
[epoch 357: 280/307] 	 train loss: 0.066579 	 lr: 0.00003
[epoch 357: 300/307] 	 train loss: 0.056007 	 lr: 0.00003
[epoch 358:   0/307] 	 train loss: 0.047724 	 lr: 0.00002
[epoch 358:  20/307] 	 train loss: 0.051392 	 lr: 0.00002
[epoch 358:  40/307] 	 train loss: 0.074925 	 lr: 0.00002

val loss: 0.343228 	 acc: 0.917342

[epoch 358:  60/307] 	 train loss: 0.179544 	 lr: 0.00002
[epoch 358:  80/307] 	 train loss: 0.099418 	 lr: 0.00002
[epoch 358: 100/307] 	 train loss: 0.095892 	 lr: 0.00002
[epoch 358: 120/307] 	 train loss: 0.143161 	 lr: 0.00002
[epoch 358: 140/307] 	 train loss: 0.077311 	 lr: 0.00002
[epoch 358: 160/307] 	 train loss: 0.124142 	 lr: 0.00002
[epoch 358: 180/307] 	 train loss: 0.165903 	 lr: 0.00002
[epoch 358: 200/307] 	 train loss: 0.216828 	 lr: 0.00002

val loss: 0.343679 	 acc: 0.917747

[epoch 358: 220/307] 	 train loss: 0.063703 	 lr: 0.00002
[epoch 358: 240/307] 	 train loss: 0.030709 	 lr: 0.00002
[epoch 358: 260/307] 	 train loss: 0.098266 	 lr: 0.00002
[epoch 358: 280/307] 	 train loss: 0.104094 	 lr: 0.00002
[epoch 358: 300/307] 	 train loss: 0.017181 	 lr: 0.00002
[epoch 359:   0/307] 	 train loss: 0.029146 	 lr: 0.00002
[epoch 359:  20/307] 	 train loss: 0.021290 	 lr: 0.00002
[epoch 359:  40/307] 	 train loss: 0.019373 	 lr: 0.00002

val loss: 0.343224 	 acc: 0.918152

[epoch 359:  60/307] 	 train loss: 0.054223 	 lr: 0.00002
[epoch 359:  80/307] 	 train loss: 0.056551 	 lr: 0.00002
[epoch 359: 100/307] 	 train loss: 0.010699 	 lr: 0.00002
[epoch 359: 120/307] 	 train loss: 0.204642 	 lr: 0.00002
[epoch 359: 140/307] 	 train loss: 0.019883 	 lr: 0.00002
[epoch 359: 160/307] 	 train loss: 0.050567 	 lr: 0.00002
[epoch 359: 180/307] 	 train loss: 0.098600 	 lr: 0.00002
[epoch 359: 200/307] 	 train loss: 0.085832 	 lr: 0.00002

val loss: 0.344015 	 acc: 0.918152

[epoch 359: 220/307] 	 train loss: 0.042716 	 lr: 0.00002
[epoch 359: 240/307] 	 train loss: 0.300617 	 lr: 0.00002
[epoch 359: 260/307] 	 train loss: 0.017471 	 lr: 0.00002
[epoch 359: 280/307] 	 train loss: 0.039950 	 lr: 0.00002
[epoch 359: 300/307] 	 train loss: 0.135359 	 lr: 0.00002
[epoch 360:   0/307] 	 train loss: 0.186315 	 lr: 0.00002
[epoch 360:  20/307] 	 train loss: 0.144567 	 lr: 0.00002
[epoch 360:  40/307] 	 train loss: 0.144344 	 lr: 0.00002

val loss: 0.343927 	 acc: 0.916532

[epoch 360:  60/307] 	 train loss: 0.033258 	 lr: 0.00002
[epoch 360:  80/307] 	 train loss: 0.034005 	 lr: 0.00002
[epoch 360: 100/307] 	 train loss: 0.030353 	 lr: 0.00002
[epoch 360: 120/307] 	 train loss: 0.364400 	 lr: 0.00002
[epoch 360: 140/307] 	 train loss: 0.156633 	 lr: 0.00002
[epoch 360: 160/307] 	 train loss: 0.094183 	 lr: 0.00002
[epoch 360: 180/307] 	 train loss: 0.010373 	 lr: 0.00002

val loss: 0.343206 	 acc: 0.916126

[epoch 360: 200/307] 	 train loss: 0.018752 	 lr: 0.00002
[epoch 360: 220/307] 	 train loss: 0.024477 	 lr: 0.00002
[epoch 360: 240/307] 	 train loss: 0.100596 	 lr: 0.00002
[epoch 360: 260/307] 	 train loss: 0.080551 	 lr: 0.00002
[epoch 360: 280/307] 	 train loss: 0.137055 	 lr: 0.00002
[epoch 360: 300/307] 	 train loss: 0.081926 	 lr: 0.00002
[epoch 361:   0/307] 	 train loss: 0.072442 	 lr: 0.00002
[epoch 361:  20/307] 	 train loss: 0.045728 	 lr: 0.00002
[epoch 361:  40/307] 	 train loss: 0.179955 	 lr: 0.00002

val loss: 0.345087 	 acc: 0.914100

[epoch 361:  60/307] 	 train loss: 0.021953 	 lr: 0.00002
[epoch 361:  80/307] 	 train loss: 0.054362 	 lr: 0.00002
[epoch 361: 100/307] 	 train loss: 0.337328 	 lr: 0.00002
[epoch 361: 120/307] 	 train loss: 0.016115 	 lr: 0.00002
[epoch 361: 140/307] 	 train loss: 0.063528 	 lr: 0.00002
[epoch 361: 160/307] 	 train loss: 0.134560 	 lr: 0.00002
[epoch 361: 180/307] 	 train loss: 0.174273 	 lr: 0.00002

val loss: 0.345579 	 acc: 0.915316

[epoch 361: 200/307] 	 train loss: 0.009897 	 lr: 0.00002
[epoch 361: 220/307] 	 train loss: 0.052462 	 lr: 0.00002
[epoch 361: 240/307] 	 train loss: 0.199693 	 lr: 0.00002
[epoch 361: 260/307] 	 train loss: 0.062331 	 lr: 0.00002
[epoch 361: 280/307] 	 train loss: 0.050621 	 lr: 0.00002
[epoch 361: 300/307] 	 train loss: 0.044763 	 lr: 0.00002
[epoch 362:   0/307] 	 train loss: 0.015855 	 lr: 0.00002
[epoch 362:  20/307] 	 train loss: 0.102534 	 lr: 0.00002
[epoch 362:  40/307] 	 train loss: 0.200651 	 lr: 0.00002

val loss: 0.341575 	 acc: 0.917747

[epoch 362:  60/307] 	 train loss: 0.224504 	 lr: 0.00002
[epoch 362:  80/307] 	 train loss: 0.058477 	 lr: 0.00002
[epoch 362: 100/307] 	 train loss: 0.005527 	 lr: 0.00002
[epoch 362: 120/307] 	 train loss: 0.012049 	 lr: 0.00002
[epoch 362: 140/307] 	 train loss: 0.061448 	 lr: 0.00002
[epoch 362: 160/307] 	 train loss: 0.110447 	 lr: 0.00002
[epoch 362: 180/307] 	 train loss: 0.027090 	 lr: 0.00002

val loss: 0.343066 	 acc: 0.917747

[epoch 362: 200/307] 	 train loss: 0.137512 	 lr: 0.00002
[epoch 362: 220/307] 	 train loss: 0.010947 	 lr: 0.00002
[epoch 362: 240/307] 	 train loss: 0.105902 	 lr: 0.00002
[epoch 362: 260/307] 	 train loss: 0.046326 	 lr: 0.00002
[epoch 362: 280/307] 	 train loss: 0.069483 	 lr: 0.00002
[epoch 362: 300/307] 	 train loss: 0.032002 	 lr: 0.00002
[epoch 363:   0/307] 	 train loss: 0.049928 	 lr: 0.00002
[epoch 363:  20/307] 	 train loss: 0.172791 	 lr: 0.00002
[epoch 363:  40/307] 	 train loss: 0.022716 	 lr: 0.00002

val loss: 0.340107 	 acc: 0.916937

[epoch 363:  60/307] 	 train loss: 0.229649 	 lr: 0.00002
[epoch 363:  80/307] 	 train loss: 0.042953 	 lr: 0.00002
[epoch 363: 100/307] 	 train loss: 0.076069 	 lr: 0.00002
[epoch 363: 120/307] 	 train loss: 0.033627 	 lr: 0.00002
[epoch 363: 140/307] 	 train loss: 0.217821 	 lr: 0.00002
[epoch 363: 160/307] 	 train loss: 0.082609 	 lr: 0.00002
[epoch 363: 180/307] 	 train loss: 0.029685 	 lr: 0.00002

val loss: 0.338937 	 acc: 0.918152

[epoch 363: 200/307] 	 train loss: 0.033226 	 lr: 0.00002
[epoch 363: 220/307] 	 train loss: 0.014782 	 lr: 0.00002
[epoch 363: 240/307] 	 train loss: 0.045120 	 lr: 0.00002
[epoch 363: 260/307] 	 train loss: 0.072749 	 lr: 0.00002
[epoch 363: 280/307] 	 train loss: 0.018117 	 lr: 0.00002
[epoch 363: 300/307] 	 train loss: 0.031790 	 lr: 0.00002
[epoch 364:   0/307] 	 train loss: 0.139452 	 lr: 0.00002
[epoch 364:  20/307] 	 train loss: 0.054877 	 lr: 0.00002

val loss: 0.340718 	 acc: 0.916937

[epoch 364:  40/307] 	 train loss: 0.079326 	 lr: 0.00002
[epoch 364:  60/307] 	 train loss: 0.089244 	 lr: 0.00002
[epoch 364:  80/307] 	 train loss: 0.056816 	 lr: 0.00002
[epoch 364: 100/307] 	 train loss: 0.018479 	 lr: 0.00002
[epoch 364: 120/307] 	 train loss: 0.052743 	 lr: 0.00002
[epoch 364: 140/307] 	 train loss: 0.176407 	 lr: 0.00002
[epoch 364: 160/307] 	 train loss: 0.140687 	 lr: 0.00002
[epoch 364: 180/307] 	 train loss: 0.003467 	 lr: 0.00002

val loss: 0.340560 	 acc: 0.919773

[epoch 364: 200/307] 	 train loss: 0.014984 	 lr: 0.00002
[epoch 364: 220/307] 	 train loss: 0.100592 	 lr: 0.00002
[epoch 364: 240/307] 	 train loss: 0.058715 	 lr: 0.00002
[epoch 364: 260/307] 	 train loss: 0.048057 	 lr: 0.00002
[epoch 364: 280/307] 	 train loss: 0.088403 	 lr: 0.00002
[epoch 364: 300/307] 	 train loss: 0.149271 	 lr: 0.00002
[epoch 365:   0/307] 	 train loss: 0.049277 	 lr: 0.00002
[epoch 365:  20/307] 	 train loss: 0.087247 	 lr: 0.00002

val loss: 0.339720 	 acc: 0.919368

[epoch 365:  40/307] 	 train loss: 0.351589 	 lr: 0.00002
[epoch 365:  60/307] 	 train loss: 0.054327 	 lr: 0.00002
[epoch 365:  80/307] 	 train loss: 0.043224 	 lr: 0.00002
[epoch 365: 100/307] 	 train loss: 0.102342 	 lr: 0.00002
[epoch 365: 120/307] 	 train loss: 0.040122 	 lr: 0.00002
[epoch 365: 140/307] 	 train loss: 0.055847 	 lr: 0.00002
[epoch 365: 160/307] 	 train loss: 0.187817 	 lr: 0.00002
[epoch 365: 180/307] 	 train loss: 0.114631 	 lr: 0.00002

val loss: 0.340908 	 acc: 0.917342

[epoch 365: 200/307] 	 train loss: 0.321424 	 lr: 0.00002
[epoch 365: 220/307] 	 train loss: 0.199412 	 lr: 0.00002
[epoch 365: 240/307] 	 train loss: 0.147485 	 lr: 0.00002
[epoch 365: 260/307] 	 train loss: 0.010467 	 lr: 0.00002
[epoch 365: 280/307] 	 train loss: 0.033465 	 lr: 0.00002
[epoch 365: 300/307] 	 train loss: 0.088114 	 lr: 0.00002
[epoch 366:   0/307] 	 train loss: 0.038493 	 lr: 0.00002
[epoch 366:  20/307] 	 train loss: 0.172588 	 lr: 0.00002

val loss: 0.340876 	 acc: 0.917342

[epoch 366:  40/307] 	 train loss: 0.088650 	 lr: 0.00002
[epoch 366:  60/307] 	 train loss: 0.211742 	 lr: 0.00002
[epoch 366:  80/307] 	 train loss: 0.027572 	 lr: 0.00002
[epoch 366: 100/307] 	 train loss: 0.102239 	 lr: 0.00002
[epoch 366: 120/307] 	 train loss: 0.068553 	 lr: 0.00002
[epoch 366: 140/307] 	 train loss: 0.049282 	 lr: 0.00002
[epoch 366: 160/307] 	 train loss: 0.078708 	 lr: 0.00002
[epoch 366: 180/307] 	 train loss: 0.271914 	 lr: 0.00002

val loss: 0.339296 	 acc: 0.919368

[epoch 366: 200/307] 	 train loss: 0.086960 	 lr: 0.00002
[epoch 366: 220/307] 	 train loss: 0.035348 	 lr: 0.00002
[epoch 366: 240/307] 	 train loss: 0.216340 	 lr: 0.00002
[epoch 366: 260/307] 	 train loss: 0.058872 	 lr: 0.00002
[epoch 366: 280/307] 	 train loss: 0.113886 	 lr: 0.00002
[epoch 366: 300/307] 	 train loss: 0.049514 	 lr: 0.00002
[epoch 367:   0/307] 	 train loss: 0.050377 	 lr: 0.00002
[epoch 367:  20/307] 	 train loss: 0.020728 	 lr: 0.00002

val loss: 0.341655 	 acc: 0.916937

[epoch 367:  40/307] 	 train loss: 0.033066 	 lr: 0.00002
[epoch 367:  60/307] 	 train loss: 0.020220 	 lr: 0.00002
[epoch 367:  80/307] 	 train loss: 0.051866 	 lr: 0.00002
[epoch 367: 100/307] 	 train loss: 0.073066 	 lr: 0.00002
[epoch 367: 120/307] 	 train loss: 0.115815 	 lr: 0.00002
[epoch 367: 140/307] 	 train loss: 0.090900 	 lr: 0.00002
[epoch 367: 160/307] 	 train loss: 0.046913 	 lr: 0.00002
[epoch 367: 180/307] 	 train loss: 0.021842 	 lr: 0.00002

val loss: 0.340628 	 acc: 0.919368

[epoch 367: 200/307] 	 train loss: 0.056159 	 lr: 0.00002
[epoch 367: 220/307] 	 train loss: 0.007195 	 lr: 0.00002
[epoch 367: 240/307] 	 train loss: 0.043291 	 lr: 0.00002
[epoch 367: 260/307] 	 train loss: 0.265501 	 lr: 0.00002
[epoch 367: 280/307] 	 train loss: 0.080950 	 lr: 0.00002
[epoch 367: 300/307] 	 train loss: 0.094054 	 lr: 0.00002
[epoch 368:   0/307] 	 train loss: 0.038416 	 lr: 0.00002
[epoch 368:  20/307] 	 train loss: 0.153150 	 lr: 0.00002

val loss: 0.341430 	 acc: 0.917747

[epoch 368:  40/307] 	 train loss: 0.162286 	 lr: 0.00002
[epoch 368:  60/307] 	 train loss: 0.057782 	 lr: 0.00002
[epoch 368:  80/307] 	 train loss: 0.101034 	 lr: 0.00002
[epoch 368: 100/307] 	 train loss: 0.046187 	 lr: 0.00002
[epoch 368: 120/307] 	 train loss: 0.098633 	 lr: 0.00002
[epoch 368: 140/307] 	 train loss: 0.062958 	 lr: 0.00002
[epoch 368: 160/307] 	 train loss: 0.069195 	 lr: 0.00002
[epoch 368: 180/307] 	 train loss: 0.191766 	 lr: 0.00002

val loss: 0.342903 	 acc: 0.918558

[epoch 368: 200/307] 	 train loss: 0.118878 	 lr: 0.00002
[epoch 368: 220/307] 	 train loss: 0.021588 	 lr: 0.00002
[epoch 368: 240/307] 	 train loss: 0.129217 	 lr: 0.00002
[epoch 368: 260/307] 	 train loss: 0.064869 	 lr: 0.00002
[epoch 368: 280/307] 	 train loss: 0.172275 	 lr: 0.00002
[epoch 368: 300/307] 	 train loss: 0.073605 	 lr: 0.00002
[epoch 369:   0/307] 	 train loss: 0.076677 	 lr: 0.00002
[epoch 369:  20/307] 	 train loss: 0.170681 	 lr: 0.00002

val loss: 0.338764 	 acc: 0.919368

[epoch 369:  40/307] 	 train loss: 0.010202 	 lr: 0.00002
[epoch 369:  60/307] 	 train loss: 0.041736 	 lr: 0.00002
[epoch 369:  80/307] 	 train loss: 0.115198 	 lr: 0.00002
[epoch 369: 100/307] 	 train loss: 0.135760 	 lr: 0.00002
[epoch 369: 120/307] 	 train loss: 0.163729 	 lr: 0.00002
[epoch 369: 140/307] 	 train loss: 0.144244 	 lr: 0.00002
[epoch 369: 160/307] 	 train loss: 0.104444 	 lr: 0.00002
[epoch 369: 180/307] 	 train loss: 0.095421 	 lr: 0.00002

val loss: 0.339971 	 acc: 0.919368

[epoch 369: 200/307] 	 train loss: 0.100420 	 lr: 0.00002
[epoch 369: 220/307] 	 train loss: 0.185370 	 lr: 0.00002
[epoch 369: 240/307] 	 train loss: 0.071405 	 lr: 0.00002
[epoch 369: 260/307] 	 train loss: 0.269636 	 lr: 0.00002
[epoch 369: 280/307] 	 train loss: 0.033570 	 lr: 0.00002
[epoch 369: 300/307] 	 train loss: 0.038564 	 lr: 0.00002
[epoch 370:   0/307] 	 train loss: 0.012767 	 lr: 0.00002
[epoch 370:  20/307] 	 train loss: 0.146366 	 lr: 0.00002

val loss: 0.344627 	 acc: 0.918963

[epoch 370:  40/307] 	 train loss: 0.048992 	 lr: 0.00002
[epoch 370:  60/307] 	 train loss: 0.161757 	 lr: 0.00002
[epoch 370:  80/307] 	 train loss: 0.114234 	 lr: 0.00002
[epoch 370: 100/307] 	 train loss: 0.010893 	 lr: 0.00002
[epoch 370: 120/307] 	 train loss: 0.035735 	 lr: 0.00002
[epoch 370: 140/307] 	 train loss: 0.059904 	 lr: 0.00002
[epoch 370: 160/307] 	 train loss: 0.144118 	 lr: 0.00002

val loss: 0.343063 	 acc: 0.919368

[epoch 370: 180/307] 	 train loss: 0.131595 	 lr: 0.00002
[epoch 370: 200/307] 	 train loss: 0.018525 	 lr: 0.00002
[epoch 370: 220/307] 	 train loss: 0.108504 	 lr: 0.00002
[epoch 370: 240/307] 	 train loss: 0.128143 	 lr: 0.00002
[epoch 370: 260/307] 	 train loss: 0.088959 	 lr: 0.00002
[epoch 370: 280/307] 	 train loss: 0.073062 	 lr: 0.00002
[epoch 370: 300/307] 	 train loss: 0.077094 	 lr: 0.00002
[epoch 371:   0/307] 	 train loss: 0.168935 	 lr: 0.00002
[epoch 371:  20/307] 	 train loss: 0.061332 	 lr: 0.00002

val loss: 0.344808 	 acc: 0.918558

[epoch 371:  40/307] 	 train loss: 0.041353 	 lr: 0.00002
[epoch 371:  60/307] 	 train loss: 0.047112 	 lr: 0.00002
[epoch 371:  80/307] 	 train loss: 0.195848 	 lr: 0.00002
[epoch 371: 100/307] 	 train loss: 0.170368 	 lr: 0.00002
[epoch 371: 120/307] 	 train loss: 0.085888 	 lr: 0.00002
[epoch 371: 140/307] 	 train loss: 0.057359 	 lr: 0.00002
[epoch 371: 160/307] 	 train loss: 0.056909 	 lr: 0.00002

val loss: 0.344690 	 acc: 0.919773

[epoch 371: 180/307] 	 train loss: 0.042354 	 lr: 0.00002
[epoch 371: 200/307] 	 train loss: 0.042566 	 lr: 0.00002
[epoch 371: 220/307] 	 train loss: 0.059319 	 lr: 0.00002
[epoch 371: 240/307] 	 train loss: 0.107333 	 lr: 0.00002
[epoch 371: 260/307] 	 train loss: 0.035788 	 lr: 0.00002
[epoch 371: 280/307] 	 train loss: 0.034797 	 lr: 0.00002
[epoch 371: 300/307] 	 train loss: 0.090758 	 lr: 0.00002
[epoch 372:   0/307] 	 train loss: 0.046846 	 lr: 0.00002
[epoch 372:  20/307] 	 train loss: 0.085828 	 lr: 0.00002

val loss: 0.344319 	 acc: 0.917342

[epoch 372:  40/307] 	 train loss: 0.066526 	 lr: 0.00002
[epoch 372:  60/307] 	 train loss: 0.005559 	 lr: 0.00002
[epoch 372:  80/307] 	 train loss: 0.061380 	 lr: 0.00002
[epoch 372: 100/307] 	 train loss: 0.229593 	 lr: 0.00002
[epoch 372: 120/307] 	 train loss: 0.137226 	 lr: 0.00002
[epoch 372: 140/307] 	 train loss: 0.028722 	 lr: 0.00002
[epoch 372: 160/307] 	 train loss: 0.025328 	 lr: 0.00002

val loss: 0.343915 	 acc: 0.917342

[epoch 372: 180/307] 	 train loss: 0.004812 	 lr: 0.00002
[epoch 372: 200/307] 	 train loss: 0.175542 	 lr: 0.00002
[epoch 372: 220/307] 	 train loss: 0.016748 	 lr: 0.00002
[epoch 372: 240/307] 	 train loss: 0.104407 	 lr: 0.00002
[epoch 372: 260/307] 	 train loss: 0.084278 	 lr: 0.00002
[epoch 372: 280/307] 	 train loss: 0.085684 	 lr: 0.00002
[epoch 372: 300/307] 	 train loss: 0.027009 	 lr: 0.00002
[epoch 373:   0/307] 	 train loss: 0.017168 	 lr: 0.00002
[epoch 373:  20/307] 	 train loss: 0.016008 	 lr: 0.00002

val loss: 0.344432 	 acc: 0.917342

[epoch 373:  40/307] 	 train loss: 0.060799 	 lr: 0.00002
[epoch 373:  60/307] 	 train loss: 0.015421 	 lr: 0.00002
[epoch 373:  80/307] 	 train loss: 0.099009 	 lr: 0.00002
[epoch 373: 100/307] 	 train loss: 0.107027 	 lr: 0.00002
[epoch 373: 120/307] 	 train loss: 0.233214 	 lr: 0.00002
[epoch 373: 140/307] 	 train loss: 0.113853 	 lr: 0.00002
[epoch 373: 160/307] 	 train loss: 0.021447 	 lr: 0.00002

val loss: 0.345046 	 acc: 0.918558

[epoch 373: 180/307] 	 train loss: 0.039024 	 lr: 0.00002
[epoch 373: 200/307] 	 train loss: 0.059887 	 lr: 0.00002
[epoch 373: 220/307] 	 train loss: 0.056881 	 lr: 0.00002
[epoch 373: 240/307] 	 train loss: 0.009704 	 lr: 0.00002
[epoch 373: 260/307] 	 train loss: 0.142830 	 lr: 0.00002
[epoch 373: 280/307] 	 train loss: 0.076507 	 lr: 0.00002
[epoch 373: 300/307] 	 train loss: 0.097423 	 lr: 0.00002
[epoch 374:   0/307] 	 train loss: 0.320429 	 lr: 0.00002

val loss: 0.344456 	 acc: 0.917342

[epoch 374:  20/307] 	 train loss: 0.034127 	 lr: 0.00002
[epoch 374:  40/307] 	 train loss: 0.088590 	 lr: 0.00002
[epoch 374:  60/307] 	 train loss: 0.031955 	 lr: 0.00002
[epoch 374:  80/307] 	 train loss: 0.003418 	 lr: 0.00002
[epoch 374: 100/307] 	 train loss: 0.214953 	 lr: 0.00002
[epoch 374: 120/307] 	 train loss: 0.039966 	 lr: 0.00002
[epoch 374: 140/307] 	 train loss: 0.096480 	 lr: 0.00002
[epoch 374: 160/307] 	 train loss: 0.048776 	 lr: 0.00002

val loss: 0.346937 	 acc: 0.915721

[epoch 374: 180/307] 	 train loss: 0.323669 	 lr: 0.00002
[epoch 374: 200/307] 	 train loss: 0.030406 	 lr: 0.00002
[epoch 374: 220/307] 	 train loss: 0.269047 	 lr: 0.00002
[epoch 374: 240/307] 	 train loss: 0.240945 	 lr: 0.00002
[epoch 374: 260/307] 	 train loss: 0.176971 	 lr: 0.00002
[epoch 374: 280/307] 	 train loss: 0.253687 	 lr: 0.00002
[epoch 374: 300/307] 	 train loss: 0.278840 	 lr: 0.00002
[epoch 375:   0/307] 	 train loss: 0.028126 	 lr: 0.00002

val loss: 0.347637 	 acc: 0.916532

[epoch 375:  20/307] 	 train loss: 0.113618 	 lr: 0.00002
[epoch 375:  40/307] 	 train loss: 0.137001 	 lr: 0.00002
[epoch 375:  60/307] 	 train loss: 0.021798 	 lr: 0.00002
[epoch 375:  80/307] 	 train loss: 0.220961 	 lr: 0.00002
[epoch 375: 100/307] 	 train loss: 0.017598 	 lr: 0.00002
[epoch 375: 120/307] 	 train loss: 0.085072 	 lr: 0.00002
[epoch 375: 140/307] 	 train loss: 0.021490 	 lr: 0.00002
[epoch 375: 160/307] 	 train loss: 0.032050 	 lr: 0.00002

val loss: 0.350339 	 acc: 0.918963

[epoch 375: 180/307] 	 train loss: 0.067211 	 lr: 0.00002
[epoch 375: 200/307] 	 train loss: 0.069584 	 lr: 0.00002
[epoch 375: 220/307] 	 train loss: 0.119327 	 lr: 0.00002
[epoch 375: 240/307] 	 train loss: 0.084529 	 lr: 0.00002
[epoch 375: 260/307] 	 train loss: 0.074681 	 lr: 0.00002
[epoch 375: 280/307] 	 train loss: 0.007764 	 lr: 0.00002
[epoch 375: 300/307] 	 train loss: 0.189846 	 lr: 0.00002
[epoch 376:   0/307] 	 train loss: 0.032773 	 lr: 0.00002

val loss: 0.348765 	 acc: 0.917342

[epoch 376:  20/307] 	 train loss: 0.038428 	 lr: 0.00002
[epoch 376:  40/307] 	 train loss: 0.051229 	 lr: 0.00002
[epoch 376:  60/307] 	 train loss: 0.156548 	 lr: 0.00002
[epoch 376:  80/307] 	 train loss: 0.048667 	 lr: 0.00002
[epoch 376: 100/307] 	 train loss: 0.049904 	 lr: 0.00002
[epoch 376: 120/307] 	 train loss: 0.143740 	 lr: 0.00002
[epoch 376: 140/307] 	 train loss: 0.080625 	 lr: 0.00002
[epoch 376: 160/307] 	 train loss: 0.245845 	 lr: 0.00002

val loss: 0.348860 	 acc: 0.916937

[epoch 376: 180/307] 	 train loss: 0.141926 	 lr: 0.00002
[epoch 376: 200/307] 	 train loss: 0.123667 	 lr: 0.00002
[epoch 376: 220/307] 	 train loss: 0.066763 	 lr: 0.00002
[epoch 376: 240/307] 	 train loss: 0.105030 	 lr: 0.00002
[epoch 376: 260/307] 	 train loss: 0.048226 	 lr: 0.00002
[epoch 376: 280/307] 	 train loss: 0.055620 	 lr: 0.00002
[epoch 376: 300/307] 	 train loss: 0.076846 	 lr: 0.00002
[epoch 377:   0/307] 	 train loss: 0.049152 	 lr: 0.00002

val loss: 0.350455 	 acc: 0.915721

[epoch 377:  20/307] 	 train loss: 0.060185 	 lr: 0.00002
[epoch 377:  40/307] 	 train loss: 0.025527 	 lr: 0.00002
[epoch 377:  60/307] 	 train loss: 0.067198 	 lr: 0.00002
[epoch 377:  80/307] 	 train loss: 0.176155 	 lr: 0.00002
[epoch 377: 100/307] 	 train loss: 0.115782 	 lr: 0.00002
[epoch 377: 120/307] 	 train loss: 0.022601 	 lr: 0.00002
[epoch 377: 140/307] 	 train loss: 0.063830 	 lr: 0.00002
[epoch 377: 160/307] 	 train loss: 0.103754 	 lr: 0.00002

val loss: 0.349063 	 acc: 0.917342

[epoch 377: 180/307] 	 train loss: 0.115542 	 lr: 0.00002
[epoch 377: 200/307] 	 train loss: 0.156459 	 lr: 0.00002
[epoch 377: 220/307] 	 train loss: 0.123167 	 lr: 0.00002
[epoch 377: 240/307] 	 train loss: 0.165001 	 lr: 0.00002
[epoch 377: 260/307] 	 train loss: 0.013062 	 lr: 0.00002
[epoch 377: 280/307] 	 train loss: 0.155060 	 lr: 0.00002
[epoch 377: 300/307] 	 train loss: 0.044739 	 lr: 0.00002
[epoch 378:   0/307] 	 train loss: 0.063435 	 lr: 0.00002

val loss: 0.349833 	 acc: 0.918152

[epoch 378:  20/307] 	 train loss: 0.046686 	 lr: 0.00002
[epoch 378:  40/307] 	 train loss: 0.151540 	 lr: 0.00002
[epoch 378:  60/307] 	 train loss: 0.077271 	 lr: 0.00002
[epoch 378:  80/307] 	 train loss: 0.163310 	 lr: 0.00002
[epoch 378: 100/307] 	 train loss: 0.105867 	 lr: 0.00002
[epoch 378: 120/307] 	 train loss: 0.086379 	 lr: 0.00002
[epoch 378: 140/307] 	 train loss: 0.119734 	 lr: 0.00002
[epoch 378: 160/307] 	 train loss: 0.025443 	 lr: 0.00002

val loss: 0.349724 	 acc: 0.918152

[epoch 378: 180/307] 	 train loss: 0.118084 	 lr: 0.00002
[epoch 378: 200/307] 	 train loss: 0.042014 	 lr: 0.00002
[epoch 378: 220/307] 	 train loss: 0.048622 	 lr: 0.00002
[epoch 378: 240/307] 	 train loss: 0.131654 	 lr: 0.00002
[epoch 378: 260/307] 	 train loss: 0.108749 	 lr: 0.00002
[epoch 378: 280/307] 	 train loss: 0.154121 	 lr: 0.00002
[epoch 378: 300/307] 	 train loss: 0.026457 	 lr: 0.00002
[epoch 379:   0/307] 	 train loss: 0.073403 	 lr: 0.00002

val loss: 0.352475 	 acc: 0.916937

[epoch 379:  20/307] 	 train loss: 0.091231 	 lr: 0.00002
[epoch 379:  40/307] 	 train loss: 0.067845 	 lr: 0.00002
[epoch 379:  60/307] 	 train loss: 0.047503 	 lr: 0.00002
[epoch 379:  80/307] 	 train loss: 0.049703 	 lr: 0.00002
[epoch 379: 100/307] 	 train loss: 0.045056 	 lr: 0.00002
[epoch 379: 120/307] 	 train loss: 0.026160 	 lr: 0.00002
[epoch 379: 140/307] 	 train loss: 0.254419 	 lr: 0.00002
[epoch 379: 160/307] 	 train loss: 0.056570 	 lr: 0.00002

val loss: 0.349683 	 acc: 0.916126

[epoch 379: 180/307] 	 train loss: 0.089804 	 lr: 0.00002
[epoch 379: 200/307] 	 train loss: 0.049525 	 lr: 0.00002
[epoch 379: 220/307] 	 train loss: 0.033301 	 lr: 0.00002
[epoch 379: 240/307] 	 train loss: 0.078524 	 lr: 0.00002
[epoch 379: 260/307] 	 train loss: 0.097201 	 lr: 0.00002
[epoch 379: 280/307] 	 train loss: 0.023427 	 lr: 0.00002
[epoch 379: 300/307] 	 train loss: 0.059431 	 lr: 0.00002
[epoch 380:   0/307] 	 train loss: 0.165252 	 lr: 0.00002

val loss: 0.348908 	 acc: 0.916937

[epoch 380:  20/307] 	 train loss: 0.031447 	 lr: 0.00002
[epoch 380:  40/307] 	 train loss: 0.117014 	 lr: 0.00002
[epoch 380:  60/307] 	 train loss: 0.114198 	 lr: 0.00002
[epoch 380:  80/307] 	 train loss: 0.144925 	 lr: 0.00002
[epoch 380: 100/307] 	 train loss: 0.016753 	 lr: 0.00002
[epoch 380: 120/307] 	 train loss: 0.085101 	 lr: 0.00002
[epoch 380: 140/307] 	 train loss: 0.081995 	 lr: 0.00002

val loss: 0.347699 	 acc: 0.918558

[epoch 380: 160/307] 	 train loss: 0.021355 	 lr: 0.00002
[epoch 380: 180/307] 	 train loss: 0.051618 	 lr: 0.00002
[epoch 380: 200/307] 	 train loss: 0.130146 	 lr: 0.00002
[epoch 380: 220/307] 	 train loss: 0.135910 	 lr: 0.00002
[epoch 380: 240/307] 	 train loss: 0.035401 	 lr: 0.00002
[epoch 380: 260/307] 	 train loss: 0.186282 	 lr: 0.00002
[epoch 380: 280/307] 	 train loss: 0.116641 	 lr: 0.00002
[epoch 380: 300/307] 	 train loss: 0.145561 	 lr: 0.00002
[epoch 381:   0/307] 	 train loss: 0.061591 	 lr: 0.00002

val loss: 0.347839 	 acc: 0.917342

[epoch 381:  20/307] 	 train loss: 0.165494 	 lr: 0.00002
[epoch 381:  40/307] 	 train loss: 0.065413 	 lr: 0.00002
[epoch 381:  60/307] 	 train loss: 0.012155 	 lr: 0.00002
[epoch 381:  80/307] 	 train loss: 0.120930 	 lr: 0.00002
[epoch 381: 100/307] 	 train loss: 0.003771 	 lr: 0.00002
[epoch 381: 120/307] 	 train loss: 0.049780 	 lr: 0.00002
[epoch 381: 140/307] 	 train loss: 0.159759 	 lr: 0.00002

val loss: 0.347787 	 acc: 0.917747

[epoch 381: 160/307] 	 train loss: 0.154594 	 lr: 0.00002
[epoch 381: 180/307] 	 train loss: 0.017591 	 lr: 0.00002
[epoch 381: 200/307] 	 train loss: 0.064179 	 lr: 0.00002
[epoch 381: 220/307] 	 train loss: 0.098272 	 lr: 0.00002
[epoch 381: 240/307] 	 train loss: 0.175856 	 lr: 0.00002
[epoch 381: 260/307] 	 train loss: 0.230323 	 lr: 0.00002
[epoch 381: 280/307] 	 train loss: 0.057123 	 lr: 0.00002
[epoch 381: 300/307] 	 train loss: 0.174057 	 lr: 0.00002
[epoch 382:   0/307] 	 train loss: 0.204277 	 lr: 0.00002

val loss: 0.348781 	 acc: 0.918152

[epoch 382:  20/307] 	 train loss: 0.087445 	 lr: 0.00002
[epoch 382:  40/307] 	 train loss: 0.058055 	 lr: 0.00002
[epoch 382:  60/307] 	 train loss: 0.049196 	 lr: 0.00002
[epoch 382:  80/307] 	 train loss: 0.028111 	 lr: 0.00002
[epoch 382: 100/307] 	 train loss: 0.092822 	 lr: 0.00002
[epoch 382: 120/307] 	 train loss: 0.031389 	 lr: 0.00002
[epoch 382: 140/307] 	 train loss: 0.171510 	 lr: 0.00002

val loss: 0.350841 	 acc: 0.916126

[epoch 382: 160/307] 	 train loss: 0.074665 	 lr: 0.00002
[epoch 382: 180/307] 	 train loss: 0.090885 	 lr: 0.00002
[epoch 382: 200/307] 	 train loss: 0.223998 	 lr: 0.00002
[epoch 382: 220/307] 	 train loss: 0.145606 	 lr: 0.00002
[epoch 382: 240/307] 	 train loss: 0.147248 	 lr: 0.00002
[epoch 382: 260/307] 	 train loss: 0.102855 	 lr: 0.00002
[epoch 382: 280/307] 	 train loss: 0.068564 	 lr: 0.00002
[epoch 382: 300/307] 	 train loss: 0.009098 	 lr: 0.00002
[epoch 383:   0/307] 	 train loss: 0.099731 	 lr: 0.00002

val loss: 0.347318 	 acc: 0.916532

[epoch 383:  20/307] 	 train loss: 0.076143 	 lr: 0.00002
[epoch 383:  40/307] 	 train loss: 0.058859 	 lr: 0.00002
[epoch 383:  60/307] 	 train loss: 0.010316 	 lr: 0.00002
[epoch 383:  80/307] 	 train loss: 0.050709 	 lr: 0.00002
[epoch 383: 100/307] 	 train loss: 0.017342 	 lr: 0.00002
[epoch 383: 120/307] 	 train loss: 0.178683 	 lr: 0.00002
[epoch 383: 140/307] 	 train loss: 0.095835 	 lr: 0.00002

val loss: 0.347306 	 acc: 0.918558

[epoch 383: 160/307] 	 train loss: 0.059913 	 lr: 0.00002
[epoch 383: 180/307] 	 train loss: 0.064660 	 lr: 0.00002
[epoch 383: 200/307] 	 train loss: 0.045732 	 lr: 0.00002
[epoch 383: 220/307] 	 train loss: 0.093081 	 lr: 0.00002
[epoch 383: 240/307] 	 train loss: 0.137807 	 lr: 0.00002
[epoch 383: 260/307] 	 train loss: 0.045604 	 lr: 0.00002
[epoch 383: 280/307] 	 train loss: 0.243568 	 lr: 0.00002
[epoch 383: 300/307] 	 train loss: 0.026636 	 lr: 0.00002

val loss: 0.349833 	 acc: 0.917747

[epoch 384:   0/307] 	 train loss: 0.035033 	 lr: 0.00002
[epoch 384:  20/307] 	 train loss: 0.051457 	 lr: 0.00002
[epoch 384:  40/307] 	 train loss: 0.130006 	 lr: 0.00002
[epoch 384:  60/307] 	 train loss: 0.051084 	 lr: 0.00002
[epoch 384:  80/307] 	 train loss: 0.112601 	 lr: 0.00002
[epoch 384: 100/307] 	 train loss: 0.038970 	 lr: 0.00002
[epoch 384: 120/307] 	 train loss: 0.071598 	 lr: 0.00002
[epoch 384: 140/307] 	 train loss: 0.074924 	 lr: 0.00002

val loss: 0.347875 	 acc: 0.918558

[epoch 384: 160/307] 	 train loss: 0.005488 	 lr: 0.00002
[epoch 384: 180/307] 	 train loss: 0.076974 	 lr: 0.00002
[epoch 384: 200/307] 	 train loss: 0.098866 	 lr: 0.00002
[epoch 384: 220/307] 	 train loss: 0.075798 	 lr: 0.00002
[epoch 384: 240/307] 	 train loss: 0.111698 	 lr: 0.00002
[epoch 384: 260/307] 	 train loss: 0.135639 	 lr: 0.00002
[epoch 384: 280/307] 	 train loss: 0.055953 	 lr: 0.00002
[epoch 384: 300/307] 	 train loss: 0.075170 	 lr: 0.00002

val loss: 0.348181 	 acc: 0.917747

[epoch 385:   0/307] 	 train loss: 0.105942 	 lr: 0.00002
[epoch 385:  20/307] 	 train loss: 0.050269 	 lr: 0.00002
[epoch 385:  40/307] 	 train loss: 0.144989 	 lr: 0.00002
[epoch 385:  60/307] 	 train loss: 0.048203 	 lr: 0.00002
[epoch 385:  80/307] 	 train loss: 0.084100 	 lr: 0.00002
[epoch 385: 100/307] 	 train loss: 0.020645 	 lr: 0.00002
[epoch 385: 120/307] 	 train loss: 0.031261 	 lr: 0.00002
[epoch 385: 140/307] 	 train loss: 0.013560 	 lr: 0.00002

val loss: 0.349228 	 acc: 0.916937

[epoch 385: 160/307] 	 train loss: 0.030977 	 lr: 0.00002
[epoch 385: 180/307] 	 train loss: 0.085451 	 lr: 0.00002
[epoch 385: 200/307] 	 train loss: 0.051397 	 lr: 0.00002
[epoch 385: 220/307] 	 train loss: 0.032137 	 lr: 0.00002
[epoch 385: 240/307] 	 train loss: 0.038682 	 lr: 0.00002
[epoch 385: 260/307] 	 train loss: 0.065413 	 lr: 0.00002
[epoch 385: 280/307] 	 train loss: 0.013656 	 lr: 0.00002
[epoch 385: 300/307] 	 train loss: 0.072934 	 lr: 0.00002

val loss: 0.348633 	 acc: 0.916126

[epoch 386:   0/307] 	 train loss: 0.023312 	 lr: 0.00002
[epoch 386:  20/307] 	 train loss: 0.114618 	 lr: 0.00002
[epoch 386:  40/307] 	 train loss: 0.032197 	 lr: 0.00002
[epoch 386:  60/307] 	 train loss: 0.348930 	 lr: 0.00002
[epoch 386:  80/307] 	 train loss: 0.053821 	 lr: 0.00002
[epoch 386: 100/307] 	 train loss: 0.010466 	 lr: 0.00002
[epoch 386: 120/307] 	 train loss: 0.126627 	 lr: 0.00002
[epoch 386: 140/307] 	 train loss: 0.120331 	 lr: 0.00002

val loss: 0.350712 	 acc: 0.916937

[epoch 386: 160/307] 	 train loss: 0.191152 	 lr: 0.00002
[epoch 386: 180/307] 	 train loss: 0.055144 	 lr: 0.00002
[epoch 386: 200/307] 	 train loss: 0.020487 	 lr: 0.00002
[epoch 386: 220/307] 	 train loss: 0.026331 	 lr: 0.00002
[epoch 386: 240/307] 	 train loss: 0.035720 	 lr: 0.00002
[epoch 386: 260/307] 	 train loss: 0.112910 	 lr: 0.00002
[epoch 386: 280/307] 	 train loss: 0.097985 	 lr: 0.00002
[epoch 386: 300/307] 	 train loss: 0.014001 	 lr: 0.00002

val loss: 0.347741 	 acc: 0.916126

[epoch 387:   0/307] 	 train loss: 0.096661 	 lr: 0.00002
[epoch 387:  20/307] 	 train loss: 0.071967 	 lr: 0.00002
[epoch 387:  40/307] 	 train loss: 0.105283 	 lr: 0.00002
[epoch 387:  60/307] 	 train loss: 0.082895 	 lr: 0.00002
[epoch 387:  80/307] 	 train loss: 0.012972 	 lr: 0.00002
[epoch 387: 100/307] 	 train loss: 0.016421 	 lr: 0.00002
[epoch 387: 120/307] 	 train loss: 0.053526 	 lr: 0.00002
[epoch 387: 140/307] 	 train loss: 0.254856 	 lr: 0.00002

val loss: 0.349654 	 acc: 0.916937

[epoch 387: 160/307] 	 train loss: 0.093570 	 lr: 0.00002
[epoch 387: 180/307] 	 train loss: 0.066676 	 lr: 0.00002
[epoch 387: 200/307] 	 train loss: 0.047295 	 lr: 0.00002
[epoch 387: 220/307] 	 train loss: 0.067492 	 lr: 0.00002
[epoch 387: 240/307] 	 train loss: 0.016773 	 lr: 0.00002
[epoch 387: 260/307] 	 train loss: 0.247595 	 lr: 0.00002
[epoch 387: 280/307] 	 train loss: 0.029970 	 lr: 0.00002

val loss: 0.348789 	 acc: 0.916532

[epoch 387: 300/307] 	 train loss: 0.084878 	 lr: 0.00002
[epoch 388:   0/307] 	 train loss: 0.148338 	 lr: 0.00002
[epoch 388:  20/307] 	 train loss: 0.171308 	 lr: 0.00002
[epoch 388:  40/307] 	 train loss: 0.028815 	 lr: 0.00002
[epoch 388:  60/307] 	 train loss: 0.018802 	 lr: 0.00002
[epoch 388:  80/307] 	 train loss: 0.128142 	 lr: 0.00002
[epoch 388: 100/307] 	 train loss: 0.022519 	 lr: 0.00002
[epoch 388: 120/307] 	 train loss: 0.083859 	 lr: 0.00002
[epoch 388: 140/307] 	 train loss: 0.022496 	 lr: 0.00002

val loss: 0.348175 	 acc: 0.916126

[epoch 388: 160/307] 	 train loss: 0.093422 	 lr: 0.00002
[epoch 388: 180/307] 	 train loss: 0.044316 	 lr: 0.00002
[epoch 388: 200/307] 	 train loss: 0.039076 	 lr: 0.00002
[epoch 388: 220/307] 	 train loss: 0.026511 	 lr: 0.00002
[epoch 388: 240/307] 	 train loss: 0.132821 	 lr: 0.00002
[epoch 388: 260/307] 	 train loss: 0.081702 	 lr: 0.00002
[epoch 388: 280/307] 	 train loss: 0.307398 	 lr: 0.00002

val loss: 0.348540 	 acc: 0.916937

[epoch 388: 300/307] 	 train loss: 0.065179 	 lr: 0.00002
[epoch 389:   0/307] 	 train loss: 0.388563 	 lr: 0.00002
[epoch 389:  20/307] 	 train loss: 0.084880 	 lr: 0.00002
[epoch 389:  40/307] 	 train loss: 0.070132 	 lr: 0.00002
[epoch 389:  60/307] 	 train loss: 0.006743 	 lr: 0.00002
[epoch 389:  80/307] 	 train loss: 0.380025 	 lr: 0.00002
[epoch 389: 100/307] 	 train loss: 0.037074 	 lr: 0.00002
[epoch 389: 120/307] 	 train loss: 0.207309 	 lr: 0.00002
[epoch 389: 140/307] 	 train loss: 0.029568 	 lr: 0.00002

val loss: 0.348221 	 acc: 0.914911

[epoch 389: 160/307] 	 train loss: 0.071260 	 lr: 0.00002
[epoch 389: 180/307] 	 train loss: 0.009510 	 lr: 0.00002
[epoch 389: 200/307] 	 train loss: 0.025227 	 lr: 0.00002
[epoch 389: 220/307] 	 train loss: 0.121966 	 lr: 0.00002
[epoch 389: 240/307] 	 train loss: 0.062271 	 lr: 0.00002
[epoch 389: 260/307] 	 train loss: 0.040374 	 lr: 0.00002
[epoch 389: 280/307] 	 train loss: 0.011900 	 lr: 0.00002

val loss: 0.350090 	 acc: 0.913695

[epoch 389: 300/307] 	 train loss: 0.099156 	 lr: 0.00002
[epoch 390:   0/307] 	 train loss: 0.041735 	 lr: 0.00002
[epoch 390:  20/307] 	 train loss: 0.303301 	 lr: 0.00002
[epoch 390:  40/307] 	 train loss: 0.010382 	 lr: 0.00002
[epoch 390:  60/307] 	 train loss: 0.256183 	 lr: 0.00002
[epoch 390:  80/307] 	 train loss: 0.134484 	 lr: 0.00002
[epoch 390: 100/307] 	 train loss: 0.053885 	 lr: 0.00002
[epoch 390: 120/307] 	 train loss: 0.065481 	 lr: 0.00002

val loss: 0.349893 	 acc: 0.913695

[epoch 390: 140/307] 	 train loss: 0.021494 	 lr: 0.00002
[epoch 390: 160/307] 	 train loss: 0.191150 	 lr: 0.00002
[epoch 390: 180/307] 	 train loss: 0.226837 	 lr: 0.00002
[epoch 390: 200/307] 	 train loss: 0.046344 	 lr: 0.00002
[epoch 390: 220/307] 	 train loss: 0.208059 	 lr: 0.00002
[epoch 390: 240/307] 	 train loss: 0.097370 	 lr: 0.00002
[epoch 390: 260/307] 	 train loss: 0.018759 	 lr: 0.00002
[epoch 390: 280/307] 	 train loss: 0.006823 	 lr: 0.00002

val loss: 0.346983 	 acc: 0.916532

[epoch 390: 300/307] 	 train loss: 0.025050 	 lr: 0.00002
[epoch 391:   0/307] 	 train loss: 0.008626 	 lr: 0.00002
[epoch 391:  20/307] 	 train loss: 0.151588 	 lr: 0.00002
[epoch 391:  40/307] 	 train loss: 0.013078 	 lr: 0.00002
[epoch 391:  60/307] 	 train loss: 0.108769 	 lr: 0.00002
[epoch 391:  80/307] 	 train loss: 0.243839 	 lr: 0.00002
[epoch 391: 100/307] 	 train loss: 0.028018 	 lr: 0.00002
[epoch 391: 120/307] 	 train loss: 0.052838 	 lr: 0.00002

val loss: 0.349230 	 acc: 0.914911

[epoch 391: 140/307] 	 train loss: 0.104861 	 lr: 0.00002
[epoch 391: 160/307] 	 train loss: 0.127358 	 lr: 0.00002
[epoch 391: 180/307] 	 train loss: 0.033747 	 lr: 0.00002
[epoch 391: 200/307] 	 train loss: 0.414260 	 lr: 0.00002
[epoch 391: 220/307] 	 train loss: 0.013972 	 lr: 0.00002
[epoch 391: 240/307] 	 train loss: 0.020381 	 lr: 0.00002
[epoch 391: 260/307] 	 train loss: 0.046602 	 lr: 0.00002
[epoch 391: 280/307] 	 train loss: 0.050412 	 lr: 0.00002

val loss: 0.347536 	 acc: 0.915316

[epoch 391: 300/307] 	 train loss: 0.039990 	 lr: 0.00002
[epoch 392:   0/307] 	 train loss: 0.053082 	 lr: 0.00002
[epoch 392:  20/307] 	 train loss: 0.041414 	 lr: 0.00002
[epoch 392:  40/307] 	 train loss: 0.058843 	 lr: 0.00002
[epoch 392:  60/307] 	 train loss: 0.113523 	 lr: 0.00002
[epoch 392:  80/307] 	 train loss: 0.050179 	 lr: 0.00002
[epoch 392: 100/307] 	 train loss: 0.077829 	 lr: 0.00002
[epoch 392: 120/307] 	 train loss: 0.015206 	 lr: 0.00002

val loss: 0.347117 	 acc: 0.916126

[epoch 392: 140/307] 	 train loss: 0.078146 	 lr: 0.00002
[epoch 392: 160/307] 	 train loss: 0.039466 	 lr: 0.00002
[epoch 392: 180/307] 	 train loss: 0.178956 	 lr: 0.00002
[epoch 392: 200/307] 	 train loss: 0.066106 	 lr: 0.00002
[epoch 392: 220/307] 	 train loss: 0.142699 	 lr: 0.00002
[epoch 392: 240/307] 	 train loss: 0.128192 	 lr: 0.00002
[epoch 392: 260/307] 	 train loss: 0.023873 	 lr: 0.00002
[epoch 392: 280/307] 	 train loss: 0.224357 	 lr: 0.00002

val loss: 0.347869 	 acc: 0.916126

[epoch 392: 300/307] 	 train loss: 0.064529 	 lr: 0.00002
[epoch 393:   0/307] 	 train loss: 0.044982 	 lr: 0.00002
[epoch 393:  20/307] 	 train loss: 0.102709 	 lr: 0.00002
[epoch 393:  40/307] 	 train loss: 0.009638 	 lr: 0.00002
[epoch 393:  60/307] 	 train loss: 0.100314 	 lr: 0.00002
[epoch 393:  80/307] 	 train loss: 0.032980 	 lr: 0.00002
[epoch 393: 100/307] 	 train loss: 0.032949 	 lr: 0.00002
[epoch 393: 120/307] 	 train loss: 0.167495 	 lr: 0.00002

val loss: 0.347632 	 acc: 0.916126

[epoch 393: 140/307] 	 train loss: 0.088046 	 lr: 0.00002
[epoch 393: 160/307] 	 train loss: 0.269259 	 lr: 0.00002
[epoch 393: 180/307] 	 train loss: 0.061330 	 lr: 0.00002
[epoch 393: 200/307] 	 train loss: 0.015033 	 lr: 0.00002
[epoch 393: 220/307] 	 train loss: 0.025782 	 lr: 0.00002
[epoch 393: 240/307] 	 train loss: 0.018638 	 lr: 0.00002
[epoch 393: 260/307] 	 train loss: 0.072219 	 lr: 0.00002
[epoch 393: 280/307] 	 train loss: 0.013477 	 lr: 0.00002

val loss: 0.346045 	 acc: 0.915316

[epoch 393: 300/307] 	 train loss: 0.135993 	 lr: 0.00002
[epoch 394:   0/307] 	 train loss: 0.002521 	 lr: 0.00002
[epoch 394:  20/307] 	 train loss: 0.030350 	 lr: 0.00002
[epoch 394:  40/307] 	 train loss: 0.078208 	 lr: 0.00002
[epoch 394:  60/307] 	 train loss: 0.024109 	 lr: 0.00002
[epoch 394:  80/307] 	 train loss: 0.223265 	 lr: 0.00002
[epoch 394: 100/307] 	 train loss: 0.122713 	 lr: 0.00002
[epoch 394: 120/307] 	 train loss: 0.007747 	 lr: 0.00002

val loss: 0.345725 	 acc: 0.916532

[epoch 394: 140/307] 	 train loss: 0.058017 	 lr: 0.00002
[epoch 394: 160/307] 	 train loss: 0.044304 	 lr: 0.00002
[epoch 394: 180/307] 	 train loss: 0.164434 	 lr: 0.00002
[epoch 394: 200/307] 	 train loss: 0.020290 	 lr: 0.00002
[epoch 394: 220/307] 	 train loss: 0.093125 	 lr: 0.00002
[epoch 394: 240/307] 	 train loss: 0.045442 	 lr: 0.00002
[epoch 394: 260/307] 	 train loss: 0.250835 	 lr: 0.00002
[epoch 394: 280/307] 	 train loss: 0.145608 	 lr: 0.00002

val loss: 0.347954 	 acc: 0.915316

[epoch 394: 300/307] 	 train loss: 0.085043 	 lr: 0.00002
[epoch 395:   0/307] 	 train loss: 0.086039 	 lr: 0.00002
[epoch 395:  20/307] 	 train loss: 0.052521 	 lr: 0.00002
[epoch 395:  40/307] 	 train loss: 0.043041 	 lr: 0.00002
[epoch 395:  60/307] 	 train loss: 0.042447 	 lr: 0.00002
[epoch 395:  80/307] 	 train loss: 0.100032 	 lr: 0.00002
[epoch 395: 100/307] 	 train loss: 0.089579 	 lr: 0.00002
[epoch 395: 120/307] 	 train loss: 0.069217 	 lr: 0.00002

val loss: 0.347698 	 acc: 0.916532

[epoch 395: 140/307] 	 train loss: 0.154903 	 lr: 0.00002
[epoch 395: 160/307] 	 train loss: 0.020783 	 lr: 0.00002
[epoch 395: 180/307] 	 train loss: 0.051860 	 lr: 0.00002
[epoch 395: 200/307] 	 train loss: 0.076243 	 lr: 0.00002
[epoch 395: 220/307] 	 train loss: 0.094642 	 lr: 0.00002
[epoch 395: 240/307] 	 train loss: 0.271560 	 lr: 0.00002
[epoch 395: 260/307] 	 train loss: 0.247687 	 lr: 0.00002
[epoch 395: 280/307] 	 train loss: 0.033573 	 lr: 0.00002

val loss: 0.347694 	 acc: 0.916532

[epoch 395: 300/307] 	 train loss: 0.094639 	 lr: 0.00002
[epoch 396:   0/307] 	 train loss: 0.009030 	 lr: 0.00002
[epoch 396:  20/307] 	 train loss: 0.010721 	 lr: 0.00002
[epoch 396:  40/307] 	 train loss: 0.070282 	 lr: 0.00002
[epoch 396:  60/307] 	 train loss: 0.093025 	 lr: 0.00002
[epoch 396:  80/307] 	 train loss: 0.112251 	 lr: 0.00002
[epoch 396: 100/307] 	 train loss: 0.030251 	 lr: 0.00002
[epoch 396: 120/307] 	 train loss: 0.290860 	 lr: 0.00002

val loss: 0.344606 	 acc: 0.916937

[epoch 396: 140/307] 	 train loss: 0.019060 	 lr: 0.00002
[epoch 396: 160/307] 	 train loss: 0.045955 	 lr: 0.00002
[epoch 396: 180/307] 	 train loss: 0.023354 	 lr: 0.00002
[epoch 396: 200/307] 	 train loss: 0.212014 	 lr: 0.00002
[epoch 396: 220/307] 	 train loss: 0.014830 	 lr: 0.00002
[epoch 396: 240/307] 	 train loss: 0.112192 	 lr: 0.00002
[epoch 396: 260/307] 	 train loss: 0.075515 	 lr: 0.00002
[epoch 396: 280/307] 	 train loss: 0.048303 	 lr: 0.00002

val loss: 0.347069 	 acc: 0.915316

[epoch 396: 300/307] 	 train loss: 0.024638 	 lr: 0.00002
[epoch 397:   0/307] 	 train loss: 0.200252 	 lr: 0.00002
[epoch 397:  20/307] 	 train loss: 0.063592 	 lr: 0.00002
[epoch 397:  40/307] 	 train loss: 0.059124 	 lr: 0.00002
[epoch 397:  60/307] 	 train loss: 0.036288 	 lr: 0.00002
[epoch 397:  80/307] 	 train loss: 0.061413 	 lr: 0.00002
[epoch 397: 100/307] 	 train loss: 0.245457 	 lr: 0.00002
[epoch 397: 120/307] 	 train loss: 0.043683 	 lr: 0.00002

val loss: 0.350276 	 acc: 0.916126

[epoch 397: 140/307] 	 train loss: 0.111232 	 lr: 0.00002
[epoch 397: 160/307] 	 train loss: 0.113279 	 lr: 0.00002
[epoch 397: 180/307] 	 train loss: 0.048221 	 lr: 0.00002
[epoch 397: 200/307] 	 train loss: 0.136942 	 lr: 0.00002
[epoch 397: 220/307] 	 train loss: 0.006450 	 lr: 0.00002
[epoch 397: 240/307] 	 train loss: 0.144335 	 lr: 0.00002
[epoch 397: 260/307] 	 train loss: 0.033383 	 lr: 0.00002

val loss: 0.350265 	 acc: 0.916126

[epoch 397: 280/307] 	 train loss: 0.071212 	 lr: 0.00002
[epoch 397: 300/307] 	 train loss: 0.058353 	 lr: 0.00002
[epoch 398:   0/307] 	 train loss: 0.050485 	 lr: 0.00002
[epoch 398:  20/307] 	 train loss: 0.208859 	 lr: 0.00002
[epoch 398:  40/307] 	 train loss: 0.036665 	 lr: 0.00002
[epoch 398:  60/307] 	 train loss: 0.061915 	 lr: 0.00002
[epoch 398:  80/307] 	 train loss: 0.081080 	 lr: 0.00002
[epoch 398: 100/307] 	 train loss: 0.009331 	 lr: 0.00002
[epoch 398: 120/307] 	 train loss: 0.105663 	 lr: 0.00002

val loss: 0.347970 	 acc: 0.915316

[epoch 398: 140/307] 	 train loss: 0.031709 	 lr: 0.00002
[epoch 398: 160/307] 	 train loss: 0.021457 	 lr: 0.00002
[epoch 398: 180/307] 	 train loss: 0.008607 	 lr: 0.00002
[epoch 398: 200/307] 	 train loss: 0.033782 	 lr: 0.00002
[epoch 398: 220/307] 	 train loss: 0.261607 	 lr: 0.00002
[epoch 398: 240/307] 	 train loss: 0.140056 	 lr: 0.00002
[epoch 398: 260/307] 	 train loss: 0.074575 	 lr: 0.00002

val loss: 0.350463 	 acc: 0.915316

[epoch 398: 280/307] 	 train loss: 0.096326 	 lr: 0.00002
[epoch 398: 300/307] 	 train loss: 0.066545 	 lr: 0.00002
[epoch 399:   0/307] 	 train loss: 0.054338 	 lr: 0.00002
[epoch 399:  20/307] 	 train loss: 0.142404 	 lr: 0.00002
[epoch 399:  40/307] 	 train loss: 0.117707 	 lr: 0.00002
[epoch 399:  60/307] 	 train loss: 0.385362 	 lr: 0.00002
[epoch 399:  80/307] 	 train loss: 0.079793 	 lr: 0.00002
[epoch 399: 100/307] 	 train loss: 0.083361 	 lr: 0.00002
[epoch 399: 120/307] 	 train loss: 0.033001 	 lr: 0.00002

val loss: 0.351812 	 acc: 0.914911

[epoch 399: 140/307] 	 train loss: 0.056216 	 lr: 0.00002
[epoch 399: 160/307] 	 train loss: 0.124216 	 lr: 0.00002
[epoch 399: 180/307] 	 train loss: 0.076024 	 lr: 0.00002
[epoch 399: 200/307] 	 train loss: 0.050103 	 lr: 0.00002
[epoch 399: 220/307] 	 train loss: 0.101018 	 lr: 0.00002
[epoch 399: 240/307] 	 train loss: 0.297410 	 lr: 0.00002
[epoch 399: 260/307] 	 train loss: 0.038526 	 lr: 0.00002

val loss: 0.349801 	 acc: 0.915721

[epoch 399: 280/307] 	 train loss: 0.171238 	 lr: 0.00002
[epoch 399: 300/307] 	 train loss: 0.013544 	 lr: 0.00002
[epoch 400:   0/307] 	 train loss: 0.094553 	 lr: 0.00001
[epoch 400:  20/307] 	 train loss: 0.173227 	 lr: 0.00001
[epoch 400:  40/307] 	 train loss: 0.077751 	 lr: 0.00001
[epoch 400:  60/307] 	 train loss: 0.018772 	 lr: 0.00001
[epoch 400:  80/307] 	 train loss: 0.101286 	 lr: 0.00001
[epoch 400: 100/307] 	 train loss: 0.087896 	 lr: 0.00001

val loss: 0.346988 	 acc: 0.915721

[epoch 400: 120/307] 	 train loss: 0.168547 	 lr: 0.00001
[epoch 400: 140/307] 	 train loss: 0.135413 	 lr: 0.00001
[epoch 400: 160/307] 	 train loss: 0.005313 	 lr: 0.00001
[epoch 400: 180/307] 	 train loss: 0.074706 	 lr: 0.00001
[epoch 400: 200/307] 	 train loss: 0.219767 	 lr: 0.00001
[epoch 400: 220/307] 	 train loss: 0.047718 	 lr: 0.00001
[epoch 400: 240/307] 	 train loss: 0.212702 	 lr: 0.00001
[epoch 400: 260/307] 	 train loss: 0.065667 	 lr: 0.00001

val loss: 0.349830 	 acc: 0.914911

[epoch 400: 280/307] 	 train loss: 0.151147 	 lr: 0.00001
[epoch 400: 300/307] 	 train loss: 0.009624 	 lr: 0.00001
