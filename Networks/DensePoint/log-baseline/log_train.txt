
**************************

[save_path]: log-baseline

[workers]: 4

[evaluate]: 1

[val_freq_epoch]: 0.5

[weight_decay]: 0

[decay_step]: 21

[print_freq_iter]: 20

[bnm_clip]: 0.01

[checkpoint]: 

[num_classes]: 40

[lr_decay]: 0.7

[bn_decay]: 0.5

[bn_momentum]: 0.9

[num_points]: 1024

[base_lr]: 0.001

[data_root]: ../../Datasets

[lr_clip]: 1e-05

[input_channels]: 0

[batch_size]: 32

[epochs]: 200

**************************

[epoch   1:   0/307] 	 train loss: 3.769802 	 lr: 0.00100
[epoch   1:  20/307] 	 train loss: 2.883722 	 lr: 0.00100
[epoch   1:  40/307] 	 train loss: 2.281057 	 lr: 0.00100
[epoch   1:  60/307] 	 train loss: 1.710605 	 lr: 0.00100
[epoch   1:  80/307] 	 train loss: 2.058690 	 lr: 0.00100
[epoch   1: 100/307] 	 train loss: 1.400288 	 lr: 0.00100
[epoch   1: 120/307] 	 train loss: 1.813465 	 lr: 0.00100
[epoch   1: 140/307] 	 train loss: 1.334540 	 lr: 0.00100

val loss: 2.452649 	 acc: 0.356969

[epoch   1: 160/307] 	 train loss: 1.258898 	 lr: 0.00100
[epoch   1: 180/307] 	 train loss: 1.619258 	 lr: 0.00100
[epoch   1: 200/307] 	 train loss: 1.566454 	 lr: 0.00100
[epoch   1: 220/307] 	 train loss: 1.168889 	 lr: 0.00100
[epoch   1: 240/307] 	 train loss: 1.234311 	 lr: 0.00100
[epoch   1: 260/307] 	 train loss: 1.593046 	 lr: 0.00100
[epoch   1: 280/307] 	 train loss: 1.470356 	 lr: 0.00100
[epoch   1: 300/307] 	 train loss: 1.542787 	 lr: 0.00100

val loss: 6.294811 	 acc: 0.211102

[epoch   2:   0/307] 	 train loss: 1.163087 	 lr: 0.00100
[epoch   2:  20/307] 	 train loss: 1.371808 	 lr: 0.00100
[epoch   2:  40/307] 	 train loss: 0.668183 	 lr: 0.00100
[epoch   2:  60/307] 	 train loss: 1.001858 	 lr: 0.00100
[epoch   2:  80/307] 	 train loss: 1.514465 	 lr: 0.00100
[epoch   2: 100/307] 	 train loss: 1.037863 	 lr: 0.00100
[epoch   2: 120/307] 	 train loss: 1.073424 	 lr: 0.00100
[epoch   2: 140/307] 	 train loss: 0.993737 	 lr: 0.00100

val loss: 0.916586 	 acc: 0.744733

[epoch   2: 160/307] 	 train loss: 0.992216 	 lr: 0.00100
[epoch   2: 180/307] 	 train loss: 1.094988 	 lr: 0.00100
[epoch   2: 200/307] 	 train loss: 1.085505 	 lr: 0.00100
[epoch   2: 220/307] 	 train loss: 1.054158 	 lr: 0.00100
[epoch   2: 240/307] 	 train loss: 1.284387 	 lr: 0.00100
[epoch   2: 260/307] 	 train loss: 0.904960 	 lr: 0.00100
[epoch   2: 280/307] 	 train loss: 1.073539 	 lr: 0.00100
[epoch   2: 300/307] 	 train loss: 0.691455 	 lr: 0.00100

val loss: 0.833440 	 acc: 0.750810

[epoch   3:   0/307] 	 train loss: 0.784047 	 lr: 0.00100
[epoch   3:  20/307] 	 train loss: 0.869792 	 lr: 0.00100
[epoch   3:  40/307] 	 train loss: 0.878070 	 lr: 0.00100
[epoch   3:  60/307] 	 train loss: 0.741738 	 lr: 0.00100
[epoch   3:  80/307] 	 train loss: 0.799594 	 lr: 0.00100
[epoch   3: 100/307] 	 train loss: 0.984192 	 lr: 0.00100
[epoch   3: 120/307] 	 train loss: 0.840873 	 lr: 0.00100
[epoch   3: 140/307] 	 train loss: 0.970410 	 lr: 0.00100

val loss: 0.820646 	 acc: 0.766613

[epoch   3: 160/307] 	 train loss: 0.776367 	 lr: 0.00100
[epoch   3: 180/307] 	 train loss: 1.068008 	 lr: 0.00100
[epoch   3: 200/307] 	 train loss: 0.455570 	 lr: 0.00100
[epoch   3: 220/307] 	 train loss: 0.607318 	 lr: 0.00100
[epoch   3: 240/307] 	 train loss: 0.957735 	 lr: 0.00100
[epoch   3: 260/307] 	 train loss: 0.835806 	 lr: 0.00100
[epoch   3: 280/307] 	 train loss: 1.044897 	 lr: 0.00100
[epoch   3: 300/307] 	 train loss: 0.625161 	 lr: 0.00100

val loss: 0.760040 	 acc: 0.770259

[epoch   4:   0/307] 	 train loss: 0.885121 	 lr: 0.00100
[epoch   4:  20/307] 	 train loss: 0.528721 	 lr: 0.00100
[epoch   4:  40/307] 	 train loss: 0.956023 	 lr: 0.00100
[epoch   4:  60/307] 	 train loss: 0.765555 	 lr: 0.00100
[epoch   4:  80/307] 	 train loss: 0.649995 	 lr: 0.00100
[epoch   4: 100/307] 	 train loss: 0.904549 	 lr: 0.00100
[epoch   4: 120/307] 	 train loss: 0.725277 	 lr: 0.00100
[epoch   4: 140/307] 	 train loss: 1.093062 	 lr: 0.00100

val loss: 0.698641 	 acc: 0.777958

[epoch   4: 160/307] 	 train loss: 0.798196 	 lr: 0.00100
[epoch   4: 180/307] 	 train loss: 0.642477 	 lr: 0.00100
[epoch   4: 200/307] 	 train loss: 1.066282 	 lr: 0.00100
[epoch   4: 220/307] 	 train loss: 0.645797 	 lr: 0.00100
[epoch   4: 240/307] 	 train loss: 0.614732 	 lr: 0.00100
[epoch   4: 260/307] 	 train loss: 0.700017 	 lr: 0.00100
[epoch   4: 280/307] 	 train loss: 0.615731 	 lr: 0.00100

val loss: 0.609094 	 acc: 0.821313

[epoch   4: 300/307] 	 train loss: 1.087859 	 lr: 0.00100
[epoch   5:   0/307] 	 train loss: 0.310093 	 lr: 0.00100
[epoch   5:  20/307] 	 train loss: 0.899534 	 lr: 0.00100
[epoch   5:  40/307] 	 train loss: 0.729316 	 lr: 0.00100
[epoch   5:  60/307] 	 train loss: 0.582501 	 lr: 0.00100
[epoch   5:  80/307] 	 train loss: 0.887420 	 lr: 0.00100
[epoch   5: 100/307] 	 train loss: 0.670830 	 lr: 0.00100
[epoch   5: 120/307] 	 train loss: 0.738718 	 lr: 0.00100
[epoch   5: 140/307] 	 train loss: 0.734315 	 lr: 0.00100

val loss: 0.641990 	 acc: 0.813614

[epoch   5: 160/307] 	 train loss: 0.562454 	 lr: 0.00100
[epoch   5: 180/307] 	 train loss: 0.533894 	 lr: 0.00100
[epoch   5: 200/307] 	 train loss: 0.466607 	 lr: 0.00100
[epoch   5: 220/307] 	 train loss: 0.684624 	 lr: 0.00100
[epoch   5: 240/307] 	 train loss: 0.612041 	 lr: 0.00100
[epoch   5: 260/307] 	 train loss: 0.566826 	 lr: 0.00100
[epoch   5: 280/307] 	 train loss: 0.574059 	 lr: 0.00100

val loss: 0.614838 	 acc: 0.801459

[epoch   5: 300/307] 	 train loss: 0.665265 	 lr: 0.00100
[epoch   6:   0/307] 	 train loss: 0.540444 	 lr: 0.00100
[epoch   6:  20/307] 	 train loss: 0.759239 	 lr: 0.00100
[epoch   6:  40/307] 	 train loss: 0.601139 	 lr: 0.00100
[epoch   6:  60/307] 	 train loss: 0.507620 	 lr: 0.00100
[epoch   6:  80/307] 	 train loss: 0.927902 	 lr: 0.00100
[epoch   6: 100/307] 	 train loss: 0.540961 	 lr: 0.00100
[epoch   6: 120/307] 	 train loss: 0.881706 	 lr: 0.00100
[epoch   6: 140/307] 	 train loss: 0.678261 	 lr: 0.00100

val loss: 0.570169 	 acc: 0.824959

[epoch   6: 160/307] 	 train loss: 0.355524 	 lr: 0.00100
[epoch   6: 180/307] 	 train loss: 0.869839 	 lr: 0.00100
[epoch   6: 200/307] 	 train loss: 0.588876 	 lr: 0.00100
[epoch   6: 220/307] 	 train loss: 0.788347 	 lr: 0.00100
[epoch   6: 240/307] 	 train loss: 0.769193 	 lr: 0.00100
[epoch   6: 260/307] 	 train loss: 0.645222 	 lr: 0.00100
[epoch   6: 280/307] 	 train loss: 0.736405 	 lr: 0.00100

val loss: 0.568290 	 acc: 0.816045

[epoch   6: 300/307] 	 train loss: 0.347579 	 lr: 0.00100
[epoch   7:   0/307] 	 train loss: 0.503166 	 lr: 0.00100
[epoch   7:  20/307] 	 train loss: 0.439084 	 lr: 0.00100
[epoch   7:  40/307] 	 train loss: 0.805844 	 lr: 0.00100
[epoch   7:  60/307] 	 train loss: 0.697141 	 lr: 0.00100
[epoch   7:  80/307] 	 train loss: 0.667367 	 lr: 0.00100
[epoch   7: 100/307] 	 train loss: 0.297044 	 lr: 0.00100
[epoch   7: 120/307] 	 train loss: 0.299182 	 lr: 0.00100
[epoch   7: 140/307] 	 train loss: 0.755685 	 lr: 0.00100

val loss: 0.530066 	 acc: 0.837115

[epoch   7: 160/307] 	 train loss: 0.806010 	 lr: 0.00100
[epoch   7: 180/307] 	 train loss: 0.867039 	 lr: 0.00100
[epoch   7: 200/307] 	 train loss: 0.534620 	 lr: 0.00100
[epoch   7: 220/307] 	 train loss: 0.463559 	 lr: 0.00100
[epoch   7: 240/307] 	 train loss: 0.364113 	 lr: 0.00100
[epoch   7: 260/307] 	 train loss: 1.164338 	 lr: 0.00100
[epoch   7: 280/307] 	 train loss: 0.397975 	 lr: 0.00100

val loss: 0.543701 	 acc: 0.828606

[epoch   7: 300/307] 	 train loss: 0.854387 	 lr: 0.00100
[epoch   8:   0/307] 	 train loss: 0.579382 	 lr: 0.00100
[epoch   8:  20/307] 	 train loss: 0.682040 	 lr: 0.00100
[epoch   8:  40/307] 	 train loss: 0.400856 	 lr: 0.00100
[epoch   8:  60/307] 	 train loss: 0.444027 	 lr: 0.00100
[epoch   8:  80/307] 	 train loss: 0.822459 	 lr: 0.00100
[epoch   8: 100/307] 	 train loss: 1.164632 	 lr: 0.00100
[epoch   8: 120/307] 	 train loss: 0.401071 	 lr: 0.00100

val loss: 0.471571 	 acc: 0.856159

[epoch   8: 140/307] 	 train loss: 0.561110 	 lr: 0.00100
[epoch   8: 160/307] 	 train loss: 0.682468 	 lr: 0.00100
[epoch   8: 180/307] 	 train loss: 0.610977 	 lr: 0.00100
[epoch   8: 200/307] 	 train loss: 0.782993 	 lr: 0.00100
[epoch   8: 220/307] 	 train loss: 0.367324 	 lr: 0.00100
[epoch   8: 240/307] 	 train loss: 0.673614 	 lr: 0.00100
[epoch   8: 260/307] 	 train loss: 0.638886 	 lr: 0.00100
[epoch   8: 280/307] 	 train loss: 0.954669 	 lr: 0.00100

val loss: 0.544578 	 acc: 0.828201

[epoch   8: 300/307] 	 train loss: 0.462325 	 lr: 0.00100
[epoch   9:   0/307] 	 train loss: 0.553128 	 lr: 0.00100
[epoch   9:  20/307] 	 train loss: 1.085431 	 lr: 0.00100
[epoch   9:  40/307] 	 train loss: 0.505565 	 lr: 0.00100
[epoch   9:  60/307] 	 train loss: 0.541160 	 lr: 0.00100
[epoch   9:  80/307] 	 train loss: 0.558911 	 lr: 0.00100
[epoch   9: 100/307] 	 train loss: 0.424565 	 lr: 0.00100
[epoch   9: 120/307] 	 train loss: 0.693024 	 lr: 0.00100

val loss: 0.457160 	 acc: 0.856969

[epoch   9: 140/307] 	 train loss: 0.594132 	 lr: 0.00100
[epoch   9: 160/307] 	 train loss: 0.643490 	 lr: 0.00100
[epoch   9: 180/307] 	 train loss: 0.611864 	 lr: 0.00100
[epoch   9: 200/307] 	 train loss: 0.749739 	 lr: 0.00100
[epoch   9: 220/307] 	 train loss: 0.303254 	 lr: 0.00100
[epoch   9: 240/307] 	 train loss: 0.742185 	 lr: 0.00100
[epoch   9: 260/307] 	 train loss: 0.471207 	 lr: 0.00100
[epoch   9: 280/307] 	 train loss: 0.570384 	 lr: 0.00100

val loss: 0.460469 	 acc: 0.857374

[epoch   9: 300/307] 	 train loss: 0.500859 	 lr: 0.00100
[epoch  10:   0/307] 	 train loss: 0.622989 	 lr: 0.00100
[epoch  10:  20/307] 	 train loss: 0.341332 	 lr: 0.00100
[epoch  10:  40/307] 	 train loss: 0.485246 	 lr: 0.00100
[epoch  10:  60/307] 	 train loss: 0.385748 	 lr: 0.00100
[epoch  10:  80/307] 	 train loss: 0.793044 	 lr: 0.00100
[epoch  10: 100/307] 	 train loss: 0.398834 	 lr: 0.00100
[epoch  10: 120/307] 	 train loss: 0.534206 	 lr: 0.00100

val loss: 0.514277 	 acc: 0.831442

[epoch  10: 140/307] 	 train loss: 0.511149 	 lr: 0.00100
[epoch  10: 160/307] 	 train loss: 0.639214 	 lr: 0.00100
[epoch  10: 180/307] 	 train loss: 0.474461 	 lr: 0.00100
[epoch  10: 200/307] 	 train loss: 1.183480 	 lr: 0.00100
[epoch  10: 220/307] 	 train loss: 0.533752 	 lr: 0.00100
[epoch  10: 240/307] 	 train loss: 0.520188 	 lr: 0.00100
[epoch  10: 260/307] 	 train loss: 0.946953 	 lr: 0.00100
[epoch  10: 280/307] 	 train loss: 0.639344 	 lr: 0.00100

val loss: 0.489152 	 acc: 0.844814

[epoch  10: 300/307] 	 train loss: 0.554761 	 lr: 0.00100
[epoch  11:   0/307] 	 train loss: 0.176982 	 lr: 0.00100
[epoch  11:  20/307] 	 train loss: 0.466706 	 lr: 0.00100
[epoch  11:  40/307] 	 train loss: 0.398354 	 lr: 0.00100
[epoch  11:  60/307] 	 train loss: 0.395580 	 lr: 0.00100
[epoch  11:  80/307] 	 train loss: 0.488543 	 lr: 0.00100
[epoch  11: 100/307] 	 train loss: 0.467696 	 lr: 0.00100
[epoch  11: 120/307] 	 train loss: 0.341531 	 lr: 0.00100

val loss: 0.441418 	 acc: 0.855348

[epoch  11: 140/307] 	 train loss: 0.211644 	 lr: 0.00100
[epoch  11: 160/307] 	 train loss: 0.576757 	 lr: 0.00100
[epoch  11: 180/307] 	 train loss: 0.450628 	 lr: 0.00100
[epoch  11: 200/307] 	 train loss: 0.522953 	 lr: 0.00100
[epoch  11: 220/307] 	 train loss: 0.438618 	 lr: 0.00100
[epoch  11: 240/307] 	 train loss: 0.584723 	 lr: 0.00100
[epoch  11: 260/307] 	 train loss: 0.319566 	 lr: 0.00100
[epoch  11: 280/307] 	 train loss: 0.626780 	 lr: 0.00100

val loss: 0.457003 	 acc: 0.854133

[epoch  11: 300/307] 	 train loss: 0.553615 	 lr: 0.00100
[epoch  12:   0/307] 	 train loss: 0.510058 	 lr: 0.00100
[epoch  12:  20/307] 	 train loss: 0.323028 	 lr: 0.00100
[epoch  12:  40/307] 	 train loss: 0.652360 	 lr: 0.00100
[epoch  12:  60/307] 	 train loss: 0.416940 	 lr: 0.00100
[epoch  12:  80/307] 	 train loss: 0.688031 	 lr: 0.00100
[epoch  12: 100/307] 	 train loss: 0.597698 	 lr: 0.00100
[epoch  12: 120/307] 	 train loss: 0.401460 	 lr: 0.00100

val loss: 0.427084 	 acc: 0.861831

[epoch  12: 140/307] 	 train loss: 0.465222 	 lr: 0.00100
[epoch  12: 160/307] 	 train loss: 0.675020 	 lr: 0.00100
[epoch  12: 180/307] 	 train loss: 0.863309 	 lr: 0.00100
[epoch  12: 200/307] 	 train loss: 0.882652 	 lr: 0.00100
[epoch  12: 220/307] 	 train loss: 0.843605 	 lr: 0.00100
[epoch  12: 240/307] 	 train loss: 0.629137 	 lr: 0.00100
[epoch  12: 260/307] 	 train loss: 0.523255 	 lr: 0.00100
[epoch  12: 280/307] 	 train loss: 0.363256 	 lr: 0.00100

val loss: 0.444704 	 acc: 0.861831

[epoch  12: 300/307] 	 train loss: 1.100574 	 lr: 0.00100
[epoch  13:   0/307] 	 train loss: 0.462250 	 lr: 0.00100
[epoch  13:  20/307] 	 train loss: 0.374979 	 lr: 0.00100
[epoch  13:  40/307] 	 train loss: 0.425213 	 lr: 0.00100
[epoch  13:  60/307] 	 train loss: 0.556837 	 lr: 0.00100
[epoch  13:  80/307] 	 train loss: 0.360395 	 lr: 0.00100
[epoch  13: 100/307] 	 train loss: 0.997416 	 lr: 0.00100
[epoch  13: 120/307] 	 train loss: 0.472271 	 lr: 0.00100

val loss: 0.404664 	 acc: 0.874797

[epoch  13: 140/307] 	 train loss: 0.452578 	 lr: 0.00100
[epoch  13: 160/307] 	 train loss: 0.804050 	 lr: 0.00100
[epoch  13: 180/307] 	 train loss: 0.452148 	 lr: 0.00100
[epoch  13: 200/307] 	 train loss: 0.568974 	 lr: 0.00100
[epoch  13: 220/307] 	 train loss: 0.735388 	 lr: 0.00100
[epoch  13: 240/307] 	 train loss: 0.381137 	 lr: 0.00100
[epoch  13: 260/307] 	 train loss: 0.318969 	 lr: 0.00100
[epoch  13: 280/307] 	 train loss: 0.720599 	 lr: 0.00100

val loss: 0.440659 	 acc: 0.863452

[epoch  13: 300/307] 	 train loss: 0.452354 	 lr: 0.00100
[epoch  14:   0/307] 	 train loss: 1.346392 	 lr: 0.00100
[epoch  14:  20/307] 	 train loss: 0.618324 	 lr: 0.00100
[epoch  14:  40/307] 	 train loss: 0.303862 	 lr: 0.00100
[epoch  14:  60/307] 	 train loss: 0.597412 	 lr: 0.00100
[epoch  14:  80/307] 	 train loss: 0.589789 	 lr: 0.00100
[epoch  14: 100/307] 	 train loss: 0.308874 	 lr: 0.00100
[epoch  14: 120/307] 	 train loss: 0.251780 	 lr: 0.00100

val loss: 0.409811 	 acc: 0.869530

[epoch  14: 140/307] 	 train loss: 0.587098 	 lr: 0.00100
[epoch  14: 160/307] 	 train loss: 0.339792 	 lr: 0.00100
[epoch  14: 180/307] 	 train loss: 0.516936 	 lr: 0.00100
[epoch  14: 200/307] 	 train loss: 0.220597 	 lr: 0.00100
[epoch  14: 220/307] 	 train loss: 0.605592 	 lr: 0.00100
[epoch  14: 240/307] 	 train loss: 0.905235 	 lr: 0.00100
[epoch  14: 260/307] 	 train loss: 0.431047 	 lr: 0.00100

val loss: 0.422123 	 acc: 0.873582

[epoch  14: 280/307] 	 train loss: 0.612207 	 lr: 0.00100
[epoch  14: 300/307] 	 train loss: 0.616854 	 lr: 0.00100
[epoch  15:   0/307] 	 train loss: 0.667600 	 lr: 0.00100
[epoch  15:  20/307] 	 train loss: 0.189508 	 lr: 0.00100
[epoch  15:  40/307] 	 train loss: 0.515580 	 lr: 0.00100
[epoch  15:  60/307] 	 train loss: 0.533672 	 lr: 0.00100
[epoch  15:  80/307] 	 train loss: 0.363565 	 lr: 0.00100
[epoch  15: 100/307] 	 train loss: 0.377102 	 lr: 0.00100
[epoch  15: 120/307] 	 train loss: 0.545026 	 lr: 0.00100

val loss: 0.417215 	 acc: 0.870340

[epoch  15: 140/307] 	 train loss: 0.637337 	 lr: 0.00100
[epoch  15: 160/307] 	 train loss: 0.758477 	 lr: 0.00100
[epoch  15: 180/307] 	 train loss: 0.506115 	 lr: 0.00100
[epoch  15: 200/307] 	 train loss: 0.413786 	 lr: 0.00100
[epoch  15: 220/307] 	 train loss: 0.648365 	 lr: 0.00100
[epoch  15: 240/307] 	 train loss: 0.570946 	 lr: 0.00100
[epoch  15: 260/307] 	 train loss: 0.573683 	 lr: 0.00100

val loss: 0.464137 	 acc: 0.860211

[epoch  15: 280/307] 	 train loss: 0.476245 	 lr: 0.00100
[epoch  15: 300/307] 	 train loss: 0.773737 	 lr: 0.00100
[epoch  16:   0/307] 	 train loss: 0.222506 	 lr: 0.00100
[epoch  16:  20/307] 	 train loss: 0.457000 	 lr: 0.00100
[epoch  16:  40/307] 	 train loss: 0.340787 	 lr: 0.00100
[epoch  16:  60/307] 	 train loss: 0.317957 	 lr: 0.00100
[epoch  16:  80/307] 	 train loss: 0.835068 	 lr: 0.00100
[epoch  16: 100/307] 	 train loss: 0.228371 	 lr: 0.00100
[epoch  16: 120/307] 	 train loss: 0.279160 	 lr: 0.00100

val loss: 0.388133 	 acc: 0.873987

[epoch  16: 140/307] 	 train loss: 0.526965 	 lr: 0.00100
[epoch  16: 160/307] 	 train loss: 0.851632 	 lr: 0.00100
[epoch  16: 180/307] 	 train loss: 0.876156 	 lr: 0.00100
[epoch  16: 200/307] 	 train loss: 0.343159 	 lr: 0.00100
[epoch  16: 220/307] 	 train loss: 0.574734 	 lr: 0.00100
[epoch  16: 240/307] 	 train loss: 0.277400 	 lr: 0.00100
[epoch  16: 260/307] 	 train loss: 0.338953 	 lr: 0.00100

val loss: 0.442283 	 acc: 0.862642

[epoch  16: 280/307] 	 train loss: 0.614720 	 lr: 0.00100
[epoch  16: 300/307] 	 train loss: 0.559957 	 lr: 0.00100
[epoch  17:   0/307] 	 train loss: 0.808018 	 lr: 0.00100
[epoch  17:  20/307] 	 train loss: 0.595928 	 lr: 0.00100
[epoch  17:  40/307] 	 train loss: 0.293291 	 lr: 0.00100
[epoch  17:  60/307] 	 train loss: 0.462040 	 lr: 0.00100
[epoch  17:  80/307] 	 train loss: 0.456896 	 lr: 0.00100
[epoch  17: 100/307] 	 train loss: 0.852201 	 lr: 0.00100
[epoch  17: 120/307] 	 train loss: 0.422888 	 lr: 0.00100

val loss: 0.418220 	 acc: 0.870340

[epoch  17: 140/307] 	 train loss: 0.616502 	 lr: 0.00100
[epoch  17: 160/307] 	 train loss: 0.798638 	 lr: 0.00100
[epoch  17: 180/307] 	 train loss: 0.364110 	 lr: 0.00100
[epoch  17: 200/307] 	 train loss: 0.451197 	 lr: 0.00100
[epoch  17: 220/307] 	 train loss: 0.610623 	 lr: 0.00100
[epoch  17: 240/307] 	 train loss: 0.425469 	 lr: 0.00100
[epoch  17: 260/307] 	 train loss: 0.760954 	 lr: 0.00100

val loss: 0.397288 	 acc: 0.881686

[epoch  17: 280/307] 	 train loss: 0.497491 	 lr: 0.00100
[epoch  17: 300/307] 	 train loss: 0.508638 	 lr: 0.00100
[epoch  18:   0/307] 	 train loss: 0.346675 	 lr: 0.00100
[epoch  18:  20/307] 	 train loss: 0.542806 	 lr: 0.00100
[epoch  18:  40/307] 	 train loss: 0.776099 	 lr: 0.00100
[epoch  18:  60/307] 	 train loss: 0.558396 	 lr: 0.00100
[epoch  18:  80/307] 	 train loss: 0.206345 	 lr: 0.00100
[epoch  18: 100/307] 	 train loss: 0.360917 	 lr: 0.00100

val loss: 0.411039 	 acc: 0.867909

[epoch  18: 120/307] 	 train loss: 0.492085 	 lr: 0.00100
[epoch  18: 140/307] 	 train loss: 0.363051 	 lr: 0.00100
[epoch  18: 160/307] 	 train loss: 0.350663 	 lr: 0.00100
[epoch  18: 180/307] 	 train loss: 0.201071 	 lr: 0.00100
[epoch  18: 200/307] 	 train loss: 0.246393 	 lr: 0.00100
[epoch  18: 220/307] 	 train loss: 0.368503 	 lr: 0.00100
[epoch  18: 240/307] 	 train loss: 0.394119 	 lr: 0.00100
[epoch  18: 260/307] 	 train loss: 0.476699 	 lr: 0.00100

val loss: 0.430968 	 acc: 0.852917

[epoch  18: 280/307] 	 train loss: 0.605979 	 lr: 0.00100
[epoch  18: 300/307] 	 train loss: 0.393224 	 lr: 0.00100
[epoch  19:   0/307] 	 train loss: 0.482958 	 lr: 0.00100
[epoch  19:  20/307] 	 train loss: 0.417210 	 lr: 0.00100
[epoch  19:  40/307] 	 train loss: 0.374335 	 lr: 0.00100
[epoch  19:  60/307] 	 train loss: 0.523210 	 lr: 0.00100
[epoch  19:  80/307] 	 train loss: 0.464400 	 lr: 0.00100
[epoch  19: 100/307] 	 train loss: 0.419970 	 lr: 0.00100

val loss: 0.378390 	 acc: 0.878444

[epoch  19: 120/307] 	 train loss: 0.215621 	 lr: 0.00100
[epoch  19: 140/307] 	 train loss: 0.712043 	 lr: 0.00100
[epoch  19: 160/307] 	 train loss: 0.110445 	 lr: 0.00100
[epoch  19: 180/307] 	 train loss: 0.249545 	 lr: 0.00100
[epoch  19: 200/307] 	 train loss: 0.490308 	 lr: 0.00100
[epoch  19: 220/307] 	 train loss: 0.393977 	 lr: 0.00100
[epoch  19: 240/307] 	 train loss: 0.320500 	 lr: 0.00100
[epoch  19: 260/307] 	 train loss: 0.546530 	 lr: 0.00100

val loss: 0.373589 	 acc: 0.880470

[epoch  19: 280/307] 	 train loss: 0.303781 	 lr: 0.00100
[epoch  19: 300/307] 	 train loss: 0.254454 	 lr: 0.00100
[epoch  20:   0/307] 	 train loss: 0.209532 	 lr: 0.00100
[epoch  20:  20/307] 	 train loss: 0.360984 	 lr: 0.00100
[epoch  20:  40/307] 	 train loss: 0.196511 	 lr: 0.00100
[epoch  20:  60/307] 	 train loss: 0.232290 	 lr: 0.00100
[epoch  20:  80/307] 	 train loss: 0.812189 	 lr: 0.00100
[epoch  20: 100/307] 	 train loss: 0.463933 	 lr: 0.00100

val loss: 0.440317 	 acc: 0.854133

[epoch  20: 120/307] 	 train loss: 0.466285 	 lr: 0.00100
[epoch  20: 140/307] 	 train loss: 0.316581 	 lr: 0.00100
[epoch  20: 160/307] 	 train loss: 0.339783 	 lr: 0.00100
[epoch  20: 180/307] 	 train loss: 0.270873 	 lr: 0.00100
[epoch  20: 200/307] 	 train loss: 0.392024 	 lr: 0.00100
[epoch  20: 220/307] 	 train loss: 0.641062 	 lr: 0.00100
[epoch  20: 240/307] 	 train loss: 0.517330 	 lr: 0.00100
[epoch  20: 260/307] 	 train loss: 0.274161 	 lr: 0.00100

val loss: 0.431446 	 acc: 0.870746

[epoch  20: 280/307] 	 train loss: 0.322661 	 lr: 0.00100
[epoch  20: 300/307] 	 train loss: 0.664123 	 lr: 0.00100
[epoch  21:   0/307] 	 train loss: 0.245651 	 lr: 0.00100
[epoch  21:  20/307] 	 train loss: 0.576334 	 lr: 0.00100
[epoch  21:  40/307] 	 train loss: 0.406980 	 lr: 0.00100
[epoch  21:  60/307] 	 train loss: 0.362144 	 lr: 0.00100
[epoch  21:  80/307] 	 train loss: 0.501638 	 lr: 0.00100
[epoch  21: 100/307] 	 train loss: 0.485169 	 lr: 0.00100

val loss: 0.415547 	 acc: 0.874392

[epoch  21: 120/307] 	 train loss: 0.241885 	 lr: 0.00100
[epoch  21: 140/307] 	 train loss: 0.447527 	 lr: 0.00100
[epoch  21: 160/307] 	 train loss: 0.672726 	 lr: 0.00100
[epoch  21: 180/307] 	 train loss: 0.563155 	 lr: 0.00100
[epoch  21: 200/307] 	 train loss: 0.533871 	 lr: 0.00100
[epoch  21: 220/307] 	 train loss: 0.849415 	 lr: 0.00100
[epoch  21: 240/307] 	 train loss: 0.686449 	 lr: 0.00100
[epoch  21: 260/307] 	 train loss: 0.308584 	 lr: 0.00100

val loss: 0.449640 	 acc: 0.868314

[epoch  21: 280/307] 	 train loss: 0.574884 	 lr: 0.00100
[epoch  21: 300/307] 	 train loss: 0.220575 	 lr: 0.00100
[epoch  22:   0/307] 	 train loss: 0.333325 	 lr: 0.00070
[epoch  22:  20/307] 	 train loss: 0.329532 	 lr: 0.00070
[epoch  22:  40/307] 	 train loss: 0.285470 	 lr: 0.00070
[epoch  22:  60/307] 	 train loss: 0.647296 	 lr: 0.00070
[epoch  22:  80/307] 	 train loss: 0.546233 	 lr: 0.00070
[epoch  22: 100/307] 	 train loss: 0.622729 	 lr: 0.00070

val loss: 0.362507 	 acc: 0.882901

[epoch  22: 120/307] 	 train loss: 0.510561 	 lr: 0.00070
[epoch  22: 140/307] 	 train loss: 0.789024 	 lr: 0.00070
[epoch  22: 160/307] 	 train loss: 0.287997 	 lr: 0.00070
[epoch  22: 180/307] 	 train loss: 0.819711 	 lr: 0.00070
[epoch  22: 200/307] 	 train loss: 0.405135 	 lr: 0.00070
[epoch  22: 220/307] 	 train loss: 0.849828 	 lr: 0.00070
[epoch  22: 240/307] 	 train loss: 0.876278 	 lr: 0.00070
[epoch  22: 260/307] 	 train loss: 0.496644 	 lr: 0.00070

val loss: 0.380555 	 acc: 0.879660

[epoch  22: 280/307] 	 train loss: 0.338905 	 lr: 0.00070
[epoch  22: 300/307] 	 train loss: 0.570037 	 lr: 0.00070
[epoch  23:   0/307] 	 train loss: 0.342000 	 lr: 0.00070
[epoch  23:  20/307] 	 train loss: 0.590839 	 lr: 0.00070
[epoch  23:  40/307] 	 train loss: 0.523505 	 lr: 0.00070
[epoch  23:  60/307] 	 train loss: 0.350621 	 lr: 0.00070
[epoch  23:  80/307] 	 train loss: 0.476993 	 lr: 0.00070
[epoch  23: 100/307] 	 train loss: 0.408596 	 lr: 0.00070

val loss: 0.360284 	 acc: 0.884522

[epoch  23: 120/307] 	 train loss: 0.479562 	 lr: 0.00070
[epoch  23: 140/307] 	 train loss: 0.332435 	 lr: 0.00070
[epoch  23: 160/307] 	 train loss: 0.322115 	 lr: 0.00070
[epoch  23: 180/307] 	 train loss: 0.309901 	 lr: 0.00070
[epoch  23: 200/307] 	 train loss: 0.348200 	 lr: 0.00070
[epoch  23: 220/307] 	 train loss: 0.707686 	 lr: 0.00070
[epoch  23: 240/307] 	 train loss: 0.356941 	 lr: 0.00070
[epoch  23: 260/307] 	 train loss: 0.305286 	 lr: 0.00070

val loss: 0.386720 	 acc: 0.879254

[epoch  23: 280/307] 	 train loss: 0.237650 	 lr: 0.00070
[epoch  23: 300/307] 	 train loss: 0.618305 	 lr: 0.00070
[epoch  24:   0/307] 	 train loss: 0.525796 	 lr: 0.00070
[epoch  24:  20/307] 	 train loss: 0.600692 	 lr: 0.00070
[epoch  24:  40/307] 	 train loss: 0.251780 	 lr: 0.00070
[epoch  24:  60/307] 	 train loss: 0.411201 	 lr: 0.00070
[epoch  24:  80/307] 	 train loss: 0.316973 	 lr: 0.00070
[epoch  24: 100/307] 	 train loss: 0.230168 	 lr: 0.00070

val loss: 0.369393 	 acc: 0.887358

[epoch  24: 120/307] 	 train loss: 0.299710 	 lr: 0.00070
[epoch  24: 140/307] 	 train loss: 0.264200 	 lr: 0.00070
[epoch  24: 160/307] 	 train loss: 0.219145 	 lr: 0.00070
[epoch  24: 180/307] 	 train loss: 0.345468 	 lr: 0.00070
[epoch  24: 200/307] 	 train loss: 0.127750 	 lr: 0.00070
[epoch  24: 220/307] 	 train loss: 0.466097 	 lr: 0.00070
[epoch  24: 240/307] 	 train loss: 0.629172 	 lr: 0.00070

val loss: 0.380758 	 acc: 0.884522

[epoch  24: 260/307] 	 train loss: 0.658636 	 lr: 0.00070
[epoch  24: 280/307] 	 train loss: 0.469346 	 lr: 0.00070
[epoch  24: 300/307] 	 train loss: 0.181011 	 lr: 0.00070
[epoch  25:   0/307] 	 train loss: 0.461108 	 lr: 0.00070
[epoch  25:  20/307] 	 train loss: 0.254890 	 lr: 0.00070
[epoch  25:  40/307] 	 train loss: 0.540367 	 lr: 0.00070
[epoch  25:  60/307] 	 train loss: 0.194604 	 lr: 0.00070
[epoch  25:  80/307] 	 train loss: 0.140447 	 lr: 0.00070
[epoch  25: 100/307] 	 train loss: 0.404623 	 lr: 0.00070

val loss: 0.359369 	 acc: 0.888169

[epoch  25: 120/307] 	 train loss: 0.440568 	 lr: 0.00070
[epoch  25: 140/307] 	 train loss: 0.289580 	 lr: 0.00070
[epoch  25: 160/307] 	 train loss: 0.269936 	 lr: 0.00070
[epoch  25: 180/307] 	 train loss: 0.285367 	 lr: 0.00070
[epoch  25: 200/307] 	 train loss: 0.524005 	 lr: 0.00070
[epoch  25: 220/307] 	 train loss: 0.135644 	 lr: 0.00070
[epoch  25: 240/307] 	 train loss: 0.517641 	 lr: 0.00070

val loss: 0.354837 	 acc: 0.881686

[epoch  25: 260/307] 	 train loss: 0.304450 	 lr: 0.00070
[epoch  25: 280/307] 	 train loss: 0.315261 	 lr: 0.00070
[epoch  25: 300/307] 	 train loss: 0.270592 	 lr: 0.00070
[epoch  26:   0/307] 	 train loss: 0.516687 	 lr: 0.00070
[epoch  26:  20/307] 	 train loss: 0.408335 	 lr: 0.00070
[epoch  26:  40/307] 	 train loss: 0.381427 	 lr: 0.00070
[epoch  26:  60/307] 	 train loss: 0.451237 	 lr: 0.00070
[epoch  26:  80/307] 	 train loss: 0.448358 	 lr: 0.00070
[epoch  26: 100/307] 	 train loss: 0.412208 	 lr: 0.00070

val loss: 0.346960 	 acc: 0.886953

[epoch  26: 120/307] 	 train loss: 0.434056 	 lr: 0.00070
[epoch  26: 140/307] 	 train loss: 0.245410 	 lr: 0.00070
[epoch  26: 160/307] 	 train loss: 0.183359 	 lr: 0.00070
[epoch  26: 180/307] 	 train loss: 0.737464 	 lr: 0.00070
[epoch  26: 200/307] 	 train loss: 0.440304 	 lr: 0.00070
[epoch  26: 220/307] 	 train loss: 0.432773 	 lr: 0.00070
[epoch  26: 240/307] 	 train loss: 0.565981 	 lr: 0.00070

val loss: 0.350966 	 acc: 0.889789

[epoch  26: 260/307] 	 train loss: 0.513256 	 lr: 0.00070
[epoch  26: 280/307] 	 train loss: 0.423985 	 lr: 0.00070
[epoch  26: 300/307] 	 train loss: 0.414098 	 lr: 0.00070
[epoch  27:   0/307] 	 train loss: 0.404288 	 lr: 0.00070
[epoch  27:  20/307] 	 train loss: 0.231141 	 lr: 0.00070
[epoch  27:  40/307] 	 train loss: 0.373044 	 lr: 0.00070
[epoch  27:  60/307] 	 train loss: 0.367434 	 lr: 0.00070
[epoch  27:  80/307] 	 train loss: 0.322243 	 lr: 0.00070
[epoch  27: 100/307] 	 train loss: 0.313230 	 lr: 0.00070

val loss: 0.363932 	 acc: 0.876013

[epoch  27: 120/307] 	 train loss: 0.398425 	 lr: 0.00070
[epoch  27: 140/307] 	 train loss: 0.478947 	 lr: 0.00070
[epoch  27: 160/307] 	 train loss: 0.467391 	 lr: 0.00070
[epoch  27: 180/307] 	 train loss: 0.262912 	 lr: 0.00070
[epoch  27: 200/307] 	 train loss: 0.687819 	 lr: 0.00070
[epoch  27: 220/307] 	 train loss: 0.232128 	 lr: 0.00070
[epoch  27: 240/307] 	 train loss: 0.452375 	 lr: 0.00070

val loss: 0.346462 	 acc: 0.893031

[epoch  27: 260/307] 	 train loss: 0.147882 	 lr: 0.00070
[epoch  27: 280/307] 	 train loss: 0.693879 	 lr: 0.00070
[epoch  27: 300/307] 	 train loss: 0.482136 	 lr: 0.00070
[epoch  28:   0/307] 	 train loss: 0.267934 	 lr: 0.00070
[epoch  28:  20/307] 	 train loss: 0.243939 	 lr: 0.00070
[epoch  28:  40/307] 	 train loss: 0.300390 	 lr: 0.00070
[epoch  28:  60/307] 	 train loss: 0.407153 	 lr: 0.00070
[epoch  28:  80/307] 	 train loss: 0.549130 	 lr: 0.00070

val loss: 0.350292 	 acc: 0.889789

[epoch  28: 100/307] 	 train loss: 0.331273 	 lr: 0.00070
[epoch  28: 120/307] 	 train loss: 0.195645 	 lr: 0.00070
[epoch  28: 140/307] 	 train loss: 0.539129 	 lr: 0.00070
[epoch  28: 160/307] 	 train loss: 0.605422 	 lr: 0.00070
[epoch  28: 180/307] 	 train loss: 0.559378 	 lr: 0.00070
[epoch  28: 200/307] 	 train loss: 0.794616 	 lr: 0.00070
[epoch  28: 220/307] 	 train loss: 0.663269 	 lr: 0.00070
[epoch  28: 240/307] 	 train loss: 0.111075 	 lr: 0.00070

val loss: 0.360280 	 acc: 0.884522

[epoch  28: 260/307] 	 train loss: 0.176416 	 lr: 0.00070
[epoch  28: 280/307] 	 train loss: 0.283657 	 lr: 0.00070
[epoch  28: 300/307] 	 train loss: 0.215658 	 lr: 0.00070
[epoch  29:   0/307] 	 train loss: 0.270967 	 lr: 0.00070
[epoch  29:  20/307] 	 train loss: 0.485119 	 lr: 0.00070
[epoch  29:  40/307] 	 train loss: 0.389632 	 lr: 0.00070
[epoch  29:  60/307] 	 train loss: 0.254961 	 lr: 0.00070
[epoch  29:  80/307] 	 train loss: 0.441862 	 lr: 0.00070

val loss: 0.371799 	 acc: 0.883306

[epoch  29: 100/307] 	 train loss: 0.443891 	 lr: 0.00070
[epoch  29: 120/307] 	 train loss: 0.293241 	 lr: 0.00070
[epoch  29: 140/307] 	 train loss: 0.474415 	 lr: 0.00070
[epoch  29: 160/307] 	 train loss: 0.286147 	 lr: 0.00070
[epoch  29: 180/307] 	 train loss: 0.661988 	 lr: 0.00070
[epoch  29: 200/307] 	 train loss: 0.394138 	 lr: 0.00070
[epoch  29: 220/307] 	 train loss: 0.522637 	 lr: 0.00070
[epoch  29: 240/307] 	 train loss: 0.379067 	 lr: 0.00070

val loss: 0.355726 	 acc: 0.891005

[epoch  29: 260/307] 	 train loss: 0.556314 	 lr: 0.00070
[epoch  29: 280/307] 	 train loss: 0.376250 	 lr: 0.00070
[epoch  29: 300/307] 	 train loss: 0.201105 	 lr: 0.00070
[epoch  30:   0/307] 	 train loss: 0.220609 	 lr: 0.00070
[epoch  30:  20/307] 	 train loss: 0.353419 	 lr: 0.00070
[epoch  30:  40/307] 	 train loss: 0.681871 	 lr: 0.00070
[epoch  30:  60/307] 	 train loss: 0.112188 	 lr: 0.00070
[epoch  30:  80/307] 	 train loss: 0.440867 	 lr: 0.00070

val loss: 0.345911 	 acc: 0.888574

[epoch  30: 100/307] 	 train loss: 0.313417 	 lr: 0.00070
[epoch  30: 120/307] 	 train loss: 0.532692 	 lr: 0.00070
[epoch  30: 140/307] 	 train loss: 0.586275 	 lr: 0.00070
[epoch  30: 160/307] 	 train loss: 0.232072 	 lr: 0.00070
[epoch  30: 180/307] 	 train loss: 0.472804 	 lr: 0.00070
[epoch  30: 200/307] 	 train loss: 0.263944 	 lr: 0.00070
[epoch  30: 220/307] 	 train loss: 0.283590 	 lr: 0.00070
[epoch  30: 240/307] 	 train loss: 0.279562 	 lr: 0.00070

val loss: 0.361402 	 acc: 0.884927

[epoch  30: 260/307] 	 train loss: 0.401062 	 lr: 0.00070
[epoch  30: 280/307] 	 train loss: 0.442967 	 lr: 0.00070
[epoch  30: 300/307] 	 train loss: 0.460652 	 lr: 0.00070
[epoch  31:   0/307] 	 train loss: 0.313035 	 lr: 0.00070
[epoch  31:  20/307] 	 train loss: 0.505962 	 lr: 0.00070
[epoch  31:  40/307] 	 train loss: 0.470939 	 lr: 0.00070
[epoch  31:  60/307] 	 train loss: 0.343196 	 lr: 0.00070
[epoch  31:  80/307] 	 train loss: 0.261194 	 lr: 0.00070

val loss: 0.366293 	 acc: 0.895867

[epoch  31: 100/307] 	 train loss: 0.187378 	 lr: 0.00070
[epoch  31: 120/307] 	 train loss: 0.281664 	 lr: 0.00070
[epoch  31: 140/307] 	 train loss: 0.452187 	 lr: 0.00070
[epoch  31: 160/307] 	 train loss: 0.444603 	 lr: 0.00070
[epoch  31: 180/307] 	 train loss: 0.302171 	 lr: 0.00070
[epoch  31: 200/307] 	 train loss: 0.269494 	 lr: 0.00070
[epoch  31: 220/307] 	 train loss: 0.345701 	 lr: 0.00070
[epoch  31: 240/307] 	 train loss: 0.287371 	 lr: 0.00070

val loss: 0.359967 	 acc: 0.887358

[epoch  31: 260/307] 	 train loss: 0.443232 	 lr: 0.00070
[epoch  31: 280/307] 	 train loss: 0.268343 	 lr: 0.00070
[epoch  31: 300/307] 	 train loss: 0.112869 	 lr: 0.00070
[epoch  32:   0/307] 	 train loss: 0.463433 	 lr: 0.00070
[epoch  32:  20/307] 	 train loss: 0.210244 	 lr: 0.00070
[epoch  32:  40/307] 	 train loss: 0.534972 	 lr: 0.00070
[epoch  32:  60/307] 	 train loss: 0.262588 	 lr: 0.00070
[epoch  32:  80/307] 	 train loss: 0.282134 	 lr: 0.00070

val loss: 0.355286 	 acc: 0.883712

[epoch  32: 100/307] 	 train loss: 0.260785 	 lr: 0.00070
[epoch  32: 120/307] 	 train loss: 0.666213 	 lr: 0.00070
[epoch  32: 140/307] 	 train loss: 0.290407 	 lr: 0.00070
[epoch  32: 160/307] 	 train loss: 0.716743 	 lr: 0.00070
[epoch  32: 180/307] 	 train loss: 0.365289 	 lr: 0.00070
[epoch  32: 200/307] 	 train loss: 0.288123 	 lr: 0.00070
[epoch  32: 220/307] 	 train loss: 0.537299 	 lr: 0.00070
[epoch  32: 240/307] 	 train loss: 0.270587 	 lr: 0.00070

val loss: 0.347088 	 acc: 0.886953

[epoch  32: 260/307] 	 train loss: 0.308886 	 lr: 0.00070
[epoch  32: 280/307] 	 train loss: 0.568303 	 lr: 0.00070
[epoch  32: 300/307] 	 train loss: 0.288403 	 lr: 0.00070
[epoch  33:   0/307] 	 train loss: 0.313828 	 lr: 0.00070
[epoch  33:  20/307] 	 train loss: 0.336209 	 lr: 0.00070
[epoch  33:  40/307] 	 train loss: 0.296420 	 lr: 0.00070
[epoch  33:  60/307] 	 train loss: 0.319739 	 lr: 0.00070
[epoch  33:  80/307] 	 train loss: 0.188868 	 lr: 0.00070

val loss: 0.353167 	 acc: 0.887763

[epoch  33: 100/307] 	 train loss: 0.346031 	 lr: 0.00070
[epoch  33: 120/307] 	 train loss: 0.675980 	 lr: 0.00070
[epoch  33: 140/307] 	 train loss: 0.817277 	 lr: 0.00070
[epoch  33: 160/307] 	 train loss: 0.702731 	 lr: 0.00070
[epoch  33: 180/307] 	 train loss: 0.288917 	 lr: 0.00070
[epoch  33: 200/307] 	 train loss: 0.327237 	 lr: 0.00070
[epoch  33: 220/307] 	 train loss: 0.135755 	 lr: 0.00070
[epoch  33: 240/307] 	 train loss: 0.624538 	 lr: 0.00070

val loss: 0.356178 	 acc: 0.894246

[epoch  33: 260/307] 	 train loss: 0.347581 	 lr: 0.00070
[epoch  33: 280/307] 	 train loss: 0.353560 	 lr: 0.00070
[epoch  33: 300/307] 	 train loss: 0.163940 	 lr: 0.00070
[epoch  34:   0/307] 	 train loss: 0.235601 	 lr: 0.00070
[epoch  34:  20/307] 	 train loss: 0.394202 	 lr: 0.00070
[epoch  34:  40/307] 	 train loss: 0.193572 	 lr: 0.00070
[epoch  34:  60/307] 	 train loss: 0.285308 	 lr: 0.00070
[epoch  34:  80/307] 	 train loss: 0.356017 	 lr: 0.00070

val loss: 0.362562 	 acc: 0.892220

[epoch  34: 100/307] 	 train loss: 0.394337 	 lr: 0.00070
[epoch  34: 120/307] 	 train loss: 0.265006 	 lr: 0.00070
[epoch  34: 140/307] 	 train loss: 0.241923 	 lr: 0.00070
[epoch  34: 160/307] 	 train loss: 0.443707 	 lr: 0.00070
[epoch  34: 180/307] 	 train loss: 0.573827 	 lr: 0.00070
[epoch  34: 200/307] 	 train loss: 0.093492 	 lr: 0.00070
[epoch  34: 220/307] 	 train loss: 0.707361 	 lr: 0.00070

val loss: 0.348543 	 acc: 0.896272

[epoch  34: 240/307] 	 train loss: 0.718040 	 lr: 0.00070
[epoch  34: 260/307] 	 train loss: 0.094005 	 lr: 0.00070
[epoch  34: 280/307] 	 train loss: 0.576757 	 lr: 0.00070
[epoch  34: 300/307] 	 train loss: 0.339178 	 lr: 0.00070
[epoch  35:   0/307] 	 train loss: 0.574896 	 lr: 0.00070
[epoch  35:  20/307] 	 train loss: 0.214441 	 lr: 0.00070
[epoch  35:  40/307] 	 train loss: 0.457959 	 lr: 0.00070
[epoch  35:  60/307] 	 train loss: 0.381442 	 lr: 0.00070
[epoch  35:  80/307] 	 train loss: 0.213620 	 lr: 0.00070

val loss: 0.383945 	 acc: 0.886143

[epoch  35: 100/307] 	 train loss: 0.286960 	 lr: 0.00070
[epoch  35: 120/307] 	 train loss: 0.181539 	 lr: 0.00070
[epoch  35: 140/307] 	 train loss: 0.247799 	 lr: 0.00070
[epoch  35: 160/307] 	 train loss: 0.431152 	 lr: 0.00070
[epoch  35: 180/307] 	 train loss: 0.195889 	 lr: 0.00070
[epoch  35: 200/307] 	 train loss: 0.292304 	 lr: 0.00070
[epoch  35: 220/307] 	 train loss: 0.205984 	 lr: 0.00070

val loss: 0.359508 	 acc: 0.886953

[epoch  35: 240/307] 	 train loss: 0.247439 	 lr: 0.00070
[epoch  35: 260/307] 	 train loss: 0.182522 	 lr: 0.00070
[epoch  35: 280/307] 	 train loss: 0.601840 	 lr: 0.00070
[epoch  35: 300/307] 	 train loss: 0.147412 	 lr: 0.00070
[epoch  36:   0/307] 	 train loss: 0.125072 	 lr: 0.00070
[epoch  36:  20/307] 	 train loss: 0.495981 	 lr: 0.00070
[epoch  36:  40/307] 	 train loss: 0.422761 	 lr: 0.00070
[epoch  36:  60/307] 	 train loss: 0.480831 	 lr: 0.00070
[epoch  36:  80/307] 	 train loss: 0.341880 	 lr: 0.00070

val loss: 0.340298 	 acc: 0.890600

[epoch  36: 100/307] 	 train loss: 0.303129 	 lr: 0.00070
[epoch  36: 120/307] 	 train loss: 0.301228 	 lr: 0.00070
[epoch  36: 140/307] 	 train loss: 0.297473 	 lr: 0.00070
[epoch  36: 160/307] 	 train loss: 0.374963 	 lr: 0.00070
[epoch  36: 180/307] 	 train loss: 0.370597 	 lr: 0.00070
[epoch  36: 200/307] 	 train loss: 0.423257 	 lr: 0.00070
[epoch  36: 220/307] 	 train loss: 0.129433 	 lr: 0.00070

val loss: 0.352344 	 acc: 0.896677

[epoch  36: 240/307] 	 train loss: 0.313209 	 lr: 0.00070
[epoch  36: 260/307] 	 train loss: 0.483760 	 lr: 0.00070
[epoch  36: 280/307] 	 train loss: 0.546966 	 lr: 0.00070
[epoch  36: 300/307] 	 train loss: 0.327927 	 lr: 0.00070
[epoch  37:   0/307] 	 train loss: 0.422396 	 lr: 0.00070
[epoch  37:  20/307] 	 train loss: 0.167651 	 lr: 0.00070
[epoch  37:  40/307] 	 train loss: 0.359210 	 lr: 0.00070
[epoch  37:  60/307] 	 train loss: 0.768593 	 lr: 0.00070
[epoch  37:  80/307] 	 train loss: 0.538529 	 lr: 0.00070

val loss: 0.345928 	 acc: 0.897893

[epoch  37: 100/307] 	 train loss: 0.416423 	 lr: 0.00070
[epoch  37: 120/307] 	 train loss: 0.252049 	 lr: 0.00070
[epoch  37: 140/307] 	 train loss: 0.408570 	 lr: 0.00070
[epoch  37: 160/307] 	 train loss: 0.464427 	 lr: 0.00070
[epoch  37: 180/307] 	 train loss: 0.188604 	 lr: 0.00070
[epoch  37: 200/307] 	 train loss: 0.317317 	 lr: 0.00070
[epoch  37: 220/307] 	 train loss: 0.315590 	 lr: 0.00070

val loss: 0.344481 	 acc: 0.889384

[epoch  37: 240/307] 	 train loss: 0.214145 	 lr: 0.00070
[epoch  37: 260/307] 	 train loss: 0.147095 	 lr: 0.00070
[epoch  37: 280/307] 	 train loss: 0.331093 	 lr: 0.00070
[epoch  37: 300/307] 	 train loss: 0.298198 	 lr: 0.00070
[epoch  38:   0/307] 	 train loss: 0.439441 	 lr: 0.00070
[epoch  38:  20/307] 	 train loss: 0.374218 	 lr: 0.00070
[epoch  38:  40/307] 	 train loss: 0.192418 	 lr: 0.00070
[epoch  38:  60/307] 	 train loss: 0.355440 	 lr: 0.00070

val loss: 0.339137 	 acc: 0.895462

[epoch  38:  80/307] 	 train loss: 0.209302 	 lr: 0.00070
[epoch  38: 100/307] 	 train loss: 0.087549 	 lr: 0.00070
[epoch  38: 120/307] 	 train loss: 0.203335 	 lr: 0.00070
[epoch  38: 140/307] 	 train loss: 0.272784 	 lr: 0.00070
[epoch  38: 160/307] 	 train loss: 0.348365 	 lr: 0.00070
[epoch  38: 180/307] 	 train loss: 0.478318 	 lr: 0.00070
[epoch  38: 200/307] 	 train loss: 0.193242 	 lr: 0.00070
[epoch  38: 220/307] 	 train loss: 0.290548 	 lr: 0.00070

val loss: 0.352487 	 acc: 0.883712

[epoch  38: 240/307] 	 train loss: 0.419800 	 lr: 0.00070
[epoch  38: 260/307] 	 train loss: 0.200722 	 lr: 0.00070
[epoch  38: 280/307] 	 train loss: 0.150110 	 lr: 0.00070
[epoch  38: 300/307] 	 train loss: 0.406669 	 lr: 0.00070
[epoch  39:   0/307] 	 train loss: 0.303385 	 lr: 0.00070
[epoch  39:  20/307] 	 train loss: 0.122373 	 lr: 0.00070
[epoch  39:  40/307] 	 train loss: 0.364773 	 lr: 0.00070
[epoch  39:  60/307] 	 train loss: 0.460150 	 lr: 0.00070

val loss: 0.366253 	 acc: 0.884117

[epoch  39:  80/307] 	 train loss: 0.342738 	 lr: 0.00070
[epoch  39: 100/307] 	 train loss: 0.637804 	 lr: 0.00070
[epoch  39: 120/307] 	 train loss: 0.341461 	 lr: 0.00070
[epoch  39: 140/307] 	 train loss: 0.385420 	 lr: 0.00070
[epoch  39: 160/307] 	 train loss: 0.607048 	 lr: 0.00070
[epoch  39: 180/307] 	 train loss: 0.535552 	 lr: 0.00070
[epoch  39: 200/307] 	 train loss: 0.296362 	 lr: 0.00070
[epoch  39: 220/307] 	 train loss: 0.395907 	 lr: 0.00070

val loss: 0.348449 	 acc: 0.888169

[epoch  39: 240/307] 	 train loss: 0.569976 	 lr: 0.00070
[epoch  39: 260/307] 	 train loss: 0.292485 	 lr: 0.00070
[epoch  39: 280/307] 	 train loss: 0.316007 	 lr: 0.00070
[epoch  39: 300/307] 	 train loss: 0.569358 	 lr: 0.00070
[epoch  40:   0/307] 	 train loss: 0.246122 	 lr: 0.00070
[epoch  40:  20/307] 	 train loss: 0.225045 	 lr: 0.00070
[epoch  40:  40/307] 	 train loss: 0.334811 	 lr: 0.00070
[epoch  40:  60/307] 	 train loss: 0.173467 	 lr: 0.00070

val loss: 0.327312 	 acc: 0.897083

[epoch  40:  80/307] 	 train loss: 0.398300 	 lr: 0.00070
[epoch  40: 100/307] 	 train loss: 0.266028 	 lr: 0.00070
[epoch  40: 120/307] 	 train loss: 0.373123 	 lr: 0.00070
[epoch  40: 140/307] 	 train loss: 0.324450 	 lr: 0.00070
[epoch  40: 160/307] 	 train loss: 0.507516 	 lr: 0.00070
[epoch  40: 180/307] 	 train loss: 0.403198 	 lr: 0.00070
[epoch  40: 200/307] 	 train loss: 0.549910 	 lr: 0.00070
[epoch  40: 220/307] 	 train loss: 0.255442 	 lr: 0.00070

val loss: 0.342895 	 acc: 0.887763

[epoch  40: 240/307] 	 train loss: 0.113101 	 lr: 0.00070
[epoch  40: 260/307] 	 train loss: 0.212018 	 lr: 0.00070
[epoch  40: 280/307] 	 train loss: 0.277965 	 lr: 0.00070
[epoch  40: 300/307] 	 train loss: 0.264640 	 lr: 0.00070
[epoch  41:   0/307] 	 train loss: 0.260630 	 lr: 0.00070
[epoch  41:  20/307] 	 train loss: 0.354146 	 lr: 0.00070
[epoch  41:  40/307] 	 train loss: 0.177240 	 lr: 0.00070
[epoch  41:  60/307] 	 train loss: 0.331373 	 lr: 0.00070

val loss: 0.337052 	 acc: 0.897893

[epoch  41:  80/307] 	 train loss: 0.225100 	 lr: 0.00070
[epoch  41: 100/307] 	 train loss: 0.161518 	 lr: 0.00070
[epoch  41: 120/307] 	 train loss: 0.386212 	 lr: 0.00070
[epoch  41: 140/307] 	 train loss: 0.614369 	 lr: 0.00070
[epoch  41: 160/307] 	 train loss: 0.180010 	 lr: 0.00070
[epoch  41: 180/307] 	 train loss: 0.382170 	 lr: 0.00070
[epoch  41: 200/307] 	 train loss: 0.638115 	 lr: 0.00070
[epoch  41: 220/307] 	 train loss: 0.386680 	 lr: 0.00070

val loss: 0.358250 	 acc: 0.891005

[epoch  41: 240/307] 	 train loss: 0.528503 	 lr: 0.00070
[epoch  41: 260/307] 	 train loss: 0.371130 	 lr: 0.00070
[epoch  41: 280/307] 	 train loss: 0.244764 	 lr: 0.00070
[epoch  41: 300/307] 	 train loss: 0.956268 	 lr: 0.00070
[epoch  42:   0/307] 	 train loss: 0.364768 	 lr: 0.00070
[epoch  42:  20/307] 	 train loss: 0.201178 	 lr: 0.00070
[epoch  42:  40/307] 	 train loss: 0.318858 	 lr: 0.00070
[epoch  42:  60/307] 	 train loss: 0.176435 	 lr: 0.00070

val loss: 0.320112 	 acc: 0.899919

[epoch  42:  80/307] 	 train loss: 0.364672 	 lr: 0.00070
[epoch  42: 100/307] 	 train loss: 0.476200 	 lr: 0.00070
[epoch  42: 120/307] 	 train loss: 0.177916 	 lr: 0.00070
[epoch  42: 140/307] 	 train loss: 0.179487 	 lr: 0.00070
[epoch  42: 160/307] 	 train loss: 0.258470 	 lr: 0.00070
[epoch  42: 180/307] 	 train loss: 0.185710 	 lr: 0.00070
[epoch  42: 200/307] 	 train loss: 0.193962 	 lr: 0.00070
[epoch  42: 220/307] 	 train loss: 0.312454 	 lr: 0.00070

val loss: 0.347406 	 acc: 0.894246

[epoch  42: 240/307] 	 train loss: 0.209253 	 lr: 0.00070
[epoch  42: 260/307] 	 train loss: 0.280864 	 lr: 0.00070
[epoch  42: 280/307] 	 train loss: 0.435976 	 lr: 0.00070
[epoch  42: 300/307] 	 train loss: 0.552658 	 lr: 0.00070
[epoch  43:   0/307] 	 train loss: 0.340986 	 lr: 0.00049
[epoch  43:  20/307] 	 train loss: 0.300373 	 lr: 0.00049
[epoch  43:  40/307] 	 train loss: 0.418990 	 lr: 0.00049
[epoch  43:  60/307] 	 train loss: 0.157834 	 lr: 0.00049

val loss: 0.337367 	 acc: 0.888169

[epoch  43:  80/307] 	 train loss: 0.261439 	 lr: 0.00049
[epoch  43: 100/307] 	 train loss: 0.248917 	 lr: 0.00049
[epoch  43: 120/307] 	 train loss: 0.543767 	 lr: 0.00049
[epoch  43: 140/307] 	 train loss: 0.443060 	 lr: 0.00049
[epoch  43: 160/307] 	 train loss: 0.590781 	 lr: 0.00049
[epoch  43: 180/307] 	 train loss: 0.435650 	 lr: 0.00049
[epoch  43: 200/307] 	 train loss: 0.218946 	 lr: 0.00049
[epoch  43: 220/307] 	 train loss: 0.447784 	 lr: 0.00049

val loss: 0.342317 	 acc: 0.897893

[epoch  43: 240/307] 	 train loss: 0.277019 	 lr: 0.00049
[epoch  43: 260/307] 	 train loss: 0.401133 	 lr: 0.00049
[epoch  43: 280/307] 	 train loss: 0.179279 	 lr: 0.00049
[epoch  43: 300/307] 	 train loss: 0.268758 	 lr: 0.00049
[epoch  44:   0/307] 	 train loss: 0.630891 	 lr: 0.00049
[epoch  44:  20/307] 	 train loss: 0.298439 	 lr: 0.00049
[epoch  44:  40/307] 	 train loss: 0.223044 	 lr: 0.00049
[epoch  44:  60/307] 	 train loss: 0.317078 	 lr: 0.00049

val loss: 0.304108 	 acc: 0.902755

[epoch  44:  80/307] 	 train loss: 0.377491 	 lr: 0.00049
[epoch  44: 100/307] 	 train loss: 0.425106 	 lr: 0.00049
[epoch  44: 120/307] 	 train loss: 0.208823 	 lr: 0.00049
[epoch  44: 140/307] 	 train loss: 0.276733 	 lr: 0.00049
[epoch  44: 160/307] 	 train loss: 0.277352 	 lr: 0.00049
[epoch  44: 180/307] 	 train loss: 0.500466 	 lr: 0.00049
[epoch  44: 200/307] 	 train loss: 0.226827 	 lr: 0.00049

val loss: 0.322076 	 acc: 0.903160

[epoch  44: 220/307] 	 train loss: 0.415421 	 lr: 0.00049
[epoch  44: 240/307] 	 train loss: 0.528118 	 lr: 0.00049
[epoch  44: 260/307] 	 train loss: 0.495951 	 lr: 0.00049
[epoch  44: 280/307] 	 train loss: 0.362435 	 lr: 0.00049
[epoch  44: 300/307] 	 train loss: 0.461917 	 lr: 0.00049
[epoch  45:   0/307] 	 train loss: 0.179876 	 lr: 0.00049
[epoch  45:  20/307] 	 train loss: 0.306795 	 lr: 0.00049
[epoch  45:  40/307] 	 train loss: 0.104075 	 lr: 0.00049
[epoch  45:  60/307] 	 train loss: 0.394950 	 lr: 0.00049

val loss: 0.321516 	 acc: 0.903566

[epoch  45:  80/307] 	 train loss: 0.632381 	 lr: 0.00049
[epoch  45: 100/307] 	 train loss: 0.342360 	 lr: 0.00049
[epoch  45: 120/307] 	 train loss: 0.375340 	 lr: 0.00049
[epoch  45: 140/307] 	 train loss: 0.226337 	 lr: 0.00049
[epoch  45: 160/307] 	 train loss: 0.217512 	 lr: 0.00049
[epoch  45: 180/307] 	 train loss: 0.153065 	 lr: 0.00049
[epoch  45: 200/307] 	 train loss: 0.411657 	 lr: 0.00049

val loss: 0.342617 	 acc: 0.898703

[epoch  45: 220/307] 	 train loss: 0.513431 	 lr: 0.00049
[epoch  45: 240/307] 	 train loss: 0.356937 	 lr: 0.00049
[epoch  45: 260/307] 	 train loss: 0.248349 	 lr: 0.00049
[epoch  45: 280/307] 	 train loss: 0.142711 	 lr: 0.00049
[epoch  45: 300/307] 	 train loss: 0.455137 	 lr: 0.00049
[epoch  46:   0/307] 	 train loss: 0.141288 	 lr: 0.00049
[epoch  46:  20/307] 	 train loss: 0.451819 	 lr: 0.00049
[epoch  46:  40/307] 	 train loss: 0.528118 	 lr: 0.00049
[epoch  46:  60/307] 	 train loss: 0.232398 	 lr: 0.00049

val loss: 0.335191 	 acc: 0.899109

[epoch  46:  80/307] 	 train loss: 0.335783 	 lr: 0.00049
[epoch  46: 100/307] 	 train loss: 0.327688 	 lr: 0.00049
[epoch  46: 120/307] 	 train loss: 0.326260 	 lr: 0.00049
[epoch  46: 140/307] 	 train loss: 0.334707 	 lr: 0.00049
[epoch  46: 160/307] 	 train loss: 0.608904 	 lr: 0.00049
[epoch  46: 180/307] 	 train loss: 0.289334 	 lr: 0.00049
[epoch  46: 200/307] 	 train loss: 0.521225 	 lr: 0.00049

val loss: 0.326236 	 acc: 0.905592

[epoch  46: 220/307] 	 train loss: 0.337336 	 lr: 0.00049
[epoch  46: 240/307] 	 train loss: 0.244164 	 lr: 0.00049
[epoch  46: 260/307] 	 train loss: 0.119284 	 lr: 0.00049
[epoch  46: 280/307] 	 train loss: 0.316212 	 lr: 0.00049
[epoch  46: 300/307] 	 train loss: 0.263093 	 lr: 0.00049
[epoch  47:   0/307] 	 train loss: 0.290868 	 lr: 0.00049
[epoch  47:  20/307] 	 train loss: 0.227826 	 lr: 0.00049
[epoch  47:  40/307] 	 train loss: 0.193700 	 lr: 0.00049
[epoch  47:  60/307] 	 train loss: 0.211781 	 lr: 0.00049

val loss: 0.327568 	 acc: 0.899514

[epoch  47:  80/307] 	 train loss: 0.338419 	 lr: 0.00049
[epoch  47: 100/307] 	 train loss: 0.387864 	 lr: 0.00049
[epoch  47: 120/307] 	 train loss: 0.525079 	 lr: 0.00049
[epoch  47: 140/307] 	 train loss: 0.577759 	 lr: 0.00049
[epoch  47: 160/307] 	 train loss: 0.230427 	 lr: 0.00049
[epoch  47: 180/307] 	 train loss: 0.300188 	 lr: 0.00049
[epoch  47: 200/307] 	 train loss: 0.175304 	 lr: 0.00049

val loss: 0.328804 	 acc: 0.907212

[epoch  47: 220/307] 	 train loss: 0.334466 	 lr: 0.00049
[epoch  47: 240/307] 	 train loss: 0.041971 	 lr: 0.00049
[epoch  47: 260/307] 	 train loss: 0.171351 	 lr: 0.00049
[epoch  47: 280/307] 	 train loss: 0.577066 	 lr: 0.00049
[epoch  47: 300/307] 	 train loss: 0.628399 	 lr: 0.00049
[epoch  48:   0/307] 	 train loss: 0.293376 	 lr: 0.00049
[epoch  48:  20/307] 	 train loss: 0.142604 	 lr: 0.00049
[epoch  48:  40/307] 	 train loss: 0.685576 	 lr: 0.00049

val loss: 0.324944 	 acc: 0.899919

[epoch  48:  60/307] 	 train loss: 0.478520 	 lr: 0.00049
[epoch  48:  80/307] 	 train loss: 0.343780 	 lr: 0.00049
[epoch  48: 100/307] 	 train loss: 0.182854 	 lr: 0.00049
[epoch  48: 120/307] 	 train loss: 0.253304 	 lr: 0.00049
[epoch  48: 140/307] 	 train loss: 0.109351 	 lr: 0.00049
[epoch  48: 160/307] 	 train loss: 0.206886 	 lr: 0.00049
[epoch  48: 180/307] 	 train loss: 0.257673 	 lr: 0.00049
[epoch  48: 200/307] 	 train loss: 0.254549 	 lr: 0.00049

val loss: 0.343700 	 acc: 0.902755

[epoch  48: 220/307] 	 train loss: 0.516569 	 lr: 0.00049
[epoch  48: 240/307] 	 train loss: 0.375039 	 lr: 0.00049
[epoch  48: 260/307] 	 train loss: 0.352570 	 lr: 0.00049
[epoch  48: 280/307] 	 train loss: 0.171886 	 lr: 0.00049
[epoch  48: 300/307] 	 train loss: 0.346233 	 lr: 0.00049
[epoch  49:   0/307] 	 train loss: 0.246052 	 lr: 0.00049
[epoch  49:  20/307] 	 train loss: 0.478091 	 lr: 0.00049
[epoch  49:  40/307] 	 train loss: 0.396685 	 lr: 0.00049

val loss: 0.313942 	 acc: 0.902350

[epoch  49:  60/307] 	 train loss: 0.128260 	 lr: 0.00049
[epoch  49:  80/307] 	 train loss: 0.209142 	 lr: 0.00049
[epoch  49: 100/307] 	 train loss: 0.120638 	 lr: 0.00049
[epoch  49: 120/307] 	 train loss: 0.110040 	 lr: 0.00049
[epoch  49: 140/307] 	 train loss: 0.406598 	 lr: 0.00049
[epoch  49: 160/307] 	 train loss: 0.147107 	 lr: 0.00049
[epoch  49: 180/307] 	 train loss: 0.297026 	 lr: 0.00049
[epoch  49: 200/307] 	 train loss: 0.242897 	 lr: 0.00049

val loss: 0.341312 	 acc: 0.897893

[epoch  49: 220/307] 	 train loss: 0.142352 	 lr: 0.00049
[epoch  49: 240/307] 	 train loss: 0.359294 	 lr: 0.00049
[epoch  49: 260/307] 	 train loss: 0.424800 	 lr: 0.00049
[epoch  49: 280/307] 	 train loss: 0.309464 	 lr: 0.00049
[epoch  49: 300/307] 	 train loss: 0.196924 	 lr: 0.00049
[epoch  50:   0/307] 	 train loss: 0.229070 	 lr: 0.00049
[epoch  50:  20/307] 	 train loss: 0.384262 	 lr: 0.00049
[epoch  50:  40/307] 	 train loss: 0.260745 	 lr: 0.00049

val loss: 0.341084 	 acc: 0.901540

[epoch  50:  60/307] 	 train loss: 0.365268 	 lr: 0.00049
[epoch  50:  80/307] 	 train loss: 0.192302 	 lr: 0.00049
[epoch  50: 100/307] 	 train loss: 0.142431 	 lr: 0.00049
[epoch  50: 120/307] 	 train loss: 0.500335 	 lr: 0.00049
[epoch  50: 140/307] 	 train loss: 0.208464 	 lr: 0.00049
[epoch  50: 160/307] 	 train loss: 0.204557 	 lr: 0.00049
[epoch  50: 180/307] 	 train loss: 0.344516 	 lr: 0.00049
[epoch  50: 200/307] 	 train loss: 0.416130 	 lr: 0.00049

val loss: 0.325016 	 acc: 0.898703

[epoch  50: 220/307] 	 train loss: 0.358881 	 lr: 0.00049
[epoch  50: 240/307] 	 train loss: 0.600492 	 lr: 0.00049
[epoch  50: 260/307] 	 train loss: 0.374678 	 lr: 0.00049
[epoch  50: 280/307] 	 train loss: 0.185875 	 lr: 0.00049
[epoch  50: 300/307] 	 train loss: 0.182518 	 lr: 0.00049
[epoch  51:   0/307] 	 train loss: 0.175440 	 lr: 0.00049
[epoch  51:  20/307] 	 train loss: 0.178071 	 lr: 0.00049
[epoch  51:  40/307] 	 train loss: 0.112190 	 lr: 0.00049

val loss: 0.352661 	 acc: 0.897893

[epoch  51:  60/307] 	 train loss: 0.205671 	 lr: 0.00049
[epoch  51:  80/307] 	 train loss: 0.500308 	 lr: 0.00049
[epoch  51: 100/307] 	 train loss: 0.264543 	 lr: 0.00049
[epoch  51: 120/307] 	 train loss: 0.419738 	 lr: 0.00049
[epoch  51: 140/307] 	 train loss: 0.305458 	 lr: 0.00049
[epoch  51: 160/307] 	 train loss: 0.146351 	 lr: 0.00049
[epoch  51: 180/307] 	 train loss: 0.299002 	 lr: 0.00049
[epoch  51: 200/307] 	 train loss: 0.550320 	 lr: 0.00049

val loss: 0.337214 	 acc: 0.897488

[epoch  51: 220/307] 	 train loss: 0.491287 	 lr: 0.00049
[epoch  51: 240/307] 	 train loss: 0.133276 	 lr: 0.00049
[epoch  51: 260/307] 	 train loss: 0.267231 	 lr: 0.00049
[epoch  51: 280/307] 	 train loss: 0.473657 	 lr: 0.00049
[epoch  51: 300/307] 	 train loss: 0.238226 	 lr: 0.00049
[epoch  52:   0/307] 	 train loss: 0.178906 	 lr: 0.00049
[epoch  52:  20/307] 	 train loss: 0.293465 	 lr: 0.00049
[epoch  52:  40/307] 	 train loss: 0.088448 	 lr: 0.00049

val loss: 0.318764 	 acc: 0.902350

[epoch  52:  60/307] 	 train loss: 0.357262 	 lr: 0.00049
[epoch  52:  80/307] 	 train loss: 0.324766 	 lr: 0.00049
[epoch  52: 100/307] 	 train loss: 0.180288 	 lr: 0.00049
[epoch  52: 120/307] 	 train loss: 0.117542 	 lr: 0.00049
[epoch  52: 140/307] 	 train loss: 0.575061 	 lr: 0.00049
[epoch  52: 160/307] 	 train loss: 0.204266 	 lr: 0.00049
[epoch  52: 180/307] 	 train loss: 0.331400 	 lr: 0.00049
[epoch  52: 200/307] 	 train loss: 0.326708 	 lr: 0.00049

val loss: 0.332867 	 acc: 0.905592

[epoch  52: 220/307] 	 train loss: 0.120679 	 lr: 0.00049
[epoch  52: 240/307] 	 train loss: 0.269847 	 lr: 0.00049
[epoch  52: 260/307] 	 train loss: 0.340044 	 lr: 0.00049
[epoch  52: 280/307] 	 train loss: 0.275128 	 lr: 0.00049
[epoch  52: 300/307] 	 train loss: 0.166976 	 lr: 0.00049
[epoch  53:   0/307] 	 train loss: 0.372898 	 lr: 0.00049
[epoch  53:  20/307] 	 train loss: 0.323642 	 lr: 0.00049
[epoch  53:  40/307] 	 train loss: 0.446245 	 lr: 0.00049

val loss: 0.363289 	 acc: 0.894246

[epoch  53:  60/307] 	 train loss: 0.341242 	 lr: 0.00049
[epoch  53:  80/307] 	 train loss: 0.178256 	 lr: 0.00049
[epoch  53: 100/307] 	 train loss: 0.340131 	 lr: 0.00049
[epoch  53: 120/307] 	 train loss: 0.291574 	 lr: 0.00049
[epoch  53: 140/307] 	 train loss: 0.094822 	 lr: 0.00049
[epoch  53: 160/307] 	 train loss: 0.493209 	 lr: 0.00049
[epoch  53: 180/307] 	 train loss: 0.298421 	 lr: 0.00049
[epoch  53: 200/307] 	 train loss: 0.327069 	 lr: 0.00049

val loss: 0.333841 	 acc: 0.898298

[epoch  53: 220/307] 	 train loss: 0.293971 	 lr: 0.00049
[epoch  53: 240/307] 	 train loss: 0.141063 	 lr: 0.00049
[epoch  53: 260/307] 	 train loss: 0.108821 	 lr: 0.00049
[epoch  53: 280/307] 	 train loss: 0.244728 	 lr: 0.00049
[epoch  53: 300/307] 	 train loss: 0.062362 	 lr: 0.00049
[epoch  54:   0/307] 	 train loss: 0.378529 	 lr: 0.00049
[epoch  54:  20/307] 	 train loss: 0.205702 	 lr: 0.00049
[epoch  54:  40/307] 	 train loss: 0.465685 	 lr: 0.00049

val loss: 0.324314 	 acc: 0.904781

[epoch  54:  60/307] 	 train loss: 0.353547 	 lr: 0.00049
[epoch  54:  80/307] 	 train loss: 0.065393 	 lr: 0.00049
[epoch  54: 100/307] 	 train loss: 0.168147 	 lr: 0.00049
[epoch  54: 120/307] 	 train loss: 0.620542 	 lr: 0.00049
[epoch  54: 140/307] 	 train loss: 0.315208 	 lr: 0.00049
[epoch  54: 160/307] 	 train loss: 0.382274 	 lr: 0.00049
[epoch  54: 180/307] 	 train loss: 0.241782 	 lr: 0.00049

val loss: 0.332488 	 acc: 0.895462

[epoch  54: 200/307] 	 train loss: 0.132328 	 lr: 0.00049
[epoch  54: 220/307] 	 train loss: 0.176317 	 lr: 0.00049
[epoch  54: 240/307] 	 train loss: 0.076436 	 lr: 0.00049
[epoch  54: 260/307] 	 train loss: 0.332813 	 lr: 0.00049
[epoch  54: 280/307] 	 train loss: 0.267683 	 lr: 0.00049
[epoch  54: 300/307] 	 train loss: 0.400670 	 lr: 0.00049
[epoch  55:   0/307] 	 train loss: 0.523214 	 lr: 0.00049
[epoch  55:  20/307] 	 train loss: 0.304832 	 lr: 0.00049
[epoch  55:  40/307] 	 train loss: 0.263188 	 lr: 0.00049

val loss: 0.336744 	 acc: 0.900324

[epoch  55:  60/307] 	 train loss: 0.298985 	 lr: 0.00049
[epoch  55:  80/307] 	 train loss: 0.470711 	 lr: 0.00049
[epoch  55: 100/307] 	 train loss: 0.368365 	 lr: 0.00049
[epoch  55: 120/307] 	 train loss: 0.274720 	 lr: 0.00049
[epoch  55: 140/307] 	 train loss: 0.294642 	 lr: 0.00049
[epoch  55: 160/307] 	 train loss: 0.147964 	 lr: 0.00049
[epoch  55: 180/307] 	 train loss: 0.098976 	 lr: 0.00049

val loss: 0.312747 	 acc: 0.907212

[epoch  55: 200/307] 	 train loss: 0.285737 	 lr: 0.00049
[epoch  55: 220/307] 	 train loss: 0.276240 	 lr: 0.00049
[epoch  55: 240/307] 	 train loss: 0.122857 	 lr: 0.00049
[epoch  55: 260/307] 	 train loss: 0.298562 	 lr: 0.00049
[epoch  55: 280/307] 	 train loss: 0.559450 	 lr: 0.00049
[epoch  55: 300/307] 	 train loss: 0.453557 	 lr: 0.00049
[epoch  56:   0/307] 	 train loss: 0.316918 	 lr: 0.00049
[epoch  56:  20/307] 	 train loss: 0.211502 	 lr: 0.00049
[epoch  56:  40/307] 	 train loss: 0.138421 	 lr: 0.00049

val loss: 0.332205 	 acc: 0.895867

[epoch  56:  60/307] 	 train loss: 0.086180 	 lr: 0.00049
[epoch  56:  80/307] 	 train loss: 0.283885 	 lr: 0.00049
[epoch  56: 100/307] 	 train loss: 0.086356 	 lr: 0.00049
[epoch  56: 120/307] 	 train loss: 0.646146 	 lr: 0.00049
[epoch  56: 140/307] 	 train loss: 0.507865 	 lr: 0.00049
[epoch  56: 160/307] 	 train loss: 0.087453 	 lr: 0.00049
[epoch  56: 180/307] 	 train loss: 0.428637 	 lr: 0.00049

val loss: 0.327268 	 acc: 0.897083

[epoch  56: 200/307] 	 train loss: 0.118083 	 lr: 0.00049
[epoch  56: 220/307] 	 train loss: 0.074204 	 lr: 0.00049
[epoch  56: 240/307] 	 train loss: 0.166053 	 lr: 0.00049
[epoch  56: 260/307] 	 train loss: 0.341329 	 lr: 0.00049
[epoch  56: 280/307] 	 train loss: 0.236946 	 lr: 0.00049
[epoch  56: 300/307] 	 train loss: 0.303286 	 lr: 0.00049
[epoch  57:   0/307] 	 train loss: 0.275411 	 lr: 0.00049
[epoch  57:  20/307] 	 train loss: 0.396334 	 lr: 0.00049
[epoch  57:  40/307] 	 train loss: 0.338803 	 lr: 0.00049

val loss: 0.323102 	 acc: 0.899514

[epoch  57:  60/307] 	 train loss: 0.275562 	 lr: 0.00049
[epoch  57:  80/307] 	 train loss: 0.444254 	 lr: 0.00049
[epoch  57: 100/307] 	 train loss: 0.085333 	 lr: 0.00049
[epoch  57: 120/307] 	 train loss: 0.407256 	 lr: 0.00049
[epoch  57: 140/307] 	 train loss: 0.259075 	 lr: 0.00049
[epoch  57: 160/307] 	 train loss: 0.101498 	 lr: 0.00049
[epoch  57: 180/307] 	 train loss: 0.274663 	 lr: 0.00049

val loss: 0.348691 	 acc: 0.902755

[epoch  57: 200/307] 	 train loss: 0.294890 	 lr: 0.00049
[epoch  57: 220/307] 	 train loss: 0.283723 	 lr: 0.00049
[epoch  57: 240/307] 	 train loss: 0.287012 	 lr: 0.00049
[epoch  57: 260/307] 	 train loss: 0.216466 	 lr: 0.00049
[epoch  57: 280/307] 	 train loss: 0.610799 	 lr: 0.00049
[epoch  57: 300/307] 	 train loss: 0.312677 	 lr: 0.00049
[epoch  58:   0/307] 	 train loss: 0.188284 	 lr: 0.00049
[epoch  58:  20/307] 	 train loss: 0.565718 	 lr: 0.00049

val loss: 0.344826 	 acc: 0.902350

[epoch  58:  40/307] 	 train loss: 0.101470 	 lr: 0.00049
[epoch  58:  60/307] 	 train loss: 0.401627 	 lr: 0.00049
[epoch  58:  80/307] 	 train loss: 0.262203 	 lr: 0.00049
[epoch  58: 100/307] 	 train loss: 0.146567 	 lr: 0.00049
[epoch  58: 120/307] 	 train loss: 0.232371 	 lr: 0.00049
[epoch  58: 140/307] 	 train loss: 0.258033 	 lr: 0.00049
[epoch  58: 160/307] 	 train loss: 0.270633 	 lr: 0.00049
[epoch  58: 180/307] 	 train loss: 0.104172 	 lr: 0.00049

val loss: 0.328478 	 acc: 0.903160

[epoch  58: 200/307] 	 train loss: 0.379171 	 lr: 0.00049
[epoch  58: 220/307] 	 train loss: 0.322408 	 lr: 0.00049
[epoch  58: 240/307] 	 train loss: 0.350118 	 lr: 0.00049
[epoch  58: 260/307] 	 train loss: 0.176524 	 lr: 0.00049
[epoch  58: 280/307] 	 train loss: 0.318772 	 lr: 0.00049
[epoch  58: 300/307] 	 train loss: 0.391383 	 lr: 0.00049
[epoch  59:   0/307] 	 train loss: 0.300906 	 lr: 0.00049
[epoch  59:  20/307] 	 train loss: 0.305035 	 lr: 0.00049

val loss: 0.342161 	 acc: 0.897083

[epoch  59:  40/307] 	 train loss: 0.058209 	 lr: 0.00049
[epoch  59:  60/307] 	 train loss: 0.161710 	 lr: 0.00049
[epoch  59:  80/307] 	 train loss: 0.187497 	 lr: 0.00049
[epoch  59: 100/307] 	 train loss: 0.552085 	 lr: 0.00049
[epoch  59: 120/307] 	 train loss: 0.387807 	 lr: 0.00049
[epoch  59: 140/307] 	 train loss: 0.196147 	 lr: 0.00049
[epoch  59: 160/307] 	 train loss: 0.338650 	 lr: 0.00049
[epoch  59: 180/307] 	 train loss: 0.206792 	 lr: 0.00049

val loss: 0.346169 	 acc: 0.903566

[epoch  59: 200/307] 	 train loss: 0.171640 	 lr: 0.00049
[epoch  59: 220/307] 	 train loss: 0.234978 	 lr: 0.00049
[epoch  59: 240/307] 	 train loss: 0.262053 	 lr: 0.00049
[epoch  59: 260/307] 	 train loss: 0.201015 	 lr: 0.00049
[epoch  59: 280/307] 	 train loss: 0.183841 	 lr: 0.00049
[epoch  59: 300/307] 	 train loss: 0.282531 	 lr: 0.00049
[epoch  60:   0/307] 	 train loss: 0.156325 	 lr: 0.00049
[epoch  60:  20/307] 	 train loss: 0.265367 	 lr: 0.00049

val loss: 0.332417 	 acc: 0.898298

[epoch  60:  40/307] 	 train loss: 0.181262 	 lr: 0.00049
[epoch  60:  60/307] 	 train loss: 0.291798 	 lr: 0.00049
[epoch  60:  80/307] 	 train loss: 0.274375 	 lr: 0.00049
[epoch  60: 100/307] 	 train loss: 0.110941 	 lr: 0.00049
[epoch  60: 120/307] 	 train loss: 0.420695 	 lr: 0.00049
[epoch  60: 140/307] 	 train loss: 0.629395 	 lr: 0.00049
[epoch  60: 160/307] 	 train loss: 0.476887 	 lr: 0.00049
[epoch  60: 180/307] 	 train loss: 0.204125 	 lr: 0.00049

val loss: 0.327228 	 acc: 0.903160

[epoch  60: 200/307] 	 train loss: 0.158910 	 lr: 0.00049
[epoch  60: 220/307] 	 train loss: 0.171434 	 lr: 0.00049
[epoch  60: 240/307] 	 train loss: 0.386716 	 lr: 0.00049
[epoch  60: 260/307] 	 train loss: 0.415630 	 lr: 0.00049
[epoch  60: 280/307] 	 train loss: 0.164221 	 lr: 0.00049
[epoch  60: 300/307] 	 train loss: 0.180619 	 lr: 0.00049
[epoch  61:   0/307] 	 train loss: 0.262014 	 lr: 0.00049
[epoch  61:  20/307] 	 train loss: 0.193939 	 lr: 0.00049

val loss: 0.366518 	 acc: 0.895462

[epoch  61:  40/307] 	 train loss: 0.380886 	 lr: 0.00049
[epoch  61:  60/307] 	 train loss: 0.266266 	 lr: 0.00049
[epoch  61:  80/307] 	 train loss: 0.221599 	 lr: 0.00049
[epoch  61: 100/307] 	 train loss: 0.305914 	 lr: 0.00049
[epoch  61: 120/307] 	 train loss: 0.678734 	 lr: 0.00049
[epoch  61: 140/307] 	 train loss: 0.485730 	 lr: 0.00049
[epoch  61: 160/307] 	 train loss: 0.477707 	 lr: 0.00049
[epoch  61: 180/307] 	 train loss: 0.353625 	 lr: 0.00049

val loss: 0.340585 	 acc: 0.907618

[epoch  61: 200/307] 	 train loss: 0.422764 	 lr: 0.00049
[epoch  61: 220/307] 	 train loss: 0.362832 	 lr: 0.00049
[epoch  61: 240/307] 	 train loss: 0.284755 	 lr: 0.00049
[epoch  61: 260/307] 	 train loss: 0.118677 	 lr: 0.00049
[epoch  61: 280/307] 	 train loss: 0.232285 	 lr: 0.00049
[epoch  61: 300/307] 	 train loss: 0.276644 	 lr: 0.00049
[epoch  62:   0/307] 	 train loss: 0.103647 	 lr: 0.00049
[epoch  62:  20/307] 	 train loss: 0.617355 	 lr: 0.00049

val loss: 0.338280 	 acc: 0.893841

[epoch  62:  40/307] 	 train loss: 0.293989 	 lr: 0.00049
[epoch  62:  60/307] 	 train loss: 0.530160 	 lr: 0.00049
[epoch  62:  80/307] 	 train loss: 0.241701 	 lr: 0.00049
[epoch  62: 100/307] 	 train loss: 0.286204 	 lr: 0.00049
[epoch  62: 120/307] 	 train loss: 0.299873 	 lr: 0.00049
[epoch  62: 140/307] 	 train loss: 0.163958 	 lr: 0.00049
[epoch  62: 160/307] 	 train loss: 0.158342 	 lr: 0.00049
[epoch  62: 180/307] 	 train loss: 0.216778 	 lr: 0.00049

val loss: 0.344520 	 acc: 0.903160

[epoch  62: 200/307] 	 train loss: 0.318539 	 lr: 0.00049
[epoch  62: 220/307] 	 train loss: 0.171476 	 lr: 0.00049
[epoch  62: 240/307] 	 train loss: 0.130180 	 lr: 0.00049
[epoch  62: 260/307] 	 train loss: 0.237156 	 lr: 0.00049
[epoch  62: 280/307] 	 train loss: 0.420481 	 lr: 0.00049
[epoch  62: 300/307] 	 train loss: 0.241972 	 lr: 0.00049
[epoch  63:   0/307] 	 train loss: 0.091551 	 lr: 0.00049
[epoch  63:  20/307] 	 train loss: 0.318146 	 lr: 0.00049

val loss: 0.326788 	 acc: 0.904376

[epoch  63:  40/307] 	 train loss: 0.100743 	 lr: 0.00049
[epoch  63:  60/307] 	 train loss: 0.298068 	 lr: 0.00049
[epoch  63:  80/307] 	 train loss: 0.315573 	 lr: 0.00049
[epoch  63: 100/307] 	 train loss: 0.396956 	 lr: 0.00049
[epoch  63: 120/307] 	 train loss: 0.211449 	 lr: 0.00049
[epoch  63: 140/307] 	 train loss: 0.178323 	 lr: 0.00049
[epoch  63: 160/307] 	 train loss: 0.219376 	 lr: 0.00049
[epoch  63: 180/307] 	 train loss: 0.616763 	 lr: 0.00049

val loss: 0.352923 	 acc: 0.895057

[epoch  63: 200/307] 	 train loss: 0.377592 	 lr: 0.00049
[epoch  63: 220/307] 	 train loss: 0.492705 	 lr: 0.00049
[epoch  63: 240/307] 	 train loss: 0.329843 	 lr: 0.00049
[epoch  63: 260/307] 	 train loss: 0.460424 	 lr: 0.00049
[epoch  63: 280/307] 	 train loss: 0.338310 	 lr: 0.00049
[epoch  63: 300/307] 	 train loss: 0.179768 	 lr: 0.00049
[epoch  64:   0/307] 	 train loss: 0.650244 	 lr: 0.00034
[epoch  64:  20/307] 	 train loss: 0.265466 	 lr: 0.00034

val loss: 0.334506 	 acc: 0.904376

[epoch  64:  40/307] 	 train loss: 0.296055 	 lr: 0.00034
[epoch  64:  60/307] 	 train loss: 0.177033 	 lr: 0.00034
[epoch  64:  80/307] 	 train loss: 0.265628 	 lr: 0.00034
[epoch  64: 100/307] 	 train loss: 0.604567 	 lr: 0.00034
[epoch  64: 120/307] 	 train loss: 0.165522 	 lr: 0.00034
[epoch  64: 140/307] 	 train loss: 0.298342 	 lr: 0.00034
[epoch  64: 160/307] 	 train loss: 0.258063 	 lr: 0.00034

val loss: 0.321616 	 acc: 0.904781

[epoch  64: 180/307] 	 train loss: 0.281912 	 lr: 0.00034
[epoch  64: 200/307] 	 train loss: 0.041098 	 lr: 0.00034
[epoch  64: 220/307] 	 train loss: 0.351139 	 lr: 0.00034
[epoch  64: 240/307] 	 train loss: 0.254237 	 lr: 0.00034
[epoch  64: 260/307] 	 train loss: 0.292920 	 lr: 0.00034
[epoch  64: 280/307] 	 train loss: 0.368802 	 lr: 0.00034
[epoch  64: 300/307] 	 train loss: 0.302660 	 lr: 0.00034
[epoch  65:   0/307] 	 train loss: 0.229196 	 lr: 0.00034
[epoch  65:  20/307] 	 train loss: 0.294240 	 lr: 0.00034

val loss: 0.327541 	 acc: 0.898298

[epoch  65:  40/307] 	 train loss: 0.187287 	 lr: 0.00034
[epoch  65:  60/307] 	 train loss: 0.329423 	 lr: 0.00034
[epoch  65:  80/307] 	 train loss: 0.219566 	 lr: 0.00034
[epoch  65: 100/307] 	 train loss: 0.260623 	 lr: 0.00034
[epoch  65: 120/307] 	 train loss: 0.342596 	 lr: 0.00034
[epoch  65: 140/307] 	 train loss: 0.085181 	 lr: 0.00034
[epoch  65: 160/307] 	 train loss: 0.276259 	 lr: 0.00034

val loss: 0.336015 	 acc: 0.899919

[epoch  65: 180/307] 	 train loss: 0.108161 	 lr: 0.00034
[epoch  65: 200/307] 	 train loss: 0.139684 	 lr: 0.00034
[epoch  65: 220/307] 	 train loss: 0.359987 	 lr: 0.00034
[epoch  65: 240/307] 	 train loss: 0.196378 	 lr: 0.00034
[epoch  65: 260/307] 	 train loss: 0.266401 	 lr: 0.00034
[epoch  65: 280/307] 	 train loss: 0.257533 	 lr: 0.00034
[epoch  65: 300/307] 	 train loss: 0.280112 	 lr: 0.00034
[epoch  66:   0/307] 	 train loss: 0.401390 	 lr: 0.00034
[epoch  66:  20/307] 	 train loss: 0.229088 	 lr: 0.00034

val loss: 0.306643 	 acc: 0.905997

[epoch  66:  40/307] 	 train loss: 0.147591 	 lr: 0.00034
[epoch  66:  60/307] 	 train loss: 0.100297 	 lr: 0.00034
[epoch  66:  80/307] 	 train loss: 0.208164 	 lr: 0.00034
[epoch  66: 100/307] 	 train loss: 0.066296 	 lr: 0.00034
[epoch  66: 120/307] 	 train loss: 0.195561 	 lr: 0.00034
[epoch  66: 140/307] 	 train loss: 0.100871 	 lr: 0.00034
[epoch  66: 160/307] 	 train loss: 0.211594 	 lr: 0.00034

val loss: 0.308325 	 acc: 0.910049

saved model with accuracy  0.9100486223662885
[epoch  66: 180/307] 	 train loss: 0.048126 	 lr: 0.00034
[epoch  66: 200/307] 	 train loss: 0.143849 	 lr: 0.00034
[epoch  66: 220/307] 	 train loss: 0.274733 	 lr: 0.00034
[epoch  66: 240/307] 	 train loss: 0.373689 	 lr: 0.00034
[epoch  66: 260/307] 	 train loss: 0.165926 	 lr: 0.00034
[epoch  66: 280/307] 	 train loss: 0.286220 	 lr: 0.00034
[epoch  66: 300/307] 	 train loss: 0.265007 	 lr: 0.00034
[epoch  67:   0/307] 	 train loss: 0.239644 	 lr: 0.00034
[epoch  67:  20/307] 	 train loss: 0.216103 	 lr: 0.00034

val loss: 0.329031 	 acc: 0.902350

[epoch  67:  40/307] 	 train loss: 0.151695 	 lr: 0.00034
[epoch  67:  60/307] 	 train loss: 0.134819 	 lr: 0.00034
[epoch  67:  80/307] 	 train loss: 0.244410 	 lr: 0.00034
[epoch  67: 100/307] 	 train loss: 0.220623 	 lr: 0.00034
[epoch  67: 120/307] 	 train loss: 0.287169 	 lr: 0.00034
[epoch  67: 140/307] 	 train loss: 0.337259 	 lr: 0.00034
[epoch  67: 160/307] 	 train loss: 0.261135 	 lr: 0.00034

val loss: 0.339267 	 acc: 0.901945

[epoch  67: 180/307] 	 train loss: 0.195142 	 lr: 0.00034
[epoch  67: 200/307] 	 train loss: 0.340818 	 lr: 0.00034
[epoch  67: 220/307] 	 train loss: 0.188049 	 lr: 0.00034
[epoch  67: 240/307] 	 train loss: 0.180634 	 lr: 0.00034
[epoch  67: 260/307] 	 train loss: 0.394249 	 lr: 0.00034
[epoch  67: 280/307] 	 train loss: 0.256819 	 lr: 0.00034
[epoch  67: 300/307] 	 train loss: 0.181724 	 lr: 0.00034
[epoch  68:   0/307] 	 train loss: 0.357718 	 lr: 0.00034

val loss: 0.343951 	 acc: 0.898298

[epoch  68:  20/307] 	 train loss: 0.411322 	 lr: 0.00034
[epoch  68:  40/307] 	 train loss: 0.366591 	 lr: 0.00034
[epoch  68:  60/307] 	 train loss: 0.254005 	 lr: 0.00034
[epoch  68:  80/307] 	 train loss: 0.203802 	 lr: 0.00034
[epoch  68: 100/307] 	 train loss: 0.145309 	 lr: 0.00034
[epoch  68: 120/307] 	 train loss: 0.201778 	 lr: 0.00034
[epoch  68: 140/307] 	 train loss: 0.121112 	 lr: 0.00034
[epoch  68: 160/307] 	 train loss: 0.223300 	 lr: 0.00034

val loss: 0.317217 	 acc: 0.909643

[epoch  68: 180/307] 	 train loss: 0.317853 	 lr: 0.00034
[epoch  68: 200/307] 	 train loss: 0.189419 	 lr: 0.00034
[epoch  68: 220/307] 	 train loss: 0.351038 	 lr: 0.00034
[epoch  68: 240/307] 	 train loss: 0.164588 	 lr: 0.00034
[epoch  68: 260/307] 	 train loss: 0.215508 	 lr: 0.00034
[epoch  68: 280/307] 	 train loss: 0.237281 	 lr: 0.00034
[epoch  68: 300/307] 	 train loss: 0.196431 	 lr: 0.00034
[epoch  69:   0/307] 	 train loss: 0.170272 	 lr: 0.00034

val loss: 0.337402 	 acc: 0.901945

[epoch  69:  20/307] 	 train loss: 0.235144 	 lr: 0.00034
[epoch  69:  40/307] 	 train loss: 0.136993 	 lr: 0.00034
[epoch  69:  60/307] 	 train loss: 0.225558 	 lr: 0.00034
[epoch  69:  80/307] 	 train loss: 0.202626 	 lr: 0.00034
[epoch  69: 100/307] 	 train loss: 0.384074 	 lr: 0.00034
[epoch  69: 120/307] 	 train loss: 0.078203 	 lr: 0.00034
[epoch  69: 140/307] 	 train loss: 0.154062 	 lr: 0.00034
[epoch  69: 160/307] 	 train loss: 0.145944 	 lr: 0.00034

val loss: 0.313397 	 acc: 0.905186

[epoch  69: 180/307] 	 train loss: 0.238002 	 lr: 0.00034
[epoch  69: 200/307] 	 train loss: 0.332673 	 lr: 0.00034
[epoch  69: 220/307] 	 train loss: 0.343245 	 lr: 0.00034
[epoch  69: 240/307] 	 train loss: 0.347038 	 lr: 0.00034
[epoch  69: 260/307] 	 train loss: 0.176517 	 lr: 0.00034
[epoch  69: 280/307] 	 train loss: 0.247466 	 lr: 0.00034
[epoch  69: 300/307] 	 train loss: 0.338459 	 lr: 0.00034
[epoch  70:   0/307] 	 train loss: 0.357216 	 lr: 0.00034

val loss: 0.320111 	 acc: 0.905997

[epoch  70:  20/307] 	 train loss: 0.249132 	 lr: 0.00034
[epoch  70:  40/307] 	 train loss: 0.037730 	 lr: 0.00034
[epoch  70:  60/307] 	 train loss: 0.176839 	 lr: 0.00034
[epoch  70:  80/307] 	 train loss: 0.480485 	 lr: 0.00034
[epoch  70: 100/307] 	 train loss: 0.147798 	 lr: 0.00034
[epoch  70: 120/307] 	 train loss: 0.264916 	 lr: 0.00034
[epoch  70: 140/307] 	 train loss: 0.337229 	 lr: 0.00034
[epoch  70: 160/307] 	 train loss: 0.156227 	 lr: 0.00034

val loss: 0.306003 	 acc: 0.907618

[epoch  70: 180/307] 	 train loss: 0.351789 	 lr: 0.00034
[epoch  70: 200/307] 	 train loss: 0.470040 	 lr: 0.00034
[epoch  70: 220/307] 	 train loss: 0.265527 	 lr: 0.00034
[epoch  70: 240/307] 	 train loss: 0.356445 	 lr: 0.00034
[epoch  70: 260/307] 	 train loss: 0.313999 	 lr: 0.00034
[epoch  70: 280/307] 	 train loss: 0.082358 	 lr: 0.00034
[epoch  70: 300/307] 	 train loss: 0.209279 	 lr: 0.00034
[epoch  71:   0/307] 	 train loss: 0.552263 	 lr: 0.00034

val loss: 0.321234 	 acc: 0.904781

[epoch  71:  20/307] 	 train loss: 0.435385 	 lr: 0.00034
[epoch  71:  40/307] 	 train loss: 0.422192 	 lr: 0.00034
[epoch  71:  60/307] 	 train loss: 0.195624 	 lr: 0.00034
[epoch  71:  80/307] 	 train loss: 0.112218 	 lr: 0.00034
[epoch  71: 100/307] 	 train loss: 0.066568 	 lr: 0.00034
[epoch  71: 120/307] 	 train loss: 0.143558 	 lr: 0.00034
[epoch  71: 140/307] 	 train loss: 0.179831 	 lr: 0.00034
[epoch  71: 160/307] 	 train loss: 0.111327 	 lr: 0.00034

val loss: 0.311599 	 acc: 0.905592

[epoch  71: 180/307] 	 train loss: 0.226971 	 lr: 0.00034
[epoch  71: 200/307] 	 train loss: 0.424385 	 lr: 0.00034
[epoch  71: 220/307] 	 train loss: 0.126448 	 lr: 0.00034
[epoch  71: 240/307] 	 train loss: 0.199178 	 lr: 0.00034
[epoch  71: 260/307] 	 train loss: 0.196130 	 lr: 0.00034
[epoch  71: 280/307] 	 train loss: 0.394291 	 lr: 0.00034
[epoch  71: 300/307] 	 train loss: 0.327444 	 lr: 0.00034
[epoch  72:   0/307] 	 train loss: 0.267321 	 lr: 0.00034

val loss: 0.325307 	 acc: 0.905592

[epoch  72:  20/307] 	 train loss: 0.174408 	 lr: 0.00034
[epoch  72:  40/307] 	 train loss: 0.160263 	 lr: 0.00034
[epoch  72:  60/307] 	 train loss: 0.184972 	 lr: 0.00034
[epoch  72:  80/307] 	 train loss: 0.179752 	 lr: 0.00034
[epoch  72: 100/307] 	 train loss: 0.345073 	 lr: 0.00034
[epoch  72: 120/307] 	 train loss: 0.380262 	 lr: 0.00034
[epoch  72: 140/307] 	 train loss: 0.428745 	 lr: 0.00034
[epoch  72: 160/307] 	 train loss: 0.144546 	 lr: 0.00034

val loss: 0.322555 	 acc: 0.903160

[epoch  72: 180/307] 	 train loss: 0.114281 	 lr: 0.00034
[epoch  72: 200/307] 	 train loss: 0.075417 	 lr: 0.00034
[epoch  72: 220/307] 	 train loss: 0.223398 	 lr: 0.00034
[epoch  72: 240/307] 	 train loss: 0.189489 	 lr: 0.00034
[epoch  72: 260/307] 	 train loss: 0.438028 	 lr: 0.00034
[epoch  72: 280/307] 	 train loss: 0.185253 	 lr: 0.00034
[epoch  72: 300/307] 	 train loss: 0.250444 	 lr: 0.00034
[epoch  73:   0/307] 	 train loss: 0.296162 	 lr: 0.00034

val loss: 0.318214 	 acc: 0.903566

[epoch  73:  20/307] 	 train loss: 0.383836 	 lr: 0.00034
[epoch  73:  40/307] 	 train loss: 0.093417 	 lr: 0.00034
[epoch  73:  60/307] 	 train loss: 0.475939 	 lr: 0.00034
[epoch  73:  80/307] 	 train loss: 0.192252 	 lr: 0.00034
[epoch  73: 100/307] 	 train loss: 0.206651 	 lr: 0.00034
[epoch  73: 120/307] 	 train loss: 0.241199 	 lr: 0.00034
[epoch  73: 140/307] 	 train loss: 0.202971 	 lr: 0.00034
[epoch  73: 160/307] 	 train loss: 0.212506 	 lr: 0.00034

val loss: 0.323114 	 acc: 0.904781

[epoch  73: 180/307] 	 train loss: 0.131056 	 lr: 0.00034
[epoch  73: 200/307] 	 train loss: 0.280483 	 lr: 0.00034
[epoch  73: 220/307] 	 train loss: 0.159829 	 lr: 0.00034
[epoch  73: 240/307] 	 train loss: 0.113556 	 lr: 0.00034
[epoch  73: 260/307] 	 train loss: 0.182260 	 lr: 0.00034
[epoch  73: 280/307] 	 train loss: 0.149230 	 lr: 0.00034
[epoch  73: 300/307] 	 train loss: 0.417523 	 lr: 0.00034
[epoch  74:   0/307] 	 train loss: 0.306131 	 lr: 0.00034

val loss: 0.321103 	 acc: 0.905997

[epoch  74:  20/307] 	 train loss: 0.328836 	 lr: 0.00034
[epoch  74:  40/307] 	 train loss: 0.125857 	 lr: 0.00034
[epoch  74:  60/307] 	 train loss: 0.525397 	 lr: 0.00034
[epoch  74:  80/307] 	 train loss: 0.357949 	 lr: 0.00034
[epoch  74: 100/307] 	 train loss: 0.162885 	 lr: 0.00034
[epoch  74: 120/307] 	 train loss: 0.227794 	 lr: 0.00034
[epoch  74: 140/307] 	 train loss: 0.105302 	 lr: 0.00034

val loss: 0.325204 	 acc: 0.903160

[epoch  74: 160/307] 	 train loss: 0.442090 	 lr: 0.00034
[epoch  74: 180/307] 	 train loss: 0.066850 	 lr: 0.00034
[epoch  74: 200/307] 	 train loss: 0.245225 	 lr: 0.00034
[epoch  74: 220/307] 	 train loss: 0.086915 	 lr: 0.00034
[epoch  74: 240/307] 	 train loss: 0.395067 	 lr: 0.00034
[epoch  74: 260/307] 	 train loss: 0.312889 	 lr: 0.00034
[epoch  74: 280/307] 	 train loss: 0.190312 	 lr: 0.00034
[epoch  74: 300/307] 	 train loss: 0.182359 	 lr: 0.00034
[epoch  75:   0/307] 	 train loss: 0.162230 	 lr: 0.00034

val loss: 0.331148 	 acc: 0.905997

[epoch  75:  20/307] 	 train loss: 0.275929 	 lr: 0.00034
[epoch  75:  40/307] 	 train loss: 0.299204 	 lr: 0.00034
[epoch  75:  60/307] 	 train loss: 0.577311 	 lr: 0.00034
[epoch  75:  80/307] 	 train loss: 0.223341 	 lr: 0.00034
[epoch  75: 100/307] 	 train loss: 0.219742 	 lr: 0.00034
[epoch  75: 120/307] 	 train loss: 0.296342 	 lr: 0.00034
[epoch  75: 140/307] 	 train loss: 0.359723 	 lr: 0.00034

val loss: 0.341479 	 acc: 0.907618

[epoch  75: 160/307] 	 train loss: 0.120271 	 lr: 0.00034
[epoch  75: 180/307] 	 train loss: 0.318751 	 lr: 0.00034
[epoch  75: 200/307] 	 train loss: 0.065888 	 lr: 0.00034
[epoch  75: 220/307] 	 train loss: 0.451859 	 lr: 0.00034
[epoch  75: 240/307] 	 train loss: 0.177153 	 lr: 0.00034
[epoch  75: 260/307] 	 train loss: 0.283937 	 lr: 0.00034
[epoch  75: 280/307] 	 train loss: 0.206118 	 lr: 0.00034
[epoch  75: 300/307] 	 train loss: 0.200612 	 lr: 0.00034
[epoch  76:   0/307] 	 train loss: 0.215720 	 lr: 0.00034

val loss: 0.343506 	 acc: 0.905592

[epoch  76:  20/307] 	 train loss: 0.299983 	 lr: 0.00034
[epoch  76:  40/307] 	 train loss: 0.132356 	 lr: 0.00034
[epoch  76:  60/307] 	 train loss: 0.063329 	 lr: 0.00034
[epoch  76:  80/307] 	 train loss: 0.360977 	 lr: 0.00034
[epoch  76: 100/307] 	 train loss: 0.241382 	 lr: 0.00034
[epoch  76: 120/307] 	 train loss: 0.268954 	 lr: 0.00034
[epoch  76: 140/307] 	 train loss: 0.230707 	 lr: 0.00034

val loss: 0.327237 	 acc: 0.902755

[epoch  76: 160/307] 	 train loss: 0.153505 	 lr: 0.00034
[epoch  76: 180/307] 	 train loss: 0.141837 	 lr: 0.00034
[epoch  76: 200/307] 	 train loss: 0.351296 	 lr: 0.00034
[epoch  76: 220/307] 	 train loss: 0.423364 	 lr: 0.00034
[epoch  76: 240/307] 	 train loss: 0.091203 	 lr: 0.00034
[epoch  76: 260/307] 	 train loss: 0.333223 	 lr: 0.00034
[epoch  76: 280/307] 	 train loss: 0.254171 	 lr: 0.00034
[epoch  76: 300/307] 	 train loss: 0.286046 	 lr: 0.00034
[epoch  77:   0/307] 	 train loss: 0.183163 	 lr: 0.00034

val loss: 0.338016 	 acc: 0.905186

[epoch  77:  20/307] 	 train loss: 0.452887 	 lr: 0.00034
[epoch  77:  40/307] 	 train loss: 0.498041 	 lr: 0.00034
[epoch  77:  60/307] 	 train loss: 0.148043 	 lr: 0.00034
[epoch  77:  80/307] 	 train loss: 0.141907 	 lr: 0.00034
[epoch  77: 100/307] 	 train loss: 0.309474 	 lr: 0.00034
[epoch  77: 120/307] 	 train loss: 0.357511 	 lr: 0.00034
[epoch  77: 140/307] 	 train loss: 0.236097 	 lr: 0.00034

val loss: 0.329456 	 acc: 0.902350

[epoch  77: 160/307] 	 train loss: 0.072201 	 lr: 0.00034
[epoch  77: 180/307] 	 train loss: 0.162180 	 lr: 0.00034
[epoch  77: 200/307] 	 train loss: 0.143682 	 lr: 0.00034
[epoch  77: 220/307] 	 train loss: 0.274511 	 lr: 0.00034
[epoch  77: 240/307] 	 train loss: 0.110917 	 lr: 0.00034
[epoch  77: 260/307] 	 train loss: 0.858384 	 lr: 0.00034
[epoch  77: 280/307] 	 train loss: 0.230906 	 lr: 0.00034
[epoch  77: 300/307] 	 train loss: 0.109176 	 lr: 0.00034

val loss: 0.321002 	 acc: 0.907618

[epoch  78:   0/307] 	 train loss: 0.644140 	 lr: 0.00034
[epoch  78:  20/307] 	 train loss: 0.136769 	 lr: 0.00034
[epoch  78:  40/307] 	 train loss: 0.324651 	 lr: 0.00034
[epoch  78:  60/307] 	 train loss: 0.370156 	 lr: 0.00034
[epoch  78:  80/307] 	 train loss: 0.071323 	 lr: 0.00034
[epoch  78: 100/307] 	 train loss: 0.061655 	 lr: 0.00034
[epoch  78: 120/307] 	 train loss: 0.049450 	 lr: 0.00034
[epoch  78: 140/307] 	 train loss: 0.200719 	 lr: 0.00034

val loss: 0.327496 	 acc: 0.902350

[epoch  78: 160/307] 	 train loss: 0.336428 	 lr: 0.00034
[epoch  78: 180/307] 	 train loss: 0.222583 	 lr: 0.00034
[epoch  78: 200/307] 	 train loss: 0.138027 	 lr: 0.00034
[epoch  78: 220/307] 	 train loss: 0.241576 	 lr: 0.00034
[epoch  78: 240/307] 	 train loss: 0.060032 	 lr: 0.00034
[epoch  78: 260/307] 	 train loss: 0.334435 	 lr: 0.00034
[epoch  78: 280/307] 	 train loss: 0.083095 	 lr: 0.00034
[epoch  78: 300/307] 	 train loss: 0.061292 	 lr: 0.00034

val loss: 0.329189 	 acc: 0.901540

[epoch  79:   0/307] 	 train loss: 0.365065 	 lr: 0.00034
[epoch  79:  20/307] 	 train loss: 0.043988 	 lr: 0.00034
[epoch  79:  40/307] 	 train loss: 0.170241 	 lr: 0.00034
[epoch  79:  60/307] 	 train loss: 0.184580 	 lr: 0.00034
[epoch  79:  80/307] 	 train loss: 0.186712 	 lr: 0.00034
[epoch  79: 100/307] 	 train loss: 0.138560 	 lr: 0.00034
[epoch  79: 120/307] 	 train loss: 0.365792 	 lr: 0.00034
[epoch  79: 140/307] 	 train loss: 0.218842 	 lr: 0.00034

val loss: 0.325013 	 acc: 0.903566

[epoch  79: 160/307] 	 train loss: 0.300261 	 lr: 0.00034
[epoch  79: 180/307] 	 train loss: 0.213856 	 lr: 0.00034
[epoch  79: 200/307] 	 train loss: 0.269468 	 lr: 0.00034
[epoch  79: 220/307] 	 train loss: 0.231630 	 lr: 0.00034
[epoch  79: 240/307] 	 train loss: 0.402014 	 lr: 0.00034
[epoch  79: 260/307] 	 train loss: 0.481093 	 lr: 0.00034
[epoch  79: 280/307] 	 train loss: 0.074145 	 lr: 0.00034
[epoch  79: 300/307] 	 train loss: 0.224857 	 lr: 0.00034

val loss: 0.315066 	 acc: 0.903971

[epoch  80:   0/307] 	 train loss: 0.263485 	 lr: 0.00034
[epoch  80:  20/307] 	 train loss: 0.156180 	 lr: 0.00034
[epoch  80:  40/307] 	 train loss: 0.250386 	 lr: 0.00034
[epoch  80:  60/307] 	 train loss: 0.412944 	 lr: 0.00034
[epoch  80:  80/307] 	 train loss: 0.213945 	 lr: 0.00034
[epoch  80: 100/307] 	 train loss: 0.146048 	 lr: 0.00034
[epoch  80: 120/307] 	 train loss: 0.183011 	 lr: 0.00034
[epoch  80: 140/307] 	 train loss: 0.109395 	 lr: 0.00034

val loss: 0.313536 	 acc: 0.908833

[epoch  80: 160/307] 	 train loss: 0.189204 	 lr: 0.00034
[epoch  80: 180/307] 	 train loss: 0.132773 	 lr: 0.00034
[epoch  80: 200/307] 	 train loss: 0.299107 	 lr: 0.00034
[epoch  80: 220/307] 	 train loss: 0.261284 	 lr: 0.00034
[epoch  80: 240/307] 	 train loss: 0.189810 	 lr: 0.00034
[epoch  80: 260/307] 	 train loss: 0.112743 	 lr: 0.00034
[epoch  80: 280/307] 	 train loss: 0.358758 	 lr: 0.00034
[epoch  80: 300/307] 	 train loss: 0.310306 	 lr: 0.00034

val loss: 0.323559 	 acc: 0.901135

[epoch  81:   0/307] 	 train loss: 0.062749 	 lr: 0.00034
[epoch  81:  20/307] 	 train loss: 0.153405 	 lr: 0.00034
[epoch  81:  40/307] 	 train loss: 0.288083 	 lr: 0.00034
[epoch  81:  60/307] 	 train loss: 0.192819 	 lr: 0.00034
[epoch  81:  80/307] 	 train loss: 0.165757 	 lr: 0.00034
[epoch  81: 100/307] 	 train loss: 0.265001 	 lr: 0.00034
[epoch  81: 120/307] 	 train loss: 0.101946 	 lr: 0.00034
[epoch  81: 140/307] 	 train loss: 0.081412 	 lr: 0.00034

val loss: 0.331733 	 acc: 0.899919

[epoch  81: 160/307] 	 train loss: 0.142760 	 lr: 0.00034
[epoch  81: 180/307] 	 train loss: 0.183951 	 lr: 0.00034
[epoch  81: 200/307] 	 train loss: 0.275195 	 lr: 0.00034
[epoch  81: 220/307] 	 train loss: 0.897247 	 lr: 0.00034
[epoch  81: 240/307] 	 train loss: 0.137801 	 lr: 0.00034
[epoch  81: 260/307] 	 train loss: 0.096622 	 lr: 0.00034
[epoch  81: 280/307] 	 train loss: 0.396027 	 lr: 0.00034

val loss: 0.320480 	 acc: 0.915316

saved model with accuracy  0.9153160453808752
[epoch  81: 300/307] 	 train loss: 0.153325 	 lr: 0.00034
[epoch  82:   0/307] 	 train loss: 0.208351 	 lr: 0.00034
[epoch  82:  20/307] 	 train loss: 0.236636 	 lr: 0.00034
[epoch  82:  40/307] 	 train loss: 0.188529 	 lr: 0.00034
[epoch  82:  60/307] 	 train loss: 0.373163 	 lr: 0.00034
[epoch  82:  80/307] 	 train loss: 0.286645 	 lr: 0.00034
[epoch  82: 100/307] 	 train loss: 0.185057 	 lr: 0.00034
[epoch  82: 120/307] 	 train loss: 0.246735 	 lr: 0.00034
[epoch  82: 140/307] 	 train loss: 0.232454 	 lr: 0.00034

val loss: 0.340116 	 acc: 0.906807

[epoch  82: 160/307] 	 train loss: 0.296013 	 lr: 0.00034
[epoch  82: 180/307] 	 train loss: 0.343798 	 lr: 0.00034
[epoch  82: 200/307] 	 train loss: 0.292808 	 lr: 0.00034
[epoch  82: 220/307] 	 train loss: 0.146672 	 lr: 0.00034
[epoch  82: 240/307] 	 train loss: 0.088937 	 lr: 0.00034
[epoch  82: 260/307] 	 train loss: 0.355819 	 lr: 0.00034
[epoch  82: 280/307] 	 train loss: 0.400663 	 lr: 0.00034

val loss: 0.334208 	 acc: 0.901540

[epoch  82: 300/307] 	 train loss: 0.307648 	 lr: 0.00034
[epoch  83:   0/307] 	 train loss: 0.116395 	 lr: 0.00034
[epoch  83:  20/307] 	 train loss: 0.173797 	 lr: 0.00034
[epoch  83:  40/307] 	 train loss: 0.139187 	 lr: 0.00034
[epoch  83:  60/307] 	 train loss: 0.082328 	 lr: 0.00034
[epoch  83:  80/307] 	 train loss: 0.102558 	 lr: 0.00034
[epoch  83: 100/307] 	 train loss: 0.331743 	 lr: 0.00034
[epoch  83: 120/307] 	 train loss: 0.219751 	 lr: 0.00034
[epoch  83: 140/307] 	 train loss: 0.136422 	 lr: 0.00034

val loss: 0.350720 	 acc: 0.903971

[epoch  83: 160/307] 	 train loss: 0.345268 	 lr: 0.00034
[epoch  83: 180/307] 	 train loss: 0.172346 	 lr: 0.00034
[epoch  83: 200/307] 	 train loss: 0.229551 	 lr: 0.00034
[epoch  83: 220/307] 	 train loss: 0.107770 	 lr: 0.00034
[epoch  83: 240/307] 	 train loss: 0.160910 	 lr: 0.00034
[epoch  83: 260/307] 	 train loss: 0.078726 	 lr: 0.00034
[epoch  83: 280/307] 	 train loss: 0.140215 	 lr: 0.00034

val loss: 0.325015 	 acc: 0.908023

[epoch  83: 300/307] 	 train loss: 0.437262 	 lr: 0.00034
[epoch  84:   0/307] 	 train loss: 0.297697 	 lr: 0.00034
[epoch  84:  20/307] 	 train loss: 0.056806 	 lr: 0.00034
[epoch  84:  40/307] 	 train loss: 0.225358 	 lr: 0.00034
[epoch  84:  60/307] 	 train loss: 0.137433 	 lr: 0.00034
[epoch  84:  80/307] 	 train loss: 0.335768 	 lr: 0.00034
[epoch  84: 100/307] 	 train loss: 0.171526 	 lr: 0.00034
[epoch  84: 120/307] 	 train loss: 0.189683 	 lr: 0.00034

val loss: 0.328060 	 acc: 0.908428

[epoch  84: 140/307] 	 train loss: 0.221556 	 lr: 0.00034
[epoch  84: 160/307] 	 train loss: 0.276252 	 lr: 0.00034
[epoch  84: 180/307] 	 train loss: 0.178695 	 lr: 0.00034
[epoch  84: 200/307] 	 train loss: 0.089880 	 lr: 0.00034
[epoch  84: 220/307] 	 train loss: 0.363056 	 lr: 0.00034
[epoch  84: 240/307] 	 train loss: 0.205700 	 lr: 0.00034
[epoch  84: 260/307] 	 train loss: 0.406934 	 lr: 0.00034
[epoch  84: 280/307] 	 train loss: 0.190096 	 lr: 0.00034

val loss: 0.323992 	 acc: 0.908833

[epoch  84: 300/307] 	 train loss: 0.192528 	 lr: 0.00034
[epoch  85:   0/307] 	 train loss: 0.223890 	 lr: 0.00024
[epoch  85:  20/307] 	 train loss: 0.377252 	 lr: 0.00024
[epoch  85:  40/307] 	 train loss: 0.168283 	 lr: 0.00024
[epoch  85:  60/307] 	 train loss: 0.125479 	 lr: 0.00024
[epoch  85:  80/307] 	 train loss: 0.272804 	 lr: 0.00024
[epoch  85: 100/307] 	 train loss: 0.191404 	 lr: 0.00024
[epoch  85: 120/307] 	 train loss: 0.097637 	 lr: 0.00024

val loss: 0.314607 	 acc: 0.909238

[epoch  85: 140/307] 	 train loss: 0.087911 	 lr: 0.00024
[epoch  85: 160/307] 	 train loss: 0.109998 	 lr: 0.00024
[epoch  85: 180/307] 	 train loss: 0.212878 	 lr: 0.00024
[epoch  85: 200/307] 	 train loss: 0.060494 	 lr: 0.00024
[epoch  85: 220/307] 	 train loss: 0.255721 	 lr: 0.00024
[epoch  85: 240/307] 	 train loss: 0.191693 	 lr: 0.00024
[epoch  85: 260/307] 	 train loss: 0.153391 	 lr: 0.00024
[epoch  85: 280/307] 	 train loss: 0.330204 	 lr: 0.00024

val loss: 0.319968 	 acc: 0.904781

[epoch  85: 300/307] 	 train loss: 0.228661 	 lr: 0.00024
[epoch  86:   0/307] 	 train loss: 0.137925 	 lr: 0.00024
[epoch  86:  20/307] 	 train loss: 0.234821 	 lr: 0.00024
[epoch  86:  40/307] 	 train loss: 0.321465 	 lr: 0.00024
[epoch  86:  60/307] 	 train loss: 0.144320 	 lr: 0.00024
[epoch  86:  80/307] 	 train loss: 0.086618 	 lr: 0.00024
[epoch  86: 100/307] 	 train loss: 0.311359 	 lr: 0.00024
[epoch  86: 120/307] 	 train loss: 0.319830 	 lr: 0.00024

val loss: 0.323479 	 acc: 0.908023

[epoch  86: 140/307] 	 train loss: 0.169321 	 lr: 0.00024
[epoch  86: 160/307] 	 train loss: 0.231225 	 lr: 0.00024
[epoch  86: 180/307] 	 train loss: 0.304727 	 lr: 0.00024
[epoch  86: 200/307] 	 train loss: 0.136183 	 lr: 0.00024
[epoch  86: 220/307] 	 train loss: 0.257001 	 lr: 0.00024
[epoch  86: 240/307] 	 train loss: 0.263097 	 lr: 0.00024
[epoch  86: 260/307] 	 train loss: 0.172485 	 lr: 0.00024
[epoch  86: 280/307] 	 train loss: 0.056578 	 lr: 0.00024

val loss: 0.336403 	 acc: 0.905592

[epoch  86: 300/307] 	 train loss: 0.198429 	 lr: 0.00024
[epoch  87:   0/307] 	 train loss: 0.452324 	 lr: 0.00024
[epoch  87:  20/307] 	 train loss: 0.512339 	 lr: 0.00024
[epoch  87:  40/307] 	 train loss: 0.137063 	 lr: 0.00024
[epoch  87:  60/307] 	 train loss: 0.035348 	 lr: 0.00024
[epoch  87:  80/307] 	 train loss: 0.292031 	 lr: 0.00024
[epoch  87: 100/307] 	 train loss: 0.192029 	 lr: 0.00024
[epoch  87: 120/307] 	 train loss: 0.184526 	 lr: 0.00024

val loss: 0.328032 	 acc: 0.897488

[epoch  87: 140/307] 	 train loss: 0.119217 	 lr: 0.00024
[epoch  87: 160/307] 	 train loss: 0.345423 	 lr: 0.00024
[epoch  87: 180/307] 	 train loss: 0.084264 	 lr: 0.00024
[epoch  87: 200/307] 	 train loss: 0.289423 	 lr: 0.00024
[epoch  87: 220/307] 	 train loss: 0.188566 	 lr: 0.00024
[epoch  87: 240/307] 	 train loss: 0.124331 	 lr: 0.00024
[epoch  87: 260/307] 	 train loss: 0.290652 	 lr: 0.00024
[epoch  87: 280/307] 	 train loss: 0.119213 	 lr: 0.00024

val loss: 0.323770 	 acc: 0.905592

[epoch  87: 300/307] 	 train loss: 0.278555 	 lr: 0.00024
[epoch  88:   0/307] 	 train loss: 0.178975 	 lr: 0.00024
[epoch  88:  20/307] 	 train loss: 0.101987 	 lr: 0.00024
[epoch  88:  40/307] 	 train loss: 0.148229 	 lr: 0.00024
[epoch  88:  60/307] 	 train loss: 0.495170 	 lr: 0.00024
[epoch  88:  80/307] 	 train loss: 0.160142 	 lr: 0.00024
[epoch  88: 100/307] 	 train loss: 0.269195 	 lr: 0.00024
[epoch  88: 120/307] 	 train loss: 0.210532 	 lr: 0.00024

val loss: 0.343920 	 acc: 0.901540

[epoch  88: 140/307] 	 train loss: 0.462785 	 lr: 0.00024
[epoch  88: 160/307] 	 train loss: 0.189449 	 lr: 0.00024
[epoch  88: 180/307] 	 train loss: 0.096795 	 lr: 0.00024
[epoch  88: 200/307] 	 train loss: 0.214328 	 lr: 0.00024
[epoch  88: 220/307] 	 train loss: 0.254300 	 lr: 0.00024
[epoch  88: 240/307] 	 train loss: 0.051114 	 lr: 0.00024
[epoch  88: 260/307] 	 train loss: 0.156710 	 lr: 0.00024
[epoch  88: 280/307] 	 train loss: 0.225548 	 lr: 0.00024

val loss: 0.319309 	 acc: 0.908428

[epoch  88: 300/307] 	 train loss: 0.190065 	 lr: 0.00024
[epoch  89:   0/307] 	 train loss: 0.178867 	 lr: 0.00024
[epoch  89:  20/307] 	 train loss: 0.064217 	 lr: 0.00024
[epoch  89:  40/307] 	 train loss: 0.092837 	 lr: 0.00024
[epoch  89:  60/307] 	 train loss: 0.321393 	 lr: 0.00024
[epoch  89:  80/307] 	 train loss: 0.114778 	 lr: 0.00024
[epoch  89: 100/307] 	 train loss: 0.161294 	 lr: 0.00024
[epoch  89: 120/307] 	 train loss: 0.146979 	 lr: 0.00024

val loss: 0.337976 	 acc: 0.905997

[epoch  89: 140/307] 	 train loss: 0.092648 	 lr: 0.00024
[epoch  89: 160/307] 	 train loss: 0.071262 	 lr: 0.00024
[epoch  89: 180/307] 	 train loss: 0.156909 	 lr: 0.00024
[epoch  89: 200/307] 	 train loss: 0.191906 	 lr: 0.00024
[epoch  89: 220/307] 	 train loss: 0.352178 	 lr: 0.00024
[epoch  89: 240/307] 	 train loss: 0.376230 	 lr: 0.00024
[epoch  89: 260/307] 	 train loss: 0.373275 	 lr: 0.00024
[epoch  89: 280/307] 	 train loss: 0.099003 	 lr: 0.00024

val loss: 0.332330 	 acc: 0.901135

[epoch  89: 300/307] 	 train loss: 0.348189 	 lr: 0.00024
[epoch  90:   0/307] 	 train loss: 0.133337 	 lr: 0.00024
[epoch  90:  20/307] 	 train loss: 0.165757 	 lr: 0.00024
[epoch  90:  40/307] 	 train loss: 0.326912 	 lr: 0.00024
[epoch  90:  60/307] 	 train loss: 0.136358 	 lr: 0.00024
[epoch  90:  80/307] 	 train loss: 0.249019 	 lr: 0.00024
[epoch  90: 100/307] 	 train loss: 0.091862 	 lr: 0.00024
[epoch  90: 120/307] 	 train loss: 0.281883 	 lr: 0.00024

val loss: 0.338228 	 acc: 0.905592

[epoch  90: 140/307] 	 train loss: 0.345821 	 lr: 0.00024
[epoch  90: 160/307] 	 train loss: 0.477264 	 lr: 0.00024
[epoch  90: 180/307] 	 train loss: 0.420085 	 lr: 0.00024
[epoch  90: 200/307] 	 train loss: 0.193620 	 lr: 0.00024
[epoch  90: 220/307] 	 train loss: 0.489963 	 lr: 0.00024
[epoch  90: 240/307] 	 train loss: 0.252761 	 lr: 0.00024
[epoch  90: 260/307] 	 train loss: 0.141408 	 lr: 0.00024
[epoch  90: 280/307] 	 train loss: 0.289165 	 lr: 0.00024

val loss: 0.353439 	 acc: 0.903566

[epoch  90: 300/307] 	 train loss: 0.555573 	 lr: 0.00024
[epoch  91:   0/307] 	 train loss: 0.265102 	 lr: 0.00024
[epoch  91:  20/307] 	 train loss: 0.219286 	 lr: 0.00024
[epoch  91:  40/307] 	 train loss: 0.265777 	 lr: 0.00024
[epoch  91:  60/307] 	 train loss: 0.163574 	 lr: 0.00024
[epoch  91:  80/307] 	 train loss: 0.333138 	 lr: 0.00024
[epoch  91: 100/307] 	 train loss: 0.314194 	 lr: 0.00024
[epoch  91: 120/307] 	 train loss: 0.164635 	 lr: 0.00024

val loss: 0.305498 	 acc: 0.908023

[epoch  91: 140/307] 	 train loss: 0.365177 	 lr: 0.00024
[epoch  91: 160/307] 	 train loss: 0.337004 	 lr: 0.00024
[epoch  91: 180/307] 	 train loss: 0.069361 	 lr: 0.00024
[epoch  91: 200/307] 	 train loss: 0.316900 	 lr: 0.00024
[epoch  91: 220/307] 	 train loss: 0.237869 	 lr: 0.00024
[epoch  91: 240/307] 	 train loss: 0.130765 	 lr: 0.00024
[epoch  91: 260/307] 	 train loss: 0.214907 	 lr: 0.00024

val loss: 0.323774 	 acc: 0.908023

[epoch  91: 280/307] 	 train loss: 0.181221 	 lr: 0.00024
[epoch  91: 300/307] 	 train loss: 0.175390 	 lr: 0.00024
[epoch  92:   0/307] 	 train loss: 0.367585 	 lr: 0.00024
[epoch  92:  20/307] 	 train loss: 0.223703 	 lr: 0.00024
[epoch  92:  40/307] 	 train loss: 0.114898 	 lr: 0.00024
[epoch  92:  60/307] 	 train loss: 0.161281 	 lr: 0.00024
[epoch  92:  80/307] 	 train loss: 0.352209 	 lr: 0.00024
[epoch  92: 100/307] 	 train loss: 0.127549 	 lr: 0.00024
[epoch  92: 120/307] 	 train loss: 0.119912 	 lr: 0.00024

val loss: 0.323448 	 acc: 0.906402

[epoch  92: 140/307] 	 train loss: 0.534937 	 lr: 0.00024
[epoch  92: 160/307] 	 train loss: 0.606713 	 lr: 0.00024
[epoch  92: 180/307] 	 train loss: 0.079254 	 lr: 0.00024
[epoch  92: 200/307] 	 train loss: 0.231576 	 lr: 0.00024
[epoch  92: 220/307] 	 train loss: 0.250990 	 lr: 0.00024
[epoch  92: 240/307] 	 train loss: 0.188483 	 lr: 0.00024
[epoch  92: 260/307] 	 train loss: 0.297224 	 lr: 0.00024

val loss: 0.320158 	 acc: 0.904781

[epoch  92: 280/307] 	 train loss: 0.135754 	 lr: 0.00024
[epoch  92: 300/307] 	 train loss: 0.251362 	 lr: 0.00024
[epoch  93:   0/307] 	 train loss: 0.284954 	 lr: 0.00024
[epoch  93:  20/307] 	 train loss: 0.168363 	 lr: 0.00024
[epoch  93:  40/307] 	 train loss: 0.302570 	 lr: 0.00024
[epoch  93:  60/307] 	 train loss: 0.338601 	 lr: 0.00024
[epoch  93:  80/307] 	 train loss: 0.671747 	 lr: 0.00024
[epoch  93: 100/307] 	 train loss: 0.296367 	 lr: 0.00024
[epoch  93: 120/307] 	 train loss: 0.082586 	 lr: 0.00024

val loss: 0.338264 	 acc: 0.901540

[epoch  93: 140/307] 	 train loss: 0.214955 	 lr: 0.00024
[epoch  93: 160/307] 	 train loss: 0.080335 	 lr: 0.00024
[epoch  93: 180/307] 	 train loss: 0.190677 	 lr: 0.00024
[epoch  93: 200/307] 	 train loss: 0.223197 	 lr: 0.00024
[epoch  93: 220/307] 	 train loss: 0.339630 	 lr: 0.00024
[epoch  93: 240/307] 	 train loss: 0.111687 	 lr: 0.00024
[epoch  93: 260/307] 	 train loss: 0.216396 	 lr: 0.00024

val loss: 0.311997 	 acc: 0.908023

[epoch  93: 280/307] 	 train loss: 0.150123 	 lr: 0.00024
[epoch  93: 300/307] 	 train loss: 0.244507 	 lr: 0.00024
[epoch  94:   0/307] 	 train loss: 0.073061 	 lr: 0.00024
[epoch  94:  20/307] 	 train loss: 0.137549 	 lr: 0.00024
[epoch  94:  40/307] 	 train loss: 0.331258 	 lr: 0.00024
[epoch  94:  60/307] 	 train loss: 0.029574 	 lr: 0.00024
[epoch  94:  80/307] 	 train loss: 0.195971 	 lr: 0.00024
[epoch  94: 100/307] 	 train loss: 0.131362 	 lr: 0.00024

val loss: 0.345396 	 acc: 0.904376

[epoch  94: 120/307] 	 train loss: 0.144246 	 lr: 0.00024
[epoch  94: 140/307] 	 train loss: 0.326222 	 lr: 0.00024
[epoch  94: 160/307] 	 train loss: 0.122184 	 lr: 0.00024
[epoch  94: 180/307] 	 train loss: 0.224340 	 lr: 0.00024
[epoch  94: 200/307] 	 train loss: 0.257049 	 lr: 0.00024
[epoch  94: 220/307] 	 train loss: 0.249015 	 lr: 0.00024
[epoch  94: 240/307] 	 train loss: 0.374652 	 lr: 0.00024
[epoch  94: 260/307] 	 train loss: 0.131706 	 lr: 0.00024

val loss: 0.329609 	 acc: 0.908833

[epoch  94: 280/307] 	 train loss: 0.209133 	 lr: 0.00024
[epoch  94: 300/307] 	 train loss: 0.240664 	 lr: 0.00024
[epoch  95:   0/307] 	 train loss: 0.343832 	 lr: 0.00024
[epoch  95:  20/307] 	 train loss: 0.138708 	 lr: 0.00024
[epoch  95:  40/307] 	 train loss: 0.062010 	 lr: 0.00024
[epoch  95:  60/307] 	 train loss: 0.124170 	 lr: 0.00024
[epoch  95:  80/307] 	 train loss: 0.213179 	 lr: 0.00024
[epoch  95: 100/307] 	 train loss: 0.281217 	 lr: 0.00024

val loss: 0.347623 	 acc: 0.901135

[epoch  95: 120/307] 	 train loss: 0.157235 	 lr: 0.00024
[epoch  95: 140/307] 	 train loss: 0.154845 	 lr: 0.00024
[epoch  95: 160/307] 	 train loss: 0.133133 	 lr: 0.00024
[epoch  95: 180/307] 	 train loss: 0.055340 	 lr: 0.00024
[epoch  95: 200/307] 	 train loss: 0.455188 	 lr: 0.00024
[epoch  95: 220/307] 	 train loss: 0.327913 	 lr: 0.00024
[epoch  95: 240/307] 	 train loss: 0.119168 	 lr: 0.00024
[epoch  95: 260/307] 	 train loss: 0.253703 	 lr: 0.00024

val loss: 0.318700 	 acc: 0.912075

[epoch  95: 280/307] 	 train loss: 0.070012 	 lr: 0.00024
[epoch  95: 300/307] 	 train loss: 0.080121 	 lr: 0.00024
[epoch  96:   0/307] 	 train loss: 0.292001 	 lr: 0.00024
[epoch  96:  20/307] 	 train loss: 0.323721 	 lr: 0.00024
[epoch  96:  40/307] 	 train loss: 0.259369 	 lr: 0.00024
[epoch  96:  60/307] 	 train loss: 0.336352 	 lr: 0.00024
[epoch  96:  80/307] 	 train loss: 0.095317 	 lr: 0.00024
[epoch  96: 100/307] 	 train loss: 0.265409 	 lr: 0.00024

val loss: 0.357731 	 acc: 0.903971

[epoch  96: 120/307] 	 train loss: 0.332309 	 lr: 0.00024
[epoch  96: 140/307] 	 train loss: 0.245838 	 lr: 0.00024
[epoch  96: 160/307] 	 train loss: 0.213218 	 lr: 0.00024
[epoch  96: 180/307] 	 train loss: 0.207907 	 lr: 0.00024
[epoch  96: 200/307] 	 train loss: 0.449048 	 lr: 0.00024
[epoch  96: 220/307] 	 train loss: 0.687818 	 lr: 0.00024
[epoch  96: 240/307] 	 train loss: 0.166925 	 lr: 0.00024
[epoch  96: 260/307] 	 train loss: 0.122698 	 lr: 0.00024

val loss: 0.330597 	 acc: 0.908023

[epoch  96: 280/307] 	 train loss: 0.306331 	 lr: 0.00024
[epoch  96: 300/307] 	 train loss: 0.356515 	 lr: 0.00024
[epoch  97:   0/307] 	 train loss: 0.239675 	 lr: 0.00024
[epoch  97:  20/307] 	 train loss: 0.320904 	 lr: 0.00024
[epoch  97:  40/307] 	 train loss: 0.151214 	 lr: 0.00024
[epoch  97:  60/307] 	 train loss: 0.312813 	 lr: 0.00024
[epoch  97:  80/307] 	 train loss: 0.396238 	 lr: 0.00024
[epoch  97: 100/307] 	 train loss: 0.105256 	 lr: 0.00024

val loss: 0.327304 	 acc: 0.909643

[epoch  97: 120/307] 	 train loss: 0.140926 	 lr: 0.00024
[epoch  97: 140/307] 	 train loss: 0.034649 	 lr: 0.00024
[epoch  97: 160/307] 	 train loss: 0.274758 	 lr: 0.00024
[epoch  97: 180/307] 	 train loss: 0.335951 	 lr: 0.00024
[epoch  97: 200/307] 	 train loss: 0.054926 	 lr: 0.00024
[epoch  97: 220/307] 	 train loss: 0.255694 	 lr: 0.00024
[epoch  97: 240/307] 	 train loss: 0.326386 	 lr: 0.00024
[epoch  97: 260/307] 	 train loss: 0.094850 	 lr: 0.00024

val loss: 0.327005 	 acc: 0.906402

[epoch  97: 280/307] 	 train loss: 0.115791 	 lr: 0.00024
[epoch  97: 300/307] 	 train loss: 0.410698 	 lr: 0.00024
[epoch  98:   0/307] 	 train loss: 0.169456 	 lr: 0.00024
[epoch  98:  20/307] 	 train loss: 0.174544 	 lr: 0.00024
[epoch  98:  40/307] 	 train loss: 0.211852 	 lr: 0.00024
[epoch  98:  60/307] 	 train loss: 0.050316 	 lr: 0.00024
[epoch  98:  80/307] 	 train loss: 0.336912 	 lr: 0.00024
[epoch  98: 100/307] 	 train loss: 0.137842 	 lr: 0.00024

val loss: 0.325953 	 acc: 0.908833

[epoch  98: 120/307] 	 train loss: 0.109546 	 lr: 0.00024
[epoch  98: 140/307] 	 train loss: 0.390939 	 lr: 0.00024
[epoch  98: 160/307] 	 train loss: 0.239447 	 lr: 0.00024
[epoch  98: 180/307] 	 train loss: 0.146007 	 lr: 0.00024
[epoch  98: 200/307] 	 train loss: 0.525404 	 lr: 0.00024
[epoch  98: 220/307] 	 train loss: 0.286568 	 lr: 0.00024
[epoch  98: 240/307] 	 train loss: 0.213328 	 lr: 0.00024
[epoch  98: 260/307] 	 train loss: 0.177831 	 lr: 0.00024

val loss: 0.349958 	 acc: 0.901945

[epoch  98: 280/307] 	 train loss: 0.359053 	 lr: 0.00024
[epoch  98: 300/307] 	 train loss: 0.120576 	 lr: 0.00024
[epoch  99:   0/307] 	 train loss: 0.392566 	 lr: 0.00024
[epoch  99:  20/307] 	 train loss: 0.291368 	 lr: 0.00024
[epoch  99:  40/307] 	 train loss: 0.222592 	 lr: 0.00024
[epoch  99:  60/307] 	 train loss: 0.156335 	 lr: 0.00024
[epoch  99:  80/307] 	 train loss: 0.272137 	 lr: 0.00024
[epoch  99: 100/307] 	 train loss: 0.237977 	 lr: 0.00024

val loss: 0.322878 	 acc: 0.912480

[epoch  99: 120/307] 	 train loss: 0.077019 	 lr: 0.00024
[epoch  99: 140/307] 	 train loss: 0.227299 	 lr: 0.00024
[epoch  99: 160/307] 	 train loss: 0.125397 	 lr: 0.00024
[epoch  99: 180/307] 	 train loss: 0.095342 	 lr: 0.00024
[epoch  99: 200/307] 	 train loss: 0.343230 	 lr: 0.00024
[epoch  99: 220/307] 	 train loss: 0.061201 	 lr: 0.00024
[epoch  99: 240/307] 	 train loss: 0.211899 	 lr: 0.00024
[epoch  99: 260/307] 	 train loss: 0.338091 	 lr: 0.00024

val loss: 0.324835 	 acc: 0.915316

[epoch  99: 280/307] 	 train loss: 0.045663 	 lr: 0.00024
[epoch  99: 300/307] 	 train loss: 0.431030 	 lr: 0.00024
[epoch 100:   0/307] 	 train loss: 0.256412 	 lr: 0.00024
[epoch 100:  20/307] 	 train loss: 0.066810 	 lr: 0.00024
[epoch 100:  40/307] 	 train loss: 0.122531 	 lr: 0.00024
[epoch 100:  60/307] 	 train loss: 0.299298 	 lr: 0.00024
[epoch 100:  80/307] 	 train loss: 0.041145 	 lr: 0.00024
[epoch 100: 100/307] 	 train loss: 0.198221 	 lr: 0.00024

val loss: 0.319776 	 acc: 0.913290

[epoch 100: 120/307] 	 train loss: 0.296732 	 lr: 0.00024
[epoch 100: 140/307] 	 train loss: 0.417007 	 lr: 0.00024
[epoch 100: 160/307] 	 train loss: 0.231546 	 lr: 0.00024
[epoch 100: 180/307] 	 train loss: 0.507658 	 lr: 0.00024
[epoch 100: 200/307] 	 train loss: 0.259241 	 lr: 0.00024
[epoch 100: 220/307] 	 train loss: 0.216085 	 lr: 0.00024
[epoch 100: 240/307] 	 train loss: 0.290806 	 lr: 0.00024
[epoch 100: 260/307] 	 train loss: 0.172367 	 lr: 0.00024

val loss: 0.336881 	 acc: 0.907212

[epoch 100: 280/307] 	 train loss: 0.565260 	 lr: 0.00024
[epoch 100: 300/307] 	 train loss: 0.192603 	 lr: 0.00024
[epoch 101:   0/307] 	 train loss: 0.351973 	 lr: 0.00024
[epoch 101:  20/307] 	 train loss: 0.368809 	 lr: 0.00024
[epoch 101:  40/307] 	 train loss: 0.329782 	 lr: 0.00024
[epoch 101:  60/307] 	 train loss: 0.193328 	 lr: 0.00024
[epoch 101:  80/307] 	 train loss: 0.298326 	 lr: 0.00024
[epoch 101: 100/307] 	 train loss: 0.112101 	 lr: 0.00024

val loss: 0.319673 	 acc: 0.913695

[epoch 101: 120/307] 	 train loss: 0.234519 	 lr: 0.00024
[epoch 101: 140/307] 	 train loss: 0.140412 	 lr: 0.00024
[epoch 101: 160/307] 	 train loss: 0.181444 	 lr: 0.00024
[epoch 101: 180/307] 	 train loss: 0.165841 	 lr: 0.00024
[epoch 101: 200/307] 	 train loss: 0.164035 	 lr: 0.00024
[epoch 101: 220/307] 	 train loss: 0.173801 	 lr: 0.00024
[epoch 101: 240/307] 	 train loss: 0.264616 	 lr: 0.00024

val loss: 0.317700 	 acc: 0.908833

[epoch 101: 260/307] 	 train loss: 0.227032 	 lr: 0.00024
[epoch 101: 280/307] 	 train loss: 0.102666 	 lr: 0.00024
[epoch 101: 300/307] 	 train loss: 0.211207 	 lr: 0.00024
[epoch 102:   0/307] 	 train loss: 0.099759 	 lr: 0.00024
[epoch 102:  20/307] 	 train loss: 0.103456 	 lr: 0.00024
[epoch 102:  40/307] 	 train loss: 0.233553 	 lr: 0.00024
[epoch 102:  60/307] 	 train loss: 0.234819 	 lr: 0.00024
[epoch 102:  80/307] 	 train loss: 0.126039 	 lr: 0.00024
[epoch 102: 100/307] 	 train loss: 0.309449 	 lr: 0.00024

val loss: 0.319284 	 acc: 0.907212

[epoch 102: 120/307] 	 train loss: 0.075217 	 lr: 0.00024
[epoch 102: 140/307] 	 train loss: 0.218796 	 lr: 0.00024
[epoch 102: 160/307] 	 train loss: 0.203005 	 lr: 0.00024
[epoch 102: 180/307] 	 train loss: 0.230499 	 lr: 0.00024
[epoch 102: 200/307] 	 train loss: 0.200919 	 lr: 0.00024
[epoch 102: 220/307] 	 train loss: 0.210597 	 lr: 0.00024
[epoch 102: 240/307] 	 train loss: 0.173923 	 lr: 0.00024

val loss: 0.330509 	 acc: 0.904781

[epoch 102: 260/307] 	 train loss: 0.180055 	 lr: 0.00024
[epoch 102: 280/307] 	 train loss: 0.197233 	 lr: 0.00024
[epoch 102: 300/307] 	 train loss: 0.324030 	 lr: 0.00024
[epoch 103:   0/307] 	 train loss: 0.303599 	 lr: 0.00024
[epoch 103:  20/307] 	 train loss: 0.369568 	 lr: 0.00024
[epoch 103:  40/307] 	 train loss: 0.367028 	 lr: 0.00024
[epoch 103:  60/307] 	 train loss: 0.226333 	 lr: 0.00024
[epoch 103:  80/307] 	 train loss: 0.190334 	 lr: 0.00024
[epoch 103: 100/307] 	 train loss: 0.261383 	 lr: 0.00024

val loss: 0.343834 	 acc: 0.904376

[epoch 103: 120/307] 	 train loss: 0.212129 	 lr: 0.00024
[epoch 103: 140/307] 	 train loss: 0.260414 	 lr: 0.00024
[epoch 103: 160/307] 	 train loss: 0.089381 	 lr: 0.00024
[epoch 103: 180/307] 	 train loss: 0.441736 	 lr: 0.00024
[epoch 103: 200/307] 	 train loss: 0.081447 	 lr: 0.00024
[epoch 103: 220/307] 	 train loss: 0.108454 	 lr: 0.00024
[epoch 103: 240/307] 	 train loss: 0.169994 	 lr: 0.00024

val loss: 0.331908 	 acc: 0.903971

[epoch 103: 260/307] 	 train loss: 0.179226 	 lr: 0.00024
[epoch 103: 280/307] 	 train loss: 0.659871 	 lr: 0.00024
[epoch 103: 300/307] 	 train loss: 0.210261 	 lr: 0.00024
[epoch 104:   0/307] 	 train loss: 0.232767 	 lr: 0.00024
[epoch 104:  20/307] 	 train loss: 0.255917 	 lr: 0.00024
[epoch 104:  40/307] 	 train loss: 0.098046 	 lr: 0.00024
[epoch 104:  60/307] 	 train loss: 0.325613 	 lr: 0.00024
[epoch 104:  80/307] 	 train loss: 0.112044 	 lr: 0.00024

val loss: 0.342054 	 acc: 0.905186

[epoch 104: 100/307] 	 train loss: 0.263741 	 lr: 0.00024
[epoch 104: 120/307] 	 train loss: 0.041858 	 lr: 0.00024
[epoch 104: 140/307] 	 train loss: 0.311204 	 lr: 0.00024
[epoch 104: 160/307] 	 train loss: 0.354640 	 lr: 0.00024
[epoch 104: 180/307] 	 train loss: 0.121431 	 lr: 0.00024
[epoch 104: 200/307] 	 train loss: 0.124578 	 lr: 0.00024
[epoch 104: 220/307] 	 train loss: 0.280045 	 lr: 0.00024
[epoch 104: 240/307] 	 train loss: 0.206658 	 lr: 0.00024

val loss: 0.326072 	 acc: 0.902350

[epoch 104: 260/307] 	 train loss: 0.243992 	 lr: 0.00024
[epoch 104: 280/307] 	 train loss: 0.346898 	 lr: 0.00024
[epoch 104: 300/307] 	 train loss: 0.286074 	 lr: 0.00024
[epoch 105:   0/307] 	 train loss: 0.315173 	 lr: 0.00024
[epoch 105:  20/307] 	 train loss: 0.128550 	 lr: 0.00024
[epoch 105:  40/307] 	 train loss: 0.137613 	 lr: 0.00024
[epoch 105:  60/307] 	 train loss: 0.233149 	 lr: 0.00024
[epoch 105:  80/307] 	 train loss: 0.472191 	 lr: 0.00024

val loss: 0.341536 	 acc: 0.903971

[epoch 105: 100/307] 	 train loss: 0.142603 	 lr: 0.00024
[epoch 105: 120/307] 	 train loss: 0.053828 	 lr: 0.00024
[epoch 105: 140/307] 	 train loss: 0.167263 	 lr: 0.00024
[epoch 105: 160/307] 	 train loss: 0.183330 	 lr: 0.00024
[epoch 105: 180/307] 	 train loss: 0.314455 	 lr: 0.00024
[epoch 105: 200/307] 	 train loss: 0.151732 	 lr: 0.00024
[epoch 105: 220/307] 	 train loss: 0.115462 	 lr: 0.00024
[epoch 105: 240/307] 	 train loss: 0.106526 	 lr: 0.00024

val loss: 0.330758 	 acc: 0.901540

[epoch 105: 260/307] 	 train loss: 0.191150 	 lr: 0.00024
[epoch 105: 280/307] 	 train loss: 0.153842 	 lr: 0.00024
[epoch 105: 300/307] 	 train loss: 0.318055 	 lr: 0.00024
[epoch 106:   0/307] 	 train loss: 0.153664 	 lr: 0.00017
[epoch 106:  20/307] 	 train loss: 0.141355 	 lr: 0.00017
[epoch 106:  40/307] 	 train loss: 0.178832 	 lr: 0.00017
[epoch 106:  60/307] 	 train loss: 0.261925 	 lr: 0.00017
[epoch 106:  80/307] 	 train loss: 0.198611 	 lr: 0.00017

val loss: 0.339597 	 acc: 0.908023

[epoch 106: 100/307] 	 train loss: 0.452648 	 lr: 0.00017
[epoch 106: 120/307] 	 train loss: 0.140253 	 lr: 0.00017
[epoch 106: 140/307] 	 train loss: 0.097760 	 lr: 0.00017
[epoch 106: 160/307] 	 train loss: 0.089138 	 lr: 0.00017
[epoch 106: 180/307] 	 train loss: 0.172271 	 lr: 0.00017
[epoch 106: 200/307] 	 train loss: 0.330464 	 lr: 0.00017
[epoch 106: 220/307] 	 train loss: 0.429445 	 lr: 0.00017
[epoch 106: 240/307] 	 train loss: 0.130676 	 lr: 0.00017

val loss: 0.308181 	 acc: 0.909238

[epoch 106: 260/307] 	 train loss: 0.399213 	 lr: 0.00017
[epoch 106: 280/307] 	 train loss: 0.253243 	 lr: 0.00017
[epoch 106: 300/307] 	 train loss: 0.584486 	 lr: 0.00017
[epoch 107:   0/307] 	 train loss: 0.300715 	 lr: 0.00017
[epoch 107:  20/307] 	 train loss: 0.199723 	 lr: 0.00017
[epoch 107:  40/307] 	 train loss: 0.109318 	 lr: 0.00017
[epoch 107:  60/307] 	 train loss: 0.179517 	 lr: 0.00017
[epoch 107:  80/307] 	 train loss: 0.480384 	 lr: 0.00017

val loss: 0.347993 	 acc: 0.904781

[epoch 107: 100/307] 	 train loss: 0.148805 	 lr: 0.00017
[epoch 107: 120/307] 	 train loss: 0.267608 	 lr: 0.00017
[epoch 107: 140/307] 	 train loss: 0.194247 	 lr: 0.00017
[epoch 107: 160/307] 	 train loss: 0.097835 	 lr: 0.00017
[epoch 107: 180/307] 	 train loss: 0.182687 	 lr: 0.00017
[epoch 107: 200/307] 	 train loss: 0.165788 	 lr: 0.00017
[epoch 107: 220/307] 	 train loss: 0.150413 	 lr: 0.00017
[epoch 107: 240/307] 	 train loss: 0.145866 	 lr: 0.00017

val loss: 0.322790 	 acc: 0.906402

[epoch 107: 260/307] 	 train loss: 0.140711 	 lr: 0.00017
[epoch 107: 280/307] 	 train loss: 0.070579 	 lr: 0.00017
[epoch 107: 300/307] 	 train loss: 0.285517 	 lr: 0.00017
[epoch 108:   0/307] 	 train loss: 0.270425 	 lr: 0.00017
[epoch 108:  20/307] 	 train loss: 0.117120 	 lr: 0.00017
[epoch 108:  40/307] 	 train loss: 0.224557 	 lr: 0.00017
[epoch 108:  60/307] 	 train loss: 0.182817 	 lr: 0.00017
[epoch 108:  80/307] 	 train loss: 0.162180 	 lr: 0.00017

val loss: 0.329747 	 acc: 0.905997

[epoch 108: 100/307] 	 train loss: 0.233088 	 lr: 0.00017
[epoch 108: 120/307] 	 train loss: 0.124398 	 lr: 0.00017
[epoch 108: 140/307] 	 train loss: 0.259990 	 lr: 0.00017
[epoch 108: 160/307] 	 train loss: 0.074867 	 lr: 0.00017
[epoch 108: 180/307] 	 train loss: 0.138905 	 lr: 0.00017
[epoch 108: 200/307] 	 train loss: 0.159917 	 lr: 0.00017
[epoch 108: 220/307] 	 train loss: 0.146137 	 lr: 0.00017
[epoch 108: 240/307] 	 train loss: 0.154368 	 lr: 0.00017

val loss: 0.332530 	 acc: 0.905592

[epoch 108: 260/307] 	 train loss: 0.182775 	 lr: 0.00017
[epoch 108: 280/307] 	 train loss: 0.179670 	 lr: 0.00017
[epoch 108: 300/307] 	 train loss: 0.045712 	 lr: 0.00017
[epoch 109:   0/307] 	 train loss: 0.258885 	 lr: 0.00017
[epoch 109:  20/307] 	 train loss: 0.160039 	 lr: 0.00017
[epoch 109:  40/307] 	 train loss: 0.142413 	 lr: 0.00017
[epoch 109:  60/307] 	 train loss: 0.071011 	 lr: 0.00017
[epoch 109:  80/307] 	 train loss: 0.221382 	 lr: 0.00017

val loss: 0.322983 	 acc: 0.904781

[epoch 109: 100/307] 	 train loss: 0.123632 	 lr: 0.00017
[epoch 109: 120/307] 	 train loss: 0.436135 	 lr: 0.00017
[epoch 109: 140/307] 	 train loss: 0.099210 	 lr: 0.00017
[epoch 109: 160/307] 	 train loss: 0.072970 	 lr: 0.00017
[epoch 109: 180/307] 	 train loss: 0.304078 	 lr: 0.00017
[epoch 109: 200/307] 	 train loss: 0.170455 	 lr: 0.00017
[epoch 109: 220/307] 	 train loss: 0.053518 	 lr: 0.00017
[epoch 109: 240/307] 	 train loss: 0.175189 	 lr: 0.00017

val loss: 0.328366 	 acc: 0.906402

[epoch 109: 260/307] 	 train loss: 0.256749 	 lr: 0.00017
[epoch 109: 280/307] 	 train loss: 0.400281 	 lr: 0.00017
[epoch 109: 300/307] 	 train loss: 0.147588 	 lr: 0.00017
[epoch 110:   0/307] 	 train loss: 0.135138 	 lr: 0.00017
[epoch 110:  20/307] 	 train loss: 0.144964 	 lr: 0.00017
[epoch 110:  40/307] 	 train loss: 0.076918 	 lr: 0.00017
[epoch 110:  60/307] 	 train loss: 0.378785 	 lr: 0.00017
[epoch 110:  80/307] 	 train loss: 0.242580 	 lr: 0.00017

val loss: 0.314017 	 acc: 0.908833

[epoch 110: 100/307] 	 train loss: 0.283946 	 lr: 0.00017
[epoch 110: 120/307] 	 train loss: 0.157920 	 lr: 0.00017
[epoch 110: 140/307] 	 train loss: 0.189042 	 lr: 0.00017
[epoch 110: 160/307] 	 train loss: 0.158965 	 lr: 0.00017
[epoch 110: 180/307] 	 train loss: 0.227896 	 lr: 0.00017
[epoch 110: 200/307] 	 train loss: 0.070974 	 lr: 0.00017
[epoch 110: 220/307] 	 train loss: 0.038354 	 lr: 0.00017
[epoch 110: 240/307] 	 train loss: 0.071104 	 lr: 0.00017

val loss: 0.344136 	 acc: 0.898703

[epoch 110: 260/307] 	 train loss: 0.062278 	 lr: 0.00017
[epoch 110: 280/307] 	 train loss: 0.063081 	 lr: 0.00017
[epoch 110: 300/307] 	 train loss: 0.089384 	 lr: 0.00017
[epoch 111:   0/307] 	 train loss: 0.383805 	 lr: 0.00017
[epoch 111:  20/307] 	 train loss: 0.067846 	 lr: 0.00017
[epoch 111:  40/307] 	 train loss: 0.164479 	 lr: 0.00017
[epoch 111:  60/307] 	 train loss: 0.077195 	 lr: 0.00017
[epoch 111:  80/307] 	 train loss: 0.238674 	 lr: 0.00017

val loss: 0.332251 	 acc: 0.904781

[epoch 111: 100/307] 	 train loss: 0.200482 	 lr: 0.00017
[epoch 111: 120/307] 	 train loss: 0.210695 	 lr: 0.00017
[epoch 111: 140/307] 	 train loss: 0.134605 	 lr: 0.00017
[epoch 111: 160/307] 	 train loss: 0.176727 	 lr: 0.00017
[epoch 111: 180/307] 	 train loss: 0.297351 	 lr: 0.00017
[epoch 111: 200/307] 	 train loss: 0.123934 	 lr: 0.00017
[epoch 111: 220/307] 	 train loss: 0.088596 	 lr: 0.00017

val loss: 0.338244 	 acc: 0.905592

[epoch 111: 240/307] 	 train loss: 0.087428 	 lr: 0.00017
[epoch 111: 260/307] 	 train loss: 0.080516 	 lr: 0.00017
[epoch 111: 280/307] 	 train loss: 0.301899 	 lr: 0.00017
[epoch 111: 300/307] 	 train loss: 0.282623 	 lr: 0.00017
[epoch 112:   0/307] 	 train loss: 0.100345 	 lr: 0.00017
[epoch 112:  20/307] 	 train loss: 0.099657 	 lr: 0.00017
[epoch 112:  40/307] 	 train loss: 0.330479 	 lr: 0.00017
[epoch 112:  60/307] 	 train loss: 0.213654 	 lr: 0.00017
[epoch 112:  80/307] 	 train loss: 0.294601 	 lr: 0.00017

val loss: 0.325170 	 acc: 0.906402

[epoch 112: 100/307] 	 train loss: 0.122446 	 lr: 0.00017
[epoch 112: 120/307] 	 train loss: 0.278466 	 lr: 0.00017
[epoch 112: 140/307] 	 train loss: 0.245474 	 lr: 0.00017
[epoch 112: 160/307] 	 train loss: 0.134755 	 lr: 0.00017
[epoch 112: 180/307] 	 train loss: 0.314633 	 lr: 0.00017
[epoch 112: 200/307] 	 train loss: 0.197684 	 lr: 0.00017
[epoch 112: 220/307] 	 train loss: 0.467819 	 lr: 0.00017

val loss: 0.318884 	 acc: 0.907618

[epoch 112: 240/307] 	 train loss: 0.212761 	 lr: 0.00017
[epoch 112: 260/307] 	 train loss: 0.175479 	 lr: 0.00017
[epoch 112: 280/307] 	 train loss: 0.236245 	 lr: 0.00017
[epoch 112: 300/307] 	 train loss: 0.121093 	 lr: 0.00017
[epoch 113:   0/307] 	 train loss: 0.212964 	 lr: 0.00017
[epoch 113:  20/307] 	 train loss: 0.639522 	 lr: 0.00017
[epoch 113:  40/307] 	 train loss: 0.227858 	 lr: 0.00017
[epoch 113:  60/307] 	 train loss: 0.118654 	 lr: 0.00017
[epoch 113:  80/307] 	 train loss: 0.173831 	 lr: 0.00017

val loss: 0.334443 	 acc: 0.909238

[epoch 113: 100/307] 	 train loss: 0.113166 	 lr: 0.00017
[epoch 113: 120/307] 	 train loss: 0.062453 	 lr: 0.00017
[epoch 113: 140/307] 	 train loss: 0.061829 	 lr: 0.00017
[epoch 113: 160/307] 	 train loss: 0.114680 	 lr: 0.00017
[epoch 113: 180/307] 	 train loss: 0.176922 	 lr: 0.00017
[epoch 113: 200/307] 	 train loss: 0.069228 	 lr: 0.00017
[epoch 113: 220/307] 	 train loss: 0.227527 	 lr: 0.00017

val loss: 0.330198 	 acc: 0.905997

[epoch 113: 240/307] 	 train loss: 0.160811 	 lr: 0.00017
[epoch 113: 260/307] 	 train loss: 0.051319 	 lr: 0.00017
[epoch 113: 280/307] 	 train loss: 0.195593 	 lr: 0.00017
[epoch 113: 300/307] 	 train loss: 0.253800 	 lr: 0.00017
[epoch 114:   0/307] 	 train loss: 0.457971 	 lr: 0.00017
[epoch 114:  20/307] 	 train loss: 0.150946 	 lr: 0.00017
[epoch 114:  40/307] 	 train loss: 0.132879 	 lr: 0.00017
[epoch 114:  60/307] 	 train loss: 0.110464 	 lr: 0.00017

val loss: 0.320243 	 acc: 0.903566

[epoch 114:  80/307] 	 train loss: 0.078473 	 lr: 0.00017
[epoch 114: 100/307] 	 train loss: 0.094568 	 lr: 0.00017
[epoch 114: 120/307] 	 train loss: 0.189183 	 lr: 0.00017
[epoch 114: 140/307] 	 train loss: 0.200056 	 lr: 0.00017
[epoch 114: 160/307] 	 train loss: 0.067426 	 lr: 0.00017
[epoch 114: 180/307] 	 train loss: 0.243736 	 lr: 0.00017
[epoch 114: 200/307] 	 train loss: 0.216339 	 lr: 0.00017
[epoch 114: 220/307] 	 train loss: 0.118686 	 lr: 0.00017

val loss: 0.336914 	 acc: 0.904781

[epoch 114: 240/307] 	 train loss: 0.145034 	 lr: 0.00017
[epoch 114: 260/307] 	 train loss: 0.434397 	 lr: 0.00017
[epoch 114: 280/307] 	 train loss: 0.347942 	 lr: 0.00017
[epoch 114: 300/307] 	 train loss: 0.224390 	 lr: 0.00017
[epoch 115:   0/307] 	 train loss: 0.389267 	 lr: 0.00017
[epoch 115:  20/307] 	 train loss: 0.130324 	 lr: 0.00017
[epoch 115:  40/307] 	 train loss: 0.193564 	 lr: 0.00017
[epoch 115:  60/307] 	 train loss: 0.118410 	 lr: 0.00017

val loss: 0.332049 	 acc: 0.908023

[epoch 115:  80/307] 	 train loss: 0.027101 	 lr: 0.00017
[epoch 115: 100/307] 	 train loss: 0.168393 	 lr: 0.00017
[epoch 115: 120/307] 	 train loss: 0.251275 	 lr: 0.00017
[epoch 115: 140/307] 	 train loss: 0.263362 	 lr: 0.00017
[epoch 115: 160/307] 	 train loss: 0.099504 	 lr: 0.00017
[epoch 115: 180/307] 	 train loss: 0.262274 	 lr: 0.00017
[epoch 115: 200/307] 	 train loss: 0.281559 	 lr: 0.00017
[epoch 115: 220/307] 	 train loss: 0.316946 	 lr: 0.00017

val loss: 0.331527 	 acc: 0.906807

[epoch 115: 240/307] 	 train loss: 0.223392 	 lr: 0.00017
[epoch 115: 260/307] 	 train loss: 0.227044 	 lr: 0.00017
[epoch 115: 280/307] 	 train loss: 0.090227 	 lr: 0.00017
[epoch 115: 300/307] 	 train loss: 0.032600 	 lr: 0.00017
[epoch 116:   0/307] 	 train loss: 0.122158 	 lr: 0.00017
[epoch 116:  20/307] 	 train loss: 0.208933 	 lr: 0.00017
[epoch 116:  40/307] 	 train loss: 0.343622 	 lr: 0.00017
[epoch 116:  60/307] 	 train loss: 0.210116 	 lr: 0.00017

val loss: 0.337396 	 acc: 0.908833

[epoch 116:  80/307] 	 train loss: 0.282821 	 lr: 0.00017
[epoch 116: 100/307] 	 train loss: 0.296502 	 lr: 0.00017
[epoch 116: 120/307] 	 train loss: 0.084664 	 lr: 0.00017
[epoch 116: 140/307] 	 train loss: 0.741938 	 lr: 0.00017
[epoch 116: 160/307] 	 train loss: 0.287011 	 lr: 0.00017
[epoch 116: 180/307] 	 train loss: 0.777745 	 lr: 0.00017
[epoch 116: 200/307] 	 train loss: 0.166127 	 lr: 0.00017
[epoch 116: 220/307] 	 train loss: 0.266086 	 lr: 0.00017

val loss: 0.323752 	 acc: 0.907618

[epoch 116: 240/307] 	 train loss: 0.186401 	 lr: 0.00017
[epoch 116: 260/307] 	 train loss: 0.527073 	 lr: 0.00017
[epoch 116: 280/307] 	 train loss: 0.258914 	 lr: 0.00017
[epoch 116: 300/307] 	 train loss: 0.122179 	 lr: 0.00017
[epoch 117:   0/307] 	 train loss: 0.176915 	 lr: 0.00017
[epoch 117:  20/307] 	 train loss: 0.193379 	 lr: 0.00017
[epoch 117:  40/307] 	 train loss: 0.073188 	 lr: 0.00017
[epoch 117:  60/307] 	 train loss: 0.129922 	 lr: 0.00017

val loss: 0.354751 	 acc: 0.899514

[epoch 117:  80/307] 	 train loss: 0.048802 	 lr: 0.00017
[epoch 117: 100/307] 	 train loss: 0.113778 	 lr: 0.00017
[epoch 117: 120/307] 	 train loss: 0.162148 	 lr: 0.00017
[epoch 117: 140/307] 	 train loss: 0.074013 	 lr: 0.00017
[epoch 117: 160/307] 	 train loss: 0.134291 	 lr: 0.00017
[epoch 117: 180/307] 	 train loss: 0.119838 	 lr: 0.00017
[epoch 117: 200/307] 	 train loss: 0.115900 	 lr: 0.00017
[epoch 117: 220/307] 	 train loss: 0.117641 	 lr: 0.00017

val loss: 0.328375 	 acc: 0.905592

[epoch 117: 240/307] 	 train loss: 0.197216 	 lr: 0.00017
[epoch 117: 260/307] 	 train loss: 0.226292 	 lr: 0.00017
[epoch 117: 280/307] 	 train loss: 0.170445 	 lr: 0.00017
[epoch 117: 300/307] 	 train loss: 0.141483 	 lr: 0.00017
[epoch 118:   0/307] 	 train loss: 0.268469 	 lr: 0.00017
[epoch 118:  20/307] 	 train loss: 0.111072 	 lr: 0.00017
[epoch 118:  40/307] 	 train loss: 0.167711 	 lr: 0.00017
[epoch 118:  60/307] 	 train loss: 0.128531 	 lr: 0.00017

val loss: 0.330982 	 acc: 0.906402

[epoch 118:  80/307] 	 train loss: 0.038501 	 lr: 0.00017
[epoch 118: 100/307] 	 train loss: 0.213336 	 lr: 0.00017
[epoch 118: 120/307] 	 train loss: 0.251890 	 lr: 0.00017
[epoch 118: 140/307] 	 train loss: 0.074993 	 lr: 0.00017
[epoch 118: 160/307] 	 train loss: 0.146803 	 lr: 0.00017
[epoch 118: 180/307] 	 train loss: 0.256569 	 lr: 0.00017
[epoch 118: 200/307] 	 train loss: 0.285910 	 lr: 0.00017
[epoch 118: 220/307] 	 train loss: 0.137669 	 lr: 0.00017

val loss: 0.335370 	 acc: 0.903160

[epoch 118: 240/307] 	 train loss: 0.058793 	 lr: 0.00017
[epoch 118: 260/307] 	 train loss: 0.313293 	 lr: 0.00017
[epoch 118: 280/307] 	 train loss: 0.127301 	 lr: 0.00017
[epoch 118: 300/307] 	 train loss: 0.112610 	 lr: 0.00017
[epoch 119:   0/307] 	 train loss: 0.317709 	 lr: 0.00017
[epoch 119:  20/307] 	 train loss: 0.315992 	 lr: 0.00017
[epoch 119:  40/307] 	 train loss: 0.323498 	 lr: 0.00017
[epoch 119:  60/307] 	 train loss: 0.211772 	 lr: 0.00017

val loss: 0.322688 	 acc: 0.909238

[epoch 119:  80/307] 	 train loss: 0.445930 	 lr: 0.00017
[epoch 119: 100/307] 	 train loss: 0.059840 	 lr: 0.00017
[epoch 119: 120/307] 	 train loss: 0.706859 	 lr: 0.00017
[epoch 119: 140/307] 	 train loss: 0.305991 	 lr: 0.00017
[epoch 119: 160/307] 	 train loss: 0.150130 	 lr: 0.00017
[epoch 119: 180/307] 	 train loss: 0.240906 	 lr: 0.00017
[epoch 119: 200/307] 	 train loss: 0.322547 	 lr: 0.00017
[epoch 119: 220/307] 	 train loss: 0.043291 	 lr: 0.00017

val loss: 0.330742 	 acc: 0.909238

[epoch 119: 240/307] 	 train loss: 0.062288 	 lr: 0.00017
[epoch 119: 260/307] 	 train loss: 0.086441 	 lr: 0.00017
[epoch 119: 280/307] 	 train loss: 0.173512 	 lr: 0.00017
[epoch 119: 300/307] 	 train loss: 0.499116 	 lr: 0.00017
[epoch 120:   0/307] 	 train loss: 0.213255 	 lr: 0.00017
[epoch 120:  20/307] 	 train loss: 0.055811 	 lr: 0.00017
[epoch 120:  40/307] 	 train loss: 0.201864 	 lr: 0.00017
[epoch 120:  60/307] 	 train loss: 0.226672 	 lr: 0.00017

val loss: 0.332117 	 acc: 0.905186

[epoch 120:  80/307] 	 train loss: 0.195818 	 lr: 0.00017
[epoch 120: 100/307] 	 train loss: 0.115862 	 lr: 0.00017
[epoch 120: 120/307] 	 train loss: 0.343778 	 lr: 0.00017
[epoch 120: 140/307] 	 train loss: 0.160533 	 lr: 0.00017
[epoch 120: 160/307] 	 train loss: 0.311394 	 lr: 0.00017
[epoch 120: 180/307] 	 train loss: 0.220638 	 lr: 0.00017
[epoch 120: 200/307] 	 train loss: 0.279252 	 lr: 0.00017
[epoch 120: 220/307] 	 train loss: 0.330357 	 lr: 0.00017

val loss: 0.334279 	 acc: 0.909238

[epoch 120: 240/307] 	 train loss: 0.128991 	 lr: 0.00017
[epoch 120: 260/307] 	 train loss: 0.367438 	 lr: 0.00017
[epoch 120: 280/307] 	 train loss: 0.217880 	 lr: 0.00017
[epoch 120: 300/307] 	 train loss: 0.158281 	 lr: 0.00017
[epoch 121:   0/307] 	 train loss: 0.203690 	 lr: 0.00017
[epoch 121:  20/307] 	 train loss: 0.321274 	 lr: 0.00017
[epoch 121:  40/307] 	 train loss: 0.607544 	 lr: 0.00017
[epoch 121:  60/307] 	 train loss: 0.166539 	 lr: 0.00017

val loss: 0.346339 	 acc: 0.903566

[epoch 121:  80/307] 	 train loss: 0.205189 	 lr: 0.00017
[epoch 121: 100/307] 	 train loss: 0.262799 	 lr: 0.00017
[epoch 121: 120/307] 	 train loss: 0.277956 	 lr: 0.00017
[epoch 121: 140/307] 	 train loss: 0.183225 	 lr: 0.00017
[epoch 121: 160/307] 	 train loss: 0.214487 	 lr: 0.00017
[epoch 121: 180/307] 	 train loss: 0.195427 	 lr: 0.00017
[epoch 121: 200/307] 	 train loss: 0.226853 	 lr: 0.00017

val loss: 0.345308 	 acc: 0.908428

[epoch 121: 220/307] 	 train loss: 0.183695 	 lr: 0.00017
[epoch 121: 240/307] 	 train loss: 0.092173 	 lr: 0.00017
[epoch 121: 260/307] 	 train loss: 0.042345 	 lr: 0.00017
[epoch 121: 280/307] 	 train loss: 0.224865 	 lr: 0.00017
[epoch 121: 300/307] 	 train loss: 0.309806 	 lr: 0.00017
[epoch 122:   0/307] 	 train loss: 0.137378 	 lr: 0.00017
[epoch 122:  20/307] 	 train loss: 0.102128 	 lr: 0.00017
[epoch 122:  40/307] 	 train loss: 0.202168 	 lr: 0.00017
[epoch 122:  60/307] 	 train loss: 0.098540 	 lr: 0.00017

val loss: 0.321602 	 acc: 0.908833

[epoch 122:  80/307] 	 train loss: 0.097272 	 lr: 0.00017
[epoch 122: 100/307] 	 train loss: 0.173223 	 lr: 0.00017
[epoch 122: 120/307] 	 train loss: 0.195873 	 lr: 0.00017
[epoch 122: 140/307] 	 train loss: 0.132531 	 lr: 0.00017
[epoch 122: 160/307] 	 train loss: 0.122595 	 lr: 0.00017
[epoch 122: 180/307] 	 train loss: 0.061145 	 lr: 0.00017
[epoch 122: 200/307] 	 train loss: 0.118711 	 lr: 0.00017

val loss: 0.334008 	 acc: 0.909643

[epoch 122: 220/307] 	 train loss: 0.244167 	 lr: 0.00017
[epoch 122: 240/307] 	 train loss: 0.174201 	 lr: 0.00017
[epoch 122: 260/307] 	 train loss: 0.058786 	 lr: 0.00017
[epoch 122: 280/307] 	 train loss: 0.261626 	 lr: 0.00017
[epoch 122: 300/307] 	 train loss: 0.045276 	 lr: 0.00017
[epoch 123:   0/307] 	 train loss: 0.168355 	 lr: 0.00017
[epoch 123:  20/307] 	 train loss: 0.245262 	 lr: 0.00017
[epoch 123:  40/307] 	 train loss: 0.131807 	 lr: 0.00017
[epoch 123:  60/307] 	 train loss: 0.119435 	 lr: 0.00017

val loss: 0.338009 	 acc: 0.907618

[epoch 123:  80/307] 	 train loss: 0.358773 	 lr: 0.00017
[epoch 123: 100/307] 	 train loss: 0.155431 	 lr: 0.00017
[epoch 123: 120/307] 	 train loss: 0.126474 	 lr: 0.00017
[epoch 123: 140/307] 	 train loss: 0.116593 	 lr: 0.00017
[epoch 123: 160/307] 	 train loss: 0.229702 	 lr: 0.00017
[epoch 123: 180/307] 	 train loss: 0.180995 	 lr: 0.00017
[epoch 123: 200/307] 	 train loss: 0.122419 	 lr: 0.00017

val loss: 0.344415 	 acc: 0.910049

[epoch 123: 220/307] 	 train loss: 0.182918 	 lr: 0.00017
[epoch 123: 240/307] 	 train loss: 0.134114 	 lr: 0.00017
[epoch 123: 260/307] 	 train loss: 0.070426 	 lr: 0.00017
[epoch 123: 280/307] 	 train loss: 0.120425 	 lr: 0.00017
[epoch 123: 300/307] 	 train loss: 0.257849 	 lr: 0.00017
[epoch 124:   0/307] 	 train loss: 0.243151 	 lr: 0.00017
[epoch 124:  20/307] 	 train loss: 0.255808 	 lr: 0.00017
[epoch 124:  40/307] 	 train loss: 0.069694 	 lr: 0.00017

val loss: 0.335349 	 acc: 0.899109

[epoch 124:  60/307] 	 train loss: 0.106304 	 lr: 0.00017
[epoch 124:  80/307] 	 train loss: 0.073985 	 lr: 0.00017
[epoch 124: 100/307] 	 train loss: 0.174809 	 lr: 0.00017
[epoch 124: 120/307] 	 train loss: 0.459210 	 lr: 0.00017
[epoch 124: 140/307] 	 train loss: 0.134645 	 lr: 0.00017
[epoch 124: 160/307] 	 train loss: 0.492215 	 lr: 0.00017
[epoch 124: 180/307] 	 train loss: 0.199590 	 lr: 0.00017
[epoch 124: 200/307] 	 train loss: 0.204715 	 lr: 0.00017

val loss: 0.339671 	 acc: 0.904781

[epoch 124: 220/307] 	 train loss: 0.112023 	 lr: 0.00017
[epoch 124: 240/307] 	 train loss: 0.312616 	 lr: 0.00017
[epoch 124: 260/307] 	 train loss: 0.291859 	 lr: 0.00017
[epoch 124: 280/307] 	 train loss: 0.023857 	 lr: 0.00017
[epoch 124: 300/307] 	 train loss: 0.329382 	 lr: 0.00017
[epoch 125:   0/307] 	 train loss: 0.223666 	 lr: 0.00017
[epoch 125:  20/307] 	 train loss: 0.165223 	 lr: 0.00017
[epoch 125:  40/307] 	 train loss: 0.187095 	 lr: 0.00017

val loss: 0.328681 	 acc: 0.910049

[epoch 125:  60/307] 	 train loss: 0.066952 	 lr: 0.00017
[epoch 125:  80/307] 	 train loss: 0.098573 	 lr: 0.00017
[epoch 125: 100/307] 	 train loss: 0.169065 	 lr: 0.00017
[epoch 125: 120/307] 	 train loss: 0.169538 	 lr: 0.00017
[epoch 125: 140/307] 	 train loss: 0.259174 	 lr: 0.00017
[epoch 125: 160/307] 	 train loss: 0.078397 	 lr: 0.00017
[epoch 125: 180/307] 	 train loss: 0.227246 	 lr: 0.00017
[epoch 125: 200/307] 	 train loss: 0.112013 	 lr: 0.00017

val loss: 0.341445 	 acc: 0.903566

[epoch 125: 220/307] 	 train loss: 0.363612 	 lr: 0.00017
[epoch 125: 240/307] 	 train loss: 0.251532 	 lr: 0.00017
[epoch 125: 260/307] 	 train loss: 0.205254 	 lr: 0.00017
[epoch 125: 280/307] 	 train loss: 0.037951 	 lr: 0.00017
[epoch 125: 300/307] 	 train loss: 0.139010 	 lr: 0.00017
[epoch 126:   0/307] 	 train loss: 0.268097 	 lr: 0.00017
[epoch 126:  20/307] 	 train loss: 0.389415 	 lr: 0.00017
[epoch 126:  40/307] 	 train loss: 0.323737 	 lr: 0.00017

val loss: 0.335608 	 acc: 0.903971

[epoch 126:  60/307] 	 train loss: 0.156364 	 lr: 0.00017
[epoch 126:  80/307] 	 train loss: 0.297528 	 lr: 0.00017
[epoch 126: 100/307] 	 train loss: 0.193096 	 lr: 0.00017
[epoch 126: 120/307] 	 train loss: 0.247680 	 lr: 0.00017
[epoch 126: 140/307] 	 train loss: 0.173658 	 lr: 0.00017
[epoch 126: 160/307] 	 train loss: 0.498635 	 lr: 0.00017
[epoch 126: 180/307] 	 train loss: 0.233570 	 lr: 0.00017
[epoch 126: 200/307] 	 train loss: 0.343800 	 lr: 0.00017

val loss: 0.323861 	 acc: 0.904376

[epoch 126: 220/307] 	 train loss: 0.135642 	 lr: 0.00017
[epoch 126: 240/307] 	 train loss: 0.071311 	 lr: 0.00017
[epoch 126: 260/307] 	 train loss: 0.167610 	 lr: 0.00017
[epoch 126: 280/307] 	 train loss: 0.228684 	 lr: 0.00017
[epoch 126: 300/307] 	 train loss: 0.278641 	 lr: 0.00017
[epoch 127:   0/307] 	 train loss: 0.219501 	 lr: 0.00012
[epoch 127:  20/307] 	 train loss: 0.151058 	 lr: 0.00012
[epoch 127:  40/307] 	 train loss: 0.201359 	 lr: 0.00012

val loss: 0.350431 	 acc: 0.906807

[epoch 127:  60/307] 	 train loss: 0.236579 	 lr: 0.00012
[epoch 127:  80/307] 	 train loss: 0.119059 	 lr: 0.00012
[epoch 127: 100/307] 	 train loss: 0.128527 	 lr: 0.00012
[epoch 127: 120/307] 	 train loss: 0.243932 	 lr: 0.00012
[epoch 127: 140/307] 	 train loss: 0.070867 	 lr: 0.00012
[epoch 127: 160/307] 	 train loss: 0.249985 	 lr: 0.00012
[epoch 127: 180/307] 	 train loss: 0.570585 	 lr: 0.00012
[epoch 127: 200/307] 	 train loss: 0.570147 	 lr: 0.00012

val loss: 0.338924 	 acc: 0.906402

[epoch 127: 220/307] 	 train loss: 0.126501 	 lr: 0.00012
[epoch 127: 240/307] 	 train loss: 0.243812 	 lr: 0.00012
[epoch 127: 260/307] 	 train loss: 0.134698 	 lr: 0.00012
[epoch 127: 280/307] 	 train loss: 0.292324 	 lr: 0.00012
[epoch 127: 300/307] 	 train loss: 0.140536 	 lr: 0.00012
[epoch 128:   0/307] 	 train loss: 0.143985 	 lr: 0.00012
[epoch 128:  20/307] 	 train loss: 0.204669 	 lr: 0.00012
[epoch 128:  40/307] 	 train loss: 0.258957 	 lr: 0.00012

val loss: 0.337809 	 acc: 0.904781

[epoch 128:  60/307] 	 train loss: 0.026521 	 lr: 0.00012
[epoch 128:  80/307] 	 train loss: 0.135536 	 lr: 0.00012
[epoch 128: 100/307] 	 train loss: 0.186092 	 lr: 0.00012
[epoch 128: 120/307] 	 train loss: 0.072559 	 lr: 0.00012
[epoch 128: 140/307] 	 train loss: 0.156311 	 lr: 0.00012
[epoch 128: 160/307] 	 train loss: 0.238279 	 lr: 0.00012
[epoch 128: 180/307] 	 train loss: 0.263167 	 lr: 0.00012
[epoch 128: 200/307] 	 train loss: 0.146892 	 lr: 0.00012

val loss: 0.338456 	 acc: 0.900729

[epoch 128: 220/307] 	 train loss: 0.072946 	 lr: 0.00012
[epoch 128: 240/307] 	 train loss: 0.150926 	 lr: 0.00012
[epoch 128: 260/307] 	 train loss: 0.077561 	 lr: 0.00012
[epoch 128: 280/307] 	 train loss: 0.108851 	 lr: 0.00012
[epoch 128: 300/307] 	 train loss: 0.125668 	 lr: 0.00012
[epoch 129:   0/307] 	 train loss: 0.242926 	 lr: 0.00012
[epoch 129:  20/307] 	 train loss: 0.301870 	 lr: 0.00012
[epoch 129:  40/307] 	 train loss: 0.316882 	 lr: 0.00012

val loss: 0.327998 	 acc: 0.909643

[epoch 129:  60/307] 	 train loss: 0.212916 	 lr: 0.00012
[epoch 129:  80/307] 	 train loss: 0.268745 	 lr: 0.00012
[epoch 129: 100/307] 	 train loss: 0.095803 	 lr: 0.00012
[epoch 129: 120/307] 	 train loss: 0.104514 	 lr: 0.00012
[epoch 129: 140/307] 	 train loss: 0.184917 	 lr: 0.00012
[epoch 129: 160/307] 	 train loss: 0.317110 	 lr: 0.00012
[epoch 129: 180/307] 	 train loss: 0.084532 	 lr: 0.00012
[epoch 129: 200/307] 	 train loss: 0.140230 	 lr: 0.00012

val loss: 0.332367 	 acc: 0.910859

[epoch 129: 220/307] 	 train loss: 0.300851 	 lr: 0.00012
[epoch 129: 240/307] 	 train loss: 0.238487 	 lr: 0.00012
[epoch 129: 260/307] 	 train loss: 0.150749 	 lr: 0.00012
[epoch 129: 280/307] 	 train loss: 0.204870 	 lr: 0.00012
[epoch 129: 300/307] 	 train loss: 0.152830 	 lr: 0.00012
[epoch 130:   0/307] 	 train loss: 0.258165 	 lr: 0.00012
[epoch 130:  20/307] 	 train loss: 0.397332 	 lr: 0.00012
[epoch 130:  40/307] 	 train loss: 0.345048 	 lr: 0.00012

val loss: 0.345809 	 acc: 0.906807

[epoch 130:  60/307] 	 train loss: 0.191220 	 lr: 0.00012
[epoch 130:  80/307] 	 train loss: 0.165364 	 lr: 0.00012
[epoch 130: 100/307] 	 train loss: 0.373249 	 lr: 0.00012
[epoch 130: 120/307] 	 train loss: 0.034395 	 lr: 0.00012
[epoch 130: 140/307] 	 train loss: 0.294867 	 lr: 0.00012
[epoch 130: 160/307] 	 train loss: 0.131852 	 lr: 0.00012
[epoch 130: 180/307] 	 train loss: 0.122258 	 lr: 0.00012
[epoch 130: 200/307] 	 train loss: 0.098528 	 lr: 0.00012

val loss: 0.318309 	 acc: 0.911669

[epoch 130: 220/307] 	 train loss: 0.232892 	 lr: 0.00012
[epoch 130: 240/307] 	 train loss: 0.091217 	 lr: 0.00012
[epoch 130: 260/307] 	 train loss: 0.169440 	 lr: 0.00012
[epoch 130: 280/307] 	 train loss: 0.315387 	 lr: 0.00012
[epoch 130: 300/307] 	 train loss: 0.163231 	 lr: 0.00012
[epoch 131:   0/307] 	 train loss: 0.340282 	 lr: 0.00012
[epoch 131:  20/307] 	 train loss: 0.230732 	 lr: 0.00012
[epoch 131:  40/307] 	 train loss: 0.138704 	 lr: 0.00012

val loss: 0.318360 	 acc: 0.912075

[epoch 131:  60/307] 	 train loss: 0.090544 	 lr: 0.00012
[epoch 131:  80/307] 	 train loss: 0.355905 	 lr: 0.00012
[epoch 131: 100/307] 	 train loss: 0.061180 	 lr: 0.00012
[epoch 131: 120/307] 	 train loss: 0.261430 	 lr: 0.00012
[epoch 131: 140/307] 	 train loss: 0.098502 	 lr: 0.00012
[epoch 131: 160/307] 	 train loss: 0.325272 	 lr: 0.00012
[epoch 131: 180/307] 	 train loss: 0.361941 	 lr: 0.00012

val loss: 0.339000 	 acc: 0.907212

[epoch 131: 200/307] 	 train loss: 0.242141 	 lr: 0.00012
[epoch 131: 220/307] 	 train loss: 0.265432 	 lr: 0.00012
[epoch 131: 240/307] 	 train loss: 0.187918 	 lr: 0.00012
[epoch 131: 260/307] 	 train loss: 0.091684 	 lr: 0.00012
[epoch 131: 280/307] 	 train loss: 0.191104 	 lr: 0.00012
[epoch 131: 300/307] 	 train loss: 0.131899 	 lr: 0.00012
[epoch 132:   0/307] 	 train loss: 0.094769 	 lr: 0.00012
[epoch 132:  20/307] 	 train loss: 0.300344 	 lr: 0.00012
[epoch 132:  40/307] 	 train loss: 0.381135 	 lr: 0.00012

val loss: 0.354281 	 acc: 0.901135

[epoch 132:  60/307] 	 train loss: 0.067241 	 lr: 0.00012
[epoch 132:  80/307] 	 train loss: 0.098431 	 lr: 0.00012
[epoch 132: 100/307] 	 train loss: 0.201703 	 lr: 0.00012
[epoch 132: 120/307] 	 train loss: 0.117685 	 lr: 0.00012
[epoch 132: 140/307] 	 train loss: 0.135112 	 lr: 0.00012
[epoch 132: 160/307] 	 train loss: 0.177234 	 lr: 0.00012
[epoch 132: 180/307] 	 train loss: 0.045692 	 lr: 0.00012

val loss: 0.331279 	 acc: 0.913695

[epoch 132: 200/307] 	 train loss: 0.280708 	 lr: 0.00012
[epoch 132: 220/307] 	 train loss: 0.112422 	 lr: 0.00012
[epoch 132: 240/307] 	 train loss: 0.119672 	 lr: 0.00012
[epoch 132: 260/307] 	 train loss: 0.077513 	 lr: 0.00012
[epoch 132: 280/307] 	 train loss: 0.300833 	 lr: 0.00012
[epoch 132: 300/307] 	 train loss: 0.242272 	 lr: 0.00012
[epoch 133:   0/307] 	 train loss: 0.334393 	 lr: 0.00012
[epoch 133:  20/307] 	 train loss: 0.216600 	 lr: 0.00012
[epoch 133:  40/307] 	 train loss: 0.131353 	 lr: 0.00012

val loss: 0.330413 	 acc: 0.909238

[epoch 133:  60/307] 	 train loss: 0.106921 	 lr: 0.00012
[epoch 133:  80/307] 	 train loss: 0.039555 	 lr: 0.00012
[epoch 133: 100/307] 	 train loss: 0.347356 	 lr: 0.00012
[epoch 133: 120/307] 	 train loss: 0.308221 	 lr: 0.00012
[epoch 133: 140/307] 	 train loss: 0.154693 	 lr: 0.00012
[epoch 133: 160/307] 	 train loss: 0.264429 	 lr: 0.00012
[epoch 133: 180/307] 	 train loss: 0.063319 	 lr: 0.00012

val loss: 0.329384 	 acc: 0.910859

[epoch 133: 200/307] 	 train loss: 0.285911 	 lr: 0.00012
[epoch 133: 220/307] 	 train loss: 0.147552 	 lr: 0.00012
[epoch 133: 240/307] 	 train loss: 0.114478 	 lr: 0.00012
[epoch 133: 260/307] 	 train loss: 0.124391 	 lr: 0.00012
[epoch 133: 280/307] 	 train loss: 0.084026 	 lr: 0.00012
[epoch 133: 300/307] 	 train loss: 0.272869 	 lr: 0.00012
[epoch 134:   0/307] 	 train loss: 0.239580 	 lr: 0.00012
[epoch 134:  20/307] 	 train loss: 0.189785 	 lr: 0.00012

val loss: 0.325615 	 acc: 0.905997

[epoch 134:  40/307] 	 train loss: 0.101085 	 lr: 0.00012
[epoch 134:  60/307] 	 train loss: 0.205809 	 lr: 0.00012
[epoch 134:  80/307] 	 train loss: 0.124581 	 lr: 0.00012
[epoch 134: 100/307] 	 train loss: 0.124496 	 lr: 0.00012
[epoch 134: 120/307] 	 train loss: 0.049101 	 lr: 0.00012
[epoch 134: 140/307] 	 train loss: 0.026765 	 lr: 0.00012
[epoch 134: 160/307] 	 train loss: 0.340679 	 lr: 0.00012
[epoch 134: 180/307] 	 train loss: 0.121428 	 lr: 0.00012

val loss: 0.316406 	 acc: 0.912885

[epoch 134: 200/307] 	 train loss: 0.359245 	 lr: 0.00012
[epoch 134: 220/307] 	 train loss: 0.059859 	 lr: 0.00012
[epoch 134: 240/307] 	 train loss: 0.227780 	 lr: 0.00012
[epoch 134: 260/307] 	 train loss: 0.063183 	 lr: 0.00012
[epoch 134: 280/307] 	 train loss: 0.115321 	 lr: 0.00012
[epoch 134: 300/307] 	 train loss: 0.192542 	 lr: 0.00012
[epoch 135:   0/307] 	 train loss: 0.268158 	 lr: 0.00012
[epoch 135:  20/307] 	 train loss: 0.115948 	 lr: 0.00012

val loss: 0.323595 	 acc: 0.911669

[epoch 135:  40/307] 	 train loss: 0.120691 	 lr: 0.00012
[epoch 135:  60/307] 	 train loss: 0.046355 	 lr: 0.00012
[epoch 135:  80/307] 	 train loss: 0.203382 	 lr: 0.00012
[epoch 135: 100/307] 	 train loss: 0.132025 	 lr: 0.00012
[epoch 135: 120/307] 	 train loss: 0.076331 	 lr: 0.00012
[epoch 135: 140/307] 	 train loss: 0.159338 	 lr: 0.00012
[epoch 135: 160/307] 	 train loss: 0.167335 	 lr: 0.00012
[epoch 135: 180/307] 	 train loss: 0.350963 	 lr: 0.00012

val loss: 0.339898 	 acc: 0.905592

[epoch 135: 200/307] 	 train loss: 0.095464 	 lr: 0.00012
[epoch 135: 220/307] 	 train loss: 0.051824 	 lr: 0.00012
[epoch 135: 240/307] 	 train loss: 0.345391 	 lr: 0.00012
[epoch 135: 260/307] 	 train loss: 0.369170 	 lr: 0.00012
[epoch 135: 280/307] 	 train loss: 0.193401 	 lr: 0.00012
[epoch 135: 300/307] 	 train loss: 0.145681 	 lr: 0.00012
[epoch 136:   0/307] 	 train loss: 0.193604 	 lr: 0.00012
[epoch 136:  20/307] 	 train loss: 0.247119 	 lr: 0.00012

val loss: 0.333676 	 acc: 0.912075

[epoch 136:  40/307] 	 train loss: 0.141534 	 lr: 0.00012
[epoch 136:  60/307] 	 train loss: 0.202383 	 lr: 0.00012
[epoch 136:  80/307] 	 train loss: 0.149386 	 lr: 0.00012
[epoch 136: 100/307] 	 train loss: 0.398975 	 lr: 0.00012
[epoch 136: 120/307] 	 train loss: 0.079520 	 lr: 0.00012
[epoch 136: 140/307] 	 train loss: 0.301675 	 lr: 0.00012
[epoch 136: 160/307] 	 train loss: 0.172334 	 lr: 0.00012
[epoch 136: 180/307] 	 train loss: 0.107897 	 lr: 0.00012

val loss: 0.347868 	 acc: 0.905592

[epoch 136: 200/307] 	 train loss: 0.037849 	 lr: 0.00012
[epoch 136: 220/307] 	 train loss: 0.086887 	 lr: 0.00012
[epoch 136: 240/307] 	 train loss: 0.125835 	 lr: 0.00012
[epoch 136: 260/307] 	 train loss: 0.236034 	 lr: 0.00012
[epoch 136: 280/307] 	 train loss: 0.220194 	 lr: 0.00012
[epoch 136: 300/307] 	 train loss: 0.191983 	 lr: 0.00012
[epoch 137:   0/307] 	 train loss: 0.097852 	 lr: 0.00012
[epoch 137:  20/307] 	 train loss: 0.095794 	 lr: 0.00012

val loss: 0.339937 	 acc: 0.910049

[epoch 137:  40/307] 	 train loss: 0.075967 	 lr: 0.00012
[epoch 137:  60/307] 	 train loss: 0.313053 	 lr: 0.00012
[epoch 137:  80/307] 	 train loss: 0.289361 	 lr: 0.00012
[epoch 137: 100/307] 	 train loss: 0.217552 	 lr: 0.00012
[epoch 137: 120/307] 	 train loss: 0.215071 	 lr: 0.00012
[epoch 137: 140/307] 	 train loss: 0.100885 	 lr: 0.00012
[epoch 137: 160/307] 	 train loss: 0.017622 	 lr: 0.00012
[epoch 137: 180/307] 	 train loss: 0.098314 	 lr: 0.00012

val loss: 0.326618 	 acc: 0.904376

[epoch 137: 200/307] 	 train loss: 0.383355 	 lr: 0.00012
[epoch 137: 220/307] 	 train loss: 0.045144 	 lr: 0.00012
[epoch 137: 240/307] 	 train loss: 0.122810 	 lr: 0.00012
[epoch 137: 260/307] 	 train loss: 0.162781 	 lr: 0.00012
[epoch 137: 280/307] 	 train loss: 0.141920 	 lr: 0.00012
[epoch 137: 300/307] 	 train loss: 0.183775 	 lr: 0.00012
[epoch 138:   0/307] 	 train loss: 0.223074 	 lr: 0.00012
[epoch 138:  20/307] 	 train loss: 0.110288 	 lr: 0.00012

val loss: 0.323010 	 acc: 0.908023

[epoch 138:  40/307] 	 train loss: 0.153374 	 lr: 0.00012
[epoch 138:  60/307] 	 train loss: 0.063873 	 lr: 0.00012
[epoch 138:  80/307] 	 train loss: 0.130933 	 lr: 0.00012
[epoch 138: 100/307] 	 train loss: 0.113302 	 lr: 0.00012
[epoch 138: 120/307] 	 train loss: 0.453262 	 lr: 0.00012
[epoch 138: 140/307] 	 train loss: 0.176477 	 lr: 0.00012
[epoch 138: 160/307] 	 train loss: 0.157180 	 lr: 0.00012
[epoch 138: 180/307] 	 train loss: 0.175660 	 lr: 0.00012

val loss: 0.327433 	 acc: 0.909238

[epoch 138: 200/307] 	 train loss: 0.150067 	 lr: 0.00012
[epoch 138: 220/307] 	 train loss: 0.311765 	 lr: 0.00012
[epoch 138: 240/307] 	 train loss: 0.067311 	 lr: 0.00012
[epoch 138: 260/307] 	 train loss: 0.224293 	 lr: 0.00012
[epoch 138: 280/307] 	 train loss: 0.058494 	 lr: 0.00012
[epoch 138: 300/307] 	 train loss: 0.176172 	 lr: 0.00012
[epoch 139:   0/307] 	 train loss: 0.209173 	 lr: 0.00012
[epoch 139:  20/307] 	 train loss: 0.175257 	 lr: 0.00012

val loss: 0.335497 	 acc: 0.904781

[epoch 139:  40/307] 	 train loss: 0.173876 	 lr: 0.00012
[epoch 139:  60/307] 	 train loss: 0.154826 	 lr: 0.00012
[epoch 139:  80/307] 	 train loss: 0.061678 	 lr: 0.00012
[epoch 139: 100/307] 	 train loss: 0.112004 	 lr: 0.00012
[epoch 139: 120/307] 	 train loss: 0.212434 	 lr: 0.00012
[epoch 139: 140/307] 	 train loss: 0.352544 	 lr: 0.00012
[epoch 139: 160/307] 	 train loss: 0.254575 	 lr: 0.00012
[epoch 139: 180/307] 	 train loss: 0.392513 	 lr: 0.00012

val loss: 0.343403 	 acc: 0.907618

[epoch 139: 200/307] 	 train loss: 0.143028 	 lr: 0.00012
[epoch 139: 220/307] 	 train loss: 0.407982 	 lr: 0.00012
[epoch 139: 240/307] 	 train loss: 0.103591 	 lr: 0.00012
[epoch 139: 260/307] 	 train loss: 0.423807 	 lr: 0.00012
[epoch 139: 280/307] 	 train loss: 0.248186 	 lr: 0.00012
[epoch 139: 300/307] 	 train loss: 0.233076 	 lr: 0.00012
[epoch 140:   0/307] 	 train loss: 0.082802 	 lr: 0.00012
[epoch 140:  20/307] 	 train loss: 0.068444 	 lr: 0.00012

val loss: 0.326945 	 acc: 0.904781

[epoch 140:  40/307] 	 train loss: 0.243482 	 lr: 0.00012
[epoch 140:  60/307] 	 train loss: 0.089587 	 lr: 0.00012
[epoch 140:  80/307] 	 train loss: 0.117317 	 lr: 0.00012
[epoch 140: 100/307] 	 train loss: 0.159671 	 lr: 0.00012
[epoch 140: 120/307] 	 train loss: 0.693443 	 lr: 0.00012
[epoch 140: 140/307] 	 train loss: 0.082533 	 lr: 0.00012
[epoch 140: 160/307] 	 train loss: 0.110895 	 lr: 0.00012
[epoch 140: 180/307] 	 train loss: 0.238444 	 lr: 0.00012

val loss: 0.348981 	 acc: 0.902350

[epoch 140: 200/307] 	 train loss: 0.110997 	 lr: 0.00012
[epoch 140: 220/307] 	 train loss: 0.195896 	 lr: 0.00012
[epoch 140: 240/307] 	 train loss: 0.179912 	 lr: 0.00012
[epoch 140: 260/307] 	 train loss: 0.090174 	 lr: 0.00012
[epoch 140: 280/307] 	 train loss: 0.109691 	 lr: 0.00012
[epoch 140: 300/307] 	 train loss: 0.076587 	 lr: 0.00012
[epoch 141:   0/307] 	 train loss: 0.284739 	 lr: 0.00012
[epoch 141:  20/307] 	 train loss: 0.232356 	 lr: 0.00012

val loss: 0.330521 	 acc: 0.905997

[epoch 141:  40/307] 	 train loss: 0.236852 	 lr: 0.00012
[epoch 141:  60/307] 	 train loss: 0.120174 	 lr: 0.00012
[epoch 141:  80/307] 	 train loss: 0.245781 	 lr: 0.00012
[epoch 141: 100/307] 	 train loss: 0.273006 	 lr: 0.00012
[epoch 141: 120/307] 	 train loss: 0.065969 	 lr: 0.00012
[epoch 141: 140/307] 	 train loss: 0.350075 	 lr: 0.00012
[epoch 141: 160/307] 	 train loss: 0.080310 	 lr: 0.00012

val loss: 0.342476 	 acc: 0.908023

[epoch 141: 180/307] 	 train loss: 0.195721 	 lr: 0.00012
[epoch 141: 200/307] 	 train loss: 0.266434 	 lr: 0.00012
[epoch 141: 220/307] 	 train loss: 0.119709 	 lr: 0.00012
[epoch 141: 240/307] 	 train loss: 0.132328 	 lr: 0.00012
[epoch 141: 260/307] 	 train loss: 0.149271 	 lr: 0.00012
[epoch 141: 280/307] 	 train loss: 0.223178 	 lr: 0.00012
[epoch 141: 300/307] 	 train loss: 0.103593 	 lr: 0.00012
[epoch 142:   0/307] 	 train loss: 0.165500 	 lr: 0.00012
[epoch 142:  20/307] 	 train loss: 0.045619 	 lr: 0.00012

val loss: 0.346054 	 acc: 0.906402

[epoch 142:  40/307] 	 train loss: 0.504343 	 lr: 0.00012
[epoch 142:  60/307] 	 train loss: 0.124915 	 lr: 0.00012
[epoch 142:  80/307] 	 train loss: 0.113171 	 lr: 0.00012
[epoch 142: 100/307] 	 train loss: 0.135080 	 lr: 0.00012
[epoch 142: 120/307] 	 train loss: 0.174744 	 lr: 0.00012
[epoch 142: 140/307] 	 train loss: 0.111886 	 lr: 0.00012
[epoch 142: 160/307] 	 train loss: 0.173733 	 lr: 0.00012

val loss: 0.335931 	 acc: 0.909643

[epoch 142: 180/307] 	 train loss: 0.190085 	 lr: 0.00012
[epoch 142: 200/307] 	 train loss: 0.160670 	 lr: 0.00012
[epoch 142: 220/307] 	 train loss: 0.109107 	 lr: 0.00012
[epoch 142: 240/307] 	 train loss: 0.084072 	 lr: 0.00012
[epoch 142: 260/307] 	 train loss: 0.112783 	 lr: 0.00012
[epoch 142: 280/307] 	 train loss: 0.114318 	 lr: 0.00012
[epoch 142: 300/307] 	 train loss: 0.196171 	 lr: 0.00012
[epoch 143:   0/307] 	 train loss: 0.058906 	 lr: 0.00012
[epoch 143:  20/307] 	 train loss: 0.180499 	 lr: 0.00012

val loss: 0.343461 	 acc: 0.902755

[epoch 143:  40/307] 	 train loss: 0.172910 	 lr: 0.00012
[epoch 143:  60/307] 	 train loss: 0.253327 	 lr: 0.00012
[epoch 143:  80/307] 	 train loss: 0.271940 	 lr: 0.00012
[epoch 143: 100/307] 	 train loss: 0.198022 	 lr: 0.00012
[epoch 143: 120/307] 	 train loss: 0.162199 	 lr: 0.00012
[epoch 143: 140/307] 	 train loss: 0.196152 	 lr: 0.00012
[epoch 143: 160/307] 	 train loss: 0.271887 	 lr: 0.00012

val loss: 0.326595 	 acc: 0.912885

[epoch 143: 180/307] 	 train loss: 0.146562 	 lr: 0.00012
[epoch 143: 200/307] 	 train loss: 0.090029 	 lr: 0.00012
[epoch 143: 220/307] 	 train loss: 0.090011 	 lr: 0.00012
[epoch 143: 240/307] 	 train loss: 0.187101 	 lr: 0.00012
[epoch 143: 260/307] 	 train loss: 0.242539 	 lr: 0.00012
[epoch 143: 280/307] 	 train loss: 0.121993 	 lr: 0.00012
[epoch 143: 300/307] 	 train loss: 0.261713 	 lr: 0.00012
[epoch 144:   0/307] 	 train loss: 0.046108 	 lr: 0.00012

val loss: 0.326261 	 acc: 0.911669

[epoch 144:  20/307] 	 train loss: 0.071715 	 lr: 0.00012
[epoch 144:  40/307] 	 train loss: 0.248017 	 lr: 0.00012
[epoch 144:  60/307] 	 train loss: 0.131509 	 lr: 0.00012
[epoch 144:  80/307] 	 train loss: 0.317717 	 lr: 0.00012
[epoch 144: 100/307] 	 train loss: 0.343926 	 lr: 0.00012
[epoch 144: 120/307] 	 train loss: 0.158350 	 lr: 0.00012
[epoch 144: 140/307] 	 train loss: 0.222082 	 lr: 0.00012
[epoch 144: 160/307] 	 train loss: 0.050897 	 lr: 0.00012

val loss: 0.339635 	 acc: 0.907618

[epoch 144: 180/307] 	 train loss: 0.205122 	 lr: 0.00012
[epoch 144: 200/307] 	 train loss: 0.175916 	 lr: 0.00012
[epoch 144: 220/307] 	 train loss: 0.260227 	 lr: 0.00012
[epoch 144: 240/307] 	 train loss: 0.084437 	 lr: 0.00012
[epoch 144: 260/307] 	 train loss: 0.437150 	 lr: 0.00012
[epoch 144: 280/307] 	 train loss: 0.190877 	 lr: 0.00012
[epoch 144: 300/307] 	 train loss: 0.397335 	 lr: 0.00012
[epoch 145:   0/307] 	 train loss: 0.242937 	 lr: 0.00012

val loss: 0.336844 	 acc: 0.908833

[epoch 145:  20/307] 	 train loss: 0.191199 	 lr: 0.00012
[epoch 145:  40/307] 	 train loss: 0.131192 	 lr: 0.00012
[epoch 145:  60/307] 	 train loss: 0.053916 	 lr: 0.00012
[epoch 145:  80/307] 	 train loss: 0.120829 	 lr: 0.00012
[epoch 145: 100/307] 	 train loss: 0.051893 	 lr: 0.00012
[epoch 145: 120/307] 	 train loss: 0.098564 	 lr: 0.00012
[epoch 145: 140/307] 	 train loss: 0.200739 	 lr: 0.00012
[epoch 145: 160/307] 	 train loss: 0.111172 	 lr: 0.00012

val loss: 0.323465 	 acc: 0.908428

[epoch 145: 180/307] 	 train loss: 0.265099 	 lr: 0.00012
[epoch 145: 200/307] 	 train loss: 0.173693 	 lr: 0.00012
[epoch 145: 220/307] 	 train loss: 0.513851 	 lr: 0.00012
[epoch 145: 240/307] 	 train loss: 0.161594 	 lr: 0.00012
[epoch 145: 260/307] 	 train loss: 0.468086 	 lr: 0.00012
[epoch 145: 280/307] 	 train loss: 0.048402 	 lr: 0.00012
[epoch 145: 300/307] 	 train loss: 0.105379 	 lr: 0.00012
[epoch 146:   0/307] 	 train loss: 0.238521 	 lr: 0.00012

val loss: 0.328425 	 acc: 0.909643

[epoch 146:  20/307] 	 train loss: 0.196309 	 lr: 0.00012
[epoch 146:  40/307] 	 train loss: 0.100722 	 lr: 0.00012
[epoch 146:  60/307] 	 train loss: 0.277705 	 lr: 0.00012
[epoch 146:  80/307] 	 train loss: 0.081636 	 lr: 0.00012
[epoch 146: 100/307] 	 train loss: 0.141930 	 lr: 0.00012
[epoch 146: 120/307] 	 train loss: 0.193651 	 lr: 0.00012
[epoch 146: 140/307] 	 train loss: 0.125058 	 lr: 0.00012
[epoch 146: 160/307] 	 train loss: 0.159061 	 lr: 0.00012

val loss: 0.348108 	 acc: 0.906807

[epoch 146: 180/307] 	 train loss: 0.139508 	 lr: 0.00012
[epoch 146: 200/307] 	 train loss: 0.165297 	 lr: 0.00012
[epoch 146: 220/307] 	 train loss: 0.145815 	 lr: 0.00012
[epoch 146: 240/307] 	 train loss: 0.023158 	 lr: 0.00012
[epoch 146: 260/307] 	 train loss: 0.157671 	 lr: 0.00012
[epoch 146: 280/307] 	 train loss: 0.147467 	 lr: 0.00012
[epoch 146: 300/307] 	 train loss: 0.180586 	 lr: 0.00012
[epoch 147:   0/307] 	 train loss: 0.059547 	 lr: 0.00012

val loss: 0.326400 	 acc: 0.910049

[epoch 147:  20/307] 	 train loss: 0.297687 	 lr: 0.00012
[epoch 147:  40/307] 	 train loss: 0.155556 	 lr: 0.00012
[epoch 147:  60/307] 	 train loss: 0.269885 	 lr: 0.00012
[epoch 147:  80/307] 	 train loss: 0.196067 	 lr: 0.00012
[epoch 147: 100/307] 	 train loss: 0.168165 	 lr: 0.00012
[epoch 147: 120/307] 	 train loss: 0.256548 	 lr: 0.00012
[epoch 147: 140/307] 	 train loss: 0.225432 	 lr: 0.00012
[epoch 147: 160/307] 	 train loss: 0.145325 	 lr: 0.00012

val loss: 0.322825 	 acc: 0.912885

[epoch 147: 180/307] 	 train loss: 0.146408 	 lr: 0.00012
[epoch 147: 200/307] 	 train loss: 0.212232 	 lr: 0.00012
[epoch 147: 220/307] 	 train loss: 0.248599 	 lr: 0.00012
[epoch 147: 240/307] 	 train loss: 0.123917 	 lr: 0.00012
[epoch 147: 260/307] 	 train loss: 0.153280 	 lr: 0.00012
[epoch 147: 280/307] 	 train loss: 0.075664 	 lr: 0.00012
[epoch 147: 300/307] 	 train loss: 0.114580 	 lr: 0.00012
[epoch 148:   0/307] 	 train loss: 0.075983 	 lr: 0.00008

val loss: 0.340748 	 acc: 0.902755

[epoch 148:  20/307] 	 train loss: 0.085668 	 lr: 0.00008
[epoch 148:  40/307] 	 train loss: 0.182642 	 lr: 0.00008
[epoch 148:  60/307] 	 train loss: 0.158761 	 lr: 0.00008
[epoch 148:  80/307] 	 train loss: 0.115423 	 lr: 0.00008
[epoch 148: 100/307] 	 train loss: 0.423943 	 lr: 0.00008
[epoch 148: 120/307] 	 train loss: 0.398203 	 lr: 0.00008
[epoch 148: 140/307] 	 train loss: 0.219990 	 lr: 0.00008
[epoch 148: 160/307] 	 train loss: 0.154826 	 lr: 0.00008

val loss: 0.332230 	 acc: 0.903971

[epoch 148: 180/307] 	 train loss: 0.317918 	 lr: 0.00008
[epoch 148: 200/307] 	 train loss: 0.299037 	 lr: 0.00008
[epoch 148: 220/307] 	 train loss: 0.343224 	 lr: 0.00008
[epoch 148: 240/307] 	 train loss: 0.221878 	 lr: 0.00008
[epoch 148: 260/307] 	 train loss: 0.094493 	 lr: 0.00008
[epoch 148: 280/307] 	 train loss: 0.282770 	 lr: 0.00008
[epoch 148: 300/307] 	 train loss: 0.035623 	 lr: 0.00008
[epoch 149:   0/307] 	 train loss: 0.194759 	 lr: 0.00008

val loss: 0.323897 	 acc: 0.908428

[epoch 149:  20/307] 	 train loss: 0.165187 	 lr: 0.00008
[epoch 149:  40/307] 	 train loss: 0.128964 	 lr: 0.00008
[epoch 149:  60/307] 	 train loss: 0.115981 	 lr: 0.00008
[epoch 149:  80/307] 	 train loss: 0.170493 	 lr: 0.00008
[epoch 149: 100/307] 	 train loss: 0.030906 	 lr: 0.00008
[epoch 149: 120/307] 	 train loss: 0.137579 	 lr: 0.00008
[epoch 149: 140/307] 	 train loss: 0.091691 	 lr: 0.00008
[epoch 149: 160/307] 	 train loss: 0.204698 	 lr: 0.00008

val loss: 0.334512 	 acc: 0.908833

[epoch 149: 180/307] 	 train loss: 0.091141 	 lr: 0.00008
[epoch 149: 200/307] 	 train loss: 0.128508 	 lr: 0.00008
[epoch 149: 220/307] 	 train loss: 0.092565 	 lr: 0.00008
[epoch 149: 240/307] 	 train loss: 0.187788 	 lr: 0.00008
[epoch 149: 260/307] 	 train loss: 0.080747 	 lr: 0.00008
[epoch 149: 280/307] 	 train loss: 0.162843 	 lr: 0.00008
[epoch 149: 300/307] 	 train loss: 0.034125 	 lr: 0.00008
[epoch 150:   0/307] 	 train loss: 0.079561 	 lr: 0.00008

val loss: 0.345380 	 acc: 0.909643

[epoch 150:  20/307] 	 train loss: 0.192981 	 lr: 0.00008
[epoch 150:  40/307] 	 train loss: 0.277207 	 lr: 0.00008
[epoch 150:  60/307] 	 train loss: 0.030452 	 lr: 0.00008
[epoch 150:  80/307] 	 train loss: 0.203225 	 lr: 0.00008
[epoch 150: 100/307] 	 train loss: 0.147749 	 lr: 0.00008
[epoch 150: 120/307] 	 train loss: 0.394005 	 lr: 0.00008
[epoch 150: 140/307] 	 train loss: 0.108361 	 lr: 0.00008
[epoch 150: 160/307] 	 train loss: 0.288540 	 lr: 0.00008

val loss: 0.325032 	 acc: 0.907212

[epoch 150: 180/307] 	 train loss: 0.179431 	 lr: 0.00008
[epoch 150: 200/307] 	 train loss: 0.227869 	 lr: 0.00008
[epoch 150: 220/307] 	 train loss: 0.058210 	 lr: 0.00008
[epoch 150: 240/307] 	 train loss: 0.049694 	 lr: 0.00008
[epoch 150: 260/307] 	 train loss: 0.055311 	 lr: 0.00008
[epoch 150: 280/307] 	 train loss: 0.164073 	 lr: 0.00008
[epoch 150: 300/307] 	 train loss: 0.124247 	 lr: 0.00008
[epoch 151:   0/307] 	 train loss: 0.055498 	 lr: 0.00008

val loss: 0.332019 	 acc: 0.908833

[epoch 151:  20/307] 	 train loss: 0.066414 	 lr: 0.00008
[epoch 151:  40/307] 	 train loss: 0.171928 	 lr: 0.00008
[epoch 151:  60/307] 	 train loss: 0.189454 	 lr: 0.00008
[epoch 151:  80/307] 	 train loss: 0.349165 	 lr: 0.00008
[epoch 151: 100/307] 	 train loss: 0.109920 	 lr: 0.00008
[epoch 151: 120/307] 	 train loss: 0.160400 	 lr: 0.00008
[epoch 151: 140/307] 	 train loss: 0.216847 	 lr: 0.00008

val loss: 0.325931 	 acc: 0.908023

[epoch 151: 160/307] 	 train loss: 0.224209 	 lr: 0.00008
[epoch 151: 180/307] 	 train loss: 0.119399 	 lr: 0.00008
[epoch 151: 200/307] 	 train loss: 0.428265 	 lr: 0.00008
[epoch 151: 220/307] 	 train loss: 0.021770 	 lr: 0.00008
[epoch 151: 240/307] 	 train loss: 0.175477 	 lr: 0.00008
[epoch 151: 260/307] 	 train loss: 0.109312 	 lr: 0.00008
[epoch 151: 280/307] 	 train loss: 0.477542 	 lr: 0.00008
[epoch 151: 300/307] 	 train loss: 0.232277 	 lr: 0.00008
[epoch 152:   0/307] 	 train loss: 0.095631 	 lr: 0.00008

val loss: 0.324137 	 acc: 0.909643

[epoch 152:  20/307] 	 train loss: 0.074535 	 lr: 0.00008
[epoch 152:  40/307] 	 train loss: 0.219222 	 lr: 0.00008
[epoch 152:  60/307] 	 train loss: 0.260062 	 lr: 0.00008
[epoch 152:  80/307] 	 train loss: 0.116879 	 lr: 0.00008
[epoch 152: 100/307] 	 train loss: 0.163012 	 lr: 0.00008
[epoch 152: 120/307] 	 train loss: 0.121249 	 lr: 0.00008
[epoch 152: 140/307] 	 train loss: 0.315049 	 lr: 0.00008

val loss: 0.329347 	 acc: 0.900729

[epoch 152: 160/307] 	 train loss: 0.116335 	 lr: 0.00008
[epoch 152: 180/307] 	 train loss: 0.657247 	 lr: 0.00008
[epoch 152: 200/307] 	 train loss: 0.252709 	 lr: 0.00008
[epoch 152: 220/307] 	 train loss: 0.120866 	 lr: 0.00008
[epoch 152: 240/307] 	 train loss: 0.258292 	 lr: 0.00008
[epoch 152: 260/307] 	 train loss: 0.117503 	 lr: 0.00008
[epoch 152: 280/307] 	 train loss: 0.072585 	 lr: 0.00008
[epoch 152: 300/307] 	 train loss: 0.214219 	 lr: 0.00008
[epoch 153:   0/307] 	 train loss: 0.162751 	 lr: 0.00008

val loss: 0.335924 	 acc: 0.907618

[epoch 153:  20/307] 	 train loss: 0.052155 	 lr: 0.00008
[epoch 153:  40/307] 	 train loss: 0.269249 	 lr: 0.00008
[epoch 153:  60/307] 	 train loss: 0.270448 	 lr: 0.00008
[epoch 153:  80/307] 	 train loss: 0.253326 	 lr: 0.00008
[epoch 153: 100/307] 	 train loss: 0.121828 	 lr: 0.00008
[epoch 153: 120/307] 	 train loss: 0.241798 	 lr: 0.00008
[epoch 153: 140/307] 	 train loss: 0.154720 	 lr: 0.00008

val loss: 0.331625 	 acc: 0.910454

[epoch 153: 160/307] 	 train loss: 0.268596 	 lr: 0.00008
[epoch 153: 180/307] 	 train loss: 0.399597 	 lr: 0.00008
[epoch 153: 200/307] 	 train loss: 0.087024 	 lr: 0.00008
[epoch 153: 220/307] 	 train loss: 0.147675 	 lr: 0.00008
[epoch 153: 240/307] 	 train loss: 0.270199 	 lr: 0.00008
[epoch 153: 260/307] 	 train loss: 0.408222 	 lr: 0.00008
[epoch 153: 280/307] 	 train loss: 0.138894 	 lr: 0.00008
[epoch 153: 300/307] 	 train loss: 0.208336 	 lr: 0.00008

val loss: 0.332987 	 acc: 0.903971

[epoch 154:   0/307] 	 train loss: 0.185537 	 lr: 0.00008
[epoch 154:  20/307] 	 train loss: 0.157697 	 lr: 0.00008
[epoch 154:  40/307] 	 train loss: 0.104478 	 lr: 0.00008
[epoch 154:  60/307] 	 train loss: 0.296791 	 lr: 0.00008
[epoch 154:  80/307] 	 train loss: 0.141066 	 lr: 0.00008
[epoch 154: 100/307] 	 train loss: 0.071477 	 lr: 0.00008
[epoch 154: 120/307] 	 train loss: 0.115984 	 lr: 0.00008
[epoch 154: 140/307] 	 train loss: 0.174819 	 lr: 0.00008

val loss: 0.329155 	 acc: 0.905592

[epoch 154: 160/307] 	 train loss: 0.199669 	 lr: 0.00008
[epoch 154: 180/307] 	 train loss: 0.242056 	 lr: 0.00008
[epoch 154: 200/307] 	 train loss: 0.056470 	 lr: 0.00008
[epoch 154: 220/307] 	 train loss: 0.169711 	 lr: 0.00008
[epoch 154: 240/307] 	 train loss: 0.166291 	 lr: 0.00008
[epoch 154: 260/307] 	 train loss: 0.102203 	 lr: 0.00008
[epoch 154: 280/307] 	 train loss: 0.209863 	 lr: 0.00008
[epoch 154: 300/307] 	 train loss: 0.078614 	 lr: 0.00008

val loss: 0.345703 	 acc: 0.908833

[epoch 155:   0/307] 	 train loss: 0.163067 	 lr: 0.00008
[epoch 155:  20/307] 	 train loss: 0.198189 	 lr: 0.00008
[epoch 155:  40/307] 	 train loss: 0.078723 	 lr: 0.00008
[epoch 155:  60/307] 	 train loss: 0.319360 	 lr: 0.00008
[epoch 155:  80/307] 	 train loss: 0.128192 	 lr: 0.00008
[epoch 155: 100/307] 	 train loss: 0.271840 	 lr: 0.00008
[epoch 155: 120/307] 	 train loss: 0.335934 	 lr: 0.00008
[epoch 155: 140/307] 	 train loss: 0.191403 	 lr: 0.00008

val loss: 0.343275 	 acc: 0.906807

[epoch 155: 160/307] 	 train loss: 0.225916 	 lr: 0.00008
[epoch 155: 180/307] 	 train loss: 0.197571 	 lr: 0.00008
[epoch 155: 200/307] 	 train loss: 0.346493 	 lr: 0.00008
[epoch 155: 220/307] 	 train loss: 0.152031 	 lr: 0.00008
[epoch 155: 240/307] 	 train loss: 0.148934 	 lr: 0.00008
[epoch 155: 260/307] 	 train loss: 0.218622 	 lr: 0.00008
[epoch 155: 280/307] 	 train loss: 0.258869 	 lr: 0.00008
[epoch 155: 300/307] 	 train loss: 0.170411 	 lr: 0.00008

val loss: 0.316412 	 acc: 0.911669

[epoch 156:   0/307] 	 train loss: 0.120771 	 lr: 0.00008
[epoch 156:  20/307] 	 train loss: 0.028816 	 lr: 0.00008
[epoch 156:  40/307] 	 train loss: 0.251705 	 lr: 0.00008
[epoch 156:  60/307] 	 train loss: 0.196678 	 lr: 0.00008
[epoch 156:  80/307] 	 train loss: 0.182429 	 lr: 0.00008
[epoch 156: 100/307] 	 train loss: 0.094751 	 lr: 0.00008
[epoch 156: 120/307] 	 train loss: 0.183820 	 lr: 0.00008
[epoch 156: 140/307] 	 train loss: 0.222273 	 lr: 0.00008

val loss: 0.343060 	 acc: 0.909643

[epoch 156: 160/307] 	 train loss: 0.300062 	 lr: 0.00008
[epoch 156: 180/307] 	 train loss: 0.157940 	 lr: 0.00008
[epoch 156: 200/307] 	 train loss: 0.252224 	 lr: 0.00008
[epoch 156: 220/307] 	 train loss: 0.142201 	 lr: 0.00008
[epoch 156: 240/307] 	 train loss: 0.156683 	 lr: 0.00008
[epoch 156: 260/307] 	 train loss: 0.199574 	 lr: 0.00008
[epoch 156: 280/307] 	 train loss: 0.284200 	 lr: 0.00008
[epoch 156: 300/307] 	 train loss: 0.475890 	 lr: 0.00008

val loss: 0.323343 	 acc: 0.913695

[epoch 157:   0/307] 	 train loss: 0.150473 	 lr: 0.00008
[epoch 157:  20/307] 	 train loss: 0.215292 	 lr: 0.00008
[epoch 157:  40/307] 	 train loss: 0.151908 	 lr: 0.00008
[epoch 157:  60/307] 	 train loss: 0.179926 	 lr: 0.00008
[epoch 157:  80/307] 	 train loss: 0.122476 	 lr: 0.00008
[epoch 157: 100/307] 	 train loss: 0.275269 	 lr: 0.00008
[epoch 157: 120/307] 	 train loss: 0.106047 	 lr: 0.00008
[epoch 157: 140/307] 	 train loss: 0.142328 	 lr: 0.00008

val loss: 0.314531 	 acc: 0.911264

[epoch 157: 160/307] 	 train loss: 0.197558 	 lr: 0.00008
[epoch 157: 180/307] 	 train loss: 0.062807 	 lr: 0.00008
[epoch 157: 200/307] 	 train loss: 0.096282 	 lr: 0.00008
[epoch 157: 220/307] 	 train loss: 0.148993 	 lr: 0.00008
[epoch 157: 240/307] 	 train loss: 0.149749 	 lr: 0.00008
[epoch 157: 260/307] 	 train loss: 0.383944 	 lr: 0.00008
[epoch 157: 280/307] 	 train loss: 0.304746 	 lr: 0.00008

val loss: 0.326934 	 acc: 0.910049

[epoch 157: 300/307] 	 train loss: 0.631616 	 lr: 0.00008
[epoch 158:   0/307] 	 train loss: 0.070702 	 lr: 0.00008
[epoch 158:  20/307] 	 train loss: 0.096245 	 lr: 0.00008
[epoch 158:  40/307] 	 train loss: 0.123949 	 lr: 0.00008
[epoch 158:  60/307] 	 train loss: 0.142186 	 lr: 0.00008
[epoch 158:  80/307] 	 train loss: 0.190646 	 lr: 0.00008
[epoch 158: 100/307] 	 train loss: 0.205298 	 lr: 0.00008
[epoch 158: 120/307] 	 train loss: 0.257408 	 lr: 0.00008
[epoch 158: 140/307] 	 train loss: 0.087344 	 lr: 0.00008

val loss: 0.322954 	 acc: 0.915721

saved model with accuracy  0.9157212317666127
[epoch 158: 160/307] 	 train loss: 0.091011 	 lr: 0.00008
[epoch 158: 180/307] 	 train loss: 0.167669 	 lr: 0.00008
[epoch 158: 200/307] 	 train loss: 0.367951 	 lr: 0.00008
[epoch 158: 220/307] 	 train loss: 0.164387 	 lr: 0.00008
[epoch 158: 240/307] 	 train loss: 0.104092 	 lr: 0.00008
[epoch 158: 260/307] 	 train loss: 0.170310 	 lr: 0.00008
[epoch 158: 280/307] 	 train loss: 0.180265 	 lr: 0.00008

val loss: 0.321577 	 acc: 0.908023

[epoch 158: 300/307] 	 train loss: 0.097322 	 lr: 0.00008
[epoch 159:   0/307] 	 train loss: 0.078895 	 lr: 0.00008
[epoch 159:  20/307] 	 train loss: 0.097522 	 lr: 0.00008
[epoch 159:  40/307] 	 train loss: 0.071008 	 lr: 0.00008
[epoch 159:  60/307] 	 train loss: 0.108437 	 lr: 0.00008
[epoch 159:  80/307] 	 train loss: 0.123706 	 lr: 0.00008
[epoch 159: 100/307] 	 train loss: 0.203859 	 lr: 0.00008
[epoch 159: 120/307] 	 train loss: 0.311581 	 lr: 0.00008
[epoch 159: 140/307] 	 train loss: 0.248959 	 lr: 0.00008

val loss: 0.341076 	 acc: 0.907212

[epoch 159: 160/307] 	 train loss: 0.179150 	 lr: 0.00008
[epoch 159: 180/307] 	 train loss: 0.308393 	 lr: 0.00008
[epoch 159: 200/307] 	 train loss: 0.291669 	 lr: 0.00008
[epoch 159: 220/307] 	 train loss: 0.130091 	 lr: 0.00008
[epoch 159: 240/307] 	 train loss: 0.212390 	 lr: 0.00008
[epoch 159: 260/307] 	 train loss: 0.018855 	 lr: 0.00008
[epoch 159: 280/307] 	 train loss: 0.122565 	 lr: 0.00008

val loss: 0.325491 	 acc: 0.910859

[epoch 159: 300/307] 	 train loss: 0.135847 	 lr: 0.00008
[epoch 160:   0/307] 	 train loss: 0.247756 	 lr: 0.00008
[epoch 160:  20/307] 	 train loss: 0.162375 	 lr: 0.00008
[epoch 160:  40/307] 	 train loss: 0.132265 	 lr: 0.00008
[epoch 160:  60/307] 	 train loss: 0.052936 	 lr: 0.00008
[epoch 160:  80/307] 	 train loss: 0.314405 	 lr: 0.00008
[epoch 160: 100/307] 	 train loss: 0.083098 	 lr: 0.00008
[epoch 160: 120/307] 	 train loss: 0.141355 	 lr: 0.00008
[epoch 160: 140/307] 	 train loss: 0.027999 	 lr: 0.00008

val loss: 0.338970 	 acc: 0.910454

[epoch 160: 160/307] 	 train loss: 0.178622 	 lr: 0.00008
[epoch 160: 180/307] 	 train loss: 0.201464 	 lr: 0.00008
[epoch 160: 200/307] 	 train loss: 0.107235 	 lr: 0.00008
[epoch 160: 220/307] 	 train loss: 0.234367 	 lr: 0.00008
[epoch 160: 240/307] 	 train loss: 0.109099 	 lr: 0.00008
[epoch 160: 260/307] 	 train loss: 0.152487 	 lr: 0.00008
[epoch 160: 280/307] 	 train loss: 0.213480 	 lr: 0.00008

val loss: 0.319816 	 acc: 0.912480

[epoch 160: 300/307] 	 train loss: 0.392878 	 lr: 0.00008
[epoch 161:   0/307] 	 train loss: 0.264185 	 lr: 0.00008
[epoch 161:  20/307] 	 train loss: 0.062438 	 lr: 0.00008
[epoch 161:  40/307] 	 train loss: 0.093044 	 lr: 0.00008
[epoch 161:  60/307] 	 train loss: 0.100456 	 lr: 0.00008
[epoch 161:  80/307] 	 train loss: 0.059900 	 lr: 0.00008
[epoch 161: 100/307] 	 train loss: 0.420498 	 lr: 0.00008
[epoch 161: 120/307] 	 train loss: 0.101606 	 lr: 0.00008

val loss: 0.334455 	 acc: 0.905186

[epoch 161: 140/307] 	 train loss: 0.117156 	 lr: 0.00008
[epoch 161: 160/307] 	 train loss: 0.247541 	 lr: 0.00008
[epoch 161: 180/307] 	 train loss: 0.169508 	 lr: 0.00008
[epoch 161: 200/307] 	 train loss: 0.381654 	 lr: 0.00008
[epoch 161: 220/307] 	 train loss: 0.222232 	 lr: 0.00008
[epoch 161: 240/307] 	 train loss: 0.084040 	 lr: 0.00008
[epoch 161: 260/307] 	 train loss: 0.061981 	 lr: 0.00008
[epoch 161: 280/307] 	 train loss: 0.081861 	 lr: 0.00008

val loss: 0.336273 	 acc: 0.911669

[epoch 161: 300/307] 	 train loss: 0.101932 	 lr: 0.00008
[epoch 162:   0/307] 	 train loss: 0.085232 	 lr: 0.00008
[epoch 162:  20/307] 	 train loss: 0.143158 	 lr: 0.00008
[epoch 162:  40/307] 	 train loss: 0.118499 	 lr: 0.00008
[epoch 162:  60/307] 	 train loss: 0.264474 	 lr: 0.00008
[epoch 162:  80/307] 	 train loss: 0.081715 	 lr: 0.00008
[epoch 162: 100/307] 	 train loss: 0.212074 	 lr: 0.00008
[epoch 162: 120/307] 	 train loss: 0.122841 	 lr: 0.00008

val loss: 0.327604 	 acc: 0.909643

[epoch 162: 140/307] 	 train loss: 0.126678 	 lr: 0.00008
[epoch 162: 160/307] 	 train loss: 0.391133 	 lr: 0.00008
[epoch 162: 180/307] 	 train loss: 0.065273 	 lr: 0.00008
[epoch 162: 200/307] 	 train loss: 0.179606 	 lr: 0.00008
[epoch 162: 220/307] 	 train loss: 0.153792 	 lr: 0.00008
[epoch 162: 240/307] 	 train loss: 0.366870 	 lr: 0.00008
[epoch 162: 260/307] 	 train loss: 0.139214 	 lr: 0.00008
[epoch 162: 280/307] 	 train loss: 0.582270 	 lr: 0.00008

val loss: 0.324363 	 acc: 0.907618

[epoch 162: 300/307] 	 train loss: 0.180930 	 lr: 0.00008
[epoch 163:   0/307] 	 train loss: 0.366363 	 lr: 0.00008
[epoch 163:  20/307] 	 train loss: 0.167673 	 lr: 0.00008
[epoch 163:  40/307] 	 train loss: 0.111774 	 lr: 0.00008
[epoch 163:  60/307] 	 train loss: 0.150910 	 lr: 0.00008
[epoch 163:  80/307] 	 train loss: 0.212564 	 lr: 0.00008
[epoch 163: 100/307] 	 train loss: 0.328969 	 lr: 0.00008
[epoch 163: 120/307] 	 train loss: 0.097005 	 lr: 0.00008

val loss: 0.332403 	 acc: 0.909238

[epoch 163: 140/307] 	 train loss: 0.023379 	 lr: 0.00008
[epoch 163: 160/307] 	 train loss: 0.227832 	 lr: 0.00008
[epoch 163: 180/307] 	 train loss: 0.482594 	 lr: 0.00008
[epoch 163: 200/307] 	 train loss: 0.134318 	 lr: 0.00008
[epoch 163: 220/307] 	 train loss: 0.066150 	 lr: 0.00008
[epoch 163: 240/307] 	 train loss: 0.092095 	 lr: 0.00008
[epoch 163: 260/307] 	 train loss: 0.218414 	 lr: 0.00008
[epoch 163: 280/307] 	 train loss: 0.115830 	 lr: 0.00008

val loss: 0.329310 	 acc: 0.906807

[epoch 163: 300/307] 	 train loss: 0.042040 	 lr: 0.00008
[epoch 164:   0/307] 	 train loss: 0.126621 	 lr: 0.00008
[epoch 164:  20/307] 	 train loss: 0.258435 	 lr: 0.00008
[epoch 164:  40/307] 	 train loss: 0.202728 	 lr: 0.00008
[epoch 164:  60/307] 	 train loss: 0.108484 	 lr: 0.00008
[epoch 164:  80/307] 	 train loss: 0.211635 	 lr: 0.00008
[epoch 164: 100/307] 	 train loss: 0.176008 	 lr: 0.00008
[epoch 164: 120/307] 	 train loss: 0.324870 	 lr: 0.00008

val loss: 0.330495 	 acc: 0.916126

saved model with accuracy  0.9161264181523501
[epoch 164: 140/307] 	 train loss: 0.075020 	 lr: 0.00008
[epoch 164: 160/307] 	 train loss: 0.083895 	 lr: 0.00008
[epoch 164: 180/307] 	 train loss: 0.102608 	 lr: 0.00008
[epoch 164: 200/307] 	 train loss: 0.154294 	 lr: 0.00008
[epoch 164: 220/307] 	 train loss: 0.213006 	 lr: 0.00008
[epoch 164: 240/307] 	 train loss: 0.201486 	 lr: 0.00008
[epoch 164: 260/307] 	 train loss: 0.122322 	 lr: 0.00008
[epoch 164: 280/307] 	 train loss: 0.072767 	 lr: 0.00008

val loss: 0.321791 	 acc: 0.911669

[epoch 164: 300/307] 	 train loss: 0.118885 	 lr: 0.00008
[epoch 165:   0/307] 	 train loss: 0.034823 	 lr: 0.00008
[epoch 165:  20/307] 	 train loss: 0.056859 	 lr: 0.00008
[epoch 165:  40/307] 	 train loss: 0.114895 	 lr: 0.00008
[epoch 165:  60/307] 	 train loss: 0.226813 	 lr: 0.00008
[epoch 165:  80/307] 	 train loss: 0.216874 	 lr: 0.00008
[epoch 165: 100/307] 	 train loss: 0.134776 	 lr: 0.00008
[epoch 165: 120/307] 	 train loss: 0.198442 	 lr: 0.00008

val loss: 0.330689 	 acc: 0.911264

[epoch 165: 140/307] 	 train loss: 0.352727 	 lr: 0.00008
[epoch 165: 160/307] 	 train loss: 0.242828 	 lr: 0.00008
[epoch 165: 180/307] 	 train loss: 0.114626 	 lr: 0.00008
[epoch 165: 200/307] 	 train loss: 0.209177 	 lr: 0.00008
[epoch 165: 220/307] 	 train loss: 0.366515 	 lr: 0.00008
[epoch 165: 240/307] 	 train loss: 0.178632 	 lr: 0.00008
[epoch 165: 260/307] 	 train loss: 0.281132 	 lr: 0.00008
[epoch 165: 280/307] 	 train loss: 0.170127 	 lr: 0.00008

val loss: 0.332783 	 acc: 0.908428

[epoch 165: 300/307] 	 train loss: 0.071516 	 lr: 0.00008
[epoch 166:   0/307] 	 train loss: 0.249588 	 lr: 0.00008
[epoch 166:  20/307] 	 train loss: 0.121668 	 lr: 0.00008
[epoch 166:  40/307] 	 train loss: 0.589118 	 lr: 0.00008
[epoch 166:  60/307] 	 train loss: 0.208992 	 lr: 0.00008
[epoch 166:  80/307] 	 train loss: 0.171512 	 lr: 0.00008
[epoch 166: 100/307] 	 train loss: 0.239673 	 lr: 0.00008
[epoch 166: 120/307] 	 train loss: 0.380363 	 lr: 0.00008

val loss: 0.334514 	 acc: 0.905997

[epoch 166: 140/307] 	 train loss: 0.191897 	 lr: 0.00008
[epoch 166: 160/307] 	 train loss: 0.162519 	 lr: 0.00008
[epoch 166: 180/307] 	 train loss: 0.243516 	 lr: 0.00008
[epoch 166: 200/307] 	 train loss: 0.076450 	 lr: 0.00008
[epoch 166: 220/307] 	 train loss: 0.042631 	 lr: 0.00008
[epoch 166: 240/307] 	 train loss: 0.356931 	 lr: 0.00008
[epoch 166: 260/307] 	 train loss: 0.079911 	 lr: 0.00008
[epoch 166: 280/307] 	 train loss: 0.204452 	 lr: 0.00008

val loss: 0.328468 	 acc: 0.907212

[epoch 166: 300/307] 	 train loss: 0.217120 	 lr: 0.00008
[epoch 167:   0/307] 	 train loss: 0.167311 	 lr: 0.00008
[epoch 167:  20/307] 	 train loss: 0.255186 	 lr: 0.00008
[epoch 167:  40/307] 	 train loss: 0.209907 	 lr: 0.00008
[epoch 167:  60/307] 	 train loss: 0.115941 	 lr: 0.00008
[epoch 167:  80/307] 	 train loss: 0.241913 	 lr: 0.00008
[epoch 167: 100/307] 	 train loss: 0.228135 	 lr: 0.00008
[epoch 167: 120/307] 	 train loss: 0.066697 	 lr: 0.00008

val loss: 0.330542 	 acc: 0.911264

[epoch 167: 140/307] 	 train loss: 0.108803 	 lr: 0.00008
[epoch 167: 160/307] 	 train loss: 0.238895 	 lr: 0.00008
[epoch 167: 180/307] 	 train loss: 0.359868 	 lr: 0.00008
[epoch 167: 200/307] 	 train loss: 0.093894 	 lr: 0.00008
[epoch 167: 220/307] 	 train loss: 0.405496 	 lr: 0.00008
[epoch 167: 240/307] 	 train loss: 0.066184 	 lr: 0.00008
[epoch 167: 260/307] 	 train loss: 0.163042 	 lr: 0.00008

val loss: 0.322031 	 acc: 0.905592

[epoch 167: 280/307] 	 train loss: 0.303870 	 lr: 0.00008
[epoch 167: 300/307] 	 train loss: 0.134426 	 lr: 0.00008
[epoch 168:   0/307] 	 train loss: 0.060844 	 lr: 0.00008
[epoch 168:  20/307] 	 train loss: 0.129219 	 lr: 0.00008
[epoch 168:  40/307] 	 train loss: 0.076772 	 lr: 0.00008
[epoch 168:  60/307] 	 train loss: 0.355126 	 lr: 0.00008
[epoch 168:  80/307] 	 train loss: 0.186849 	 lr: 0.00008
[epoch 168: 100/307] 	 train loss: 0.202811 	 lr: 0.00008
[epoch 168: 120/307] 	 train loss: 0.271767 	 lr: 0.00008

val loss: 0.324037 	 acc: 0.905997

[epoch 168: 140/307] 	 train loss: 0.319695 	 lr: 0.00008
[epoch 168: 160/307] 	 train loss: 0.157376 	 lr: 0.00008
[epoch 168: 180/307] 	 train loss: 0.151944 	 lr: 0.00008
[epoch 168: 200/307] 	 train loss: 0.060704 	 lr: 0.00008
[epoch 168: 220/307] 	 train loss: 0.061520 	 lr: 0.00008
[epoch 168: 240/307] 	 train loss: 0.267546 	 lr: 0.00008
[epoch 168: 260/307] 	 train loss: 0.068096 	 lr: 0.00008

val loss: 0.337279 	 acc: 0.904781

[epoch 168: 280/307] 	 train loss: 0.172749 	 lr: 0.00008
[epoch 168: 300/307] 	 train loss: 0.125821 	 lr: 0.00008
[epoch 169:   0/307] 	 train loss: 0.127262 	 lr: 0.00006
[epoch 169:  20/307] 	 train loss: 0.264209 	 lr: 0.00006
[epoch 169:  40/307] 	 train loss: 0.027242 	 lr: 0.00006
[epoch 169:  60/307] 	 train loss: 0.189769 	 lr: 0.00006
[epoch 169:  80/307] 	 train loss: 0.181763 	 lr: 0.00006
[epoch 169: 100/307] 	 train loss: 0.146522 	 lr: 0.00006
[epoch 169: 120/307] 	 train loss: 0.193496 	 lr: 0.00006

val loss: 0.320310 	 acc: 0.913695

[epoch 169: 140/307] 	 train loss: 0.223267 	 lr: 0.00006
[epoch 169: 160/307] 	 train loss: 0.106791 	 lr: 0.00006
[epoch 169: 180/307] 	 train loss: 0.505815 	 lr: 0.00006
[epoch 169: 200/307] 	 train loss: 0.180663 	 lr: 0.00006
[epoch 169: 220/307] 	 train loss: 0.089734 	 lr: 0.00006
[epoch 169: 240/307] 	 train loss: 0.431315 	 lr: 0.00006
[epoch 169: 260/307] 	 train loss: 0.116882 	 lr: 0.00006

val loss: 0.314016 	 acc: 0.911669

[epoch 169: 280/307] 	 train loss: 0.150065 	 lr: 0.00006
[epoch 169: 300/307] 	 train loss: 0.369816 	 lr: 0.00006
[epoch 170:   0/307] 	 train loss: 0.373383 	 lr: 0.00006
[epoch 170:  20/307] 	 train loss: 0.418346 	 lr: 0.00006
[epoch 170:  40/307] 	 train loss: 0.209673 	 lr: 0.00006
[epoch 170:  60/307] 	 train loss: 0.152246 	 lr: 0.00006
[epoch 170:  80/307] 	 train loss: 0.242956 	 lr: 0.00006
[epoch 170: 100/307] 	 train loss: 0.151699 	 lr: 0.00006
[epoch 170: 120/307] 	 train loss: 0.166408 	 lr: 0.00006

val loss: 0.326759 	 acc: 0.908428

[epoch 170: 140/307] 	 train loss: 0.407628 	 lr: 0.00006
[epoch 170: 160/307] 	 train loss: 0.168617 	 lr: 0.00006
[epoch 170: 180/307] 	 train loss: 0.111450 	 lr: 0.00006
[epoch 170: 200/307] 	 train loss: 0.300139 	 lr: 0.00006
[epoch 170: 220/307] 	 train loss: 0.157728 	 lr: 0.00006
[epoch 170: 240/307] 	 train loss: 0.122808 	 lr: 0.00006
[epoch 170: 260/307] 	 train loss: 0.288668 	 lr: 0.00006

val loss: 0.318339 	 acc: 0.908428

[epoch 170: 280/307] 	 train loss: 0.176695 	 lr: 0.00006
[epoch 170: 300/307] 	 train loss: 0.213996 	 lr: 0.00006
[epoch 171:   0/307] 	 train loss: 0.124314 	 lr: 0.00006
[epoch 171:  20/307] 	 train loss: 0.240611 	 lr: 0.00006
[epoch 171:  40/307] 	 train loss: 0.325229 	 lr: 0.00006
[epoch 171:  60/307] 	 train loss: 0.333786 	 lr: 0.00006
[epoch 171:  80/307] 	 train loss: 0.155972 	 lr: 0.00006
[epoch 171: 100/307] 	 train loss: 0.303901 	 lr: 0.00006

val loss: 0.329406 	 acc: 0.910859

[epoch 171: 120/307] 	 train loss: 0.320214 	 lr: 0.00006
[epoch 171: 140/307] 	 train loss: 0.277064 	 lr: 0.00006
[epoch 171: 160/307] 	 train loss: 0.073387 	 lr: 0.00006
[epoch 171: 180/307] 	 train loss: 0.221437 	 lr: 0.00006
[epoch 171: 200/307] 	 train loss: 0.165283 	 lr: 0.00006
[epoch 171: 220/307] 	 train loss: 0.180274 	 lr: 0.00006
[epoch 171: 240/307] 	 train loss: 0.423625 	 lr: 0.00006
[epoch 171: 260/307] 	 train loss: 0.292092 	 lr: 0.00006

val loss: 0.331802 	 acc: 0.912885

[epoch 171: 280/307] 	 train loss: 0.201086 	 lr: 0.00006
[epoch 171: 300/307] 	 train loss: 0.260619 	 lr: 0.00006
[epoch 172:   0/307] 	 train loss: 0.137862 	 lr: 0.00006
[epoch 172:  20/307] 	 train loss: 0.088941 	 lr: 0.00006
[epoch 172:  40/307] 	 train loss: 0.134352 	 lr: 0.00006
[epoch 172:  60/307] 	 train loss: 0.080712 	 lr: 0.00006
[epoch 172:  80/307] 	 train loss: 0.310148 	 lr: 0.00006
[epoch 172: 100/307] 	 train loss: 0.133644 	 lr: 0.00006

val loss: 0.329050 	 acc: 0.908833

[epoch 172: 120/307] 	 train loss: 0.164041 	 lr: 0.00006
[epoch 172: 140/307] 	 train loss: 0.309193 	 lr: 0.00006
[epoch 172: 160/307] 	 train loss: 0.232940 	 lr: 0.00006
[epoch 172: 180/307] 	 train loss: 0.178906 	 lr: 0.00006
[epoch 172: 200/307] 	 train loss: 0.127538 	 lr: 0.00006
[epoch 172: 220/307] 	 train loss: 0.273353 	 lr: 0.00006
[epoch 172: 240/307] 	 train loss: 0.179566 	 lr: 0.00006
[epoch 172: 260/307] 	 train loss: 0.153521 	 lr: 0.00006

val loss: 0.304108 	 acc: 0.913695

[epoch 172: 280/307] 	 train loss: 0.030454 	 lr: 0.00006
[epoch 172: 300/307] 	 train loss: 0.090867 	 lr: 0.00006
[epoch 173:   0/307] 	 train loss: 0.253007 	 lr: 0.00006
[epoch 173:  20/307] 	 train loss: 0.188216 	 lr: 0.00006
[epoch 173:  40/307] 	 train loss: 0.263057 	 lr: 0.00006
[epoch 173:  60/307] 	 train loss: 0.510765 	 lr: 0.00006
[epoch 173:  80/307] 	 train loss: 0.065174 	 lr: 0.00006
[epoch 173: 100/307] 	 train loss: 0.150978 	 lr: 0.00006

val loss: 0.318879 	 acc: 0.913290

[epoch 173: 120/307] 	 train loss: 0.160244 	 lr: 0.00006
[epoch 173: 140/307] 	 train loss: 0.265837 	 lr: 0.00006
[epoch 173: 160/307] 	 train loss: 0.220617 	 lr: 0.00006
[epoch 173: 180/307] 	 train loss: 0.150192 	 lr: 0.00006
[epoch 173: 200/307] 	 train loss: 0.090528 	 lr: 0.00006
[epoch 173: 220/307] 	 train loss: 0.141282 	 lr: 0.00006
[epoch 173: 240/307] 	 train loss: 0.025103 	 lr: 0.00006
[epoch 173: 260/307] 	 train loss: 0.166264 	 lr: 0.00006

val loss: 0.336087 	 acc: 0.916532

saved model with accuracy  0.9165316045380876
[epoch 173: 280/307] 	 train loss: 0.115066 	 lr: 0.00006
[epoch 173: 300/307] 	 train loss: 0.166383 	 lr: 0.00006
[epoch 174:   0/307] 	 train loss: 0.163332 	 lr: 0.00006
[epoch 174:  20/307] 	 train loss: 0.278357 	 lr: 0.00006
[epoch 174:  40/307] 	 train loss: 0.192720 	 lr: 0.00006
[epoch 174:  60/307] 	 train loss: 0.117239 	 lr: 0.00006
[epoch 174:  80/307] 	 train loss: 0.064726 	 lr: 0.00006
[epoch 174: 100/307] 	 train loss: 0.217711 	 lr: 0.00006

val loss: 0.339725 	 acc: 0.911264

[epoch 174: 120/307] 	 train loss: 0.229962 	 lr: 0.00006
[epoch 174: 140/307] 	 train loss: 0.257033 	 lr: 0.00006
[epoch 174: 160/307] 	 train loss: 0.184626 	 lr: 0.00006
[epoch 174: 180/307] 	 train loss: 0.035032 	 lr: 0.00006
[epoch 174: 200/307] 	 train loss: 0.126100 	 lr: 0.00006
[epoch 174: 220/307] 	 train loss: 0.069541 	 lr: 0.00006
[epoch 174: 240/307] 	 train loss: 0.265492 	 lr: 0.00006
[epoch 174: 260/307] 	 train loss: 0.233918 	 lr: 0.00006

val loss: 0.335969 	 acc: 0.908428

[epoch 174: 280/307] 	 train loss: 0.131333 	 lr: 0.00006
[epoch 174: 300/307] 	 train loss: 0.324460 	 lr: 0.00006
[epoch 175:   0/307] 	 train loss: 0.155507 	 lr: 0.00006
[epoch 175:  20/307] 	 train loss: 0.117781 	 lr: 0.00006
[epoch 175:  40/307] 	 train loss: 0.144036 	 lr: 0.00006
[epoch 175:  60/307] 	 train loss: 0.164464 	 lr: 0.00006
[epoch 175:  80/307] 	 train loss: 0.173892 	 lr: 0.00006
[epoch 175: 100/307] 	 train loss: 0.360114 	 lr: 0.00006

val loss: 0.335936 	 acc: 0.912075

[epoch 175: 120/307] 	 train loss: 0.239810 	 lr: 0.00006
[epoch 175: 140/307] 	 train loss: 0.382367 	 lr: 0.00006
[epoch 175: 160/307] 	 train loss: 0.319035 	 lr: 0.00006
[epoch 175: 180/307] 	 train loss: 0.161004 	 lr: 0.00006
[epoch 175: 200/307] 	 train loss: 0.021412 	 lr: 0.00006
[epoch 175: 220/307] 	 train loss: 0.263031 	 lr: 0.00006
[epoch 175: 240/307] 	 train loss: 0.077375 	 lr: 0.00006
[epoch 175: 260/307] 	 train loss: 0.186858 	 lr: 0.00006

val loss: 0.331318 	 acc: 0.908833

[epoch 175: 280/307] 	 train loss: 0.140923 	 lr: 0.00006
[epoch 175: 300/307] 	 train loss: 0.280274 	 lr: 0.00006
[epoch 176:   0/307] 	 train loss: 0.074199 	 lr: 0.00006
[epoch 176:  20/307] 	 train loss: 0.123583 	 lr: 0.00006
[epoch 176:  40/307] 	 train loss: 0.162036 	 lr: 0.00006
[epoch 176:  60/307] 	 train loss: 0.173964 	 lr: 0.00006
[epoch 176:  80/307] 	 train loss: 0.076982 	 lr: 0.00006
[epoch 176: 100/307] 	 train loss: 0.062265 	 lr: 0.00006

val loss: 0.323996 	 acc: 0.914506

[epoch 176: 120/307] 	 train loss: 0.129417 	 lr: 0.00006
[epoch 176: 140/307] 	 train loss: 0.364915 	 lr: 0.00006
[epoch 176: 160/307] 	 train loss: 0.063234 	 lr: 0.00006
[epoch 176: 180/307] 	 train loss: 0.246912 	 lr: 0.00006
[epoch 176: 200/307] 	 train loss: 0.043999 	 lr: 0.00006
[epoch 176: 220/307] 	 train loss: 0.140784 	 lr: 0.00006
[epoch 176: 240/307] 	 train loss: 0.154336 	 lr: 0.00006
[epoch 176: 260/307] 	 train loss: 0.049092 	 lr: 0.00006

val loss: 0.324280 	 acc: 0.908023

[epoch 176: 280/307] 	 train loss: 0.446621 	 lr: 0.00006
[epoch 176: 300/307] 	 train loss: 0.232741 	 lr: 0.00006
[epoch 177:   0/307] 	 train loss: 0.115275 	 lr: 0.00006
[epoch 177:  20/307] 	 train loss: 0.339374 	 lr: 0.00006
[epoch 177:  40/307] 	 train loss: 0.177800 	 lr: 0.00006
[epoch 177:  60/307] 	 train loss: 0.145773 	 lr: 0.00006
[epoch 177:  80/307] 	 train loss: 0.408508 	 lr: 0.00006
[epoch 177: 100/307] 	 train loss: 0.308491 	 lr: 0.00006

val loss: 0.350645 	 acc: 0.908023

[epoch 177: 120/307] 	 train loss: 0.311732 	 lr: 0.00006
[epoch 177: 140/307] 	 train loss: 0.156681 	 lr: 0.00006
[epoch 177: 160/307] 	 train loss: 0.230895 	 lr: 0.00006
[epoch 177: 180/307] 	 train loss: 0.457858 	 lr: 0.00006
[epoch 177: 200/307] 	 train loss: 0.088120 	 lr: 0.00006
[epoch 177: 220/307] 	 train loss: 0.196658 	 lr: 0.00006
[epoch 177: 240/307] 	 train loss: 0.179105 	 lr: 0.00006

val loss: 0.316477 	 acc: 0.913290

[epoch 177: 260/307] 	 train loss: 0.182580 	 lr: 0.00006
[epoch 177: 280/307] 	 train loss: 0.124380 	 lr: 0.00006
[epoch 177: 300/307] 	 train loss: 0.147994 	 lr: 0.00006
[epoch 178:   0/307] 	 train loss: 0.247175 	 lr: 0.00006
[epoch 178:  20/307] 	 train loss: 0.258552 	 lr: 0.00006
[epoch 178:  40/307] 	 train loss: 0.212952 	 lr: 0.00006
[epoch 178:  60/307] 	 train loss: 0.088566 	 lr: 0.00006
[epoch 178:  80/307] 	 train loss: 0.199699 	 lr: 0.00006
[epoch 178: 100/307] 	 train loss: 0.115246 	 lr: 0.00006

val loss: 0.342289 	 acc: 0.910454

[epoch 178: 120/307] 	 train loss: 0.069661 	 lr: 0.00006
[epoch 178: 140/307] 	 train loss: 0.048911 	 lr: 0.00006
[epoch 178: 160/307] 	 train loss: 0.159803 	 lr: 0.00006
[epoch 178: 180/307] 	 train loss: 0.136477 	 lr: 0.00006
[epoch 178: 200/307] 	 train loss: 0.127595 	 lr: 0.00006
[epoch 178: 220/307] 	 train loss: 0.328452 	 lr: 0.00006
[epoch 178: 240/307] 	 train loss: 0.144675 	 lr: 0.00006

val loss: 0.326273 	 acc: 0.916532

[epoch 178: 260/307] 	 train loss: 0.035265 	 lr: 0.00006
[epoch 178: 280/307] 	 train loss: 0.158364 	 lr: 0.00006
[epoch 178: 300/307] 	 train loss: 0.152113 	 lr: 0.00006
[epoch 179:   0/307] 	 train loss: 0.128869 	 lr: 0.00006
[epoch 179:  20/307] 	 train loss: 0.186972 	 lr: 0.00006
[epoch 179:  40/307] 	 train loss: 0.258310 	 lr: 0.00006
[epoch 179:  60/307] 	 train loss: 0.134041 	 lr: 0.00006
[epoch 179:  80/307] 	 train loss: 0.161891 	 lr: 0.00006
[epoch 179: 100/307] 	 train loss: 0.579054 	 lr: 0.00006

val loss: 0.331213 	 acc: 0.906402

[epoch 179: 120/307] 	 train loss: 0.477743 	 lr: 0.00006
[epoch 179: 140/307] 	 train loss: 0.363591 	 lr: 0.00006
[epoch 179: 160/307] 	 train loss: 0.213839 	 lr: 0.00006
[epoch 179: 180/307] 	 train loss: 0.125635 	 lr: 0.00006
[epoch 179: 200/307] 	 train loss: 0.207586 	 lr: 0.00006
[epoch 179: 220/307] 	 train loss: 0.237321 	 lr: 0.00006
[epoch 179: 240/307] 	 train loss: 0.162132 	 lr: 0.00006

val loss: 0.323619 	 acc: 0.906807

[epoch 179: 260/307] 	 train loss: 0.310230 	 lr: 0.00006
[epoch 179: 280/307] 	 train loss: 0.134408 	 lr: 0.00006
[epoch 179: 300/307] 	 train loss: 0.162473 	 lr: 0.00006
[epoch 180:   0/307] 	 train loss: 0.223598 	 lr: 0.00006
[epoch 180:  20/307] 	 train loss: 0.118273 	 lr: 0.00006
[epoch 180:  40/307] 	 train loss: 0.315207 	 lr: 0.00006
[epoch 180:  60/307] 	 train loss: 0.080783 	 lr: 0.00006
[epoch 180:  80/307] 	 train loss: 0.201885 	 lr: 0.00006
[epoch 180: 100/307] 	 train loss: 0.256565 	 lr: 0.00006

val loss: 0.316307 	 acc: 0.915316

[epoch 180: 120/307] 	 train loss: 0.130100 	 lr: 0.00006
[epoch 180: 140/307] 	 train loss: 0.192298 	 lr: 0.00006
[epoch 180: 160/307] 	 train loss: 0.395529 	 lr: 0.00006
[epoch 180: 180/307] 	 train loss: 0.221919 	 lr: 0.00006
[epoch 180: 200/307] 	 train loss: 0.084393 	 lr: 0.00006
[epoch 180: 220/307] 	 train loss: 0.247482 	 lr: 0.00006
[epoch 180: 240/307] 	 train loss: 0.190707 	 lr: 0.00006

val loss: 0.336715 	 acc: 0.907212

[epoch 180: 260/307] 	 train loss: 0.126707 	 lr: 0.00006
[epoch 180: 280/307] 	 train loss: 0.097037 	 lr: 0.00006
[epoch 180: 300/307] 	 train loss: 0.209455 	 lr: 0.00006
[epoch 181:   0/307] 	 train loss: 0.060695 	 lr: 0.00006
[epoch 181:  20/307] 	 train loss: 0.096438 	 lr: 0.00006
[epoch 181:  40/307] 	 train loss: 0.260902 	 lr: 0.00006
[epoch 181:  60/307] 	 train loss: 0.114564 	 lr: 0.00006
[epoch 181:  80/307] 	 train loss: 0.403047 	 lr: 0.00006

val loss: 0.336717 	 acc: 0.910049

[epoch 181: 100/307] 	 train loss: 0.321814 	 lr: 0.00006
[epoch 181: 120/307] 	 train loss: 0.206161 	 lr: 0.00006
[epoch 181: 140/307] 	 train loss: 0.186243 	 lr: 0.00006
[epoch 181: 160/307] 	 train loss: 0.145671 	 lr: 0.00006
[epoch 181: 180/307] 	 train loss: 0.079984 	 lr: 0.00006
[epoch 181: 200/307] 	 train loss: 0.101050 	 lr: 0.00006
[epoch 181: 220/307] 	 train loss: 0.416190 	 lr: 0.00006
[epoch 181: 240/307] 	 train loss: 0.120700 	 lr: 0.00006

val loss: 0.327467 	 acc: 0.907212

[epoch 181: 260/307] 	 train loss: 0.208362 	 lr: 0.00006
[epoch 181: 280/307] 	 train loss: 0.203487 	 lr: 0.00006
[epoch 181: 300/307] 	 train loss: 0.239013 	 lr: 0.00006
[epoch 182:   0/307] 	 train loss: 0.153420 	 lr: 0.00006
[epoch 182:  20/307] 	 train loss: 0.408947 	 lr: 0.00006
[epoch 182:  40/307] 	 train loss: 0.173197 	 lr: 0.00006
[epoch 182:  60/307] 	 train loss: 0.126587 	 lr: 0.00006
[epoch 182:  80/307] 	 train loss: 0.127170 	 lr: 0.00006

val loss: 0.323735 	 acc: 0.908833

[epoch 182: 100/307] 	 train loss: 0.155249 	 lr: 0.00006
[epoch 182: 120/307] 	 train loss: 0.069040 	 lr: 0.00006
[epoch 182: 140/307] 	 train loss: 0.065906 	 lr: 0.00006
[epoch 182: 160/307] 	 train loss: 0.280084 	 lr: 0.00006
[epoch 182: 180/307] 	 train loss: 0.091236 	 lr: 0.00006
[epoch 182: 200/307] 	 train loss: 0.310722 	 lr: 0.00006
[epoch 182: 220/307] 	 train loss: 0.176868 	 lr: 0.00006
[epoch 182: 240/307] 	 train loss: 0.147100 	 lr: 0.00006

val loss: 0.328415 	 acc: 0.908023

[epoch 182: 260/307] 	 train loss: 0.085221 	 lr: 0.00006
[epoch 182: 280/307] 	 train loss: 0.208196 	 lr: 0.00006
[epoch 182: 300/307] 	 train loss: 0.121786 	 lr: 0.00006
[epoch 183:   0/307] 	 train loss: 0.260858 	 lr: 0.00006
[epoch 183:  20/307] 	 train loss: 0.063202 	 lr: 0.00006
[epoch 183:  40/307] 	 train loss: 0.145186 	 lr: 0.00006
[epoch 183:  60/307] 	 train loss: 0.176058 	 lr: 0.00006
[epoch 183:  80/307] 	 train loss: 0.178552 	 lr: 0.00006

val loss: 0.321668 	 acc: 0.908833

[epoch 183: 100/307] 	 train loss: 0.388421 	 lr: 0.00006
[epoch 183: 120/307] 	 train loss: 0.615306 	 lr: 0.00006
[epoch 183: 140/307] 	 train loss: 0.178790 	 lr: 0.00006
[epoch 183: 160/307] 	 train loss: 0.247969 	 lr: 0.00006
[epoch 183: 180/307] 	 train loss: 0.120780 	 lr: 0.00006
[epoch 183: 200/307] 	 train loss: 0.333190 	 lr: 0.00006
[epoch 183: 220/307] 	 train loss: 0.082035 	 lr: 0.00006
[epoch 183: 240/307] 	 train loss: 0.288568 	 lr: 0.00006

val loss: 0.332984 	 acc: 0.909238

[epoch 183: 260/307] 	 train loss: 0.100610 	 lr: 0.00006
[epoch 183: 280/307] 	 train loss: 0.200361 	 lr: 0.00006
[epoch 183: 300/307] 	 train loss: 0.124832 	 lr: 0.00006
[epoch 184:   0/307] 	 train loss: 0.274121 	 lr: 0.00006
[epoch 184:  20/307] 	 train loss: 0.101105 	 lr: 0.00006
[epoch 184:  40/307] 	 train loss: 0.177785 	 lr: 0.00006
[epoch 184:  60/307] 	 train loss: 0.186346 	 lr: 0.00006
[epoch 184:  80/307] 	 train loss: 0.207946 	 lr: 0.00006

val loss: 0.350971 	 acc: 0.908428

[epoch 184: 100/307] 	 train loss: 0.215822 	 lr: 0.00006
[epoch 184: 120/307] 	 train loss: 0.190861 	 lr: 0.00006
[epoch 184: 140/307] 	 train loss: 0.149906 	 lr: 0.00006
[epoch 184: 160/307] 	 train loss: 0.060312 	 lr: 0.00006
[epoch 184: 180/307] 	 train loss: 0.051937 	 lr: 0.00006
[epoch 184: 200/307] 	 train loss: 0.088767 	 lr: 0.00006
[epoch 184: 220/307] 	 train loss: 0.103361 	 lr: 0.00006
[epoch 184: 240/307] 	 train loss: 0.272219 	 lr: 0.00006

val loss: 0.336473 	 acc: 0.906807

[epoch 184: 260/307] 	 train loss: 0.083214 	 lr: 0.00006
[epoch 184: 280/307] 	 train loss: 0.081431 	 lr: 0.00006
[epoch 184: 300/307] 	 train loss: 0.086204 	 lr: 0.00006
[epoch 185:   0/307] 	 train loss: 0.199639 	 lr: 0.00006
[epoch 185:  20/307] 	 train loss: 0.146081 	 lr: 0.00006
[epoch 185:  40/307] 	 train loss: 0.278559 	 lr: 0.00006
[epoch 185:  60/307] 	 train loss: 0.026767 	 lr: 0.00006
[epoch 185:  80/307] 	 train loss: 0.213500 	 lr: 0.00006

val loss: 0.315614 	 acc: 0.906807

[epoch 185: 100/307] 	 train loss: 0.397123 	 lr: 0.00006
[epoch 185: 120/307] 	 train loss: 0.185658 	 lr: 0.00006
[epoch 185: 140/307] 	 train loss: 0.317767 	 lr: 0.00006
[epoch 185: 160/307] 	 train loss: 0.097059 	 lr: 0.00006
[epoch 185: 180/307] 	 train loss: 0.204294 	 lr: 0.00006
[epoch 185: 200/307] 	 train loss: 0.045164 	 lr: 0.00006
[epoch 185: 220/307] 	 train loss: 0.180976 	 lr: 0.00006
[epoch 185: 240/307] 	 train loss: 0.191140 	 lr: 0.00006

val loss: 0.329311 	 acc: 0.905997

[epoch 185: 260/307] 	 train loss: 0.254412 	 lr: 0.00006
[epoch 185: 280/307] 	 train loss: 0.166406 	 lr: 0.00006
[epoch 185: 300/307] 	 train loss: 0.022082 	 lr: 0.00006
[epoch 186:   0/307] 	 train loss: 0.390816 	 lr: 0.00006
[epoch 186:  20/307] 	 train loss: 0.214907 	 lr: 0.00006
[epoch 186:  40/307] 	 train loss: 0.100839 	 lr: 0.00006
[epoch 186:  60/307] 	 train loss: 0.120154 	 lr: 0.00006
[epoch 186:  80/307] 	 train loss: 0.209430 	 lr: 0.00006

val loss: 0.334191 	 acc: 0.910049

[epoch 186: 100/307] 	 train loss: 0.288133 	 lr: 0.00006
[epoch 186: 120/307] 	 train loss: 0.100494 	 lr: 0.00006
[epoch 186: 140/307] 	 train loss: 0.154356 	 lr: 0.00006
[epoch 186: 160/307] 	 train loss: 0.147930 	 lr: 0.00006
[epoch 186: 180/307] 	 train loss: 0.126656 	 lr: 0.00006
[epoch 186: 200/307] 	 train loss: 0.253595 	 lr: 0.00006
[epoch 186: 220/307] 	 train loss: 0.191253 	 lr: 0.00006
[epoch 186: 240/307] 	 train loss: 0.057888 	 lr: 0.00006

val loss: 0.334846 	 acc: 0.908428

[epoch 186: 260/307] 	 train loss: 0.021858 	 lr: 0.00006
[epoch 186: 280/307] 	 train loss: 0.110022 	 lr: 0.00006
[epoch 186: 300/307] 	 train loss: 0.198166 	 lr: 0.00006
[epoch 187:   0/307] 	 train loss: 0.119962 	 lr: 0.00006
[epoch 187:  20/307] 	 train loss: 0.054377 	 lr: 0.00006
[epoch 187:  40/307] 	 train loss: 0.098967 	 lr: 0.00006
[epoch 187:  60/307] 	 train loss: 0.262717 	 lr: 0.00006
[epoch 187:  80/307] 	 train loss: 0.308895 	 lr: 0.00006

val loss: 0.342561 	 acc: 0.905186

[epoch 187: 100/307] 	 train loss: 0.085492 	 lr: 0.00006
[epoch 187: 120/307] 	 train loss: 0.116373 	 lr: 0.00006
[epoch 187: 140/307] 	 train loss: 0.147635 	 lr: 0.00006
[epoch 187: 160/307] 	 train loss: 0.129179 	 lr: 0.00006
[epoch 187: 180/307] 	 train loss: 0.206036 	 lr: 0.00006
[epoch 187: 200/307] 	 train loss: 0.150913 	 lr: 0.00006
[epoch 187: 220/307] 	 train loss: 0.272287 	 lr: 0.00006

val loss: 0.332773 	 acc: 0.909643

[epoch 187: 240/307] 	 train loss: 0.153865 	 lr: 0.00006
[epoch 187: 260/307] 	 train loss: 0.114311 	 lr: 0.00006
[epoch 187: 280/307] 	 train loss: 0.127941 	 lr: 0.00006
[epoch 187: 300/307] 	 train loss: 0.047629 	 lr: 0.00006
[epoch 188:   0/307] 	 train loss: 0.065510 	 lr: 0.00006
[epoch 188:  20/307] 	 train loss: 0.154114 	 lr: 0.00006
[epoch 188:  40/307] 	 train loss: 0.058322 	 lr: 0.00006
[epoch 188:  60/307] 	 train loss: 0.238737 	 lr: 0.00006
[epoch 188:  80/307] 	 train loss: 0.141544 	 lr: 0.00006

val loss: 0.344041 	 acc: 0.909238

[epoch 188: 100/307] 	 train loss: 0.165609 	 lr: 0.00006
[epoch 188: 120/307] 	 train loss: 0.186108 	 lr: 0.00006
[epoch 188: 140/307] 	 train loss: 0.171846 	 lr: 0.00006
[epoch 188: 160/307] 	 train loss: 0.223956 	 lr: 0.00006
[epoch 188: 180/307] 	 train loss: 0.232477 	 lr: 0.00006
[epoch 188: 200/307] 	 train loss: 0.071781 	 lr: 0.00006
[epoch 188: 220/307] 	 train loss: 0.306423 	 lr: 0.00006

val loss: 0.339456 	 acc: 0.903971

[epoch 188: 240/307] 	 train loss: 0.161649 	 lr: 0.00006
[epoch 188: 260/307] 	 train loss: 0.290834 	 lr: 0.00006
[epoch 188: 280/307] 	 train loss: 0.109345 	 lr: 0.00006
[epoch 188: 300/307] 	 train loss: 0.334455 	 lr: 0.00006
[epoch 189:   0/307] 	 train loss: 0.216627 	 lr: 0.00006
[epoch 189:  20/307] 	 train loss: 0.231450 	 lr: 0.00006
[epoch 189:  40/307] 	 train loss: 0.345870 	 lr: 0.00006
[epoch 189:  60/307] 	 train loss: 0.174625 	 lr: 0.00006
[epoch 189:  80/307] 	 train loss: 0.102003 	 lr: 0.00006

val loss: 0.333424 	 acc: 0.912480

[epoch 189: 100/307] 	 train loss: 0.105291 	 lr: 0.00006
[epoch 189: 120/307] 	 train loss: 0.131692 	 lr: 0.00006
[epoch 189: 140/307] 	 train loss: 0.132467 	 lr: 0.00006
[epoch 189: 160/307] 	 train loss: 0.260302 	 lr: 0.00006
[epoch 189: 180/307] 	 train loss: 0.096235 	 lr: 0.00006
[epoch 189: 200/307] 	 train loss: 0.106469 	 lr: 0.00006
[epoch 189: 220/307] 	 train loss: 0.148692 	 lr: 0.00006

val loss: 0.329577 	 acc: 0.908023

[epoch 189: 240/307] 	 train loss: 0.225648 	 lr: 0.00006
[epoch 189: 260/307] 	 train loss: 0.180360 	 lr: 0.00006
[epoch 189: 280/307] 	 train loss: 0.073106 	 lr: 0.00006
[epoch 189: 300/307] 	 train loss: 0.162615 	 lr: 0.00006
[epoch 190:   0/307] 	 train loss: 0.219269 	 lr: 0.00004
[epoch 190:  20/307] 	 train loss: 0.250855 	 lr: 0.00004
[epoch 190:  40/307] 	 train loss: 0.260993 	 lr: 0.00004
[epoch 190:  60/307] 	 train loss: 0.357365 	 lr: 0.00004
[epoch 190:  80/307] 	 train loss: 0.242140 	 lr: 0.00004

val loss: 0.334595 	 acc: 0.913695

[epoch 190: 100/307] 	 train loss: 0.187384 	 lr: 0.00004
[epoch 190: 120/307] 	 train loss: 0.144325 	 lr: 0.00004
[epoch 190: 140/307] 	 train loss: 0.159316 	 lr: 0.00004
[epoch 190: 160/307] 	 train loss: 0.181539 	 lr: 0.00004
[epoch 190: 180/307] 	 train loss: 0.248878 	 lr: 0.00004
[epoch 190: 200/307] 	 train loss: 0.030634 	 lr: 0.00004
[epoch 190: 220/307] 	 train loss: 0.135478 	 lr: 0.00004

val loss: 0.352110 	 acc: 0.908428

[epoch 190: 240/307] 	 train loss: 0.241884 	 lr: 0.00004
[epoch 190: 260/307] 	 train loss: 0.216329 	 lr: 0.00004
[epoch 190: 280/307] 	 train loss: 0.110987 	 lr: 0.00004
[epoch 190: 300/307] 	 train loss: 0.361394 	 lr: 0.00004
[epoch 191:   0/307] 	 train loss: 0.189132 	 lr: 0.00004
[epoch 191:  20/307] 	 train loss: 0.245161 	 lr: 0.00004
[epoch 191:  40/307] 	 train loss: 0.228556 	 lr: 0.00004
[epoch 191:  60/307] 	 train loss: 0.231616 	 lr: 0.00004

val loss: 0.340556 	 acc: 0.910049

[epoch 191:  80/307] 	 train loss: 0.119313 	 lr: 0.00004
[epoch 191: 100/307] 	 train loss: 0.011336 	 lr: 0.00004
[epoch 191: 120/307] 	 train loss: 0.160161 	 lr: 0.00004
[epoch 191: 140/307] 	 train loss: 0.031041 	 lr: 0.00004
[epoch 191: 160/307] 	 train loss: 0.291823 	 lr: 0.00004
[epoch 191: 180/307] 	 train loss: 0.164636 	 lr: 0.00004
[epoch 191: 200/307] 	 train loss: 0.054748 	 lr: 0.00004
[epoch 191: 220/307] 	 train loss: 0.037240 	 lr: 0.00004

val loss: 0.328932 	 acc: 0.909643

[epoch 191: 240/307] 	 train loss: 0.070156 	 lr: 0.00004
[epoch 191: 260/307] 	 train loss: 0.098726 	 lr: 0.00004
[epoch 191: 280/307] 	 train loss: 0.143384 	 lr: 0.00004
[epoch 191: 300/307] 	 train loss: 0.348053 	 lr: 0.00004
[epoch 192:   0/307] 	 train loss: 0.256723 	 lr: 0.00004
[epoch 192:  20/307] 	 train loss: 0.165427 	 lr: 0.00004
[epoch 192:  40/307] 	 train loss: 0.080273 	 lr: 0.00004
[epoch 192:  60/307] 	 train loss: 0.218648 	 lr: 0.00004

val loss: 0.332094 	 acc: 0.911669

[epoch 192:  80/307] 	 train loss: 0.074632 	 lr: 0.00004
[epoch 192: 100/307] 	 train loss: 0.180525 	 lr: 0.00004
[epoch 192: 120/307] 	 train loss: 0.256466 	 lr: 0.00004
[epoch 192: 140/307] 	 train loss: 0.033332 	 lr: 0.00004
[epoch 192: 160/307] 	 train loss: 0.277261 	 lr: 0.00004
[epoch 192: 180/307] 	 train loss: 0.298986 	 lr: 0.00004
[epoch 192: 200/307] 	 train loss: 0.517138 	 lr: 0.00004
[epoch 192: 220/307] 	 train loss: 0.277620 	 lr: 0.00004

val loss: 0.340370 	 acc: 0.908428

[epoch 192: 240/307] 	 train loss: 0.215609 	 lr: 0.00004
[epoch 192: 260/307] 	 train loss: 0.112711 	 lr: 0.00004
[epoch 192: 280/307] 	 train loss: 0.106237 	 lr: 0.00004
[epoch 192: 300/307] 	 train loss: 0.308316 	 lr: 0.00004
[epoch 193:   0/307] 	 train loss: 0.178026 	 lr: 0.00004
[epoch 193:  20/307] 	 train loss: 0.180070 	 lr: 0.00004
[epoch 193:  40/307] 	 train loss: 0.350122 	 lr: 0.00004
[epoch 193:  60/307] 	 train loss: 0.109930 	 lr: 0.00004

val loss: 0.334088 	 acc: 0.911264

[epoch 193:  80/307] 	 train loss: 0.126822 	 lr: 0.00004
[epoch 193: 100/307] 	 train loss: 0.299400 	 lr: 0.00004
[epoch 193: 120/307] 	 train loss: 0.096589 	 lr: 0.00004
[epoch 193: 140/307] 	 train loss: 0.252620 	 lr: 0.00004
[epoch 193: 160/307] 	 train loss: 0.149998 	 lr: 0.00004
[epoch 193: 180/307] 	 train loss: 0.214764 	 lr: 0.00004
[epoch 193: 200/307] 	 train loss: 0.148816 	 lr: 0.00004
[epoch 193: 220/307] 	 train loss: 0.259543 	 lr: 0.00004

val loss: 0.332164 	 acc: 0.906807

[epoch 193: 240/307] 	 train loss: 0.324099 	 lr: 0.00004
[epoch 193: 260/307] 	 train loss: 0.114649 	 lr: 0.00004
[epoch 193: 280/307] 	 train loss: 0.138722 	 lr: 0.00004
[epoch 193: 300/307] 	 train loss: 0.177605 	 lr: 0.00004
[epoch 194:   0/307] 	 train loss: 0.252345 	 lr: 0.00004
[epoch 194:  20/307] 	 train loss: 0.241721 	 lr: 0.00004
[epoch 194:  40/307] 	 train loss: 0.408037 	 lr: 0.00004
[epoch 194:  60/307] 	 train loss: 0.199290 	 lr: 0.00004

val loss: 0.339716 	 acc: 0.912075

[epoch 194:  80/307] 	 train loss: 0.083494 	 lr: 0.00004
[epoch 194: 100/307] 	 train loss: 0.095410 	 lr: 0.00004
[epoch 194: 120/307] 	 train loss: 0.166387 	 lr: 0.00004
[epoch 194: 140/307] 	 train loss: 0.099297 	 lr: 0.00004
[epoch 194: 160/307] 	 train loss: 0.069538 	 lr: 0.00004
[epoch 194: 180/307] 	 train loss: 0.177400 	 lr: 0.00004
[epoch 194: 200/307] 	 train loss: 0.173280 	 lr: 0.00004
[epoch 194: 220/307] 	 train loss: 0.098441 	 lr: 0.00004

val loss: 0.335588 	 acc: 0.907212

[epoch 194: 240/307] 	 train loss: 0.074487 	 lr: 0.00004
[epoch 194: 260/307] 	 train loss: 0.122475 	 lr: 0.00004
[epoch 194: 280/307] 	 train loss: 0.120526 	 lr: 0.00004
[epoch 194: 300/307] 	 train loss: 0.169214 	 lr: 0.00004
[epoch 195:   0/307] 	 train loss: 0.157585 	 lr: 0.00004
[epoch 195:  20/307] 	 train loss: 0.180147 	 lr: 0.00004
[epoch 195:  40/307] 	 train loss: 0.219051 	 lr: 0.00004
[epoch 195:  60/307] 	 train loss: 0.456557 	 lr: 0.00004

val loss: 0.327115 	 acc: 0.908023

[epoch 195:  80/307] 	 train loss: 0.140886 	 lr: 0.00004
[epoch 195: 100/307] 	 train loss: 0.115224 	 lr: 0.00004
[epoch 195: 120/307] 	 train loss: 0.104434 	 lr: 0.00004
[epoch 195: 140/307] 	 train loss: 0.026785 	 lr: 0.00004
[epoch 195: 160/307] 	 train loss: 0.031304 	 lr: 0.00004
[epoch 195: 180/307] 	 train loss: 0.206916 	 lr: 0.00004
[epoch 195: 200/307] 	 train loss: 0.091762 	 lr: 0.00004
[epoch 195: 220/307] 	 train loss: 0.393447 	 lr: 0.00004

val loss: 0.336765 	 acc: 0.905592

[epoch 195: 240/307] 	 train loss: 0.045563 	 lr: 0.00004
[epoch 195: 260/307] 	 train loss: 0.174316 	 lr: 0.00004
[epoch 195: 280/307] 	 train loss: 0.105086 	 lr: 0.00004
[epoch 195: 300/307] 	 train loss: 0.184450 	 lr: 0.00004
[epoch 196:   0/307] 	 train loss: 0.148906 	 lr: 0.00004
[epoch 196:  20/307] 	 train loss: 0.100293 	 lr: 0.00004
[epoch 196:  40/307] 	 train loss: 0.078691 	 lr: 0.00004
[epoch 196:  60/307] 	 train loss: 0.085703 	 lr: 0.00004

val loss: 0.333337 	 acc: 0.912075

[epoch 196:  80/307] 	 train loss: 0.365960 	 lr: 0.00004
[epoch 196: 100/307] 	 train loss: 0.287255 	 lr: 0.00004
[epoch 196: 120/307] 	 train loss: 0.139454 	 lr: 0.00004
[epoch 196: 140/307] 	 train loss: 0.072607 	 lr: 0.00004
[epoch 196: 160/307] 	 train loss: 0.067914 	 lr: 0.00004
[epoch 196: 180/307] 	 train loss: 0.188277 	 lr: 0.00004
[epoch 196: 200/307] 	 train loss: 0.269973 	 lr: 0.00004
[epoch 196: 220/307] 	 train loss: 0.225232 	 lr: 0.00004

val loss: 0.350462 	 acc: 0.903971

[epoch 196: 240/307] 	 train loss: 0.295181 	 lr: 0.00004
[epoch 196: 260/307] 	 train loss: 0.289600 	 lr: 0.00004
[epoch 196: 280/307] 	 train loss: 0.055537 	 lr: 0.00004
[epoch 196: 300/307] 	 train loss: 0.275861 	 lr: 0.00004
[epoch 197:   0/307] 	 train loss: 0.030665 	 lr: 0.00004
[epoch 197:  20/307] 	 train loss: 0.043421 	 lr: 0.00004
[epoch 197:  40/307] 	 train loss: 0.056919 	 lr: 0.00004
[epoch 197:  60/307] 	 train loss: 0.164983 	 lr: 0.00004

val loss: 0.332820 	 acc: 0.909643

[epoch 197:  80/307] 	 train loss: 0.055757 	 lr: 0.00004
[epoch 197: 100/307] 	 train loss: 0.301541 	 lr: 0.00004
[epoch 197: 120/307] 	 train loss: 0.014269 	 lr: 0.00004
[epoch 197: 140/307] 	 train loss: 0.132380 	 lr: 0.00004
[epoch 197: 160/307] 	 train loss: 0.208554 	 lr: 0.00004
[epoch 197: 180/307] 	 train loss: 0.180389 	 lr: 0.00004
[epoch 197: 200/307] 	 train loss: 0.113850 	 lr: 0.00004

val loss: 0.317328 	 acc: 0.913290

[epoch 197: 220/307] 	 train loss: 0.285516 	 lr: 0.00004
[epoch 197: 240/307] 	 train loss: 0.169856 	 lr: 0.00004
[epoch 197: 260/307] 	 train loss: 0.183242 	 lr: 0.00004
[epoch 197: 280/307] 	 train loss: 0.234593 	 lr: 0.00004
[epoch 197: 300/307] 	 train loss: 0.127443 	 lr: 0.00004
[epoch 198:   0/307] 	 train loss: 0.320610 	 lr: 0.00004
[epoch 198:  20/307] 	 train loss: 0.204009 	 lr: 0.00004
[epoch 198:  40/307] 	 train loss: 0.423221 	 lr: 0.00004
[epoch 198:  60/307] 	 train loss: 0.367367 	 lr: 0.00004

val loss: 0.336805 	 acc: 0.905997

[epoch 198:  80/307] 	 train loss: 0.377540 	 lr: 0.00004
[epoch 198: 100/307] 	 train loss: 0.152760 	 lr: 0.00004
[epoch 198: 120/307] 	 train loss: 0.126378 	 lr: 0.00004
[epoch 198: 140/307] 	 train loss: 0.102406 	 lr: 0.00004
[epoch 198: 160/307] 	 train loss: 0.046732 	 lr: 0.00004
[epoch 198: 180/307] 	 train loss: 0.089990 	 lr: 0.00004
[epoch 198: 200/307] 	 train loss: 0.291651 	 lr: 0.00004

val loss: 0.342471 	 acc: 0.905997

[epoch 198: 220/307] 	 train loss: 0.289940 	 lr: 0.00004
[epoch 198: 240/307] 	 train loss: 0.073264 	 lr: 0.00004
[epoch 198: 260/307] 	 train loss: 0.125867 	 lr: 0.00004
[epoch 198: 280/307] 	 train loss: 0.399782 	 lr: 0.00004
[epoch 198: 300/307] 	 train loss: 0.147241 	 lr: 0.00004
[epoch 199:   0/307] 	 train loss: 0.205079 	 lr: 0.00004
[epoch 199:  20/307] 	 train loss: 0.168695 	 lr: 0.00004
[epoch 199:  40/307] 	 train loss: 0.129669 	 lr: 0.00004
[epoch 199:  60/307] 	 train loss: 0.171683 	 lr: 0.00004

val loss: 0.340309 	 acc: 0.912480

[epoch 199:  80/307] 	 train loss: 0.161156 	 lr: 0.00004
[epoch 199: 100/307] 	 train loss: 0.154070 	 lr: 0.00004
[epoch 199: 120/307] 	 train loss: 0.094867 	 lr: 0.00004
[epoch 199: 140/307] 	 train loss: 0.141339 	 lr: 0.00004
[epoch 199: 160/307] 	 train loss: 0.187157 	 lr: 0.00004
[epoch 199: 180/307] 	 train loss: 0.343456 	 lr: 0.00004
[epoch 199: 200/307] 	 train loss: 0.137814 	 lr: 0.00004

val loss: 0.342398 	 acc: 0.907618

[epoch 199: 220/307] 	 train loss: 0.406783 	 lr: 0.00004
[epoch 199: 240/307] 	 train loss: 0.324882 	 lr: 0.00004
[epoch 199: 260/307] 	 train loss: 0.237800 	 lr: 0.00004
[epoch 199: 280/307] 	 train loss: 0.113255 	 lr: 0.00004
[epoch 199: 300/307] 	 train loss: 0.274610 	 lr: 0.00004
[epoch 200:   0/307] 	 train loss: 0.030902 	 lr: 0.00004
[epoch 200:  20/307] 	 train loss: 0.199887 	 lr: 0.00004
[epoch 200:  40/307] 	 train loss: 0.223332 	 lr: 0.00004
[epoch 200:  60/307] 	 train loss: 0.273894 	 lr: 0.00004

val loss: 0.341589 	 acc: 0.908023

[epoch 200:  80/307] 	 train loss: 0.112239 	 lr: 0.00004
[epoch 200: 100/307] 	 train loss: 0.138195 	 lr: 0.00004
[epoch 200: 120/307] 	 train loss: 0.134975 	 lr: 0.00004
[epoch 200: 140/307] 	 train loss: 0.469694 	 lr: 0.00004
[epoch 200: 160/307] 	 train loss: 0.071499 	 lr: 0.00004
[epoch 200: 180/307] 	 train loss: 0.253143 	 lr: 0.00004
[epoch 200: 200/307] 	 train loss: 0.075267 	 lr: 0.00004

val loss: 0.352304 	 acc: 0.905997

[epoch 200: 220/307] 	 train loss: 0.066721 	 lr: 0.00004
[epoch 200: 240/307] 	 train loss: 0.136249 	 lr: 0.00004
[epoch 200: 260/307] 	 train loss: 0.104044 	 lr: 0.00004
[epoch 200: 280/307] 	 train loss: 0.171774 	 lr: 0.00004
[epoch 200: 300/307] 	 train loss: 0.110623 	 lr: 0.00004

**************************

[save_path]: log-baseline

[epochs]: 200

[lr_decay]: 0.7

[num_points]: 1024

[workers]: 4

[num_classes]: 40

[print_freq_iter]: 20

[weight_decay]: 0

[batch_size]: 32

[bn_decay]: 0.5

[lr_clip]: 1e-05

[base_lr]: 0.001

[bnm_clip]: 0.01

[val_freq_epoch]: 0.5

[evaluate]: 1

[data_root]: ../../Datasets

[decay_step]: 21

[checkpoint]: log-baseline/cls_iter_53244_acc_0.916532.pth

[bn_momentum]: 0.9

[input_channels]: 0

**************************

Load model successfully: log-baseline/cls_iter_53244_acc_0.916532.pth
[epoch   1:   0/307] 	 train loss: 0.080005 	 lr: 0.00100
[epoch   1:  20/307] 	 train loss: 0.165949 	 lr: 0.00100
[epoch   1:  40/307] 	 train loss: 0.158615 	 lr: 0.00100
[epoch   1:  60/307] 	 train loss: 0.159026 	 lr: 0.00100
[epoch   1:  80/307] 	 train loss: 0.177927 	 lr: 0.00100
[epoch   1: 100/307] 	 train loss: 0.170544 	 lr: 0.00100
[epoch   1: 120/307] 	 train loss: 0.363238 	 lr: 0.00100
[epoch   1: 140/307] 	 train loss: 0.180722 	 lr: 0.00100

val loss: 3.395339 	 acc: 0.643031

[epoch   1: 160/307] 	 train loss: 0.168324 	 lr: 0.00100
[epoch   1: 180/307] 	 train loss: 0.376524 	 lr: 0.00100
[epoch   1: 200/307] 	 train loss: 0.164083 	 lr: 0.00100
[epoch   1: 220/307] 	 train loss: 0.201693 	 lr: 0.00100
[epoch   1: 240/307] 	 train loss: 0.214319 	 lr: 0.00100
[epoch   1: 260/307] 	 train loss: 0.449858 	 lr: 0.00100
[epoch   1: 280/307] 	 train loss: 0.130793 	 lr: 0.00100
[epoch   1: 300/307] 	 train loss: 0.420990 	 lr: 0.00100

val loss: 15.335645 	 acc: 0.298622

[epoch   2:   0/307] 	 train loss: 0.247484 	 lr: 0.00100
[epoch   2:  20/307] 	 train loss: 0.118320 	 lr: 0.00100
[epoch   2:  40/307] 	 train loss: 0.157022 	 lr: 0.00100
[epoch   2:  60/307] 	 train loss: 0.216799 	 lr: 0.00100
[epoch   2:  80/307] 	 train loss: 0.440609 	 lr: 0.00100
[epoch   2: 100/307] 	 train loss: 0.072739 	 lr: 0.00100
[epoch   2: 120/307] 	 train loss: 0.075008 	 lr: 0.00100
[epoch   2: 140/307] 	 train loss: 0.261130 	 lr: 0.00100

val loss: 0.381797 	 acc: 0.898703

[epoch   2: 160/307] 	 train loss: 0.155039 	 lr: 0.00100
[epoch   2: 180/307] 	 train loss: 0.167638 	 lr: 0.00100
[epoch   2: 200/307] 	 train loss: 0.192187 	 lr: 0.00100
[epoch   2: 220/307] 	 train loss: 0.248424 	 lr: 0.00100
[epoch   2: 240/307] 	 train loss: 0.554602 	 lr: 0.00100
[epoch   2: 260/307] 	 train loss: 0.258011 	 lr: 0.00100
[epoch   2: 280/307] 	 train loss: 0.183094 	 lr: 0.00100
[epoch   2: 300/307] 	 train loss: 0.129052 	 lr: 0.00100

val loss: 0.409507 	 acc: 0.892626

[epoch   3:   0/307] 	 train loss: 0.077530 	 lr: 0.00100
[epoch   3:  20/307] 	 train loss: 0.347200 	 lr: 0.00100
[epoch   3:  40/307] 	 train loss: 0.503582 	 lr: 0.00100
[epoch   3:  60/307] 	 train loss: 0.226476 	 lr: 0.00100
[epoch   3:  80/307] 	 train loss: 0.132012 	 lr: 0.00100
[epoch   3: 100/307] 	 train loss: 0.189180 	 lr: 0.00100
[epoch   3: 120/307] 	 train loss: 0.161265 	 lr: 0.00100
[epoch   3: 140/307] 	 train loss: 0.224331 	 lr: 0.00100

val loss: 0.423310 	 acc: 0.895057

[epoch   3: 160/307] 	 train loss: 0.220549 	 lr: 0.00100
[epoch   3: 180/307] 	 train loss: 0.477047 	 lr: 0.00100
[epoch   3: 200/307] 	 train loss: 0.250076 	 lr: 0.00100
[epoch   3: 220/307] 	 train loss: 0.167711 	 lr: 0.00100
[epoch   3: 240/307] 	 train loss: 0.451079 	 lr: 0.00100
[epoch   3: 260/307] 	 train loss: 0.187581 	 lr: 0.00100
[epoch   3: 280/307] 	 train loss: 0.151483 	 lr: 0.00100
[epoch   3: 300/307] 	 train loss: 0.195766 	 lr: 0.00100

val loss: 0.359840 	 acc: 0.905997

[epoch   4:   0/307] 	 train loss: 0.123628 	 lr: 0.00100
[epoch   4:  20/307] 	 train loss: 0.166430 	 lr: 0.00100
[epoch   4:  40/307] 	 train loss: 0.110092 	 lr: 0.00100
[epoch   4:  60/307] 	 train loss: 0.221159 	 lr: 0.00100
[epoch   4:  80/307] 	 train loss: 0.387769 	 lr: 0.00100
[epoch   4: 100/307] 	 train loss: 0.134354 	 lr: 0.00100
[epoch   4: 120/307] 	 train loss: 0.189261 	 lr: 0.00100
[epoch   4: 140/307] 	 train loss: 0.414835 	 lr: 0.00100

val loss: 0.386695 	 acc: 0.890194

[epoch   4: 160/307] 	 train loss: 0.111800 	 lr: 0.00100
[epoch   4: 180/307] 	 train loss: 0.162964 	 lr: 0.00100
[epoch   4: 200/307] 	 train loss: 0.245280 	 lr: 0.00100
[epoch   4: 220/307] 	 train loss: 0.205904 	 lr: 0.00100
[epoch   4: 240/307] 	 train loss: 0.210178 	 lr: 0.00100
[epoch   4: 260/307] 	 train loss: 0.359981 	 lr: 0.00100
[epoch   4: 280/307] 	 train loss: 0.186193 	 lr: 0.00100

val loss: 0.416821 	 acc: 0.893841

[epoch   4: 300/307] 	 train loss: 0.378585 	 lr: 0.00100
[epoch   5:   0/307] 	 train loss: 0.175741 	 lr: 0.00100
[epoch   5:  20/307] 	 train loss: 0.528510 	 lr: 0.00100
[epoch   5:  40/307] 	 train loss: 0.186636 	 lr: 0.00100
[epoch   5:  60/307] 	 train loss: 0.308645 	 lr: 0.00100
[epoch   5:  80/307] 	 train loss: 0.402262 	 lr: 0.00100
[epoch   5: 100/307] 	 train loss: 0.277502 	 lr: 0.00100
[epoch   5: 120/307] 	 train loss: 0.243000 	 lr: 0.00100
[epoch   5: 140/307] 	 train loss: 0.537303 	 lr: 0.00100

val loss: 0.394870 	 acc: 0.897488

[epoch   5: 160/307] 	 train loss: 0.134399 	 lr: 0.00100
[epoch   5: 180/307] 	 train loss: 0.063436 	 lr: 0.00100
[epoch   5: 200/307] 	 train loss: 0.309424 	 lr: 0.00100
[epoch   5: 220/307] 	 train loss: 0.397443 	 lr: 0.00100
[epoch   5: 240/307] 	 train loss: 0.483582 	 lr: 0.00100
[epoch   5: 260/307] 	 train loss: 0.179627 	 lr: 0.00100
[epoch   5: 280/307] 	 train loss: 0.316115 	 lr: 0.00100

val loss: 0.398412 	 acc: 0.882091

[epoch   5: 300/307] 	 train loss: 0.366204 	 lr: 0.00100
[epoch   6:   0/307] 	 train loss: 0.126429 	 lr: 0.00100
[epoch   6:  20/307] 	 train loss: 0.361888 	 lr: 0.00100
[epoch   6:  40/307] 	 train loss: 0.211060 	 lr: 0.00100
[epoch   6:  60/307] 	 train loss: 0.161016 	 lr: 0.00100
[epoch   6:  80/307] 	 train loss: 0.478999 	 lr: 0.00100
[epoch   6: 100/307] 	 train loss: 0.170616 	 lr: 0.00100
[epoch   6: 120/307] 	 train loss: 0.336564 	 lr: 0.00100
[epoch   6: 140/307] 	 train loss: 0.695359 	 lr: 0.00100

val loss: 0.372645 	 acc: 0.901945

[epoch   6: 160/307] 	 train loss: 0.066161 	 lr: 0.00100
[epoch   6: 180/307] 	 train loss: 0.205723 	 lr: 0.00100
[epoch   6: 200/307] 	 train loss: 0.218825 	 lr: 0.00100
[epoch   6: 220/307] 	 train loss: 0.250785 	 lr: 0.00100
[epoch   6: 240/307] 	 train loss: 0.348506 	 lr: 0.00100
[epoch   6: 260/307] 	 train loss: 0.270056 	 lr: 0.00100
[epoch   6: 280/307] 	 train loss: 0.137524 	 lr: 0.00100

val loss: 0.377980 	 acc: 0.890600

[epoch   6: 300/307] 	 train loss: 0.167993 	 lr: 0.00100
[epoch   7:   0/307] 	 train loss: 0.058952 	 lr: 0.00100
[epoch   7:  20/307] 	 train loss: 0.080668 	 lr: 0.00100
[epoch   7:  40/307] 	 train loss: 0.223088 	 lr: 0.00100
[epoch   7:  60/307] 	 train loss: 0.141235 	 lr: 0.00100
[epoch   7:  80/307] 	 train loss: 0.239403 	 lr: 0.00100
[epoch   7: 100/307] 	 train loss: 0.232492 	 lr: 0.00100
[epoch   7: 120/307] 	 train loss: 0.054833 	 lr: 0.00100
[epoch   7: 140/307] 	 train loss: 0.551122 	 lr: 0.00100

val loss: 0.373066 	 acc: 0.898703

[epoch   7: 160/307] 	 train loss: 0.209217 	 lr: 0.00100
[epoch   7: 180/307] 	 train loss: 0.150004 	 lr: 0.00100
[epoch   7: 200/307] 	 train loss: 0.052388 	 lr: 0.00100
[epoch   7: 220/307] 	 train loss: 0.199566 	 lr: 0.00100
[epoch   7: 240/307] 	 train loss: 0.091567 	 lr: 0.00100
[epoch   7: 260/307] 	 train loss: 0.628719 	 lr: 0.00100
[epoch   7: 280/307] 	 train loss: 0.108017 	 lr: 0.00100

val loss: 0.367427 	 acc: 0.898703

[epoch   7: 300/307] 	 train loss: 0.392900 	 lr: 0.00100
[epoch   8:   0/307] 	 train loss: 0.175384 	 lr: 0.00100
[epoch   8:  20/307] 	 train loss: 0.279175 	 lr: 0.00100
[epoch   8:  40/307] 	 train loss: 0.226631 	 lr: 0.00100
[epoch   8:  60/307] 	 train loss: 0.183332 	 lr: 0.00100
[epoch   8:  80/307] 	 train loss: 0.666332 	 lr: 0.00100
[epoch   8: 100/307] 	 train loss: 0.395179 	 lr: 0.00100
[epoch   8: 120/307] 	 train loss: 0.069652 	 lr: 0.00100

val loss: 0.370050 	 acc: 0.902755

[epoch   8: 140/307] 	 train loss: 0.403272 	 lr: 0.00100
[epoch   8: 160/307] 	 train loss: 0.071348 	 lr: 0.00100
[epoch   8: 180/307] 	 train loss: 0.199602 	 lr: 0.00100
[epoch   8: 200/307] 	 train loss: 0.302490 	 lr: 0.00100
[epoch   8: 220/307] 	 train loss: 0.111331 	 lr: 0.00100
[epoch   8: 240/307] 	 train loss: 0.193465 	 lr: 0.00100
[epoch   8: 260/307] 	 train loss: 0.173608 	 lr: 0.00100
[epoch   8: 280/307] 	 train loss: 0.308722 	 lr: 0.00100

val loss: 0.420045 	 acc: 0.889789

[epoch   8: 300/307] 	 train loss: 0.374827 	 lr: 0.00100
[epoch   9:   0/307] 	 train loss: 0.153245 	 lr: 0.00100
[epoch   9:  20/307] 	 train loss: 0.679245 	 lr: 0.00100
[epoch   9:  40/307] 	 train loss: 0.274665 	 lr: 0.00100
[epoch   9:  60/307] 	 train loss: 0.197502 	 lr: 0.00100
[epoch   9:  80/307] 	 train loss: 0.290353 	 lr: 0.00100
[epoch   9: 100/307] 	 train loss: 0.258819 	 lr: 0.00100
[epoch   9: 120/307] 	 train loss: 0.304104 	 lr: 0.00100

val loss: 0.374828 	 acc: 0.893841

[epoch   9: 140/307] 	 train loss: 0.237076 	 lr: 0.00100
[epoch   9: 160/307] 	 train loss: 0.203462 	 lr: 0.00100
[epoch   9: 180/307] 	 train loss: 0.510863 	 lr: 0.00100
[epoch   9: 200/307] 	 train loss: 0.448552 	 lr: 0.00100
[epoch   9: 220/307] 	 train loss: 0.131216 	 lr: 0.00100
[epoch   9: 240/307] 	 train loss: 0.128161 	 lr: 0.00100
[epoch   9: 260/307] 	 train loss: 0.188746 	 lr: 0.00100
[epoch   9: 280/307] 	 train loss: 0.135911 	 lr: 0.00100

val loss: 0.377489 	 acc: 0.896272

[epoch   9: 300/307] 	 train loss: 0.225771 	 lr: 0.00100
[epoch  10:   0/307] 	 train loss: 0.343409 	 lr: 0.00100
[epoch  10:  20/307] 	 train loss: 0.324574 	 lr: 0.00100
[epoch  10:  40/307] 	 train loss: 0.132091 	 lr: 0.00100
[epoch  10:  60/307] 	 train loss: 0.060205 	 lr: 0.00100
[epoch  10:  80/307] 	 train loss: 0.302092 	 lr: 0.00100
[epoch  10: 100/307] 	 train loss: 0.106219 	 lr: 0.00100
[epoch  10: 120/307] 	 train loss: 0.305681 	 lr: 0.00100

val loss: 0.398322 	 acc: 0.875203

[epoch  10: 140/307] 	 train loss: 0.113813 	 lr: 0.00100
[epoch  10: 160/307] 	 train loss: 0.422098 	 lr: 0.00100
[epoch  10: 180/307] 	 train loss: 0.093702 	 lr: 0.00100
[epoch  10: 200/307] 	 train loss: 0.705668 	 lr: 0.00100
[epoch  10: 220/307] 	 train loss: 0.109628 	 lr: 0.00100
[epoch  10: 240/307] 	 train loss: 0.119248 	 lr: 0.00100
[epoch  10: 260/307] 	 train loss: 0.688069 	 lr: 0.00100
[epoch  10: 280/307] 	 train loss: 0.178610 	 lr: 0.00100

val loss: 0.418217 	 acc: 0.893436

[epoch  10: 300/307] 	 train loss: 0.432209 	 lr: 0.00100
[epoch  11:   0/307] 	 train loss: 0.188548 	 lr: 0.00100
[epoch  11:  20/307] 	 train loss: 0.245445 	 lr: 0.00100
[epoch  11:  40/307] 	 train loss: 0.451036 	 lr: 0.00100
[epoch  11:  60/307] 	 train loss: 0.236439 	 lr: 0.00100
[epoch  11:  80/307] 	 train loss: 0.131122 	 lr: 0.00100
[epoch  11: 100/307] 	 train loss: 0.248384 	 lr: 0.00100
[epoch  11: 120/307] 	 train loss: 0.109154 	 lr: 0.00100

val loss: 0.354504 	 acc: 0.897083

[epoch  11: 140/307] 	 train loss: 0.027840 	 lr: 0.00100
[epoch  11: 160/307] 	 train loss: 0.139199 	 lr: 0.00100
[epoch  11: 180/307] 	 train loss: 0.288245 	 lr: 0.00100
[epoch  11: 200/307] 	 train loss: 0.421229 	 lr: 0.00100
[epoch  11: 220/307] 	 train loss: 0.078889 	 lr: 0.00100
[epoch  11: 240/307] 	 train loss: 0.317480 	 lr: 0.00100
[epoch  11: 260/307] 	 train loss: 0.489659 	 lr: 0.00100
[epoch  11: 280/307] 	 train loss: 0.320893 	 lr: 0.00100

val loss: 0.397495 	 acc: 0.885737

[epoch  11: 300/307] 	 train loss: 0.337362 	 lr: 0.00100
[epoch  12:   0/307] 	 train loss: 0.215262 	 lr: 0.00100
[epoch  12:  20/307] 	 train loss: 0.160550 	 lr: 0.00100
[epoch  12:  40/307] 	 train loss: 0.322072 	 lr: 0.00100
[epoch  12:  60/307] 	 train loss: 0.214988 	 lr: 0.00100
[epoch  12:  80/307] 	 train loss: 0.364519 	 lr: 0.00100
[epoch  12: 100/307] 	 train loss: 0.254218 	 lr: 0.00100
[epoch  12: 120/307] 	 train loss: 0.262755 	 lr: 0.00100

val loss: 0.355774 	 acc: 0.894652

[epoch  12: 140/307] 	 train loss: 0.127293 	 lr: 0.00100
[epoch  12: 160/307] 	 train loss: 0.414908 	 lr: 0.00100
[epoch  12: 180/307] 	 train loss: 0.205301 	 lr: 0.00100
[epoch  12: 200/307] 	 train loss: 0.787882 	 lr: 0.00100
[epoch  12: 220/307] 	 train loss: 0.374513 	 lr: 0.00100
[epoch  12: 240/307] 	 train loss: 0.432667 	 lr: 0.00100
[epoch  12: 260/307] 	 train loss: 0.257133 	 lr: 0.00100
[epoch  12: 280/307] 	 train loss: 0.211410 	 lr: 0.00100

val loss: 0.369676 	 acc: 0.891815

[epoch  12: 300/307] 	 train loss: 0.429572 	 lr: 0.00100
[epoch  13:   0/307] 	 train loss: 0.480743 	 lr: 0.00100
[epoch  13:  20/307] 	 train loss: 0.286059 	 lr: 0.00100
[epoch  13:  40/307] 	 train loss: 0.281289 	 lr: 0.00100
[epoch  13:  60/307] 	 train loss: 0.250904 	 lr: 0.00100
[epoch  13:  80/307] 	 train loss: 0.116276 	 lr: 0.00100
[epoch  13: 100/307] 	 train loss: 0.467901 	 lr: 0.00100
[epoch  13: 120/307] 	 train loss: 0.354582 	 lr: 0.00100

val loss: 0.341231 	 acc: 0.899514

[epoch  13: 140/307] 	 train loss: 0.177150 	 lr: 0.00100
[epoch  13: 160/307] 	 train loss: 0.306849 	 lr: 0.00100
[epoch  13: 180/307] 	 train loss: 0.264075 	 lr: 0.00100
[epoch  13: 200/307] 	 train loss: 0.168031 	 lr: 0.00100
[epoch  13: 220/307] 	 train loss: 0.378906 	 lr: 0.00100
[epoch  13: 240/307] 	 train loss: 0.074372 	 lr: 0.00100
[epoch  13: 260/307] 	 train loss: 0.151379 	 lr: 0.00100
[epoch  13: 280/307] 	 train loss: 0.355368 	 lr: 0.00100

val loss: 0.350317 	 acc: 0.899109

[epoch  13: 300/307] 	 train loss: 0.171872 	 lr: 0.00100
[epoch  14:   0/307] 	 train loss: 0.371134 	 lr: 0.00100
[epoch  14:  20/307] 	 train loss: 0.198889 	 lr: 0.00100
[epoch  14:  40/307] 	 train loss: 0.356668 	 lr: 0.00100
[epoch  14:  60/307] 	 train loss: 0.321340 	 lr: 0.00100
[epoch  14:  80/307] 	 train loss: 0.463626 	 lr: 0.00100
[epoch  14: 100/307] 	 train loss: 0.306313 	 lr: 0.00100
[epoch  14: 120/307] 	 train loss: 0.103780 	 lr: 0.00100

val loss: 0.355568 	 acc: 0.896677

[epoch  14: 140/307] 	 train loss: 0.308284 	 lr: 0.00100
[epoch  14: 160/307] 	 train loss: 0.314705 	 lr: 0.00100
[epoch  14: 180/307] 	 train loss: 0.145136 	 lr: 0.00100
[epoch  14: 200/307] 	 train loss: 0.144597 	 lr: 0.00100
[epoch  14: 220/307] 	 train loss: 0.327904 	 lr: 0.00100
[epoch  14: 240/307] 	 train loss: 0.486645 	 lr: 0.00100
[epoch  14: 260/307] 	 train loss: 0.322578 	 lr: 0.00100

val loss: 0.360829 	 acc: 0.895867

[epoch  14: 280/307] 	 train loss: 0.229309 	 lr: 0.00100
[epoch  14: 300/307] 	 train loss: 0.210776 	 lr: 0.00100
[epoch  15:   0/307] 	 train loss: 0.338722 	 lr: 0.00100
[epoch  15:  20/307] 	 train loss: 0.100729 	 lr: 0.00100
[epoch  15:  40/307] 	 train loss: 0.273013 	 lr: 0.00100
[epoch  15:  60/307] 	 train loss: 0.241981 	 lr: 0.00100
[epoch  15:  80/307] 	 train loss: 0.144631 	 lr: 0.00100
[epoch  15: 100/307] 	 train loss: 0.102237 	 lr: 0.00100
[epoch  15: 120/307] 	 train loss: 0.380512 	 lr: 0.00100

val loss: 0.344371 	 acc: 0.903160

[epoch  15: 140/307] 	 train loss: 0.560194 	 lr: 0.00100
[epoch  15: 160/307] 	 train loss: 0.479606 	 lr: 0.00100
[epoch  15: 180/307] 	 train loss: 0.383639 	 lr: 0.00100
[epoch  15: 200/307] 	 train loss: 0.266325 	 lr: 0.00100
[epoch  15: 220/307] 	 train loss: 0.280560 	 lr: 0.00100
[epoch  15: 240/307] 	 train loss: 0.384139 	 lr: 0.00100
[epoch  15: 260/307] 	 train loss: 0.206012 	 lr: 0.00100

val loss: 0.426578 	 acc: 0.893031

[epoch  15: 280/307] 	 train loss: 0.242727 	 lr: 0.00100
[epoch  15: 300/307] 	 train loss: 0.186921 	 lr: 0.00100
[epoch  16:   0/307] 	 train loss: 0.038839 	 lr: 0.00100
[epoch  16:  20/307] 	 train loss: 0.255492 	 lr: 0.00100
[epoch  16:  40/307] 	 train loss: 0.253573 	 lr: 0.00100
[epoch  16:  60/307] 	 train loss: 0.173078 	 lr: 0.00100
[epoch  16:  80/307] 	 train loss: 0.288908 	 lr: 0.00100
[epoch  16: 100/307] 	 train loss: 0.130398 	 lr: 0.00100
[epoch  16: 120/307] 	 train loss: 0.132027 	 lr: 0.00100

val loss: 0.358751 	 acc: 0.889789

[epoch  16: 140/307] 	 train loss: 0.412067 	 lr: 0.00100
[epoch  16: 160/307] 	 train loss: 0.329011 	 lr: 0.00100
[epoch  16: 180/307] 	 train loss: 0.463324 	 lr: 0.00100
[epoch  16: 200/307] 	 train loss: 0.275709 	 lr: 0.00100
[epoch  16: 220/307] 	 train loss: 0.274596 	 lr: 0.00100
[epoch  16: 240/307] 	 train loss: 0.302150 	 lr: 0.00100
[epoch  16: 260/307] 	 train loss: 0.346927 	 lr: 0.00100

val loss: 0.413825 	 acc: 0.892626

[epoch  16: 280/307] 	 train loss: 0.578295 	 lr: 0.00100
[epoch  16: 300/307] 	 train loss: 0.264596 	 lr: 0.00100
[epoch  17:   0/307] 	 train loss: 0.312842 	 lr: 0.00100
[epoch  17:  20/307] 	 train loss: 0.404380 	 lr: 0.00100
[epoch  17:  40/307] 	 train loss: 0.128220 	 lr: 0.00100
[epoch  17:  60/307] 	 train loss: 0.348951 	 lr: 0.00100
[epoch  17:  80/307] 	 train loss: 0.419511 	 lr: 0.00100
[epoch  17: 100/307] 	 train loss: 0.196573 	 lr: 0.00100
[epoch  17: 120/307] 	 train loss: 0.323851 	 lr: 0.00100

val loss: 0.424316 	 acc: 0.888169

[epoch  17: 140/307] 	 train loss: 0.338330 	 lr: 0.00100
[epoch  17: 160/307] 	 train loss: 0.495187 	 lr: 0.00100
[epoch  17: 180/307] 	 train loss: 0.185284 	 lr: 0.00100
[epoch  17: 200/307] 	 train loss: 0.162764 	 lr: 0.00100
[epoch  17: 220/307] 	 train loss: 0.173510 	 lr: 0.00100
[epoch  17: 240/307] 	 train loss: 0.195253 	 lr: 0.00100
[epoch  17: 260/307] 	 train loss: 0.592776 	 lr: 0.00100

val loss: 0.351985 	 acc: 0.907212

[epoch  17: 280/307] 	 train loss: 0.260476 	 lr: 0.00100
[epoch  17: 300/307] 	 train loss: 0.309294 	 lr: 0.00100
[epoch  18:   0/307] 	 train loss: 0.247555 	 lr: 0.00100
[epoch  18:  20/307] 	 train loss: 0.238902 	 lr: 0.00100
[epoch  18:  40/307] 	 train loss: 0.274125 	 lr: 0.00100
[epoch  18:  60/307] 	 train loss: 0.229145 	 lr: 0.00100
[epoch  18:  80/307] 	 train loss: 0.104727 	 lr: 0.00100
[epoch  18: 100/307] 	 train loss: 0.107400 	 lr: 0.00100

val loss: 0.367838 	 acc: 0.895057

[epoch  18: 120/307] 	 train loss: 0.332863 	 lr: 0.00100
[epoch  18: 140/307] 	 train loss: 0.129636 	 lr: 0.00100
[epoch  18: 160/307] 	 train loss: 0.222388 	 lr: 0.00100
[epoch  18: 180/307] 	 train loss: 0.146193 	 lr: 0.00100
[epoch  18: 200/307] 	 train loss: 0.368211 	 lr: 0.00100
[epoch  18: 220/307] 	 train loss: 0.275269 	 lr: 0.00100
[epoch  18: 240/307] 	 train loss: 0.101617 	 lr: 0.00100
[epoch  18: 260/307] 	 train loss: 0.213781 	 lr: 0.00100

val loss: 0.375192 	 acc: 0.886143

[epoch  18: 280/307] 	 train loss: 0.368788 	 lr: 0.00100
[epoch  18: 300/307] 	 train loss: 0.324023 	 lr: 0.00100
[epoch  19:   0/307] 	 train loss: 0.231779 	 lr: 0.00100
[epoch  19:  20/307] 	 train loss: 0.098649 	 lr: 0.00100
[epoch  19:  40/307] 	 train loss: 0.294175 	 lr: 0.00100
[epoch  19:  60/307] 	 train loss: 0.263358 	 lr: 0.00100
[epoch  19:  80/307] 	 train loss: 0.454012 	 lr: 0.00100
[epoch  19: 100/307] 	 train loss: 0.216401 	 lr: 0.00100

val loss: 0.399469 	 acc: 0.891005

[epoch  19: 120/307] 	 train loss: 0.072275 	 lr: 0.00100
[epoch  19: 140/307] 	 train loss: 0.219618 	 lr: 0.00100
[epoch  19: 160/307] 	 train loss: 0.039150 	 lr: 0.00100
[epoch  19: 180/307] 	 train loss: 0.197209 	 lr: 0.00100
[epoch  19: 200/307] 	 train loss: 0.249299 	 lr: 0.00100
[epoch  19: 220/307] 	 train loss: 0.433486 	 lr: 0.00100
[epoch  19: 240/307] 	 train loss: 0.162739 	 lr: 0.00100
[epoch  19: 260/307] 	 train loss: 0.376610 	 lr: 0.00100

val loss: 0.370247 	 acc: 0.893841

[epoch  19: 280/307] 	 train loss: 0.210876 	 lr: 0.00100
[epoch  19: 300/307] 	 train loss: 0.048576 	 lr: 0.00100
[epoch  20:   0/307] 	 train loss: 0.075169 	 lr: 0.00100
[epoch  20:  20/307] 	 train loss: 0.129773 	 lr: 0.00100
[epoch  20:  40/307] 	 train loss: 0.167391 	 lr: 0.00100
[epoch  20:  60/307] 	 train loss: 0.122251 	 lr: 0.00100
[epoch  20:  80/307] 	 train loss: 0.290871 	 lr: 0.00100
[epoch  20: 100/307] 	 train loss: 0.329922 	 lr: 0.00100

val loss: 0.409254 	 acc: 0.885332

[epoch  20: 120/307] 	 train loss: 0.265533 	 lr: 0.00100
[epoch  20: 140/307] 	 train loss: 0.139414 	 lr: 0.00100
[epoch  20: 160/307] 	 train loss: 0.178215 	 lr: 0.00100
[epoch  20: 180/307] 	 train loss: 0.138323 	 lr: 0.00100
[epoch  20: 200/307] 	 train loss: 0.120881 	 lr: 0.00100
[epoch  20: 220/307] 	 train loss: 0.462896 	 lr: 0.00100
[epoch  20: 240/307] 	 train loss: 0.350602 	 lr: 0.00100
[epoch  20: 260/307] 	 train loss: 0.389731 	 lr: 0.00100

val loss: 0.385358 	 acc: 0.900324

[epoch  20: 280/307] 	 train loss: 0.256104 	 lr: 0.00100
[epoch  20: 300/307] 	 train loss: 0.313316 	 lr: 0.00100
[epoch  21:   0/307] 	 train loss: 0.116033 	 lr: 0.00100
[epoch  21:  20/307] 	 train loss: 0.424210 	 lr: 0.00100
[epoch  21:  40/307] 	 train loss: 0.284180 	 lr: 0.00100
[epoch  21:  60/307] 	 train loss: 0.290306 	 lr: 0.00100
[epoch  21:  80/307] 	 train loss: 0.279104 	 lr: 0.00100
[epoch  21: 100/307] 	 train loss: 0.161977 	 lr: 0.00100

val loss: 0.368766 	 acc: 0.894652

[epoch  21: 120/307] 	 train loss: 0.218292 	 lr: 0.00100
[epoch  21: 140/307] 	 train loss: 0.227585 	 lr: 0.00100
[epoch  21: 160/307] 	 train loss: 0.260895 	 lr: 0.00100
[epoch  21: 180/307] 	 train loss: 0.116935 	 lr: 0.00100
[epoch  21: 200/307] 	 train loss: 0.204464 	 lr: 0.00100
[epoch  21: 220/307] 	 train loss: 0.345547 	 lr: 0.00100
[epoch  21: 240/307] 	 train loss: 0.282015 	 lr: 0.00100
[epoch  21: 260/307] 	 train loss: 0.197521 	 lr: 0.00100

val loss: 0.376574 	 acc: 0.893841

[epoch  21: 280/307] 	 train loss: 0.202396 	 lr: 0.00100
[epoch  21: 300/307] 	 train loss: 0.116644 	 lr: 0.00100
[epoch  22:   0/307] 	 train loss: 0.254347 	 lr: 0.00070
[epoch  22:  20/307] 	 train loss: 0.217183 	 lr: 0.00070
[epoch  22:  40/307] 	 train loss: 0.160238 	 lr: 0.00070
[epoch  22:  60/307] 	 train loss: 0.453556 	 lr: 0.00070
[epoch  22:  80/307] 	 train loss: 0.506268 	 lr: 0.00070
[epoch  22: 100/307] 	 train loss: 0.318622 	 lr: 0.00070

val loss: 0.371230 	 acc: 0.895462

[epoch  22: 120/307] 	 train loss: 0.170190 	 lr: 0.00070
[epoch  22: 140/307] 	 train loss: 0.527038 	 lr: 0.00070
[epoch  22: 160/307] 	 train loss: 0.319123 	 lr: 0.00070
[epoch  22: 180/307] 	 train loss: 0.448454 	 lr: 0.00070
[epoch  22: 200/307] 	 train loss: 0.166489 	 lr: 0.00070
[epoch  22: 220/307] 	 train loss: 0.690440 	 lr: 0.00070
[epoch  22: 240/307] 	 train loss: 0.238558 	 lr: 0.00070
[epoch  22: 260/307] 	 train loss: 0.216879 	 lr: 0.00070

val loss: 0.353802 	 acc: 0.898703

[epoch  22: 280/307] 	 train loss: 0.254633 	 lr: 0.00070
[epoch  22: 300/307] 	 train loss: 0.456766 	 lr: 0.00070
[epoch  23:   0/307] 	 train loss: 0.067900 	 lr: 0.00070
[epoch  23:  20/307] 	 train loss: 0.298256 	 lr: 0.00070
[epoch  23:  40/307] 	 train loss: 0.410079 	 lr: 0.00070
[epoch  23:  60/307] 	 train loss: 0.313525 	 lr: 0.00070
[epoch  23:  80/307] 	 train loss: 0.285963 	 lr: 0.00070
[epoch  23: 100/307] 	 train loss: 0.240997 	 lr: 0.00070

val loss: 0.338904 	 acc: 0.900324

[epoch  23: 120/307] 	 train loss: 0.272417 	 lr: 0.00070
[epoch  23: 140/307] 	 train loss: 0.175561 	 lr: 0.00070
[epoch  23: 160/307] 	 train loss: 0.128671 	 lr: 0.00070
[epoch  23: 180/307] 	 train loss: 0.235040 	 lr: 0.00070
[epoch  23: 200/307] 	 train loss: 0.176047 	 lr: 0.00070
[epoch  23: 220/307] 	 train loss: 0.464379 	 lr: 0.00070
[epoch  23: 240/307] 	 train loss: 0.258973 	 lr: 0.00070
[epoch  23: 260/307] 	 train loss: 0.094760 	 lr: 0.00070

val loss: 0.353215 	 acc: 0.893841

[epoch  23: 280/307] 	 train loss: 0.117058 	 lr: 0.00070
[epoch  23: 300/307] 	 train loss: 0.334301 	 lr: 0.00070
[epoch  24:   0/307] 	 train loss: 0.128375 	 lr: 0.00070
[epoch  24:  20/307] 	 train loss: 0.376847 	 lr: 0.00070
[epoch  24:  40/307] 	 train loss: 0.274478 	 lr: 0.00070
[epoch  24:  60/307] 	 train loss: 0.271882 	 lr: 0.00070
[epoch  24:  80/307] 	 train loss: 0.188288 	 lr: 0.00070
[epoch  24: 100/307] 	 train loss: 0.197395 	 lr: 0.00070

val loss: 0.357850 	 acc: 0.902755

[epoch  24: 120/307] 	 train loss: 0.149273 	 lr: 0.00070
[epoch  24: 140/307] 	 train loss: 0.180357 	 lr: 0.00070
[epoch  24: 160/307] 	 train loss: 0.105710 	 lr: 0.00070
[epoch  24: 180/307] 	 train loss: 0.172996 	 lr: 0.00070
[epoch  24: 200/307] 	 train loss: 0.058067 	 lr: 0.00070
[epoch  24: 220/307] 	 train loss: 0.230116 	 lr: 0.00070
[epoch  24: 240/307] 	 train loss: 0.430362 	 lr: 0.00070

val loss: 0.375181 	 acc: 0.893031

[epoch  24: 260/307] 	 train loss: 0.232436 	 lr: 0.00070
[epoch  24: 280/307] 	 train loss: 0.254907 	 lr: 0.00070
[epoch  24: 300/307] 	 train loss: 0.133139 	 lr: 0.00070
[epoch  25:   0/307] 	 train loss: 0.327937 	 lr: 0.00070
[epoch  25:  20/307] 	 train loss: 0.088854 	 lr: 0.00070
[epoch  25:  40/307] 	 train loss: 0.629082 	 lr: 0.00070
[epoch  25:  60/307] 	 train loss: 0.054415 	 lr: 0.00070
[epoch  25:  80/307] 	 train loss: 0.133492 	 lr: 0.00070
[epoch  25: 100/307] 	 train loss: 0.099315 	 lr: 0.00070

val loss: 0.378236 	 acc: 0.898298

[epoch  25: 120/307] 	 train loss: 0.284776 	 lr: 0.00070
[epoch  25: 140/307] 	 train loss: 0.190698 	 lr: 0.00070
[epoch  25: 160/307] 	 train loss: 0.052487 	 lr: 0.00070
[epoch  25: 180/307] 	 train loss: 0.117031 	 lr: 0.00070
[epoch  25: 200/307] 	 train loss: 0.329023 	 lr: 0.00070
[epoch  25: 220/307] 	 train loss: 0.064050 	 lr: 0.00070
[epoch  25: 240/307] 	 train loss: 0.422037 	 lr: 0.00070

val loss: 0.350224 	 acc: 0.899919

[epoch  25: 260/307] 	 train loss: 0.131062 	 lr: 0.00070
[epoch  25: 280/307] 	 train loss: 0.094314 	 lr: 0.00070
[epoch  25: 300/307] 	 train loss: 0.201380 	 lr: 0.00070
[epoch  26:   0/307] 	 train loss: 0.181908 	 lr: 0.00070
[epoch  26:  20/307] 	 train loss: 0.215174 	 lr: 0.00070
[epoch  26:  40/307] 	 train loss: 0.210382 	 lr: 0.00070
[epoch  26:  60/307] 	 train loss: 0.268971 	 lr: 0.00070
[epoch  26:  80/307] 	 train loss: 0.158221 	 lr: 0.00070
[epoch  26: 100/307] 	 train loss: 0.248860 	 lr: 0.00070

val loss: 0.344689 	 acc: 0.910049

saved model with accuracy  0.9100486223662885
[epoch  26: 120/307] 	 train loss: 0.185336 	 lr: 0.00070
[epoch  26: 140/307] 	 train loss: 0.167932 	 lr: 0.00070
[epoch  26: 160/307] 	 train loss: 0.173554 	 lr: 0.00070
[epoch  26: 180/307] 	 train loss: 0.575670 	 lr: 0.00070
[epoch  26: 200/307] 	 train loss: 0.285719 	 lr: 0.00070
[epoch  26: 220/307] 	 train loss: 0.260606 	 lr: 0.00070
[epoch  26: 240/307] 	 train loss: 0.364494 	 lr: 0.00070

val loss: 0.352265 	 acc: 0.895057

[epoch  26: 260/307] 	 train loss: 0.183077 	 lr: 0.00070
[epoch  26: 280/307] 	 train loss: 0.281844 	 lr: 0.00070
[epoch  26: 300/307] 	 train loss: 0.216532 	 lr: 0.00070
[epoch  27:   0/307] 	 train loss: 0.217192 	 lr: 0.00070
[epoch  27:  20/307] 	 train loss: 0.210709 	 lr: 0.00070
[epoch  27:  40/307] 	 train loss: 0.166423 	 lr: 0.00070
[epoch  27:  60/307] 	 train loss: 0.277018 	 lr: 0.00070
[epoch  27:  80/307] 	 train loss: 0.198874 	 lr: 0.00070
[epoch  27: 100/307] 	 train loss: 0.033369 	 lr: 0.00070

val loss: 0.359117 	 acc: 0.894652

[epoch  27: 120/307] 	 train loss: 0.326601 	 lr: 0.00070
[epoch  27: 140/307] 	 train loss: 0.430633 	 lr: 0.00070
[epoch  27: 160/307] 	 train loss: 0.148379 	 lr: 0.00070
[epoch  27: 180/307] 	 train loss: 0.154258 	 lr: 0.00070
[epoch  27: 200/307] 	 train loss: 0.202844 	 lr: 0.00070
[epoch  27: 220/307] 	 train loss: 0.063799 	 lr: 0.00070
[epoch  27: 240/307] 	 train loss: 0.199620 	 lr: 0.00070

val loss: 0.352184 	 acc: 0.906402

[epoch  27: 260/307] 	 train loss: 0.218673 	 lr: 0.00070
[epoch  27: 280/307] 	 train loss: 0.330430 	 lr: 0.00070
[epoch  27: 300/307] 	 train loss: 0.094586 	 lr: 0.00070
[epoch  28:   0/307] 	 train loss: 0.265941 	 lr: 0.00070
[epoch  28:  20/307] 	 train loss: 0.129981 	 lr: 0.00070
[epoch  28:  40/307] 	 train loss: 0.210773 	 lr: 0.00070
[epoch  28:  60/307] 	 train loss: 0.218675 	 lr: 0.00070
[epoch  28:  80/307] 	 train loss: 0.365519 	 lr: 0.00070

val loss: 0.355929 	 acc: 0.905997

[epoch  28: 100/307] 	 train loss: 0.248561 	 lr: 0.00070
[epoch  28: 120/307] 	 train loss: 0.139947 	 lr: 0.00070
[epoch  28: 140/307] 	 train loss: 0.186867 	 lr: 0.00070
[epoch  28: 160/307] 	 train loss: 0.228765 	 lr: 0.00070
[epoch  28: 180/307] 	 train loss: 0.194916 	 lr: 0.00070
[epoch  28: 200/307] 	 train loss: 0.536042 	 lr: 0.00070
[epoch  28: 220/307] 	 train loss: 0.572772 	 lr: 0.00070
[epoch  28: 240/307] 	 train loss: 0.079491 	 lr: 0.00070

val loss: 0.353922 	 acc: 0.891815

[epoch  28: 260/307] 	 train loss: 0.217622 	 lr: 0.00070
[epoch  28: 280/307] 	 train loss: 0.200155 	 lr: 0.00070
[epoch  28: 300/307] 	 train loss: 0.148796 	 lr: 0.00070
[epoch  29:   0/307] 	 train loss: 0.214121 	 lr: 0.00070
[epoch  29:  20/307] 	 train loss: 0.412737 	 lr: 0.00070
[epoch  29:  40/307] 	 train loss: 0.206453 	 lr: 0.00070
[epoch  29:  60/307] 	 train loss: 0.182831 	 lr: 0.00070
[epoch  29:  80/307] 	 train loss: 0.196975 	 lr: 0.00070

val loss: 0.350943 	 acc: 0.895462

[epoch  29: 100/307] 	 train loss: 0.240438 	 lr: 0.00070
[epoch  29: 120/307] 	 train loss: 0.127549 	 lr: 0.00070
[epoch  29: 140/307] 	 train loss: 0.423307 	 lr: 0.00070
[epoch  29: 160/307] 	 train loss: 0.128778 	 lr: 0.00070
[epoch  29: 180/307] 	 train loss: 0.210828 	 lr: 0.00070
[epoch  29: 200/307] 	 train loss: 0.344829 	 lr: 0.00070
[epoch  29: 220/307] 	 train loss: 0.265487 	 lr: 0.00070
[epoch  29: 240/307] 	 train loss: 0.169676 	 lr: 0.00070

val loss: 0.353044 	 acc: 0.905997

[epoch  29: 260/307] 	 train loss: 0.278248 	 lr: 0.00070
[epoch  29: 280/307] 	 train loss: 0.203961 	 lr: 0.00070
[epoch  29: 300/307] 	 train loss: 0.098568 	 lr: 0.00070
[epoch  30:   0/307] 	 train loss: 0.139457 	 lr: 0.00070
[epoch  30:  20/307] 	 train loss: 0.104654 	 lr: 0.00070
[epoch  30:  40/307] 	 train loss: 0.592553 	 lr: 0.00070
[epoch  30:  60/307] 	 train loss: 0.077763 	 lr: 0.00070
[epoch  30:  80/307] 	 train loss: 0.250064 	 lr: 0.00070

val loss: 0.325078 	 acc: 0.905592

[epoch  30: 100/307] 	 train loss: 0.324736 	 lr: 0.00070
[epoch  30: 120/307] 	 train loss: 0.182313 	 lr: 0.00070
[epoch  30: 140/307] 	 train loss: 0.493803 	 lr: 0.00070
[epoch  30: 160/307] 	 train loss: 0.069680 	 lr: 0.00070
[epoch  30: 180/307] 	 train loss: 0.477842 	 lr: 0.00070
[epoch  30: 200/307] 	 train loss: 0.134785 	 lr: 0.00070
[epoch  30: 220/307] 	 train loss: 0.142152 	 lr: 0.00070
[epoch  30: 240/307] 	 train loss: 0.254873 	 lr: 0.00070

val loss: 0.352296 	 acc: 0.897488

[epoch  30: 260/307] 	 train loss: 0.152487 	 lr: 0.00070
[epoch  30: 280/307] 	 train loss: 0.152976 	 lr: 0.00070
[epoch  30: 300/307] 	 train loss: 0.367629 	 lr: 0.00070
[epoch  31:   0/307] 	 train loss: 0.204571 	 lr: 0.00070
[epoch  31:  20/307] 	 train loss: 0.401992 	 lr: 0.00070
[epoch  31:  40/307] 	 train loss: 0.231567 	 lr: 0.00070
[epoch  31:  60/307] 	 train loss: 0.184313 	 lr: 0.00070
[epoch  31:  80/307] 	 train loss: 0.188737 	 lr: 0.00070

val loss: 0.363455 	 acc: 0.899919

[epoch  31: 100/307] 	 train loss: 0.103318 	 lr: 0.00070
[epoch  31: 120/307] 	 train loss: 0.302847 	 lr: 0.00070
[epoch  31: 140/307] 	 train loss: 0.129754 	 lr: 0.00070
[epoch  31: 160/307] 	 train loss: 0.494467 	 lr: 0.00070
[epoch  31: 180/307] 	 train loss: 0.370180 	 lr: 0.00070
[epoch  31: 200/307] 	 train loss: 0.087988 	 lr: 0.00070
[epoch  31: 220/307] 	 train loss: 0.223285 	 lr: 0.00070
[epoch  31: 240/307] 	 train loss: 0.156368 	 lr: 0.00070

val loss: 0.343729 	 acc: 0.903160

[epoch  31: 260/307] 	 train loss: 0.346408 	 lr: 0.00070
[epoch  31: 280/307] 	 train loss: 0.114923 	 lr: 0.00070
[epoch  31: 300/307] 	 train loss: 0.058183 	 lr: 0.00070
[epoch  32:   0/307] 	 train loss: 0.202458 	 lr: 0.00070
[epoch  32:  20/307] 	 train loss: 0.149950 	 lr: 0.00070
[epoch  32:  40/307] 	 train loss: 0.404650 	 lr: 0.00070
[epoch  32:  60/307] 	 train loss: 0.207666 	 lr: 0.00070
[epoch  32:  80/307] 	 train loss: 0.148629 	 lr: 0.00070

val loss: 0.351447 	 acc: 0.901945

[epoch  32: 100/307] 	 train loss: 0.195416 	 lr: 0.00070
[epoch  32: 120/307] 	 train loss: 0.318817 	 lr: 0.00070
[epoch  32: 140/307] 	 train loss: 0.203989 	 lr: 0.00070
[epoch  32: 160/307] 	 train loss: 0.267769 	 lr: 0.00070
[epoch  32: 180/307] 	 train loss: 0.235611 	 lr: 0.00070
[epoch  32: 200/307] 	 train loss: 0.017866 	 lr: 0.00070
[epoch  32: 220/307] 	 train loss: 0.282629 	 lr: 0.00070
[epoch  32: 240/307] 	 train loss: 0.233218 	 lr: 0.00070

val loss: 0.336143 	 acc: 0.903566

[epoch  32: 260/307] 	 train loss: 0.290739 	 lr: 0.00070
[epoch  32: 280/307] 	 train loss: 0.431737 	 lr: 0.00070
[epoch  32: 300/307] 	 train loss: 0.174146 	 lr: 0.00070
[epoch  33:   0/307] 	 train loss: 0.160553 	 lr: 0.00070
[epoch  33:  20/307] 	 train loss: 0.169687 	 lr: 0.00070
[epoch  33:  40/307] 	 train loss: 0.164547 	 lr: 0.00070
[epoch  33:  60/307] 	 train loss: 0.292215 	 lr: 0.00070
[epoch  33:  80/307] 	 train loss: 0.195686 	 lr: 0.00070

val loss: 0.366247 	 acc: 0.901540

[epoch  33: 100/307] 	 train loss: 0.133893 	 lr: 0.00070
[epoch  33: 120/307] 	 train loss: 0.272120 	 lr: 0.00070
[epoch  33: 140/307] 	 train loss: 0.587104 	 lr: 0.00070
[epoch  33: 160/307] 	 train loss: 0.247060 	 lr: 0.00070
[epoch  33: 180/307] 	 train loss: 0.137649 	 lr: 0.00070
[epoch  33: 200/307] 	 train loss: 0.221618 	 lr: 0.00070
[epoch  33: 220/307] 	 train loss: 0.090129 	 lr: 0.00070
[epoch  33: 240/307] 	 train loss: 0.272749 	 lr: 0.00070

val loss: 0.347008 	 acc: 0.904781

[epoch  33: 260/307] 	 train loss: 0.163791 	 lr: 0.00070
[epoch  33: 280/307] 	 train loss: 0.046697 	 lr: 0.00070
[epoch  33: 300/307] 	 train loss: 0.121031 	 lr: 0.00070
[epoch  34:   0/307] 	 train loss: 0.171708 	 lr: 0.00070
[epoch  34:  20/307] 	 train loss: 0.146521 	 lr: 0.00070
[epoch  34:  40/307] 	 train loss: 0.081487 	 lr: 0.00070
[epoch  34:  60/307] 	 train loss: 0.253358 	 lr: 0.00070
[epoch  34:  80/307] 	 train loss: 0.300192 	 lr: 0.00070

val loss: 0.347159 	 acc: 0.900729

[epoch  34: 100/307] 	 train loss: 0.357528 	 lr: 0.00070
[epoch  34: 120/307] 	 train loss: 0.062386 	 lr: 0.00070
[epoch  34: 140/307] 	 train loss: 0.108645 	 lr: 0.00070
[epoch  34: 160/307] 	 train loss: 0.239538 	 lr: 0.00070
[epoch  34: 180/307] 	 train loss: 0.413009 	 lr: 0.00070
[epoch  34: 200/307] 	 train loss: 0.013431 	 lr: 0.00070
[epoch  34: 220/307] 	 train loss: 0.402497 	 lr: 0.00070

val loss: 0.347061 	 acc: 0.901135

[epoch  34: 240/307] 	 train loss: 0.426179 	 lr: 0.00070
[epoch  34: 260/307] 	 train loss: 0.038213 	 lr: 0.00070
[epoch  34: 280/307] 	 train loss: 0.212512 	 lr: 0.00070
[epoch  34: 300/307] 	 train loss: 0.167960 	 lr: 0.00070
[epoch  35:   0/307] 	 train loss: 0.345334 	 lr: 0.00070
[epoch  35:  20/307] 	 train loss: 0.323712 	 lr: 0.00070
[epoch  35:  40/307] 	 train loss: 0.200861 	 lr: 0.00070
[epoch  35:  60/307] 	 train loss: 0.371106 	 lr: 0.00070
[epoch  35:  80/307] 	 train loss: 0.085420 	 lr: 0.00070

val loss: 0.352883 	 acc: 0.898703

[epoch  35: 100/307] 	 train loss: 0.058681 	 lr: 0.00070
[epoch  35: 120/307] 	 train loss: 0.164876 	 lr: 0.00070
[epoch  35: 140/307] 	 train loss: 0.143128 	 lr: 0.00070
[epoch  35: 160/307] 	 train loss: 0.255109 	 lr: 0.00070
[epoch  35: 180/307] 	 train loss: 0.199370 	 lr: 0.00070
[epoch  35: 200/307] 	 train loss: 0.185841 	 lr: 0.00070
[epoch  35: 220/307] 	 train loss: 0.099153 	 lr: 0.00070

val loss: 0.345530 	 acc: 0.899109

[epoch  35: 240/307] 	 train loss: 0.082888 	 lr: 0.00070
[epoch  35: 260/307] 	 train loss: 0.149506 	 lr: 0.00070
[epoch  35: 280/307] 	 train loss: 0.173064 	 lr: 0.00070
[epoch  35: 300/307] 	 train loss: 0.195836 	 lr: 0.00070
[epoch  36:   0/307] 	 train loss: 0.112887 	 lr: 0.00070
[epoch  36:  20/307] 	 train loss: 0.337679 	 lr: 0.00070
[epoch  36:  40/307] 	 train loss: 0.257652 	 lr: 0.00070
[epoch  36:  60/307] 	 train loss: 0.324491 	 lr: 0.00070
[epoch  36:  80/307] 	 train loss: 0.124516 	 lr: 0.00070

val loss: 0.331543 	 acc: 0.905592

[epoch  36: 100/307] 	 train loss: 0.223362 	 lr: 0.00070
[epoch  36: 120/307] 	 train loss: 0.087802 	 lr: 0.00070
[epoch  36: 140/307] 	 train loss: 0.171056 	 lr: 0.00070
[epoch  36: 160/307] 	 train loss: 0.237425 	 lr: 0.00070
[epoch  36: 180/307] 	 train loss: 0.234780 	 lr: 0.00070
[epoch  36: 200/307] 	 train loss: 0.375840 	 lr: 0.00070
[epoch  36: 220/307] 	 train loss: 0.072703 	 lr: 0.00070

val loss: 0.344329 	 acc: 0.907212

[epoch  36: 240/307] 	 train loss: 0.207463 	 lr: 0.00070
[epoch  36: 260/307] 	 train loss: 0.450254 	 lr: 0.00070
[epoch  36: 280/307] 	 train loss: 0.415829 	 lr: 0.00070
[epoch  36: 300/307] 	 train loss: 0.210689 	 lr: 0.00070
[epoch  37:   0/307] 	 train loss: 0.257829 	 lr: 0.00070
[epoch  37:  20/307] 	 train loss: 0.053976 	 lr: 0.00070
[epoch  37:  40/307] 	 train loss: 0.213370 	 lr: 0.00070
[epoch  37:  60/307] 	 train loss: 0.427977 	 lr: 0.00070
[epoch  37:  80/307] 	 train loss: 0.312469 	 lr: 0.00070

val loss: 0.346038 	 acc: 0.904376

[epoch  37: 100/307] 	 train loss: 0.242113 	 lr: 0.00070
[epoch  37: 120/307] 	 train loss: 0.124983 	 lr: 0.00070
[epoch  37: 140/307] 	 train loss: 0.197097 	 lr: 0.00070
[epoch  37: 160/307] 	 train loss: 0.166003 	 lr: 0.00070
[epoch  37: 180/307] 	 train loss: 0.174653 	 lr: 0.00070
[epoch  37: 200/307] 	 train loss: 0.194441 	 lr: 0.00070
[epoch  37: 220/307] 	 train loss: 0.362793 	 lr: 0.00070

val loss: 0.347883 	 acc: 0.905186

[epoch  37: 240/307] 	 train loss: 0.167979 	 lr: 0.00070
[epoch  37: 260/307] 	 train loss: 0.130873 	 lr: 0.00070
[epoch  37: 280/307] 	 train loss: 0.175674 	 lr: 0.00070
[epoch  37: 300/307] 	 train loss: 0.152890 	 lr: 0.00070
[epoch  38:   0/307] 	 train loss: 0.311114 	 lr: 0.00070
[epoch  38:  20/307] 	 train loss: 0.157330 	 lr: 0.00070
[epoch  38:  40/307] 	 train loss: 0.181019 	 lr: 0.00070
[epoch  38:  60/307] 	 train loss: 0.222061 	 lr: 0.00070

val loss: 0.339290 	 acc: 0.904781

[epoch  38:  80/307] 	 train loss: 0.115091 	 lr: 0.00070
[epoch  38: 100/307] 	 train loss: 0.065350 	 lr: 0.00070
[epoch  38: 120/307] 	 train loss: 0.138946 	 lr: 0.00070
[epoch  38: 140/307] 	 train loss: 0.155070 	 lr: 0.00070
[epoch  38: 160/307] 	 train loss: 0.320797 	 lr: 0.00070
[epoch  38: 180/307] 	 train loss: 0.265429 	 lr: 0.00070
[epoch  38: 200/307] 	 train loss: 0.170700 	 lr: 0.00070
[epoch  38: 220/307] 	 train loss: 0.046785 	 lr: 0.00070

val loss: 0.334626 	 acc: 0.905592

[epoch  38: 240/307] 	 train loss: 0.249957 	 lr: 0.00070
[epoch  38: 260/307] 	 train loss: 0.243478 	 lr: 0.00070
[epoch  38: 280/307] 	 train loss: 0.147026 	 lr: 0.00070
[epoch  38: 300/307] 	 train loss: 0.153161 	 lr: 0.00070
[epoch  39:   0/307] 	 train loss: 0.163274 	 lr: 0.00070
[epoch  39:  20/307] 	 train loss: 0.104847 	 lr: 0.00070
[epoch  39:  40/307] 	 train loss: 0.240962 	 lr: 0.00070
[epoch  39:  60/307] 	 train loss: 0.316861 	 lr: 0.00070

val loss: 0.340078 	 acc: 0.905592

[epoch  39:  80/307] 	 train loss: 0.232395 	 lr: 0.00070
[epoch  39: 100/307] 	 train loss: 0.299489 	 lr: 0.00070
[epoch  39: 120/307] 	 train loss: 0.314176 	 lr: 0.00070
[epoch  39: 140/307] 	 train loss: 0.227792 	 lr: 0.00070
[epoch  39: 160/307] 	 train loss: 0.262577 	 lr: 0.00070
[epoch  39: 180/307] 	 train loss: 0.409351 	 lr: 0.00070
[epoch  39: 200/307] 	 train loss: 0.155323 	 lr: 0.00070
[epoch  39: 220/307] 	 train loss: 0.351181 	 lr: 0.00070

val loss: 0.349818 	 acc: 0.901945

[epoch  39: 240/307] 	 train loss: 0.137628 	 lr: 0.00070
[epoch  39: 260/307] 	 train loss: 0.204391 	 lr: 0.00070
[epoch  39: 280/307] 	 train loss: 0.105237 	 lr: 0.00070
[epoch  39: 300/307] 	 train loss: 0.251689 	 lr: 0.00070
[epoch  40:   0/307] 	 train loss: 0.212483 	 lr: 0.00070
[epoch  40:  20/307] 	 train loss: 0.135274 	 lr: 0.00070
[epoch  40:  40/307] 	 train loss: 0.345279 	 lr: 0.00070
[epoch  40:  60/307] 	 train loss: 0.066254 	 lr: 0.00070

val loss: 0.338230 	 acc: 0.907618

[epoch  40:  80/307] 	 train loss: 0.340422 	 lr: 0.00070
[epoch  40: 100/307] 	 train loss: 0.068689 	 lr: 0.00070
[epoch  40: 120/307] 	 train loss: 0.291940 	 lr: 0.00070
[epoch  40: 140/307] 	 train loss: 0.365120 	 lr: 0.00070
[epoch  40: 160/307] 	 train loss: 0.210284 	 lr: 0.00070
[epoch  40: 180/307] 	 train loss: 0.285599 	 lr: 0.00070
[epoch  40: 200/307] 	 train loss: 0.221269 	 lr: 0.00070
[epoch  40: 220/307] 	 train loss: 0.071966 	 lr: 0.00070

val loss: 0.351345 	 acc: 0.895867

[epoch  40: 240/307] 	 train loss: 0.085344 	 lr: 0.00070
[epoch  40: 260/307] 	 train loss: 0.037439 	 lr: 0.00070
[epoch  40: 280/307] 	 train loss: 0.393871 	 lr: 0.00070
[epoch  40: 300/307] 	 train loss: 0.107386 	 lr: 0.00070
[epoch  41:   0/307] 	 train loss: 0.143737 	 lr: 0.00070
[epoch  41:  20/307] 	 train loss: 0.340551 	 lr: 0.00070
[epoch  41:  40/307] 	 train loss: 0.103917 	 lr: 0.00070
[epoch  41:  60/307] 	 train loss: 0.173995 	 lr: 0.00070

val loss: 0.341952 	 acc: 0.912075

saved model with accuracy  0.9120745542949756
[epoch  41:  80/307] 	 train loss: 0.136085 	 lr: 0.00070
[epoch  41: 100/307] 	 train loss: 0.126053 	 lr: 0.00070
[epoch  41: 120/307] 	 train loss: 0.203222 	 lr: 0.00070
[epoch  41: 140/307] 	 train loss: 0.348190 	 lr: 0.00070
[epoch  41: 160/307] 	 train loss: 0.168728 	 lr: 0.00070
[epoch  41: 180/307] 	 train loss: 0.130793 	 lr: 0.00070
[epoch  41: 200/307] 	 train loss: 0.335508 	 lr: 0.00070
[epoch  41: 220/307] 	 train loss: 0.414399 	 lr: 0.00070

val loss: 0.368278 	 acc: 0.898703

[epoch  41: 240/307] 	 train loss: 0.308418 	 lr: 0.00070
[epoch  41: 260/307] 	 train loss: 0.268520 	 lr: 0.00070
[epoch  41: 280/307] 	 train loss: 0.173235 	 lr: 0.00070
[epoch  41: 300/307] 	 train loss: 0.338611 	 lr: 0.00070
[epoch  42:   0/307] 	 train loss: 0.168878 	 lr: 0.00070
[epoch  42:  20/307] 	 train loss: 0.182335 	 lr: 0.00070
[epoch  42:  40/307] 	 train loss: 0.121702 	 lr: 0.00070
[epoch  42:  60/307] 	 train loss: 0.053354 	 lr: 0.00070

val loss: 0.329073 	 acc: 0.910454

[epoch  42:  80/307] 	 train loss: 0.475239 	 lr: 0.00070
[epoch  42: 100/307] 	 train loss: 0.272248 	 lr: 0.00070
[epoch  42: 120/307] 	 train loss: 0.126124 	 lr: 0.00070
[epoch  42: 140/307] 	 train loss: 0.099660 	 lr: 0.00070
[epoch  42: 160/307] 	 train loss: 0.089089 	 lr: 0.00070
[epoch  42: 180/307] 	 train loss: 0.077549 	 lr: 0.00070
[epoch  42: 200/307] 	 train loss: 0.219378 	 lr: 0.00070
[epoch  42: 220/307] 	 train loss: 0.160551 	 lr: 0.00070

val loss: 0.356263 	 acc: 0.906807

[epoch  42: 240/307] 	 train loss: 0.094288 	 lr: 0.00070
[epoch  42: 260/307] 	 train loss: 0.346024 	 lr: 0.00070
[epoch  42: 280/307] 	 train loss: 0.403144 	 lr: 0.00070
[epoch  42: 300/307] 	 train loss: 0.476070 	 lr: 0.00070
[epoch  43:   0/307] 	 train loss: 0.228262 	 lr: 0.00049
[epoch  43:  20/307] 	 train loss: 0.068368 	 lr: 0.00049
[epoch  43:  40/307] 	 train loss: 0.326611 	 lr: 0.00049
[epoch  43:  60/307] 	 train loss: 0.169173 	 lr: 0.00049

val loss: 0.342839 	 acc: 0.899514

[epoch  43:  80/307] 	 train loss: 0.116748 	 lr: 0.00049
[epoch  43: 100/307] 	 train loss: 0.297291 	 lr: 0.00049
[epoch  43: 120/307] 	 train loss: 0.492375 	 lr: 0.00049
[epoch  43: 140/307] 	 train loss: 0.446091 	 lr: 0.00049
[epoch  43: 160/307] 	 train loss: 0.377248 	 lr: 0.00049
[epoch  43: 180/307] 	 train loss: 0.237324 	 lr: 0.00049
[epoch  43: 200/307] 	 train loss: 0.117411 	 lr: 0.00049
[epoch  43: 220/307] 	 train loss: 0.378785 	 lr: 0.00049

val loss: 0.353689 	 acc: 0.903160

[epoch  43: 240/307] 	 train loss: 0.151474 	 lr: 0.00049
[epoch  43: 260/307] 	 train loss: 0.155122 	 lr: 0.00049
[epoch  43: 280/307] 	 train loss: 0.072841 	 lr: 0.00049
[epoch  43: 300/307] 	 train loss: 0.153450 	 lr: 0.00049
[epoch  44:   0/307] 	 train loss: 0.377556 	 lr: 0.00049
[epoch  44:  20/307] 	 train loss: 0.178094 	 lr: 0.00049
[epoch  44:  40/307] 	 train loss: 0.399311 	 lr: 0.00049
[epoch  44:  60/307] 	 train loss: 0.193313 	 lr: 0.00049

val loss: 0.319540 	 acc: 0.909643

[epoch  44:  80/307] 	 train loss: 0.141024 	 lr: 0.00049
[epoch  44: 100/307] 	 train loss: 0.164306 	 lr: 0.00049
[epoch  44: 120/307] 	 train loss: 0.089341 	 lr: 0.00049
[epoch  44: 140/307] 	 train loss: 0.114409 	 lr: 0.00049
[epoch  44: 160/307] 	 train loss: 0.237436 	 lr: 0.00049
[epoch  44: 180/307] 	 train loss: 0.438517 	 lr: 0.00049
[epoch  44: 200/307] 	 train loss: 0.177030 	 lr: 0.00049

val loss: 0.325978 	 acc: 0.903971

[epoch  44: 220/307] 	 train loss: 0.151263 	 lr: 0.00049
[epoch  44: 240/307] 	 train loss: 0.420376 	 lr: 0.00049
[epoch  44: 260/307] 	 train loss: 0.212772 	 lr: 0.00049
[epoch  44: 280/307] 	 train loss: 0.138227 	 lr: 0.00049
[epoch  44: 300/307] 	 train loss: 0.459471 	 lr: 0.00049
[epoch  45:   0/307] 	 train loss: 0.116589 	 lr: 0.00049
[epoch  45:  20/307] 	 train loss: 0.110130 	 lr: 0.00049
[epoch  45:  40/307] 	 train loss: 0.074118 	 lr: 0.00049
[epoch  45:  60/307] 	 train loss: 0.236456 	 lr: 0.00049

val loss: 0.331679 	 acc: 0.908428

[epoch  45:  80/307] 	 train loss: 0.415669 	 lr: 0.00049
[epoch  45: 100/307] 	 train loss: 0.164169 	 lr: 0.00049
[epoch  45: 120/307] 	 train loss: 0.354637 	 lr: 0.00049
[epoch  45: 140/307] 	 train loss: 0.096662 	 lr: 0.00049
[epoch  45: 160/307] 	 train loss: 0.349110 	 lr: 0.00049
[epoch  45: 180/307] 	 train loss: 0.106848 	 lr: 0.00049
[epoch  45: 200/307] 	 train loss: 0.321700 	 lr: 0.00049

val loss: 0.357687 	 acc: 0.901945

[epoch  45: 220/307] 	 train loss: 0.347841 	 lr: 0.00049
[epoch  45: 240/307] 	 train loss: 0.282837 	 lr: 0.00049
[epoch  45: 260/307] 	 train loss: 0.230891 	 lr: 0.00049
[epoch  45: 280/307] 	 train loss: 0.067401 	 lr: 0.00049
[epoch  45: 300/307] 	 train loss: 0.321591 	 lr: 0.00049
[epoch  46:   0/307] 	 train loss: 0.104013 	 lr: 0.00049
[epoch  46:  20/307] 	 train loss: 0.270245 	 lr: 0.00049
[epoch  46:  40/307] 	 train loss: 0.248933 	 lr: 0.00049
[epoch  46:  60/307] 	 train loss: 0.131126 	 lr: 0.00049

val loss: 0.350571 	 acc: 0.905592

[epoch  46:  80/307] 	 train loss: 0.239175 	 lr: 0.00049
[epoch  46: 100/307] 	 train loss: 0.173986 	 lr: 0.00049
[epoch  46: 120/307] 	 train loss: 0.100531 	 lr: 0.00049
[epoch  46: 140/307] 	 train loss: 0.223653 	 lr: 0.00049
[epoch  46: 160/307] 	 train loss: 0.380161 	 lr: 0.00049
[epoch  46: 180/307] 	 train loss: 0.094595 	 lr: 0.00049
[epoch  46: 200/307] 	 train loss: 0.362893 	 lr: 0.00049

val loss: 0.328864 	 acc: 0.910454

[epoch  46: 220/307] 	 train loss: 0.235738 	 lr: 0.00049
[epoch  46: 240/307] 	 train loss: 0.123446 	 lr: 0.00049
[epoch  46: 260/307] 	 train loss: 0.091236 	 lr: 0.00049
[epoch  46: 280/307] 	 train loss: 0.200653 	 lr: 0.00049
[epoch  46: 300/307] 	 train loss: 0.289816 	 lr: 0.00049
[epoch  47:   0/307] 	 train loss: 0.193145 	 lr: 0.00049
[epoch  47:  20/307] 	 train loss: 0.186870 	 lr: 0.00049
[epoch  47:  40/307] 	 train loss: 0.149982 	 lr: 0.00049
[epoch  47:  60/307] 	 train loss: 0.102935 	 lr: 0.00049

val loss: 0.335917 	 acc: 0.899109

[epoch  47:  80/307] 	 train loss: 0.361667 	 lr: 0.00049
[epoch  47: 100/307] 	 train loss: 0.217104 	 lr: 0.00049
[epoch  47: 120/307] 	 train loss: 0.242546 	 lr: 0.00049
[epoch  47: 140/307] 	 train loss: 0.353077 	 lr: 0.00049
[epoch  47: 160/307] 	 train loss: 0.143495 	 lr: 0.00049
[epoch  47: 180/307] 	 train loss: 0.255386 	 lr: 0.00049
[epoch  47: 200/307] 	 train loss: 0.116724 	 lr: 0.00049

val loss: 0.337231 	 acc: 0.905186

[epoch  47: 220/307] 	 train loss: 0.244289 	 lr: 0.00049
[epoch  47: 240/307] 	 train loss: 0.033450 	 lr: 0.00049
[epoch  47: 260/307] 	 train loss: 0.106913 	 lr: 0.00049
[epoch  47: 280/307] 	 train loss: 0.350934 	 lr: 0.00049
[epoch  47: 300/307] 	 train loss: 0.372464 	 lr: 0.00049
[epoch  48:   0/307] 	 train loss: 0.300749 	 lr: 0.00049
[epoch  48:  20/307] 	 train loss: 0.133212 	 lr: 0.00049
[epoch  48:  40/307] 	 train loss: 0.589648 	 lr: 0.00049

val loss: 0.322276 	 acc: 0.911264

[epoch  48:  60/307] 	 train loss: 0.273305 	 lr: 0.00049
[epoch  48:  80/307] 	 train loss: 0.104778 	 lr: 0.00049
[epoch  48: 100/307] 	 train loss: 0.085953 	 lr: 0.00049
[epoch  48: 120/307] 	 train loss: 0.074389 	 lr: 0.00049
[epoch  48: 140/307] 	 train loss: 0.151981 	 lr: 0.00049
[epoch  48: 160/307] 	 train loss: 0.167746 	 lr: 0.00049
[epoch  48: 180/307] 	 train loss: 0.194361 	 lr: 0.00049
[epoch  48: 200/307] 	 train loss: 0.212093 	 lr: 0.00049

val loss: 0.339611 	 acc: 0.911264

[epoch  48: 220/307] 	 train loss: 0.337667 	 lr: 0.00049
[epoch  48: 240/307] 	 train loss: 0.281478 	 lr: 0.00049
[epoch  48: 260/307] 	 train loss: 0.212532 	 lr: 0.00049
[epoch  48: 280/307] 	 train loss: 0.051458 	 lr: 0.00049
[epoch  48: 300/307] 	 train loss: 0.186496 	 lr: 0.00049
[epoch  49:   0/307] 	 train loss: 0.180602 	 lr: 0.00049
[epoch  49:  20/307] 	 train loss: 0.293941 	 lr: 0.00049
[epoch  49:  40/307] 	 train loss: 0.349198 	 lr: 0.00049

val loss: 0.312108 	 acc: 0.910859

[epoch  49:  60/307] 	 train loss: 0.174392 	 lr: 0.00049
[epoch  49:  80/307] 	 train loss: 0.098416 	 lr: 0.00049
[epoch  49: 100/307] 	 train loss: 0.070129 	 lr: 0.00049
[epoch  49: 120/307] 	 train loss: 0.090597 	 lr: 0.00049
[epoch  49: 140/307] 	 train loss: 0.232883 	 lr: 0.00049
[epoch  49: 160/307] 	 train loss: 0.136061 	 lr: 0.00049
[epoch  49: 180/307] 	 train loss: 0.292092 	 lr: 0.00049
[epoch  49: 200/307] 	 train loss: 0.208871 	 lr: 0.00049

val loss: 0.338132 	 acc: 0.903971

[epoch  49: 220/307] 	 train loss: 0.086936 	 lr: 0.00049
[epoch  49: 240/307] 	 train loss: 0.227453 	 lr: 0.00049
[epoch  49: 260/307] 	 train loss: 0.254429 	 lr: 0.00049
[epoch  49: 280/307] 	 train loss: 0.247132 	 lr: 0.00049
[epoch  49: 300/307] 	 train loss: 0.046675 	 lr: 0.00049
[epoch  50:   0/307] 	 train loss: 0.175602 	 lr: 0.00049
[epoch  50:  20/307] 	 train loss: 0.131445 	 lr: 0.00049
[epoch  50:  40/307] 	 train loss: 0.049381 	 lr: 0.00049

val loss: 0.334935 	 acc: 0.905997

[epoch  50:  60/307] 	 train loss: 0.217889 	 lr: 0.00049
[epoch  50:  80/307] 	 train loss: 0.086145 	 lr: 0.00049
[epoch  50: 100/307] 	 train loss: 0.159593 	 lr: 0.00049
[epoch  50: 120/307] 	 train loss: 0.313251 	 lr: 0.00049
[epoch  50: 140/307] 	 train loss: 0.094348 	 lr: 0.00049
[epoch  50: 160/307] 	 train loss: 0.064838 	 lr: 0.00049
[epoch  50: 180/307] 	 train loss: 0.366693 	 lr: 0.00049
[epoch  50: 200/307] 	 train loss: 0.180012 	 lr: 0.00049

val loss: 0.347988 	 acc: 0.904376

[epoch  50: 220/307] 	 train loss: 0.192528 	 lr: 0.00049
[epoch  50: 240/307] 	 train loss: 0.328001 	 lr: 0.00049
[epoch  50: 260/307] 	 train loss: 0.262667 	 lr: 0.00049
[epoch  50: 280/307] 	 train loss: 0.207724 	 lr: 0.00049
[epoch  50: 300/307] 	 train loss: 0.128197 	 lr: 0.00049
[epoch  51:   0/307] 	 train loss: 0.087173 	 lr: 0.00049
[epoch  51:  20/307] 	 train loss: 0.195318 	 lr: 0.00049
[epoch  51:  40/307] 	 train loss: 0.111651 	 lr: 0.00049

val loss: 0.369418 	 acc: 0.898703

[epoch  51:  60/307] 	 train loss: 0.131641 	 lr: 0.00049
[epoch  51:  80/307] 	 train loss: 0.228183 	 lr: 0.00049
[epoch  51: 100/307] 	 train loss: 0.121309 	 lr: 0.00049
[epoch  51: 120/307] 	 train loss: 0.297315 	 lr: 0.00049
[epoch  51: 140/307] 	 train loss: 0.340417 	 lr: 0.00049
[epoch  51: 160/307] 	 train loss: 0.065372 	 lr: 0.00049
[epoch  51: 180/307] 	 train loss: 0.168344 	 lr: 0.00049
[epoch  51: 200/307] 	 train loss: 0.249435 	 lr: 0.00049

val loss: 0.364863 	 acc: 0.900324

[epoch  51: 220/307] 	 train loss: 0.142348 	 lr: 0.00049
[epoch  51: 240/307] 	 train loss: 0.112426 	 lr: 0.00049
[epoch  51: 260/307] 	 train loss: 0.061191 	 lr: 0.00049
[epoch  51: 280/307] 	 train loss: 0.278155 	 lr: 0.00049
[epoch  51: 300/307] 	 train loss: 0.134662 	 lr: 0.00049
[epoch  52:   0/307] 	 train loss: 0.154860 	 lr: 0.00049
[epoch  52:  20/307] 	 train loss: 0.214726 	 lr: 0.00049
[epoch  52:  40/307] 	 train loss: 0.059028 	 lr: 0.00049

val loss: 0.332272 	 acc: 0.907212

[epoch  52:  60/307] 	 train loss: 0.346052 	 lr: 0.00049
[epoch  52:  80/307] 	 train loss: 0.108416 	 lr: 0.00049
[epoch  52: 100/307] 	 train loss: 0.027307 	 lr: 0.00049
[epoch  52: 120/307] 	 train loss: 0.088681 	 lr: 0.00049
[epoch  52: 140/307] 	 train loss: 0.128905 	 lr: 0.00049
[epoch  52: 160/307] 	 train loss: 0.248499 	 lr: 0.00049
[epoch  52: 180/307] 	 train loss: 0.283417 	 lr: 0.00049
[epoch  52: 200/307] 	 train loss: 0.419624 	 lr: 0.00049

val loss: 0.357674 	 acc: 0.910049

[epoch  52: 220/307] 	 train loss: 0.125994 	 lr: 0.00049
[epoch  52: 240/307] 	 train loss: 0.249716 	 lr: 0.00049
[epoch  52: 260/307] 	 train loss: 0.089540 	 lr: 0.00049
[epoch  52: 280/307] 	 train loss: 0.189022 	 lr: 0.00049
[epoch  52: 300/307] 	 train loss: 0.109230 	 lr: 0.00049
[epoch  53:   0/307] 	 train loss: 0.090598 	 lr: 0.00049
[epoch  53:  20/307] 	 train loss: 0.240480 	 lr: 0.00049
[epoch  53:  40/307] 	 train loss: 0.338409 	 lr: 0.00049

val loss: 0.374864 	 acc: 0.897488

[epoch  53:  60/307] 	 train loss: 0.159244 	 lr: 0.00049
[epoch  53:  80/307] 	 train loss: 0.082885 	 lr: 0.00049
[epoch  53: 100/307] 	 train loss: 0.057097 	 lr: 0.00049
[epoch  53: 120/307] 	 train loss: 0.204944 	 lr: 0.00049
[epoch  53: 140/307] 	 train loss: 0.043677 	 lr: 0.00049
[epoch  53: 160/307] 	 train loss: 0.520164 	 lr: 0.00049
[epoch  53: 180/307] 	 train loss: 0.080339 	 lr: 0.00049
[epoch  53: 200/307] 	 train loss: 0.292765 	 lr: 0.00049

val loss: 0.370040 	 acc: 0.900324

[epoch  53: 220/307] 	 train loss: 0.263213 	 lr: 0.00049
[epoch  53: 240/307] 	 train loss: 0.077818 	 lr: 0.00049
[epoch  53: 260/307] 	 train loss: 0.044207 	 lr: 0.00049
[epoch  53: 280/307] 	 train loss: 0.149707 	 lr: 0.00049
[epoch  53: 300/307] 	 train loss: 0.031691 	 lr: 0.00049
[epoch  54:   0/307] 	 train loss: 0.145293 	 lr: 0.00049
[epoch  54:  20/307] 	 train loss: 0.124390 	 lr: 0.00049
[epoch  54:  40/307] 	 train loss: 0.314251 	 lr: 0.00049

val loss: 0.345050 	 acc: 0.909238

[epoch  54:  60/307] 	 train loss: 0.122925 	 lr: 0.00049
[epoch  54:  80/307] 	 train loss: 0.062503 	 lr: 0.00049
[epoch  54: 100/307] 	 train loss: 0.142807 	 lr: 0.00049
[epoch  54: 120/307] 	 train loss: 0.588719 	 lr: 0.00049
[epoch  54: 140/307] 	 train loss: 0.122810 	 lr: 0.00049
[epoch  54: 160/307] 	 train loss: 0.323783 	 lr: 0.00049
[epoch  54: 180/307] 	 train loss: 0.196929 	 lr: 0.00049

val loss: 0.345472 	 acc: 0.899109

[epoch  54: 200/307] 	 train loss: 0.090505 	 lr: 0.00049
[epoch  54: 220/307] 	 train loss: 0.153844 	 lr: 0.00049
[epoch  54: 240/307] 	 train loss: 0.126964 	 lr: 0.00049
[epoch  54: 260/307] 	 train loss: 0.237737 	 lr: 0.00049
[epoch  54: 280/307] 	 train loss: 0.183567 	 lr: 0.00049
[epoch  54: 300/307] 	 train loss: 0.210693 	 lr: 0.00049
[epoch  55:   0/307] 	 train loss: 0.307070 	 lr: 0.00049
[epoch  55:  20/307] 	 train loss: 0.334775 	 lr: 0.00049
[epoch  55:  40/307] 	 train loss: 0.177578 	 lr: 0.00049

val loss: 0.360885 	 acc: 0.902755

[epoch  55:  60/307] 	 train loss: 0.143672 	 lr: 0.00049
[epoch  55:  80/307] 	 train loss: 0.318471 	 lr: 0.00049
[epoch  55: 100/307] 	 train loss: 0.245360 	 lr: 0.00049
[epoch  55: 120/307] 	 train loss: 0.212603 	 lr: 0.00049
[epoch  55: 140/307] 	 train loss: 0.318353 	 lr: 0.00049
[epoch  55: 160/307] 	 train loss: 0.105232 	 lr: 0.00049
[epoch  55: 180/307] 	 train loss: 0.041145 	 lr: 0.00049

val loss: 0.332359 	 acc: 0.904781

[epoch  55: 200/307] 	 train loss: 0.426007 	 lr: 0.00049
[epoch  55: 220/307] 	 train loss: 0.232026 	 lr: 0.00049
[epoch  55: 240/307] 	 train loss: 0.055467 	 lr: 0.00049
[epoch  55: 260/307] 	 train loss: 0.340369 	 lr: 0.00049
[epoch  55: 280/307] 	 train loss: 0.360828 	 lr: 0.00049
[epoch  55: 300/307] 	 train loss: 0.257791 	 lr: 0.00049
[epoch  56:   0/307] 	 train loss: 0.163854 	 lr: 0.00049
[epoch  56:  20/307] 	 train loss: 0.107110 	 lr: 0.00049
[epoch  56:  40/307] 	 train loss: 0.091381 	 lr: 0.00049

val loss: 0.356537 	 acc: 0.908023

[epoch  56:  60/307] 	 train loss: 0.238760 	 lr: 0.00049
[epoch  56:  80/307] 	 train loss: 0.207758 	 lr: 0.00049
[epoch  56: 100/307] 	 train loss: 0.070287 	 lr: 0.00049
[epoch  56: 120/307] 	 train loss: 0.283464 	 lr: 0.00049
[epoch  56: 140/307] 	 train loss: 0.199325 	 lr: 0.00049
[epoch  56: 160/307] 	 train loss: 0.037993 	 lr: 0.00049
[epoch  56: 180/307] 	 train loss: 0.208834 	 lr: 0.00049

val loss: 0.332073 	 acc: 0.901540

[epoch  56: 200/307] 	 train loss: 0.060328 	 lr: 0.00049
[epoch  56: 220/307] 	 train loss: 0.054508 	 lr: 0.00049
[epoch  56: 240/307] 	 train loss: 0.140558 	 lr: 0.00049
[epoch  56: 260/307] 	 train loss: 0.100919 	 lr: 0.00049
[epoch  56: 280/307] 	 train loss: 0.123049 	 lr: 0.00049
[epoch  56: 300/307] 	 train loss: 0.108749 	 lr: 0.00049
[epoch  57:   0/307] 	 train loss: 0.240375 	 lr: 0.00049
[epoch  57:  20/307] 	 train loss: 0.229139 	 lr: 0.00049
[epoch  57:  40/307] 	 train loss: 0.186278 	 lr: 0.00049

val loss: 0.319408 	 acc: 0.912885

saved model with accuracy  0.9128849270664505
[epoch  57:  60/307] 	 train loss: 0.176827 	 lr: 0.00049
[epoch  57:  80/307] 	 train loss: 0.326504 	 lr: 0.00049
[epoch  57: 100/307] 	 train loss: 0.164077 	 lr: 0.00049
[epoch  57: 120/307] 	 train loss: 0.222272 	 lr: 0.00049
[epoch  57: 140/307] 	 train loss: 0.152470 	 lr: 0.00049
[epoch  57: 160/307] 	 train loss: 0.025654 	 lr: 0.00049
[epoch  57: 180/307] 	 train loss: 0.262819 	 lr: 0.00049

val loss: 0.346482 	 acc: 0.905186

[epoch  57: 200/307] 	 train loss: 0.211791 	 lr: 0.00049
[epoch  57: 220/307] 	 train loss: 0.117633 	 lr: 0.00049
[epoch  57: 240/307] 	 train loss: 0.237756 	 lr: 0.00049
[epoch  57: 260/307] 	 train loss: 0.132421 	 lr: 0.00049
[epoch  57: 280/307] 	 train loss: 0.604357 	 lr: 0.00049
[epoch  57: 300/307] 	 train loss: 0.184668 	 lr: 0.00049
[epoch  58:   0/307] 	 train loss: 0.080606 	 lr: 0.00049
[epoch  58:  20/307] 	 train loss: 0.355016 	 lr: 0.00049

val loss: 0.346417 	 acc: 0.906807

[epoch  58:  40/307] 	 train loss: 0.039995 	 lr: 0.00049
[epoch  58:  60/307] 	 train loss: 0.368241 	 lr: 0.00049
[epoch  58:  80/307] 	 train loss: 0.085895 	 lr: 0.00049
[epoch  58: 100/307] 	 train loss: 0.292202 	 lr: 0.00049
[epoch  58: 120/307] 	 train loss: 0.066183 	 lr: 0.00049
[epoch  58: 140/307] 	 train loss: 0.063619 	 lr: 0.00049
[epoch  58: 160/307] 	 train loss: 0.241144 	 lr: 0.00049
[epoch  58: 180/307] 	 train loss: 0.067004 	 lr: 0.00049

val loss: 0.323453 	 acc: 0.909643

[epoch  58: 200/307] 	 train loss: 0.429040 	 lr: 0.00049
[epoch  58: 220/307] 	 train loss: 0.164072 	 lr: 0.00049
[epoch  58: 240/307] 	 train loss: 0.155428 	 lr: 0.00049
[epoch  58: 260/307] 	 train loss: 0.343519 	 lr: 0.00049
[epoch  58: 280/307] 	 train loss: 0.330060 	 lr: 0.00049
[epoch  58: 300/307] 	 train loss: 0.158985 	 lr: 0.00049
[epoch  59:   0/307] 	 train loss: 0.218394 	 lr: 0.00049
[epoch  59:  20/307] 	 train loss: 0.148309 	 lr: 0.00049

val loss: 0.345845 	 acc: 0.908023

[epoch  59:  40/307] 	 train loss: 0.043065 	 lr: 0.00049
[epoch  59:  60/307] 	 train loss: 0.151412 	 lr: 0.00049
[epoch  59:  80/307] 	 train loss: 0.152309 	 lr: 0.00049
[epoch  59: 100/307] 	 train loss: 0.325448 	 lr: 0.00049
[epoch  59: 120/307] 	 train loss: 0.232640 	 lr: 0.00049
[epoch  59: 140/307] 	 train loss: 0.125177 	 lr: 0.00049
[epoch  59: 160/307] 	 train loss: 0.290130 	 lr: 0.00049
[epoch  59: 180/307] 	 train loss: 0.166899 	 lr: 0.00049

val loss: 0.332273 	 acc: 0.910859

[epoch  59: 200/307] 	 train loss: 0.055864 	 lr: 0.00049
[epoch  59: 220/307] 	 train loss: 0.150833 	 lr: 0.00049
[epoch  59: 240/307] 	 train loss: 0.171145 	 lr: 0.00049
[epoch  59: 260/307] 	 train loss: 0.081458 	 lr: 0.00049
[epoch  59: 280/307] 	 train loss: 0.040147 	 lr: 0.00049
[epoch  59: 300/307] 	 train loss: 0.164130 	 lr: 0.00049
[epoch  60:   0/307] 	 train loss: 0.051467 	 lr: 0.00049
[epoch  60:  20/307] 	 train loss: 0.241666 	 lr: 0.00049

val loss: 0.332432 	 acc: 0.904781

[epoch  60:  40/307] 	 train loss: 0.090256 	 lr: 0.00049
[epoch  60:  60/307] 	 train loss: 0.281983 	 lr: 0.00049
[epoch  60:  80/307] 	 train loss: 0.218989 	 lr: 0.00049
[epoch  60: 100/307] 	 train loss: 0.043959 	 lr: 0.00049
[epoch  60: 120/307] 	 train loss: 0.361082 	 lr: 0.00049
[epoch  60: 140/307] 	 train loss: 0.253219 	 lr: 0.00049
[epoch  60: 160/307] 	 train loss: 0.123282 	 lr: 0.00049
[epoch  60: 180/307] 	 train loss: 0.098768 	 lr: 0.00049

val loss: 0.323379 	 acc: 0.910859

[epoch  60: 200/307] 	 train loss: 0.097754 	 lr: 0.00049
[epoch  60: 220/307] 	 train loss: 0.177007 	 lr: 0.00049
[epoch  60: 240/307] 	 train loss: 0.169048 	 lr: 0.00049
[epoch  60: 260/307] 	 train loss: 0.165631 	 lr: 0.00049
[epoch  60: 280/307] 	 train loss: 0.114464 	 lr: 0.00049
[epoch  60: 300/307] 	 train loss: 0.118742 	 lr: 0.00049
[epoch  61:   0/307] 	 train loss: 0.269996 	 lr: 0.00049
[epoch  61:  20/307] 	 train loss: 0.162794 	 lr: 0.00049

val loss: 0.361340 	 acc: 0.901540

[epoch  61:  40/307] 	 train loss: 0.093111 	 lr: 0.00049
[epoch  61:  60/307] 	 train loss: 0.388499 	 lr: 0.00049
[epoch  61:  80/307] 	 train loss: 0.182248 	 lr: 0.00049
[epoch  61: 100/307] 	 train loss: 0.157037 	 lr: 0.00049
[epoch  61: 120/307] 	 train loss: 0.459633 	 lr: 0.00049
[epoch  61: 140/307] 	 train loss: 0.551343 	 lr: 0.00049
[epoch  61: 160/307] 	 train loss: 0.271368 	 lr: 0.00049
[epoch  61: 180/307] 	 train loss: 0.164265 	 lr: 0.00049

val loss: 0.343806 	 acc: 0.910859

[epoch  61: 200/307] 	 train loss: 0.290853 	 lr: 0.00049
[epoch  61: 220/307] 	 train loss: 0.209054 	 lr: 0.00049
[epoch  61: 240/307] 	 train loss: 0.276425 	 lr: 0.00049
[epoch  61: 260/307] 	 train loss: 0.145963 	 lr: 0.00049
[epoch  61: 280/307] 	 train loss: 0.181796 	 lr: 0.00049
[epoch  61: 300/307] 	 train loss: 0.131124 	 lr: 0.00049
[epoch  62:   0/307] 	 train loss: 0.138928 	 lr: 0.00049
[epoch  62:  20/307] 	 train loss: 0.490375 	 lr: 0.00049

val loss: 0.339820 	 acc: 0.898703

[epoch  62:  40/307] 	 train loss: 0.163048 	 lr: 0.00049
[epoch  62:  60/307] 	 train loss: 0.246823 	 lr: 0.00049
[epoch  62:  80/307] 	 train loss: 0.109718 	 lr: 0.00049
[epoch  62: 100/307] 	 train loss: 0.166942 	 lr: 0.00049
[epoch  62: 120/307] 	 train loss: 0.267659 	 lr: 0.00049
[epoch  62: 140/307] 	 train loss: 0.081656 	 lr: 0.00049
[epoch  62: 160/307] 	 train loss: 0.037088 	 lr: 0.00049
[epoch  62: 180/307] 	 train loss: 0.170651 	 lr: 0.00049

val loss: 0.355276 	 acc: 0.905186

[epoch  62: 200/307] 	 train loss: 0.106264 	 lr: 0.00049
[epoch  62: 220/307] 	 train loss: 0.075630 	 lr: 0.00049
[epoch  62: 240/307] 	 train loss: 0.160891 	 lr: 0.00049
[epoch  62: 260/307] 	 train loss: 0.172924 	 lr: 0.00049
[epoch  62: 280/307] 	 train loss: 0.153576 	 lr: 0.00049
[epoch  62: 300/307] 	 train loss: 0.214877 	 lr: 0.00049
[epoch  63:   0/307] 	 train loss: 0.063161 	 lr: 0.00049
[epoch  63:  20/307] 	 train loss: 0.219014 	 lr: 0.00049

val loss: 0.340595 	 acc: 0.909643

[epoch  63:  40/307] 	 train loss: 0.121604 	 lr: 0.00049
[epoch  63:  60/307] 	 train loss: 0.203125 	 lr: 0.00049
[epoch  63:  80/307] 	 train loss: 0.201374 	 lr: 0.00049
[epoch  63: 100/307] 	 train loss: 0.231615 	 lr: 0.00049
[epoch  63: 120/307] 	 train loss: 0.064785 	 lr: 0.00049
[epoch  63: 140/307] 	 train loss: 0.149186 	 lr: 0.00049
[epoch  63: 160/307] 	 train loss: 0.105504 	 lr: 0.00049
[epoch  63: 180/307] 	 train loss: 0.437801 	 lr: 0.00049

val loss: 0.376030 	 acc: 0.908428

[epoch  63: 200/307] 	 train loss: 0.148376 	 lr: 0.00049
[epoch  63: 220/307] 	 train loss: 0.495634 	 lr: 0.00049
[epoch  63: 240/307] 	 train loss: 0.079417 	 lr: 0.00049
[epoch  63: 260/307] 	 train loss: 0.342798 	 lr: 0.00049
[epoch  63: 280/307] 	 train loss: 0.227749 	 lr: 0.00049
[epoch  63: 300/307] 	 train loss: 0.060421 	 lr: 0.00049
[epoch  64:   0/307] 	 train loss: 0.385155 	 lr: 0.00034
[epoch  64:  20/307] 	 train loss: 0.215233 	 lr: 0.00034

val loss: 0.350590 	 acc: 0.913290

saved model with accuracy  0.913290113452188
[epoch  64:  40/307] 	 train loss: 0.288594 	 lr: 0.00034
[epoch  64:  60/307] 	 train loss: 0.132871 	 lr: 0.00034
[epoch  64:  80/307] 	 train loss: 0.141391 	 lr: 0.00034
[epoch  64: 100/307] 	 train loss: 0.320017 	 lr: 0.00034
[epoch  64: 120/307] 	 train loss: 0.107941 	 lr: 0.00034
[epoch  64: 140/307] 	 train loss: 0.216590 	 lr: 0.00034
[epoch  64: 160/307] 	 train loss: 0.190877 	 lr: 0.00034

val loss: 0.350016 	 acc: 0.907212

[epoch  64: 180/307] 	 train loss: 0.148774 	 lr: 0.00034
[epoch  64: 200/307] 	 train loss: 0.056905 	 lr: 0.00034
[epoch  64: 220/307] 	 train loss: 0.204433 	 lr: 0.00034
[epoch  64: 240/307] 	 train loss: 0.238185 	 lr: 0.00034
[epoch  64: 260/307] 	 train loss: 0.107292 	 lr: 0.00034
[epoch  64: 280/307] 	 train loss: 0.231515 	 lr: 0.00034
[epoch  64: 300/307] 	 train loss: 0.123056 	 lr: 0.00034
[epoch  65:   0/307] 	 train loss: 0.095048 	 lr: 0.00034
[epoch  65:  20/307] 	 train loss: 0.181162 	 lr: 0.00034

val loss: 0.326625 	 acc: 0.908428

[epoch  65:  40/307] 	 train loss: 0.157039 	 lr: 0.00034
[epoch  65:  60/307] 	 train loss: 0.383172 	 lr: 0.00034
[epoch  65:  80/307] 	 train loss: 0.143356 	 lr: 0.00034
[epoch  65: 100/307] 	 train loss: 0.136070 	 lr: 0.00034
[epoch  65: 120/307] 	 train loss: 0.229529 	 lr: 0.00034
[epoch  65: 140/307] 	 train loss: 0.205761 	 lr: 0.00034
[epoch  65: 160/307] 	 train loss: 0.177027 	 lr: 0.00034

val loss: 0.341162 	 acc: 0.906402

[epoch  65: 180/307] 	 train loss: 0.131799 	 lr: 0.00034
[epoch  65: 200/307] 	 train loss: 0.041305 	 lr: 0.00034
[epoch  65: 220/307] 	 train loss: 0.305239 	 lr: 0.00034
[epoch  65: 240/307] 	 train loss: 0.124623 	 lr: 0.00034
[epoch  65: 260/307] 	 train loss: 0.297745 	 lr: 0.00034
[epoch  65: 280/307] 	 train loss: 0.158515 	 lr: 0.00034
[epoch  65: 300/307] 	 train loss: 0.110153 	 lr: 0.00034
[epoch  66:   0/307] 	 train loss: 0.205277 	 lr: 0.00034
[epoch  66:  20/307] 	 train loss: 0.101978 	 lr: 0.00034

val loss: 0.334812 	 acc: 0.906402

[epoch  66:  40/307] 	 train loss: 0.113685 	 lr: 0.00034
[epoch  66:  60/307] 	 train loss: 0.073986 	 lr: 0.00034
[epoch  66:  80/307] 	 train loss: 0.149004 	 lr: 0.00034
[epoch  66: 100/307] 	 train loss: 0.065544 	 lr: 0.00034
[epoch  66: 120/307] 	 train loss: 0.125122 	 lr: 0.00034
[epoch  66: 140/307] 	 train loss: 0.136748 	 lr: 0.00034
[epoch  66: 160/307] 	 train loss: 0.135810 	 lr: 0.00034

val loss: 0.328900 	 acc: 0.912075

[epoch  66: 180/307] 	 train loss: 0.057306 	 lr: 0.00034
[epoch  66: 200/307] 	 train loss: 0.129444 	 lr: 0.00034
[epoch  66: 220/307] 	 train loss: 0.075714 	 lr: 0.00034
[epoch  66: 240/307] 	 train loss: 0.251602 	 lr: 0.00034
[epoch  66: 260/307] 	 train loss: 0.123238 	 lr: 0.00034
[epoch  66: 280/307] 	 train loss: 0.171001 	 lr: 0.00034
[epoch  66: 300/307] 	 train loss: 0.133042 	 lr: 0.00034
[epoch  67:   0/307] 	 train loss: 0.177286 	 lr: 0.00034
[epoch  67:  20/307] 	 train loss: 0.103011 	 lr: 0.00034

val loss: 0.334722 	 acc: 0.911264

[epoch  67:  40/307] 	 train loss: 0.127073 	 lr: 0.00034
[epoch  67:  60/307] 	 train loss: 0.101718 	 lr: 0.00034
[epoch  67:  80/307] 	 train loss: 0.141008 	 lr: 0.00034
[epoch  67: 100/307] 	 train loss: 0.106422 	 lr: 0.00034
[epoch  67: 120/307] 	 train loss: 0.154599 	 lr: 0.00034
[epoch  67: 140/307] 	 train loss: 0.149451 	 lr: 0.00034
[epoch  67: 160/307] 	 train loss: 0.229302 	 lr: 0.00034

val loss: 0.353050 	 acc: 0.908023

[epoch  67: 180/307] 	 train loss: 0.119987 	 lr: 0.00034
[epoch  67: 200/307] 	 train loss: 0.333263 	 lr: 0.00034
[epoch  67: 220/307] 	 train loss: 0.314970 	 lr: 0.00034
[epoch  67: 240/307] 	 train loss: 0.227208 	 lr: 0.00034
[epoch  67: 260/307] 	 train loss: 0.230476 	 lr: 0.00034
[epoch  67: 280/307] 	 train loss: 0.159624 	 lr: 0.00034
[epoch  67: 300/307] 	 train loss: 0.107057 	 lr: 0.00034
[epoch  68:   0/307] 	 train loss: 0.227806 	 lr: 0.00034

val loss: 0.352422 	 acc: 0.902350

[epoch  68:  20/307] 	 train loss: 0.295794 	 lr: 0.00034
[epoch  68:  40/307] 	 train loss: 0.352284 	 lr: 0.00034
[epoch  68:  60/307] 	 train loss: 0.240239 	 lr: 0.00034
[epoch  68:  80/307] 	 train loss: 0.043447 	 lr: 0.00034
[epoch  68: 100/307] 	 train loss: 0.132594 	 lr: 0.00034
[epoch  68: 120/307] 	 train loss: 0.169380 	 lr: 0.00034
[epoch  68: 140/307] 	 train loss: 0.090328 	 lr: 0.00034
[epoch  68: 160/307] 	 train loss: 0.306801 	 lr: 0.00034

val loss: 0.330918 	 acc: 0.911264

[epoch  68: 180/307] 	 train loss: 0.269524 	 lr: 0.00034
[epoch  68: 200/307] 	 train loss: 0.085392 	 lr: 0.00034
[epoch  68: 220/307] 	 train loss: 0.227698 	 lr: 0.00034
[epoch  68: 240/307] 	 train loss: 0.136041 	 lr: 0.00034
[epoch  68: 260/307] 	 train loss: 0.102024 	 lr: 0.00034
[epoch  68: 280/307] 	 train loss: 0.252273 	 lr: 0.00034
[epoch  68: 300/307] 	 train loss: 0.070562 	 lr: 0.00034
[epoch  69:   0/307] 	 train loss: 0.150075 	 lr: 0.00034

val loss: 0.338445 	 acc: 0.906402

[epoch  69:  20/307] 	 train loss: 0.234168 	 lr: 0.00034
[epoch  69:  40/307] 	 train loss: 0.139303 	 lr: 0.00034
[epoch  69:  60/307] 	 train loss: 0.188379 	 lr: 0.00034
[epoch  69:  80/307] 	 train loss: 0.169644 	 lr: 0.00034
[epoch  69: 100/307] 	 train loss: 0.325324 	 lr: 0.00034
[epoch  69: 120/307] 	 train loss: 0.113983 	 lr: 0.00034
[epoch  69: 140/307] 	 train loss: 0.148919 	 lr: 0.00034
[epoch  69: 160/307] 	 train loss: 0.073219 	 lr: 0.00034

val loss: 0.328486 	 acc: 0.906807

[epoch  69: 180/307] 	 train loss: 0.218907 	 lr: 0.00034
[epoch  69: 200/307] 	 train loss: 0.181166 	 lr: 0.00034
[epoch  69: 220/307] 	 train loss: 0.156951 	 lr: 0.00034
[epoch  69: 240/307] 	 train loss: 0.340323 	 lr: 0.00034
[epoch  69: 260/307] 	 train loss: 0.074420 	 lr: 0.00034
[epoch  69: 280/307] 	 train loss: 0.215906 	 lr: 0.00034
[epoch  69: 300/307] 	 train loss: 0.424973 	 lr: 0.00034
[epoch  70:   0/307] 	 train loss: 0.321176 	 lr: 0.00034

val loss: 0.338416 	 acc: 0.911669

[epoch  70:  20/307] 	 train loss: 0.147737 	 lr: 0.00034
[epoch  70:  40/307] 	 train loss: 0.045923 	 lr: 0.00034
[epoch  70:  60/307] 	 train loss: 0.144727 	 lr: 0.00034
[epoch  70:  80/307] 	 train loss: 0.091501 	 lr: 0.00034
[epoch  70: 100/307] 	 train loss: 0.179176 	 lr: 0.00034
[epoch  70: 120/307] 	 train loss: 0.198475 	 lr: 0.00034
[epoch  70: 140/307] 	 train loss: 0.146291 	 lr: 0.00034
[epoch  70: 160/307] 	 train loss: 0.144464 	 lr: 0.00034

val loss: 0.324568 	 acc: 0.908428

[epoch  70: 180/307] 	 train loss: 0.234000 	 lr: 0.00034
[epoch  70: 200/307] 	 train loss: 0.289626 	 lr: 0.00034
[epoch  70: 220/307] 	 train loss: 0.138203 	 lr: 0.00034
[epoch  70: 240/307] 	 train loss: 0.298159 	 lr: 0.00034
[epoch  70: 260/307] 	 train loss: 0.158284 	 lr: 0.00034
[epoch  70: 280/307] 	 train loss: 0.056450 	 lr: 0.00034
[epoch  70: 300/307] 	 train loss: 0.144602 	 lr: 0.00034
[epoch  71:   0/307] 	 train loss: 0.291954 	 lr: 0.00034

val loss: 0.327833 	 acc: 0.908833

[epoch  71:  20/307] 	 train loss: 0.199107 	 lr: 0.00034
[epoch  71:  40/307] 	 train loss: 0.341107 	 lr: 0.00034
[epoch  71:  60/307] 	 train loss: 0.124121 	 lr: 0.00034
[epoch  71:  80/307] 	 train loss: 0.098278 	 lr: 0.00034
[epoch  71: 100/307] 	 train loss: 0.036998 	 lr: 0.00034
[epoch  71: 120/307] 	 train loss: 0.072742 	 lr: 0.00034
[epoch  71: 140/307] 	 train loss: 0.215554 	 lr: 0.00034
[epoch  71: 160/307] 	 train loss: 0.105667 	 lr: 0.00034

val loss: 0.330418 	 acc: 0.911669

[epoch  71: 180/307] 	 train loss: 0.155783 	 lr: 0.00034
[epoch  71: 200/307] 	 train loss: 0.190107 	 lr: 0.00034
[epoch  71: 220/307] 	 train loss: 0.063542 	 lr: 0.00034
[epoch  71: 240/307] 	 train loss: 0.226991 	 lr: 0.00034
[epoch  71: 260/307] 	 train loss: 0.095585 	 lr: 0.00034
[epoch  71: 280/307] 	 train loss: 0.330166 	 lr: 0.00034
[epoch  71: 300/307] 	 train loss: 0.204824 	 lr: 0.00034
[epoch  72:   0/307] 	 train loss: 0.171713 	 lr: 0.00034

val loss: 0.333185 	 acc: 0.908428

[epoch  72:  20/307] 	 train loss: 0.129340 	 lr: 0.00034
[epoch  72:  40/307] 	 train loss: 0.194357 	 lr: 0.00034
[epoch  72:  60/307] 	 train loss: 0.250258 	 lr: 0.00034
[epoch  72:  80/307] 	 train loss: 0.250565 	 lr: 0.00034
[epoch  72: 100/307] 	 train loss: 0.271708 	 lr: 0.00034
[epoch  72: 120/307] 	 train loss: 0.304940 	 lr: 0.00034
[epoch  72: 140/307] 	 train loss: 0.423901 	 lr: 0.00034
[epoch  72: 160/307] 	 train loss: 0.063167 	 lr: 0.00034

val loss: 0.348164 	 acc: 0.908428

[epoch  72: 180/307] 	 train loss: 0.210553 	 lr: 0.00034
[epoch  72: 200/307] 	 train loss: 0.095752 	 lr: 0.00034
[epoch  72: 220/307] 	 train loss: 0.216669 	 lr: 0.00034
[epoch  72: 240/307] 	 train loss: 0.092260 	 lr: 0.00034
[epoch  72: 260/307] 	 train loss: 0.231207 	 lr: 0.00034
[epoch  72: 280/307] 	 train loss: 0.073562 	 lr: 0.00034
[epoch  72: 300/307] 	 train loss: 0.266576 	 lr: 0.00034
[epoch  73:   0/307] 	 train loss: 0.202042 	 lr: 0.00034

val loss: 0.328694 	 acc: 0.911669

[epoch  73:  20/307] 	 train loss: 0.215999 	 lr: 0.00034
[epoch  73:  40/307] 	 train loss: 0.130974 	 lr: 0.00034
[epoch  73:  60/307] 	 train loss: 0.204026 	 lr: 0.00034
[epoch  73:  80/307] 	 train loss: 0.208375 	 lr: 0.00034
[epoch  73: 100/307] 	 train loss: 0.129918 	 lr: 0.00034
[epoch  73: 120/307] 	 train loss: 0.147899 	 lr: 0.00034
[epoch  73: 140/307] 	 train loss: 0.118194 	 lr: 0.00034
[epoch  73: 160/307] 	 train loss: 0.258274 	 lr: 0.00034

val loss: 0.350779 	 acc: 0.903566

[epoch  73: 180/307] 	 train loss: 0.080532 	 lr: 0.00034
[epoch  73: 200/307] 	 train loss: 0.236791 	 lr: 0.00034
[epoch  73: 220/307] 	 train loss: 0.065454 	 lr: 0.00034
[epoch  73: 240/307] 	 train loss: 0.063389 	 lr: 0.00034
[epoch  73: 260/307] 	 train loss: 0.176212 	 lr: 0.00034
[epoch  73: 280/307] 	 train loss: 0.236359 	 lr: 0.00034
[epoch  73: 300/307] 	 train loss: 0.503639 	 lr: 0.00034
[epoch  74:   0/307] 	 train loss: 0.200802 	 lr: 0.00034

val loss: 0.322241 	 acc: 0.909238

[epoch  74:  20/307] 	 train loss: 0.115873 	 lr: 0.00034
[epoch  74:  40/307] 	 train loss: 0.062482 	 lr: 0.00034
[epoch  74:  60/307] 	 train loss: 0.273083 	 lr: 0.00034
[epoch  74:  80/307] 	 train loss: 0.304747 	 lr: 0.00034
[epoch  74: 100/307] 	 train loss: 0.228804 	 lr: 0.00034
[epoch  74: 120/307] 	 train loss: 0.189390 	 lr: 0.00034
[epoch  74: 140/307] 	 train loss: 0.115806 	 lr: 0.00034

val loss: 0.342838 	 acc: 0.905186

[epoch  74: 160/307] 	 train loss: 0.219124 	 lr: 0.00034
[epoch  74: 180/307] 	 train loss: 0.077960 	 lr: 0.00034
[epoch  74: 200/307] 	 train loss: 0.294064 	 lr: 0.00034
[epoch  74: 220/307] 	 train loss: 0.012444 	 lr: 0.00034
[epoch  74: 240/307] 	 train loss: 0.171157 	 lr: 0.00034
[epoch  74: 260/307] 	 train loss: 0.140287 	 lr: 0.00034
[epoch  74: 280/307] 	 train loss: 0.071160 	 lr: 0.00034
[epoch  74: 300/307] 	 train loss: 0.146420 	 lr: 0.00034
[epoch  75:   0/307] 	 train loss: 0.114115 	 lr: 0.00034

val loss: 0.349551 	 acc: 0.907212

[epoch  75:  20/307] 	 train loss: 0.306305 	 lr: 0.00034
[epoch  75:  40/307] 	 train loss: 0.290892 	 lr: 0.00034
[epoch  75:  60/307] 	 train loss: 0.428851 	 lr: 0.00034
[epoch  75:  80/307] 	 train loss: 0.045905 	 lr: 0.00034
[epoch  75: 100/307] 	 train loss: 0.247410 	 lr: 0.00034
[epoch  75: 120/307] 	 train loss: 0.324906 	 lr: 0.00034
[epoch  75: 140/307] 	 train loss: 0.390417 	 lr: 0.00034

val loss: 0.348145 	 acc: 0.907618

[epoch  75: 160/307] 	 train loss: 0.064195 	 lr: 0.00034
[epoch  75: 180/307] 	 train loss: 0.229844 	 lr: 0.00034
[epoch  75: 200/307] 	 train loss: 0.062661 	 lr: 0.00034
[epoch  75: 220/307] 	 train loss: 0.422631 	 lr: 0.00034
[epoch  75: 240/307] 	 train loss: 0.048779 	 lr: 0.00034
[epoch  75: 260/307] 	 train loss: 0.239518 	 lr: 0.00034
[epoch  75: 280/307] 	 train loss: 0.340259 	 lr: 0.00034
[epoch  75: 300/307] 	 train loss: 0.166839 	 lr: 0.00034
[epoch  76:   0/307] 	 train loss: 0.119045 	 lr: 0.00034

val loss: 0.368280 	 acc: 0.911669

[epoch  76:  20/307] 	 train loss: 0.195678 	 lr: 0.00034
[epoch  76:  40/307] 	 train loss: 0.100444 	 lr: 0.00034
[epoch  76:  60/307] 	 train loss: 0.027636 	 lr: 0.00034
[epoch  76:  80/307] 	 train loss: 0.352869 	 lr: 0.00034
[epoch  76: 100/307] 	 train loss: 0.220899 	 lr: 0.00034
[epoch  76: 120/307] 	 train loss: 0.246711 	 lr: 0.00034
[epoch  76: 140/307] 	 train loss: 0.220396 	 lr: 0.00034

val loss: 0.333282 	 acc: 0.913695

saved model with accuracy  0.9136952998379254
[epoch  76: 160/307] 	 train loss: 0.155660 	 lr: 0.00034
[epoch  76: 180/307] 	 train loss: 0.097081 	 lr: 0.00034
[epoch  76: 200/307] 	 train loss: 0.218240 	 lr: 0.00034
[epoch  76: 220/307] 	 train loss: 0.431865 	 lr: 0.00034
[epoch  76: 240/307] 	 train loss: 0.073825 	 lr: 0.00034
[epoch  76: 260/307] 	 train loss: 0.293019 	 lr: 0.00034
[epoch  76: 280/307] 	 train loss: 0.091134 	 lr: 0.00034
[epoch  76: 300/307] 	 train loss: 0.164430 	 lr: 0.00034
[epoch  77:   0/307] 	 train loss: 0.190686 	 lr: 0.00034

val loss: 0.328777 	 acc: 0.916532

saved model with accuracy  0.9165316045380876
[epoch  77:  20/307] 	 train loss: 0.167267 	 lr: 0.00034
[epoch  77:  40/307] 	 train loss: 0.177264 	 lr: 0.00034
[epoch  77:  60/307] 	 train loss: 0.188961 	 lr: 0.00034
[epoch  77:  80/307] 	 train loss: 0.108399 	 lr: 0.00034
[epoch  77: 100/307] 	 train loss: 0.198048 	 lr: 0.00034
[epoch  77: 120/307] 	 train loss: 0.217155 	 lr: 0.00034
[epoch  77: 140/307] 	 train loss: 0.196827 	 lr: 0.00034

val loss: 0.349038 	 acc: 0.907212

[epoch  77: 160/307] 	 train loss: 0.081893 	 lr: 0.00034
[epoch  77: 180/307] 	 train loss: 0.086697 	 lr: 0.00034
[epoch  77: 200/307] 	 train loss: 0.099932 	 lr: 0.00034
[epoch  77: 220/307] 	 train loss: 0.271541 	 lr: 0.00034
[epoch  77: 240/307] 	 train loss: 0.064889 	 lr: 0.00034
[epoch  77: 260/307] 	 train loss: 0.851502 	 lr: 0.00034
[epoch  77: 280/307] 	 train loss: 0.508459 	 lr: 0.00034
[epoch  77: 300/307] 	 train loss: 0.043334 	 lr: 0.00034

val loss: 0.341582 	 acc: 0.907212

[epoch  78:   0/307] 	 train loss: 0.423098 	 lr: 0.00034
[epoch  78:  20/307] 	 train loss: 0.088992 	 lr: 0.00034
[epoch  78:  40/307] 	 train loss: 0.178214 	 lr: 0.00034
[epoch  78:  60/307] 	 train loss: 0.335628 	 lr: 0.00034
[epoch  78:  80/307] 	 train loss: 0.074831 	 lr: 0.00034
[epoch  78: 100/307] 	 train loss: 0.057870 	 lr: 0.00034
[epoch  78: 120/307] 	 train loss: 0.039412 	 lr: 0.00034
[epoch  78: 140/307] 	 train loss: 0.110924 	 lr: 0.00034

val loss: 0.339375 	 acc: 0.905997

[epoch  78: 160/307] 	 train loss: 0.264130 	 lr: 0.00034
[epoch  78: 180/307] 	 train loss: 0.082735 	 lr: 0.00034
[epoch  78: 200/307] 	 train loss: 0.069882 	 lr: 0.00034
[epoch  78: 220/307] 	 train loss: 0.184773 	 lr: 0.00034
[epoch  78: 240/307] 	 train loss: 0.034876 	 lr: 0.00034
[epoch  78: 260/307] 	 train loss: 0.175855 	 lr: 0.00034
[epoch  78: 280/307] 	 train loss: 0.040520 	 lr: 0.00034
[epoch  78: 300/307] 	 train loss: 0.044527 	 lr: 0.00034

val loss: 0.338448 	 acc: 0.905997

[epoch  79:   0/307] 	 train loss: 0.195251 	 lr: 0.00034
[epoch  79:  20/307] 	 train loss: 0.054357 	 lr: 0.00034
[epoch  79:  40/307] 	 train loss: 0.193024 	 lr: 0.00034
[epoch  79:  60/307] 	 train loss: 0.078756 	 lr: 0.00034
[epoch  79:  80/307] 	 train loss: 0.078899 	 lr: 0.00034
[epoch  79: 100/307] 	 train loss: 0.077009 	 lr: 0.00034
[epoch  79: 120/307] 	 train loss: 0.397256 	 lr: 0.00034
[epoch  79: 140/307] 	 train loss: 0.171346 	 lr: 0.00034

val loss: 0.346414 	 acc: 0.906807

[epoch  79: 160/307] 	 train loss: 0.050126 	 lr: 0.00034
[epoch  79: 180/307] 	 train loss: 0.175316 	 lr: 0.00034
[epoch  79: 200/307] 	 train loss: 0.174419 	 lr: 0.00034
[epoch  79: 220/307] 	 train loss: 0.178067 	 lr: 0.00034
[epoch  79: 240/307] 	 train loss: 0.138923 	 lr: 0.00034
[epoch  79: 260/307] 	 train loss: 0.348335 	 lr: 0.00034
[epoch  79: 280/307] 	 train loss: 0.035899 	 lr: 0.00034
[epoch  79: 300/307] 	 train loss: 0.172116 	 lr: 0.00034

val loss: 0.332162 	 acc: 0.905997

[epoch  80:   0/307] 	 train loss: 0.148779 	 lr: 0.00034
[epoch  80:  20/307] 	 train loss: 0.107000 	 lr: 0.00034
[epoch  80:  40/307] 	 train loss: 0.109823 	 lr: 0.00034
[epoch  80:  60/307] 	 train loss: 0.352105 	 lr: 0.00034
[epoch  80:  80/307] 	 train loss: 0.098245 	 lr: 0.00034
[epoch  80: 100/307] 	 train loss: 0.108662 	 lr: 0.00034
[epoch  80: 120/307] 	 train loss: 0.141772 	 lr: 0.00034
[epoch  80: 140/307] 	 train loss: 0.164599 	 lr: 0.00034

val loss: 0.342655 	 acc: 0.906807

[epoch  80: 160/307] 	 train loss: 0.127060 	 lr: 0.00034
[epoch  80: 180/307] 	 train loss: 0.066457 	 lr: 0.00034
[epoch  80: 200/307] 	 train loss: 0.346582 	 lr: 0.00034
[epoch  80: 220/307] 	 train loss: 0.289973 	 lr: 0.00034
[epoch  80: 240/307] 	 train loss: 0.065652 	 lr: 0.00034
[epoch  80: 260/307] 	 train loss: 0.083463 	 lr: 0.00034
[epoch  80: 280/307] 	 train loss: 0.158573 	 lr: 0.00034
[epoch  80: 300/307] 	 train loss: 0.208734 	 lr: 0.00034

val loss: 0.356590 	 acc: 0.905186

[epoch  81:   0/307] 	 train loss: 0.099492 	 lr: 0.00034
[epoch  81:  20/307] 	 train loss: 0.201509 	 lr: 0.00034
[epoch  81:  40/307] 	 train loss: 0.180437 	 lr: 0.00034
[epoch  81:  60/307] 	 train loss: 0.186915 	 lr: 0.00034
[epoch  81:  80/307] 	 train loss: 0.053292 	 lr: 0.00034
[epoch  81: 100/307] 	 train loss: 0.188979 	 lr: 0.00034
[epoch  81: 120/307] 	 train loss: 0.057058 	 lr: 0.00034
[epoch  81: 140/307] 	 train loss: 0.087574 	 lr: 0.00034

val loss: 0.347165 	 acc: 0.904781

[epoch  81: 160/307] 	 train loss: 0.072185 	 lr: 0.00034
[epoch  81: 180/307] 	 train loss: 0.079245 	 lr: 0.00034
[epoch  81: 200/307] 	 train loss: 0.110344 	 lr: 0.00034
[epoch  81: 220/307] 	 train loss: 1.007468 	 lr: 0.00034
[epoch  81: 240/307] 	 train loss: 0.097971 	 lr: 0.00034
[epoch  81: 260/307] 	 train loss: 0.058484 	 lr: 0.00034
[epoch  81: 280/307] 	 train loss: 0.229088 	 lr: 0.00034

val loss: 0.362738 	 acc: 0.910859

[epoch  81: 300/307] 	 train loss: 0.205654 	 lr: 0.00034
[epoch  82:   0/307] 	 train loss: 0.134894 	 lr: 0.00034
[epoch  82:  20/307] 	 train loss: 0.228375 	 lr: 0.00034
[epoch  82:  40/307] 	 train loss: 0.062447 	 lr: 0.00034
[epoch  82:  60/307] 	 train loss: 0.218978 	 lr: 0.00034
[epoch  82:  80/307] 	 train loss: 0.214136 	 lr: 0.00034
[epoch  82: 100/307] 	 train loss: 0.309169 	 lr: 0.00034
[epoch  82: 120/307] 	 train loss: 0.216585 	 lr: 0.00034
[epoch  82: 140/307] 	 train loss: 0.091565 	 lr: 0.00034

val loss: 0.368158 	 acc: 0.910049

[epoch  82: 160/307] 	 train loss: 0.198785 	 lr: 0.00034
[epoch  82: 180/307] 	 train loss: 0.549795 	 lr: 0.00034
[epoch  82: 200/307] 	 train loss: 0.185819 	 lr: 0.00034
[epoch  82: 220/307] 	 train loss: 0.107955 	 lr: 0.00034
[epoch  82: 240/307] 	 train loss: 0.077756 	 lr: 0.00034
[epoch  82: 260/307] 	 train loss: 0.168780 	 lr: 0.00034
[epoch  82: 280/307] 	 train loss: 0.251241 	 lr: 0.00034

val loss: 0.347782 	 acc: 0.908428

[epoch  82: 300/307] 	 train loss: 0.059880 	 lr: 0.00034
[epoch  83:   0/307] 	 train loss: 0.130956 	 lr: 0.00034
[epoch  83:  20/307] 	 train loss: 0.047302 	 lr: 0.00034
[epoch  83:  40/307] 	 train loss: 0.154890 	 lr: 0.00034
[epoch  83:  60/307] 	 train loss: 0.026643 	 lr: 0.00034
[epoch  83:  80/307] 	 train loss: 0.036582 	 lr: 0.00034
[epoch  83: 100/307] 	 train loss: 0.228801 	 lr: 0.00034
[epoch  83: 120/307] 	 train loss: 0.161644 	 lr: 0.00034
[epoch  83: 140/307] 	 train loss: 0.150292 	 lr: 0.00034

val loss: 0.373488 	 acc: 0.901945

[epoch  83: 160/307] 	 train loss: 0.255541 	 lr: 0.00034
[epoch  83: 180/307] 	 train loss: 0.121533 	 lr: 0.00034
[epoch  83: 200/307] 	 train loss: 0.191045 	 lr: 0.00034
[epoch  83: 220/307] 	 train loss: 0.126705 	 lr: 0.00034
[epoch  83: 240/307] 	 train loss: 0.123263 	 lr: 0.00034
[epoch  83: 260/307] 	 train loss: 0.039760 	 lr: 0.00034
[epoch  83: 280/307] 	 train loss: 0.219775 	 lr: 0.00034

val loss: 0.341108 	 acc: 0.909643

[epoch  83: 300/307] 	 train loss: 0.489868 	 lr: 0.00034
[epoch  84:   0/307] 	 train loss: 0.198585 	 lr: 0.00034
[epoch  84:  20/307] 	 train loss: 0.013789 	 lr: 0.00034
[epoch  84:  40/307] 	 train loss: 0.132305 	 lr: 0.00034
[epoch  84:  60/307] 	 train loss: 0.076965 	 lr: 0.00034
[epoch  84:  80/307] 	 train loss: 0.421380 	 lr: 0.00034
[epoch  84: 100/307] 	 train loss: 0.243537 	 lr: 0.00034
[epoch  84: 120/307] 	 train loss: 0.250626 	 lr: 0.00034

val loss: 0.334460 	 acc: 0.913290

[epoch  84: 140/307] 	 train loss: 0.340436 	 lr: 0.00034
[epoch  84: 160/307] 	 train loss: 0.076841 	 lr: 0.00034
[epoch  84: 180/307] 	 train loss: 0.155391 	 lr: 0.00034
[epoch  84: 200/307] 	 train loss: 0.069109 	 lr: 0.00034
[epoch  84: 220/307] 	 train loss: 0.340335 	 lr: 0.00034
[epoch  84: 240/307] 	 train loss: 0.155996 	 lr: 0.00034
[epoch  84: 260/307] 	 train loss: 0.102483 	 lr: 0.00034
[epoch  84: 280/307] 	 train loss: 0.075899 	 lr: 0.00034

val loss: 0.359854 	 acc: 0.908833

[epoch  84: 300/307] 	 train loss: 0.149209 	 lr: 0.00034
[epoch  85:   0/307] 	 train loss: 0.139935 	 lr: 0.00024
[epoch  85:  20/307] 	 train loss: 0.163875 	 lr: 0.00024
[epoch  85:  40/307] 	 train loss: 0.160263 	 lr: 0.00024
[epoch  85:  60/307] 	 train loss: 0.104097 	 lr: 0.00024
[epoch  85:  80/307] 	 train loss: 0.091298 	 lr: 0.00024
[epoch  85: 100/307] 	 train loss: 0.241666 	 lr: 0.00024
[epoch  85: 120/307] 	 train loss: 0.060079 	 lr: 0.00024

val loss: 0.343914 	 acc: 0.914100

[epoch  85: 140/307] 	 train loss: 0.114714 	 lr: 0.00024
[epoch  85: 160/307] 	 train loss: 0.099410 	 lr: 0.00024
[epoch  85: 180/307] 	 train loss: 0.101630 	 lr: 0.00024
[epoch  85: 200/307] 	 train loss: 0.024898 	 lr: 0.00024
[epoch  85: 220/307] 	 train loss: 0.101950 	 lr: 0.00024
[epoch  85: 240/307] 	 train loss: 0.152434 	 lr: 0.00024
[epoch  85: 260/307] 	 train loss: 0.117865 	 lr: 0.00024
[epoch  85: 280/307] 	 train loss: 0.197139 	 lr: 0.00024

val loss: 0.349339 	 acc: 0.908428

[epoch  85: 300/307] 	 train loss: 0.330889 	 lr: 0.00024
[epoch  86:   0/307] 	 train loss: 0.058025 	 lr: 0.00024
[epoch  86:  20/307] 	 train loss: 0.081377 	 lr: 0.00024
[epoch  86:  40/307] 	 train loss: 0.160760 	 lr: 0.00024
[epoch  86:  60/307] 	 train loss: 0.091792 	 lr: 0.00024
[epoch  86:  80/307] 	 train loss: 0.149002 	 lr: 0.00024
[epoch  86: 100/307] 	 train loss: 0.275721 	 lr: 0.00024
[epoch  86: 120/307] 	 train loss: 0.153858 	 lr: 0.00024

val loss: 0.342250 	 acc: 0.911264

[epoch  86: 140/307] 	 train loss: 0.149168 	 lr: 0.00024
[epoch  86: 160/307] 	 train loss: 0.155244 	 lr: 0.00024
[epoch  86: 180/307] 	 train loss: 0.232942 	 lr: 0.00024
[epoch  86: 200/307] 	 train loss: 0.137027 	 lr: 0.00024
[epoch  86: 220/307] 	 train loss: 0.175524 	 lr: 0.00024
[epoch  86: 240/307] 	 train loss: 0.146983 	 lr: 0.00024
[epoch  86: 260/307] 	 train loss: 0.109388 	 lr: 0.00024
[epoch  86: 280/307] 	 train loss: 0.021268 	 lr: 0.00024

val loss: 0.352292 	 acc: 0.910859

[epoch  86: 300/307] 	 train loss: 0.149529 	 lr: 0.00024
[epoch  87:   0/307] 	 train loss: 0.350075 	 lr: 0.00024
[epoch  87:  20/307] 	 train loss: 0.486384 	 lr: 0.00024
[epoch  87:  40/307] 	 train loss: 0.142651 	 lr: 0.00024
[epoch  87:  60/307] 	 train loss: 0.045383 	 lr: 0.00024
[epoch  87:  80/307] 	 train loss: 0.122672 	 lr: 0.00024
[epoch  87: 100/307] 	 train loss: 0.201491 	 lr: 0.00024
[epoch  87: 120/307] 	 train loss: 0.059730 	 lr: 0.00024

val loss: 0.346354 	 acc: 0.905186

[epoch  87: 140/307] 	 train loss: 0.099351 	 lr: 0.00024
[epoch  87: 160/307] 	 train loss: 0.324069 	 lr: 0.00024
[epoch  87: 180/307] 	 train loss: 0.076032 	 lr: 0.00024
[epoch  87: 200/307] 	 train loss: 0.210781 	 lr: 0.00024
[epoch  87: 220/307] 	 train loss: 0.170487 	 lr: 0.00024
[epoch  87: 240/307] 	 train loss: 0.055772 	 lr: 0.00024
[epoch  87: 260/307] 	 train loss: 0.419734 	 lr: 0.00024
[epoch  87: 280/307] 	 train loss: 0.146398 	 lr: 0.00024

val loss: 0.348292 	 acc: 0.906402

[epoch  87: 300/307] 	 train loss: 0.257244 	 lr: 0.00024
[epoch  88:   0/307] 	 train loss: 0.078350 	 lr: 0.00024
[epoch  88:  20/307] 	 train loss: 0.164696 	 lr: 0.00024
[epoch  88:  40/307] 	 train loss: 0.229423 	 lr: 0.00024
[epoch  88:  60/307] 	 train loss: 0.270859 	 lr: 0.00024
[epoch  88:  80/307] 	 train loss: 0.118997 	 lr: 0.00024
[epoch  88: 100/307] 	 train loss: 0.189419 	 lr: 0.00024
[epoch  88: 120/307] 	 train loss: 0.026908 	 lr: 0.00024

val loss: 0.371801 	 acc: 0.898298

[epoch  88: 140/307] 	 train loss: 0.454534 	 lr: 0.00024
[epoch  88: 160/307] 	 train loss: 0.134773 	 lr: 0.00024
[epoch  88: 180/307] 	 train loss: 0.063629 	 lr: 0.00024
[epoch  88: 200/307] 	 train loss: 0.063454 	 lr: 0.00024
[epoch  88: 220/307] 	 train loss: 0.101112 	 lr: 0.00024
[epoch  88: 240/307] 	 train loss: 0.053562 	 lr: 0.00024
[epoch  88: 260/307] 	 train loss: 0.034661 	 lr: 0.00024
[epoch  88: 280/307] 	 train loss: 0.200328 	 lr: 0.00024

val loss: 0.345374 	 acc: 0.905592

[epoch  88: 300/307] 	 train loss: 0.158394 	 lr: 0.00024
[epoch  89:   0/307] 	 train loss: 0.097754 	 lr: 0.00024
[epoch  89:  20/307] 	 train loss: 0.049134 	 lr: 0.00024
[epoch  89:  40/307] 	 train loss: 0.049558 	 lr: 0.00024
[epoch  89:  60/307] 	 train loss: 0.231097 	 lr: 0.00024
[epoch  89:  80/307] 	 train loss: 0.187966 	 lr: 0.00024
[epoch  89: 100/307] 	 train loss: 0.209472 	 lr: 0.00024
[epoch  89: 120/307] 	 train loss: 0.141231 	 lr: 0.00024

val loss: 0.342365 	 acc: 0.910454

[epoch  89: 140/307] 	 train loss: 0.059765 	 lr: 0.00024
[epoch  89: 160/307] 	 train loss: 0.060864 	 lr: 0.00024
[epoch  89: 180/307] 	 train loss: 0.030424 	 lr: 0.00024
[epoch  89: 200/307] 	 train loss: 0.138226 	 lr: 0.00024
[epoch  89: 220/307] 	 train loss: 0.366519 	 lr: 0.00024
[epoch  89: 240/307] 	 train loss: 0.253038 	 lr: 0.00024
[epoch  89: 260/307] 	 train loss: 0.227466 	 lr: 0.00024
[epoch  89: 280/307] 	 train loss: 0.132410 	 lr: 0.00024

val loss: 0.352277 	 acc: 0.908833

[epoch  89: 300/307] 	 train loss: 0.258371 	 lr: 0.00024
[epoch  90:   0/307] 	 train loss: 0.104874 	 lr: 0.00024
[epoch  90:  20/307] 	 train loss: 0.141884 	 lr: 0.00024
[epoch  90:  40/307] 	 train loss: 0.181308 	 lr: 0.00024
[epoch  90:  60/307] 	 train loss: 0.121258 	 lr: 0.00024
[epoch  90:  80/307] 	 train loss: 0.179541 	 lr: 0.00024
[epoch  90: 100/307] 	 train loss: 0.035343 	 lr: 0.00024
[epoch  90: 120/307] 	 train loss: 0.132954 	 lr: 0.00024

val loss: 0.361863 	 acc: 0.911264

[epoch  90: 140/307] 	 train loss: 0.450054 	 lr: 0.00024
[epoch  90: 160/307] 	 train loss: 0.317058 	 lr: 0.00024
[epoch  90: 180/307] 	 train loss: 0.073123 	 lr: 0.00024
[epoch  90: 200/307] 	 train loss: 0.136785 	 lr: 0.00024
[epoch  90: 220/307] 	 train loss: 0.344069 	 lr: 0.00024
[epoch  90: 240/307] 	 train loss: 0.255172 	 lr: 0.00024
[epoch  90: 260/307] 	 train loss: 0.242838 	 lr: 0.00024
[epoch  90: 280/307] 	 train loss: 0.227073 	 lr: 0.00024

val loss: 0.356150 	 acc: 0.903971

[epoch  90: 300/307] 	 train loss: 0.440334 	 lr: 0.00024
[epoch  91:   0/307] 	 train loss: 0.183743 	 lr: 0.00024
[epoch  91:  20/307] 	 train loss: 0.129225 	 lr: 0.00024
[epoch  91:  40/307] 	 train loss: 0.136337 	 lr: 0.00024
[epoch  91:  60/307] 	 train loss: 0.049172 	 lr: 0.00024
[epoch  91:  80/307] 	 train loss: 0.308469 	 lr: 0.00024
[epoch  91: 100/307] 	 train loss: 0.242707 	 lr: 0.00024
[epoch  91: 120/307] 	 train loss: 0.071540 	 lr: 0.00024

val loss: 0.315875 	 acc: 0.914506

[epoch  91: 140/307] 	 train loss: 0.267056 	 lr: 0.00024
[epoch  91: 160/307] 	 train loss: 0.250849 	 lr: 0.00024
[epoch  91: 180/307] 	 train loss: 0.031839 	 lr: 0.00024
[epoch  91: 200/307] 	 train loss: 0.174155 	 lr: 0.00024
[epoch  91: 220/307] 	 train loss: 0.251943 	 lr: 0.00024
[epoch  91: 240/307] 	 train loss: 0.094146 	 lr: 0.00024
[epoch  91: 260/307] 	 train loss: 0.197738 	 lr: 0.00024

val loss: 0.342016 	 acc: 0.907618

[epoch  91: 280/307] 	 train loss: 0.132875 	 lr: 0.00024
[epoch  91: 300/307] 	 train loss: 0.135686 	 lr: 0.00024
[epoch  92:   0/307] 	 train loss: 0.254458 	 lr: 0.00024
[epoch  92:  20/307] 	 train loss: 0.134294 	 lr: 0.00024
[epoch  92:  40/307] 	 train loss: 0.037153 	 lr: 0.00024
[epoch  92:  60/307] 	 train loss: 0.168642 	 lr: 0.00024
[epoch  92:  80/307] 	 train loss: 0.312614 	 lr: 0.00024
[epoch  92: 100/307] 	 train loss: 0.111839 	 lr: 0.00024
[epoch  92: 120/307] 	 train loss: 0.057929 	 lr: 0.00024

val loss: 0.342789 	 acc: 0.904781

[epoch  92: 140/307] 	 train loss: 0.249801 	 lr: 0.00024
[epoch  92: 160/307] 	 train loss: 0.408670 	 lr: 0.00024
[epoch  92: 180/307] 	 train loss: 0.059661 	 lr: 0.00024
[epoch  92: 200/307] 	 train loss: 0.188853 	 lr: 0.00024
[epoch  92: 220/307] 	 train loss: 0.128025 	 lr: 0.00024
[epoch  92: 240/307] 	 train loss: 0.250954 	 lr: 0.00024
[epoch  92: 260/307] 	 train loss: 0.141355 	 lr: 0.00024

val loss: 0.332785 	 acc: 0.903160

[epoch  92: 280/307] 	 train loss: 0.097732 	 lr: 0.00024
[epoch  92: 300/307] 	 train loss: 0.166764 	 lr: 0.00024
[epoch  93:   0/307] 	 train loss: 0.187526 	 lr: 0.00024
[epoch  93:  20/307] 	 train loss: 0.070344 	 lr: 0.00024
[epoch  93:  40/307] 	 train loss: 0.162953 	 lr: 0.00024
[epoch  93:  60/307] 	 train loss: 0.266879 	 lr: 0.00024
[epoch  93:  80/307] 	 train loss: 0.338404 	 lr: 0.00024
[epoch  93: 100/307] 	 train loss: 0.183536 	 lr: 0.00024
[epoch  93: 120/307] 	 train loss: 0.096638 	 lr: 0.00024

val loss: 0.362672 	 acc: 0.906807

[epoch  93: 140/307] 	 train loss: 0.280538 	 lr: 0.00024
[epoch  93: 160/307] 	 train loss: 0.060550 	 lr: 0.00024
[epoch  93: 180/307] 	 train loss: 0.113469 	 lr: 0.00024
[epoch  93: 200/307] 	 train loss: 0.151508 	 lr: 0.00024
[epoch  93: 220/307] 	 train loss: 0.237030 	 lr: 0.00024
[epoch  93: 240/307] 	 train loss: 0.104613 	 lr: 0.00024
[epoch  93: 260/307] 	 train loss: 0.123798 	 lr: 0.00024

val loss: 0.324602 	 acc: 0.905592

[epoch  93: 280/307] 	 train loss: 0.194641 	 lr: 0.00024
[epoch  93: 300/307] 	 train loss: 0.195954 	 lr: 0.00024
[epoch  94:   0/307] 	 train loss: 0.171667 	 lr: 0.00024
[epoch  94:  20/307] 	 train loss: 0.086751 	 lr: 0.00024
[epoch  94:  40/307] 	 train loss: 0.166572 	 lr: 0.00024
[epoch  94:  60/307] 	 train loss: 0.021177 	 lr: 0.00024
[epoch  94:  80/307] 	 train loss: 0.169094 	 lr: 0.00024
[epoch  94: 100/307] 	 train loss: 0.105623 	 lr: 0.00024

val loss: 0.363800 	 acc: 0.904376

[epoch  94: 120/307] 	 train loss: 0.234562 	 lr: 0.00024
[epoch  94: 140/307] 	 train loss: 0.221466 	 lr: 0.00024
[epoch  94: 160/307] 	 train loss: 0.137258 	 lr: 0.00024
[epoch  94: 180/307] 	 train loss: 0.118710 	 lr: 0.00024
[epoch  94: 200/307] 	 train loss: 0.219757 	 lr: 0.00024
[epoch  94: 220/307] 	 train loss: 0.162580 	 lr: 0.00024
[epoch  94: 240/307] 	 train loss: 0.200200 	 lr: 0.00024
[epoch  94: 260/307] 	 train loss: 0.079256 	 lr: 0.00024

val loss: 0.349898 	 acc: 0.907618

[epoch  94: 280/307] 	 train loss: 0.261122 	 lr: 0.00024
[epoch  94: 300/307] 	 train loss: 0.201330 	 lr: 0.00024
[epoch  95:   0/307] 	 train loss: 0.249759 	 lr: 0.00024
[epoch  95:  20/307] 	 train loss: 0.161228 	 lr: 0.00024
[epoch  95:  40/307] 	 train loss: 0.077132 	 lr: 0.00024
[epoch  95:  60/307] 	 train loss: 0.120900 	 lr: 0.00024
[epoch  95:  80/307] 	 train loss: 0.306261 	 lr: 0.00024
[epoch  95: 100/307] 	 train loss: 0.191396 	 lr: 0.00024

val loss: 0.356449 	 acc: 0.907212

[epoch  95: 120/307] 	 train loss: 0.076941 	 lr: 0.00024
[epoch  95: 140/307] 	 train loss: 0.268262 	 lr: 0.00024
[epoch  95: 160/307] 	 train loss: 0.120421 	 lr: 0.00024
[epoch  95: 180/307] 	 train loss: 0.025530 	 lr: 0.00024
[epoch  95: 200/307] 	 train loss: 0.098567 	 lr: 0.00024
[epoch  95: 220/307] 	 train loss: 0.088655 	 lr: 0.00024
[epoch  95: 240/307] 	 train loss: 0.091148 	 lr: 0.00024
[epoch  95: 260/307] 	 train loss: 0.128791 	 lr: 0.00024

val loss: 0.328046 	 acc: 0.912480

[epoch  95: 280/307] 	 train loss: 0.059826 	 lr: 0.00024
[epoch  95: 300/307] 	 train loss: 0.132524 	 lr: 0.00024
[epoch  96:   0/307] 	 train loss: 0.173004 	 lr: 0.00024
[epoch  96:  20/307] 	 train loss: 0.133232 	 lr: 0.00024
[epoch  96:  40/307] 	 train loss: 0.162667 	 lr: 0.00024
[epoch  96:  60/307] 	 train loss: 0.345729 	 lr: 0.00024
[epoch  96:  80/307] 	 train loss: 0.076064 	 lr: 0.00024
[epoch  96: 100/307] 	 train loss: 0.149748 	 lr: 0.00024

val loss: 0.375776 	 acc: 0.906402

[epoch  96: 120/307] 	 train loss: 0.317225 	 lr: 0.00024
[epoch  96: 140/307] 	 train loss: 0.171012 	 lr: 0.00024
[epoch  96: 160/307] 	 train loss: 0.249521 	 lr: 0.00024
[epoch  96: 180/307] 	 train loss: 0.370404 	 lr: 0.00024
[epoch  96: 200/307] 	 train loss: 0.221100 	 lr: 0.00024
[epoch  96: 220/307] 	 train loss: 0.289131 	 lr: 0.00024
[epoch  96: 240/307] 	 train loss: 0.119945 	 lr: 0.00024
[epoch  96: 260/307] 	 train loss: 0.028297 	 lr: 0.00024

val loss: 0.344255 	 acc: 0.906402

[epoch  96: 280/307] 	 train loss: 0.407220 	 lr: 0.00024
[epoch  96: 300/307] 	 train loss: 0.141817 	 lr: 0.00024
[epoch  97:   0/307] 	 train loss: 0.167754 	 lr: 0.00024
[epoch  97:  20/307] 	 train loss: 0.261059 	 lr: 0.00024
[epoch  97:  40/307] 	 train loss: 0.111450 	 lr: 0.00024
[epoch  97:  60/307] 	 train loss: 0.317111 	 lr: 0.00024
[epoch  97:  80/307] 	 train loss: 0.140424 	 lr: 0.00024
[epoch  97: 100/307] 	 train loss: 0.053765 	 lr: 0.00024

val loss: 0.360233 	 acc: 0.908428

[epoch  97: 120/307] 	 train loss: 0.138969 	 lr: 0.00024
[epoch  97: 140/307] 	 train loss: 0.067603 	 lr: 0.00024
[epoch  97: 160/307] 	 train loss: 0.128469 	 lr: 0.00024
[epoch  97: 180/307] 	 train loss: 0.291298 	 lr: 0.00024
[epoch  97: 200/307] 	 train loss: 0.026651 	 lr: 0.00024
[epoch  97: 220/307] 	 train loss: 0.197582 	 lr: 0.00024
[epoch  97: 240/307] 	 train loss: 0.220342 	 lr: 0.00024
[epoch  97: 260/307] 	 train loss: 0.066609 	 lr: 0.00024

val loss: 0.337622 	 acc: 0.914506

[epoch  97: 280/307] 	 train loss: 0.160354 	 lr: 0.00024
[epoch  97: 300/307] 	 train loss: 0.438676 	 lr: 0.00024
[epoch  98:   0/307] 	 train loss: 0.126716 	 lr: 0.00024
[epoch  98:  20/307] 	 train loss: 0.157618 	 lr: 0.00024
[epoch  98:  40/307] 	 train loss: 0.134706 	 lr: 0.00024
[epoch  98:  60/307] 	 train loss: 0.050347 	 lr: 0.00024
[epoch  98:  80/307] 	 train loss: 0.351529 	 lr: 0.00024
[epoch  98: 100/307] 	 train loss: 0.063976 	 lr: 0.00024

val loss: 0.352360 	 acc: 0.910859

[epoch  98: 120/307] 	 train loss: 0.030417 	 lr: 0.00024
[epoch  98: 140/307] 	 train loss: 0.282259 	 lr: 0.00024
[epoch  98: 160/307] 	 train loss: 0.136640 	 lr: 0.00024
[epoch  98: 180/307] 	 train loss: 0.169441 	 lr: 0.00024
[epoch  98: 200/307] 	 train loss: 0.253573 	 lr: 0.00024
[epoch  98: 220/307] 	 train loss: 0.131758 	 lr: 0.00024
[epoch  98: 240/307] 	 train loss: 0.131775 	 lr: 0.00024
[epoch  98: 260/307] 	 train loss: 0.153741 	 lr: 0.00024

val loss: 0.350468 	 acc: 0.909643

[epoch  98: 280/307] 	 train loss: 0.063477 	 lr: 0.00024
[epoch  98: 300/307] 	 train loss: 0.091153 	 lr: 0.00024
[epoch  99:   0/307] 	 train loss: 0.206925 	 lr: 0.00024
[epoch  99:  20/307] 	 train loss: 0.307722 	 lr: 0.00024
[epoch  99:  40/307] 	 train loss: 0.100838 	 lr: 0.00024
[epoch  99:  60/307] 	 train loss: 0.094351 	 lr: 0.00024
[epoch  99:  80/307] 	 train loss: 0.225388 	 lr: 0.00024
[epoch  99: 100/307] 	 train loss: 0.271517 	 lr: 0.00024

val loss: 0.323792 	 acc: 0.913695

[epoch  99: 120/307] 	 train loss: 0.064137 	 lr: 0.00024
[epoch  99: 140/307] 	 train loss: 0.216659 	 lr: 0.00024
[epoch  99: 160/307] 	 train loss: 0.072520 	 lr: 0.00024
[epoch  99: 180/307] 	 train loss: 0.082463 	 lr: 0.00024
[epoch  99: 200/307] 	 train loss: 0.203656 	 lr: 0.00024
[epoch  99: 220/307] 	 train loss: 0.055234 	 lr: 0.00024
[epoch  99: 240/307] 	 train loss: 0.253210 	 lr: 0.00024
[epoch  99: 260/307] 	 train loss: 0.146371 	 lr: 0.00024

val loss: 0.344413 	 acc: 0.910859

[epoch  99: 280/307] 	 train loss: 0.015758 	 lr: 0.00024
[epoch  99: 300/307] 	 train loss: 0.246410 	 lr: 0.00024
[epoch 100:   0/307] 	 train loss: 0.211373 	 lr: 0.00024
[epoch 100:  20/307] 	 train loss: 0.038323 	 lr: 0.00024
[epoch 100:  40/307] 	 train loss: 0.109328 	 lr: 0.00024
[epoch 100:  60/307] 	 train loss: 0.259116 	 lr: 0.00024
[epoch 100:  80/307] 	 train loss: 0.025912 	 lr: 0.00024
[epoch 100: 100/307] 	 train loss: 0.214636 	 lr: 0.00024

val loss: 0.349043 	 acc: 0.914506

[epoch 100: 120/307] 	 train loss: 0.416601 	 lr: 0.00024
[epoch 100: 140/307] 	 train loss: 0.293668 	 lr: 0.00024
[epoch 100: 160/307] 	 train loss: 0.333926 	 lr: 0.00024
[epoch 100: 180/307] 	 train loss: 0.139789 	 lr: 0.00024
[epoch 100: 200/307] 	 train loss: 0.191164 	 lr: 0.00024
[epoch 100: 220/307] 	 train loss: 0.082259 	 lr: 0.00024
[epoch 100: 240/307] 	 train loss: 0.476381 	 lr: 0.00024
[epoch 100: 260/307] 	 train loss: 0.135927 	 lr: 0.00024

val loss: 0.348819 	 acc: 0.913695

[epoch 100: 280/307] 	 train loss: 0.570461 	 lr: 0.00024
[epoch 100: 300/307] 	 train loss: 0.091796 	 lr: 0.00024
[epoch 101:   0/307] 	 train loss: 0.250658 	 lr: 0.00024
[epoch 101:  20/307] 	 train loss: 0.198359 	 lr: 0.00024
[epoch 101:  40/307] 	 train loss: 0.121034 	 lr: 0.00024
[epoch 101:  60/307] 	 train loss: 0.107186 	 lr: 0.00024
[epoch 101:  80/307] 	 train loss: 0.296200 	 lr: 0.00024
[epoch 101: 100/307] 	 train loss: 0.065046 	 lr: 0.00024

val loss: 0.337391 	 acc: 0.912885

[epoch 101: 120/307] 	 train loss: 0.180704 	 lr: 0.00024
[epoch 101: 140/307] 	 train loss: 0.067257 	 lr: 0.00024
[epoch 101: 160/307] 	 train loss: 0.110674 	 lr: 0.00024
[epoch 101: 180/307] 	 train loss: 0.185662 	 lr: 0.00024
[epoch 101: 200/307] 	 train loss: 0.128995 	 lr: 0.00024
[epoch 101: 220/307] 	 train loss: 0.050790 	 lr: 0.00024
[epoch 101: 240/307] 	 train loss: 0.197430 	 lr: 0.00024

val loss: 0.342831 	 acc: 0.914100

[epoch 101: 260/307] 	 train loss: 0.120544 	 lr: 0.00024
[epoch 101: 280/307] 	 train loss: 0.195201 	 lr: 0.00024
[epoch 101: 300/307] 	 train loss: 0.163026 	 lr: 0.00024
[epoch 102:   0/307] 	 train loss: 0.057151 	 lr: 0.00024
[epoch 102:  20/307] 	 train loss: 0.111542 	 lr: 0.00024
[epoch 102:  40/307] 	 train loss: 0.183666 	 lr: 0.00024
[epoch 102:  60/307] 	 train loss: 0.210095 	 lr: 0.00024
[epoch 102:  80/307] 	 train loss: 0.029087 	 lr: 0.00024
[epoch 102: 100/307] 	 train loss: 0.268101 	 lr: 0.00024

val loss: 0.344290 	 acc: 0.905997

[epoch 102: 120/307] 	 train loss: 0.049298 	 lr: 0.00024
[epoch 102: 140/307] 	 train loss: 0.101996 	 lr: 0.00024
[epoch 102: 160/307] 	 train loss: 0.165884 	 lr: 0.00024
[epoch 102: 180/307] 	 train loss: 0.179796 	 lr: 0.00024
[epoch 102: 200/307] 	 train loss: 0.086973 	 lr: 0.00024
[epoch 102: 220/307] 	 train loss: 0.184278 	 lr: 0.00024
[epoch 102: 240/307] 	 train loss: 0.130569 	 lr: 0.00024

val loss: 0.344243 	 acc: 0.908023

[epoch 102: 260/307] 	 train loss: 0.105926 	 lr: 0.00024
[epoch 102: 280/307] 	 train loss: 0.114959 	 lr: 0.00024
[epoch 102: 300/307] 	 train loss: 0.208545 	 lr: 0.00024
[epoch 103:   0/307] 	 train loss: 0.151269 	 lr: 0.00024
[epoch 103:  20/307] 	 train loss: 0.278062 	 lr: 0.00024
[epoch 103:  40/307] 	 train loss: 0.329694 	 lr: 0.00024
[epoch 103:  60/307] 	 train loss: 0.227403 	 lr: 0.00024
[epoch 103:  80/307] 	 train loss: 0.192195 	 lr: 0.00024
[epoch 103: 100/307] 	 train loss: 0.225413 	 lr: 0.00024

val loss: 0.355345 	 acc: 0.909238

[epoch 103: 120/307] 	 train loss: 0.241529 	 lr: 0.00024
[epoch 103: 140/307] 	 train loss: 0.218930 	 lr: 0.00024
[epoch 103: 160/307] 	 train loss: 0.046148 	 lr: 0.00024
[epoch 103: 180/307] 	 train loss: 0.251172 	 lr: 0.00024
[epoch 103: 200/307] 	 train loss: 0.028565 	 lr: 0.00024
[epoch 103: 220/307] 	 train loss: 0.134150 	 lr: 0.00024
[epoch 103: 240/307] 	 train loss: 0.236423 	 lr: 0.00024

val loss: 0.341042 	 acc: 0.912075

[epoch 103: 260/307] 	 train loss: 0.090114 	 lr: 0.00024
[epoch 103: 280/307] 	 train loss: 0.260924 	 lr: 0.00024
[epoch 103: 300/307] 	 train loss: 0.116394 	 lr: 0.00024
[epoch 104:   0/307] 	 train loss: 0.319328 	 lr: 0.00024
[epoch 104:  20/307] 	 train loss: 0.071571 	 lr: 0.00024
[epoch 104:  40/307] 	 train loss: 0.065612 	 lr: 0.00024
[epoch 104:  60/307] 	 train loss: 0.221049 	 lr: 0.00024
[epoch 104:  80/307] 	 train loss: 0.083990 	 lr: 0.00024

val loss: 0.345087 	 acc: 0.915316

[epoch 104: 100/307] 	 train loss: 0.164863 	 lr: 0.00024
[epoch 104: 120/307] 	 train loss: 0.014375 	 lr: 0.00024
[epoch 104: 140/307] 	 train loss: 0.250147 	 lr: 0.00024
[epoch 104: 160/307] 	 train loss: 0.374741 	 lr: 0.00024
[epoch 104: 180/307] 	 train loss: 0.105448 	 lr: 0.00024
[epoch 104: 200/307] 	 train loss: 0.124620 	 lr: 0.00024
[epoch 104: 220/307] 	 train loss: 0.239178 	 lr: 0.00024
[epoch 104: 240/307] 	 train loss: 0.158296 	 lr: 0.00024

val loss: 0.333422 	 acc: 0.911264

[epoch 104: 260/307] 	 train loss: 0.217406 	 lr: 0.00024
[epoch 104: 280/307] 	 train loss: 0.284475 	 lr: 0.00024
[epoch 104: 300/307] 	 train loss: 0.238964 	 lr: 0.00024
[epoch 105:   0/307] 	 train loss: 0.169902 	 lr: 0.00024
[epoch 105:  20/307] 	 train loss: 0.094109 	 lr: 0.00024
[epoch 105:  40/307] 	 train loss: 0.061335 	 lr: 0.00024
[epoch 105:  60/307] 	 train loss: 0.115743 	 lr: 0.00024
[epoch 105:  80/307] 	 train loss: 0.272667 	 lr: 0.00024

val loss: 0.339943 	 acc: 0.911264

[epoch 105: 100/307] 	 train loss: 0.114097 	 lr: 0.00024
[epoch 105: 120/307] 	 train loss: 0.035770 	 lr: 0.00024
[epoch 105: 140/307] 	 train loss: 0.075021 	 lr: 0.00024
[epoch 105: 160/307] 	 train loss: 0.053627 	 lr: 0.00024
[epoch 105: 180/307] 	 train loss: 0.209757 	 lr: 0.00024
[epoch 105: 200/307] 	 train loss: 0.118534 	 lr: 0.00024
[epoch 105: 220/307] 	 train loss: 0.044162 	 lr: 0.00024
[epoch 105: 240/307] 	 train loss: 0.212493 	 lr: 0.00024

val loss: 0.327129 	 acc: 0.911264

[epoch 105: 260/307] 	 train loss: 0.204980 	 lr: 0.00024
[epoch 105: 280/307] 	 train loss: 0.104178 	 lr: 0.00024
[epoch 105: 300/307] 	 train loss: 0.313330 	 lr: 0.00024
[epoch 106:   0/307] 	 train loss: 0.053827 	 lr: 0.00017
[epoch 106:  20/307] 	 train loss: 0.067234 	 lr: 0.00017
[epoch 106:  40/307] 	 train loss: 0.057014 	 lr: 0.00017
[epoch 106:  60/307] 	 train loss: 0.380790 	 lr: 0.00017
[epoch 106:  80/307] 	 train loss: 0.146149 	 lr: 0.00017

val loss: 0.348723 	 acc: 0.913290

[epoch 106: 100/307] 	 train loss: 0.239715 	 lr: 0.00017
[epoch 106: 120/307] 	 train loss: 0.040146 	 lr: 0.00017
[epoch 106: 140/307] 	 train loss: 0.061941 	 lr: 0.00017
[epoch 106: 160/307] 	 train loss: 0.034782 	 lr: 0.00017
[epoch 106: 180/307] 	 train loss: 0.137599 	 lr: 0.00017
[epoch 106: 200/307] 	 train loss: 0.231399 	 lr: 0.00017
[epoch 106: 220/307] 	 train loss: 0.285849 	 lr: 0.00017
[epoch 106: 240/307] 	 train loss: 0.071214 	 lr: 0.00017

val loss: 0.308014 	 acc: 0.915316

[epoch 106: 260/307] 	 train loss: 0.224444 	 lr: 0.00017
[epoch 106: 280/307] 	 train loss: 0.115944 	 lr: 0.00017
[epoch 106: 300/307] 	 train loss: 0.279349 	 lr: 0.00017
[epoch 107:   0/307] 	 train loss: 0.265287 	 lr: 0.00017
[epoch 107:  20/307] 	 train loss: 0.242914 	 lr: 0.00017
[epoch 107:  40/307] 	 train loss: 0.077434 	 lr: 0.00017
[epoch 107:  60/307] 	 train loss: 0.189364 	 lr: 0.00017
[epoch 107:  80/307] 	 train loss: 0.440182 	 lr: 0.00017

val loss: 0.372179 	 acc: 0.909238

[epoch 107: 100/307] 	 train loss: 0.134350 	 lr: 0.00017
[epoch 107: 120/307] 	 train loss: 0.184289 	 lr: 0.00017
[epoch 107: 140/307] 	 train loss: 0.137630 	 lr: 0.00017
[epoch 107: 160/307] 	 train loss: 0.066565 	 lr: 0.00017
[epoch 107: 180/307] 	 train loss: 0.111498 	 lr: 0.00017
[epoch 107: 200/307] 	 train loss: 0.135040 	 lr: 0.00017
[epoch 107: 220/307] 	 train loss: 0.157438 	 lr: 0.00017
[epoch 107: 240/307] 	 train loss: 0.326056 	 lr: 0.00017

val loss: 0.334395 	 acc: 0.910049

[epoch 107: 260/307] 	 train loss: 0.178122 	 lr: 0.00017
[epoch 107: 280/307] 	 train loss: 0.183396 	 lr: 0.00017
[epoch 107: 300/307] 	 train loss: 0.117078 	 lr: 0.00017
[epoch 108:   0/307] 	 train loss: 0.228794 	 lr: 0.00017
[epoch 108:  20/307] 	 train loss: 0.126084 	 lr: 0.00017
[epoch 108:  40/307] 	 train loss: 0.086533 	 lr: 0.00017
[epoch 108:  60/307] 	 train loss: 0.117311 	 lr: 0.00017
[epoch 108:  80/307] 	 train loss: 0.113393 	 lr: 0.00017

val loss: 0.331642 	 acc: 0.910049

[epoch 108: 100/307] 	 train loss: 0.125521 	 lr: 0.00017
[epoch 108: 120/307] 	 train loss: 0.108013 	 lr: 0.00017
[epoch 108: 140/307] 	 train loss: 0.252381 	 lr: 0.00017
[epoch 108: 160/307] 	 train loss: 0.084030 	 lr: 0.00017
[epoch 108: 180/307] 	 train loss: 0.102353 	 lr: 0.00017
[epoch 108: 200/307] 	 train loss: 0.184168 	 lr: 0.00017
[epoch 108: 220/307] 	 train loss: 0.269567 	 lr: 0.00017
[epoch 108: 240/307] 	 train loss: 0.102715 	 lr: 0.00017

val loss: 0.334239 	 acc: 0.912885

[epoch 108: 260/307] 	 train loss: 0.052946 	 lr: 0.00017
[epoch 108: 280/307] 	 train loss: 0.086424 	 lr: 0.00017
[epoch 108: 300/307] 	 train loss: 0.045227 	 lr: 0.00017
[epoch 109:   0/307] 	 train loss: 0.274245 	 lr: 0.00017
[epoch 109:  20/307] 	 train loss: 0.128730 	 lr: 0.00017
[epoch 109:  40/307] 	 train loss: 0.124309 	 lr: 0.00017
[epoch 109:  60/307] 	 train loss: 0.028556 	 lr: 0.00017
[epoch 109:  80/307] 	 train loss: 0.176413 	 lr: 0.00017

val loss: 0.334066 	 acc: 0.913290

[epoch 109: 100/307] 	 train loss: 0.216077 	 lr: 0.00017
[epoch 109: 120/307] 	 train loss: 0.439657 	 lr: 0.00017
[epoch 109: 140/307] 	 train loss: 0.092675 	 lr: 0.00017
[epoch 109: 160/307] 	 train loss: 0.051058 	 lr: 0.00017
[epoch 109: 180/307] 	 train loss: 0.202977 	 lr: 0.00017
[epoch 109: 200/307] 	 train loss: 0.037713 	 lr: 0.00017
[epoch 109: 220/307] 	 train loss: 0.025022 	 lr: 0.00017
[epoch 109: 240/307] 	 train loss: 0.164945 	 lr: 0.00017

val loss: 0.334989 	 acc: 0.908428

[epoch 109: 260/307] 	 train loss: 0.291758 	 lr: 0.00017
[epoch 109: 280/307] 	 train loss: 0.197481 	 lr: 0.00017
[epoch 109: 300/307] 	 train loss: 0.142372 	 lr: 0.00017
[epoch 110:   0/307] 	 train loss: 0.057901 	 lr: 0.00017
[epoch 110:  20/307] 	 train loss: 0.382540 	 lr: 0.00017
[epoch 110:  40/307] 	 train loss: 0.081765 	 lr: 0.00017
[epoch 110:  60/307] 	 train loss: 0.228649 	 lr: 0.00017
[epoch 110:  80/307] 	 train loss: 0.091818 	 lr: 0.00017

val loss: 0.324844 	 acc: 0.916937

saved model with accuracy  0.916936790923825
[epoch 110: 100/307] 	 train loss: 0.279310 	 lr: 0.00017
[epoch 110: 120/307] 	 train loss: 0.077450 	 lr: 0.00017
[epoch 110: 140/307] 	 train loss: 0.164787 	 lr: 0.00017
[epoch 110: 160/307] 	 train loss: 0.077307 	 lr: 0.00017
[epoch 110: 180/307] 	 train loss: 0.341247 	 lr: 0.00017
[epoch 110: 200/307] 	 train loss: 0.044131 	 lr: 0.00017
[epoch 110: 220/307] 	 train loss: 0.047320 	 lr: 0.00017
[epoch 110: 240/307] 	 train loss: 0.064280 	 lr: 0.00017

val loss: 0.346416 	 acc: 0.913290

[epoch 110: 260/307] 	 train loss: 0.053844 	 lr: 0.00017
[epoch 110: 280/307] 	 train loss: 0.010449 	 lr: 0.00017
[epoch 110: 300/307] 	 train loss: 0.115612 	 lr: 0.00017
[epoch 111:   0/307] 	 train loss: 0.283368 	 lr: 0.00017
[epoch 111:  20/307] 	 train loss: 0.031063 	 lr: 0.00017
[epoch 111:  40/307] 	 train loss: 0.087230 	 lr: 0.00017
[epoch 111:  60/307] 	 train loss: 0.080503 	 lr: 0.00017
[epoch 111:  80/307] 	 train loss: 0.083809 	 lr: 0.00017

val loss: 0.331365 	 acc: 0.915721

[epoch 111: 100/307] 	 train loss: 0.164111 	 lr: 0.00017
[epoch 111: 120/307] 	 train loss: 0.254668 	 lr: 0.00017
[epoch 111: 140/307] 	 train loss: 0.095898 	 lr: 0.00017
[epoch 111: 160/307] 	 train loss: 0.042910 	 lr: 0.00017
[epoch 111: 180/307] 	 train loss: 0.390492 	 lr: 0.00017
[epoch 111: 200/307] 	 train loss: 0.246760 	 lr: 0.00017
[epoch 111: 220/307] 	 train loss: 0.116080 	 lr: 0.00017

val loss: 0.350444 	 acc: 0.912075

[epoch 111: 240/307] 	 train loss: 0.097127 	 lr: 0.00017
[epoch 111: 260/307] 	 train loss: 0.056736 	 lr: 0.00017
[epoch 111: 280/307] 	 train loss: 0.110781 	 lr: 0.00017
[epoch 111: 300/307] 	 train loss: 0.256935 	 lr: 0.00017
[epoch 112:   0/307] 	 train loss: 0.062699 	 lr: 0.00017
[epoch 112:  20/307] 	 train loss: 0.062650 	 lr: 0.00017
[epoch 112:  40/307] 	 train loss: 0.175260 	 lr: 0.00017
[epoch 112:  60/307] 	 train loss: 0.104797 	 lr: 0.00017
[epoch 112:  80/307] 	 train loss: 0.123957 	 lr: 0.00017

val loss: 0.331849 	 acc: 0.912480

[epoch 112: 100/307] 	 train loss: 0.057957 	 lr: 0.00017
[epoch 112: 120/307] 	 train loss: 0.132266 	 lr: 0.00017
[epoch 112: 140/307] 	 train loss: 0.333324 	 lr: 0.00017
[epoch 112: 160/307] 	 train loss: 0.101574 	 lr: 0.00017
[epoch 112: 180/307] 	 train loss: 0.208526 	 lr: 0.00017
[epoch 112: 200/307] 	 train loss: 0.086139 	 lr: 0.00017
[epoch 112: 220/307] 	 train loss: 0.340394 	 lr: 0.00017

val loss: 0.330853 	 acc: 0.910859

[epoch 112: 240/307] 	 train loss: 0.145179 	 lr: 0.00017
[epoch 112: 260/307] 	 train loss: 0.140906 	 lr: 0.00017
[epoch 112: 280/307] 	 train loss: 0.055695 	 lr: 0.00017
[epoch 112: 300/307] 	 train loss: 0.091679 	 lr: 0.00017
[epoch 113:   0/307] 	 train loss: 0.112558 	 lr: 0.00017
[epoch 113:  20/307] 	 train loss: 0.408876 	 lr: 0.00017
[epoch 113:  40/307] 	 train loss: 0.088490 	 lr: 0.00017
[epoch 113:  60/307] 	 train loss: 0.324625 	 lr: 0.00017
[epoch 113:  80/307] 	 train loss: 0.095893 	 lr: 0.00017

val loss: 0.355700 	 acc: 0.907212

[epoch 113: 100/307] 	 train loss: 0.082120 	 lr: 0.00017
[epoch 113: 120/307] 	 train loss: 0.076430 	 lr: 0.00017
[epoch 113: 140/307] 	 train loss: 0.026782 	 lr: 0.00017
[epoch 113: 160/307] 	 train loss: 0.081822 	 lr: 0.00017
[epoch 113: 180/307] 	 train loss: 0.149673 	 lr: 0.00017
[epoch 113: 200/307] 	 train loss: 0.046534 	 lr: 0.00017
[epoch 113: 220/307] 	 train loss: 0.130801 	 lr: 0.00017

val loss: 0.333704 	 acc: 0.908428

[epoch 113: 240/307] 	 train loss: 0.103615 	 lr: 0.00017
[epoch 113: 260/307] 	 train loss: 0.046377 	 lr: 0.00017
[epoch 113: 280/307] 	 train loss: 0.071617 	 lr: 0.00017
[epoch 113: 300/307] 	 train loss: 0.200611 	 lr: 0.00017
[epoch 114:   0/307] 	 train loss: 0.434125 	 lr: 0.00017
[epoch 114:  20/307] 	 train loss: 0.125432 	 lr: 0.00017
[epoch 114:  40/307] 	 train loss: 0.067953 	 lr: 0.00017
[epoch 114:  60/307] 	 train loss: 0.077275 	 lr: 0.00017

val loss: 0.324237 	 acc: 0.911669

[epoch 114:  80/307] 	 train loss: 0.047744 	 lr: 0.00017
[epoch 114: 100/307] 	 train loss: 0.042044 	 lr: 0.00017
[epoch 114: 120/307] 	 train loss: 0.057905 	 lr: 0.00017
[epoch 114: 140/307] 	 train loss: 0.140498 	 lr: 0.00017
[epoch 114: 160/307] 	 train loss: 0.025085 	 lr: 0.00017
[epoch 114: 180/307] 	 train loss: 0.077024 	 lr: 0.00017
[epoch 114: 200/307] 	 train loss: 0.160732 	 lr: 0.00017
[epoch 114: 220/307] 	 train loss: 0.104779 	 lr: 0.00017

val loss: 0.342469 	 acc: 0.911264

[epoch 114: 240/307] 	 train loss: 0.116613 	 lr: 0.00017
[epoch 114: 260/307] 	 train loss: 0.360785 	 lr: 0.00017
[epoch 114: 280/307] 	 train loss: 0.174408 	 lr: 0.00017
[epoch 114: 300/307] 	 train loss: 0.160153 	 lr: 0.00017
[epoch 115:   0/307] 	 train loss: 0.293605 	 lr: 0.00017
[epoch 115:  20/307] 	 train loss: 0.095627 	 lr: 0.00017
[epoch 115:  40/307] 	 train loss: 0.265805 	 lr: 0.00017
[epoch 115:  60/307] 	 train loss: 0.165110 	 lr: 0.00017

val loss: 0.361877 	 acc: 0.909238

[epoch 115:  80/307] 	 train loss: 0.209378 	 lr: 0.00017
[epoch 115: 100/307] 	 train loss: 0.256246 	 lr: 0.00017
[epoch 115: 120/307] 	 train loss: 0.223247 	 lr: 0.00017
[epoch 115: 140/307] 	 train loss: 0.192098 	 lr: 0.00017
[epoch 115: 160/307] 	 train loss: 0.216263 	 lr: 0.00017
[epoch 115: 180/307] 	 train loss: 0.130591 	 lr: 0.00017
[epoch 115: 200/307] 	 train loss: 0.180158 	 lr: 0.00017
[epoch 115: 220/307] 	 train loss: 0.326379 	 lr: 0.00017

val loss: 0.340550 	 acc: 0.910049

[epoch 115: 240/307] 	 train loss: 0.309467 	 lr: 0.00017
[epoch 115: 260/307] 	 train loss: 0.198428 	 lr: 0.00017
[epoch 115: 280/307] 	 train loss: 0.020492 	 lr: 0.00017
[epoch 115: 300/307] 	 train loss: 0.028389 	 lr: 0.00017
[epoch 116:   0/307] 	 train loss: 0.125434 	 lr: 0.00017
[epoch 116:  20/307] 	 train loss: 0.184715 	 lr: 0.00017
[epoch 116:  40/307] 	 train loss: 0.250011 	 lr: 0.00017
[epoch 116:  60/307] 	 train loss: 0.233293 	 lr: 0.00017

val loss: 0.341822 	 acc: 0.909643

[epoch 116:  80/307] 	 train loss: 0.244482 	 lr: 0.00017
[epoch 116: 100/307] 	 train loss: 0.258603 	 lr: 0.00017
[epoch 116: 120/307] 	 train loss: 0.121815 	 lr: 0.00017
[epoch 116: 140/307] 	 train loss: 0.239489 	 lr: 0.00017
[epoch 116: 160/307] 	 train loss: 0.186821 	 lr: 0.00017
[epoch 116: 180/307] 	 train loss: 0.727158 	 lr: 0.00017
[epoch 116: 200/307] 	 train loss: 0.309841 	 lr: 0.00017
[epoch 116: 220/307] 	 train loss: 0.206773 	 lr: 0.00017

val loss: 0.318777 	 acc: 0.910859

[epoch 116: 240/307] 	 train loss: 0.175699 	 lr: 0.00017
[epoch 116: 260/307] 	 train loss: 0.447809 	 lr: 0.00017
[epoch 116: 280/307] 	 train loss: 0.159142 	 lr: 0.00017
[epoch 116: 300/307] 	 train loss: 0.066453 	 lr: 0.00017
[epoch 117:   0/307] 	 train loss: 0.044221 	 lr: 0.00017
[epoch 117:  20/307] 	 train loss: 0.201583 	 lr: 0.00017
[epoch 117:  40/307] 	 train loss: 0.051856 	 lr: 0.00017
[epoch 117:  60/307] 	 train loss: 0.246621 	 lr: 0.00017

val loss: 0.359237 	 acc: 0.908428

[epoch 117:  80/307] 	 train loss: 0.074111 	 lr: 0.00017
[epoch 117: 100/307] 	 train loss: 0.083973 	 lr: 0.00017
[epoch 117: 120/307] 	 train loss: 0.160554 	 lr: 0.00017
[epoch 117: 140/307] 	 train loss: 0.045514 	 lr: 0.00017
[epoch 117: 160/307] 	 train loss: 0.128828 	 lr: 0.00017
[epoch 117: 180/307] 	 train loss: 0.053534 	 lr: 0.00017
[epoch 117: 200/307] 	 train loss: 0.098599 	 lr: 0.00017
[epoch 117: 220/307] 	 train loss: 0.059615 	 lr: 0.00017

val loss: 0.348095 	 acc: 0.907618

[epoch 117: 240/307] 	 train loss: 0.121952 	 lr: 0.00017
[epoch 117: 260/307] 	 train loss: 0.162837 	 lr: 0.00017
[epoch 117: 280/307] 	 train loss: 0.142589 	 lr: 0.00017
[epoch 117: 300/307] 	 train loss: 0.068082 	 lr: 0.00017
[epoch 118:   0/307] 	 train loss: 0.148481 	 lr: 0.00017
[epoch 118:  20/307] 	 train loss: 0.176706 	 lr: 0.00017
[epoch 118:  40/307] 	 train loss: 0.155831 	 lr: 0.00017
[epoch 118:  60/307] 	 train loss: 0.067128 	 lr: 0.00017

val loss: 0.338705 	 acc: 0.908833

[epoch 118:  80/307] 	 train loss: 0.019714 	 lr: 0.00017
[epoch 118: 100/307] 	 train loss: 0.167429 	 lr: 0.00017
[epoch 118: 120/307] 	 train loss: 0.217514 	 lr: 0.00017
[epoch 118: 140/307] 	 train loss: 0.055358 	 lr: 0.00017
[epoch 118: 160/307] 	 train loss: 0.190756 	 lr: 0.00017
[epoch 118: 180/307] 	 train loss: 0.167248 	 lr: 0.00017
[epoch 118: 200/307] 	 train loss: 0.130520 	 lr: 0.00017
[epoch 118: 220/307] 	 train loss: 0.075815 	 lr: 0.00017

val loss: 0.318517 	 acc: 0.915721

[epoch 118: 240/307] 	 train loss: 0.060921 	 lr: 0.00017
[epoch 118: 260/307] 	 train loss: 0.258390 	 lr: 0.00017
[epoch 118: 280/307] 	 train loss: 0.099359 	 lr: 0.00017
[epoch 118: 300/307] 	 train loss: 0.089879 	 lr: 0.00017
[epoch 119:   0/307] 	 train loss: 0.193355 	 lr: 0.00017
[epoch 119:  20/307] 	 train loss: 0.127044 	 lr: 0.00017
[epoch 119:  40/307] 	 train loss: 0.094375 	 lr: 0.00017
[epoch 119:  60/307] 	 train loss: 0.137317 	 lr: 0.00017

val loss: 0.339550 	 acc: 0.913290

[epoch 119:  80/307] 	 train loss: 0.266181 	 lr: 0.00017
[epoch 119: 100/307] 	 train loss: 0.058173 	 lr: 0.00017
[epoch 119: 120/307] 	 train loss: 0.538676 	 lr: 0.00017
[epoch 119: 140/307] 	 train loss: 0.150253 	 lr: 0.00017
[epoch 119: 160/307] 	 train loss: 0.065660 	 lr: 0.00017
[epoch 119: 180/307] 	 train loss: 0.165155 	 lr: 0.00017
[epoch 119: 200/307] 	 train loss: 0.179412 	 lr: 0.00017
[epoch 119: 220/307] 	 train loss: 0.029210 	 lr: 0.00017

val loss: 0.346199 	 acc: 0.912075

[epoch 119: 240/307] 	 train loss: 0.189440 	 lr: 0.00017
[epoch 119: 260/307] 	 train loss: 0.065914 	 lr: 0.00017
[epoch 119: 280/307] 	 train loss: 0.041614 	 lr: 0.00017
[epoch 119: 300/307] 	 train loss: 0.287465 	 lr: 0.00017
[epoch 120:   0/307] 	 train loss: 0.139003 	 lr: 0.00017
[epoch 120:  20/307] 	 train loss: 0.022540 	 lr: 0.00017
[epoch 120:  40/307] 	 train loss: 0.068830 	 lr: 0.00017
[epoch 120:  60/307] 	 train loss: 0.133817 	 lr: 0.00017

val loss: 0.346572 	 acc: 0.910049

[epoch 120:  80/307] 	 train loss: 0.104975 	 lr: 0.00017
[epoch 120: 100/307] 	 train loss: 0.119547 	 lr: 0.00017
[epoch 120: 120/307] 	 train loss: 0.351489 	 lr: 0.00017
[epoch 120: 140/307] 	 train loss: 0.112557 	 lr: 0.00017
[epoch 120: 160/307] 	 train loss: 0.197605 	 lr: 0.00017
[epoch 120: 180/307] 	 train loss: 0.098533 	 lr: 0.00017
[epoch 120: 200/307] 	 train loss: 0.174814 	 lr: 0.00017
[epoch 120: 220/307] 	 train loss: 0.187340 	 lr: 0.00017

val loss: 0.339242 	 acc: 0.909643

[epoch 120: 240/307] 	 train loss: 0.090274 	 lr: 0.00017
[epoch 120: 260/307] 	 train loss: 0.109452 	 lr: 0.00017
[epoch 120: 280/307] 	 train loss: 0.047329 	 lr: 0.00017
[epoch 120: 300/307] 	 train loss: 0.167843 	 lr: 0.00017
[epoch 121:   0/307] 	 train loss: 0.133645 	 lr: 0.00017
[epoch 121:  20/307] 	 train loss: 0.019442 	 lr: 0.00017
[epoch 121:  40/307] 	 train loss: 0.404081 	 lr: 0.00017
[epoch 121:  60/307] 	 train loss: 0.197198 	 lr: 0.00017

val loss: 0.348196 	 acc: 0.908023

[epoch 121:  80/307] 	 train loss: 0.125442 	 lr: 0.00017
[epoch 121: 100/307] 	 train loss: 0.125402 	 lr: 0.00017
[epoch 121: 120/307] 	 train loss: 0.259049 	 lr: 0.00017
[epoch 121: 140/307] 	 train loss: 0.215694 	 lr: 0.00017
[epoch 121: 160/307] 	 train loss: 0.123143 	 lr: 0.00017
[epoch 121: 180/307] 	 train loss: 0.130753 	 lr: 0.00017
[epoch 121: 200/307] 	 train loss: 0.106775 	 lr: 0.00017

val loss: 0.355359 	 acc: 0.910454

[epoch 121: 220/307] 	 train loss: 0.154121 	 lr: 0.00017
[epoch 121: 240/307] 	 train loss: 0.106853 	 lr: 0.00017
[epoch 121: 260/307] 	 train loss: 0.024272 	 lr: 0.00017
[epoch 121: 280/307] 	 train loss: 0.262922 	 lr: 0.00017
[epoch 121: 300/307] 	 train loss: 0.195217 	 lr: 0.00017
[epoch 122:   0/307] 	 train loss: 0.132558 	 lr: 0.00017
[epoch 122:  20/307] 	 train loss: 0.054470 	 lr: 0.00017
[epoch 122:  40/307] 	 train loss: 0.233728 	 lr: 0.00017
[epoch 122:  60/307] 	 train loss: 0.169129 	 lr: 0.00017

val loss: 0.327642 	 acc: 0.914911

[epoch 122:  80/307] 	 train loss: 0.092107 	 lr: 0.00017
[epoch 122: 100/307] 	 train loss: 0.101291 	 lr: 0.00017
[epoch 122: 120/307] 	 train loss: 0.164779 	 lr: 0.00017
[epoch 122: 140/307] 	 train loss: 0.119115 	 lr: 0.00017
[epoch 122: 160/307] 	 train loss: 0.066074 	 lr: 0.00017
[epoch 122: 180/307] 	 train loss: 0.040689 	 lr: 0.00017
[epoch 122: 200/307] 	 train loss: 0.092910 	 lr: 0.00017

val loss: 0.345725 	 acc: 0.907618

[epoch 122: 220/307] 	 train loss: 0.208375 	 lr: 0.00017
[epoch 122: 240/307] 	 train loss: 0.160087 	 lr: 0.00017
[epoch 122: 260/307] 	 train loss: 0.054472 	 lr: 0.00017
[epoch 122: 280/307] 	 train loss: 0.273525 	 lr: 0.00017
[epoch 122: 300/307] 	 train loss: 0.025727 	 lr: 0.00017
[epoch 123:   0/307] 	 train loss: 0.064819 	 lr: 0.00017
[epoch 123:  20/307] 	 train loss: 0.157004 	 lr: 0.00017
[epoch 123:  40/307] 	 train loss: 0.042915 	 lr: 0.00017
[epoch 123:  60/307] 	 train loss: 0.133855 	 lr: 0.00017

val loss: 0.340049 	 acc: 0.911264

[epoch 123:  80/307] 	 train loss: 0.321557 	 lr: 0.00017
[epoch 123: 100/307] 	 train loss: 0.046606 	 lr: 0.00017
[epoch 123: 120/307] 	 train loss: 0.136373 	 lr: 0.00017
[epoch 123: 140/307] 	 train loss: 0.198816 	 lr: 0.00017
[epoch 123: 160/307] 	 train loss: 0.138512 	 lr: 0.00017
[epoch 123: 180/307] 	 train loss: 0.156016 	 lr: 0.00017
[epoch 123: 200/307] 	 train loss: 0.050519 	 lr: 0.00017

val loss: 0.335635 	 acc: 0.916532

[epoch 123: 220/307] 	 train loss: 0.237919 	 lr: 0.00017
[epoch 123: 240/307] 	 train loss: 0.012853 	 lr: 0.00017
[epoch 123: 260/307] 	 train loss: 0.039181 	 lr: 0.00017
[epoch 123: 280/307] 	 train loss: 0.192982 	 lr: 0.00017
[epoch 123: 300/307] 	 train loss: 0.103673 	 lr: 0.00017
[epoch 124:   0/307] 	 train loss: 0.132340 	 lr: 0.00017
[epoch 124:  20/307] 	 train loss: 0.165539 	 lr: 0.00017
[epoch 124:  40/307] 	 train loss: 0.059152 	 lr: 0.00017

val loss: 0.339832 	 acc: 0.908428

[epoch 124:  60/307] 	 train loss: 0.069641 	 lr: 0.00017
[epoch 124:  80/307] 	 train loss: 0.036873 	 lr: 0.00017
[epoch 124: 100/307] 	 train loss: 0.075949 	 lr: 0.00017
[epoch 124: 120/307] 	 train loss: 0.197997 	 lr: 0.00017
[epoch 124: 140/307] 	 train loss: 0.063455 	 lr: 0.00017
[epoch 124: 160/307] 	 train loss: 0.380952 	 lr: 0.00017
[epoch 124: 180/307] 	 train loss: 0.143451 	 lr: 0.00017
[epoch 124: 200/307] 	 train loss: 0.190333 	 lr: 0.00017

val loss: 0.331231 	 acc: 0.912480

[epoch 124: 220/307] 	 train loss: 0.165868 	 lr: 0.00017
[epoch 124: 240/307] 	 train loss: 0.092020 	 lr: 0.00017
[epoch 124: 260/307] 	 train loss: 0.204538 	 lr: 0.00017
[epoch 124: 280/307] 	 train loss: 0.074266 	 lr: 0.00017
[epoch 124: 300/307] 	 train loss: 0.148420 	 lr: 0.00017
[epoch 125:   0/307] 	 train loss: 0.075113 	 lr: 0.00017
[epoch 125:  20/307] 	 train loss: 0.095168 	 lr: 0.00017
[epoch 125:  40/307] 	 train loss: 0.071460 	 lr: 0.00017

val loss: 0.341879 	 acc: 0.914100

[epoch 125:  60/307] 	 train loss: 0.044385 	 lr: 0.00017
[epoch 125:  80/307] 	 train loss: 0.154932 	 lr: 0.00017
[epoch 125: 100/307] 	 train loss: 0.108839 	 lr: 0.00017
[epoch 125: 120/307] 	 train loss: 0.166176 	 lr: 0.00017
[epoch 125: 140/307] 	 train loss: 0.242193 	 lr: 0.00017
[epoch 125: 160/307] 	 train loss: 0.026969 	 lr: 0.00017
[epoch 125: 180/307] 	 train loss: 0.187336 	 lr: 0.00017
[epoch 125: 200/307] 	 train loss: 0.028314 	 lr: 0.00017

val loss: 0.333346 	 acc: 0.910049

[epoch 125: 220/307] 	 train loss: 0.187901 	 lr: 0.00017
[epoch 125: 240/307] 	 train loss: 0.127775 	 lr: 0.00017
[epoch 125: 260/307] 	 train loss: 0.245962 	 lr: 0.00017
[epoch 125: 280/307] 	 train loss: 0.046160 	 lr: 0.00017
[epoch 125: 300/307] 	 train loss: 0.108894 	 lr: 0.00017
[epoch 126:   0/307] 	 train loss: 0.195889 	 lr: 0.00017
[epoch 126:  20/307] 	 train loss: 0.203826 	 lr: 0.00017
[epoch 126:  40/307] 	 train loss: 0.100288 	 lr: 0.00017

val loss: 0.355650 	 acc: 0.908023

[epoch 126:  60/307] 	 train loss: 0.121192 	 lr: 0.00017
[epoch 126:  80/307] 	 train loss: 0.265801 	 lr: 0.00017
[epoch 126: 100/307] 	 train loss: 0.240334 	 lr: 0.00017
[epoch 126: 120/307] 	 train loss: 0.574655 	 lr: 0.00017
[epoch 126: 140/307] 	 train loss: 0.061623 	 lr: 0.00017
[epoch 126: 160/307] 	 train loss: 0.375451 	 lr: 0.00017
[epoch 126: 180/307] 	 train loss: 0.056124 	 lr: 0.00017
[epoch 126: 200/307] 	 train loss: 0.207384 	 lr: 0.00017

val loss: 0.340233 	 acc: 0.908833

[epoch 126: 220/307] 	 train loss: 0.147806 	 lr: 0.00017
[epoch 126: 240/307] 	 train loss: 0.068065 	 lr: 0.00017
[epoch 126: 260/307] 	 train loss: 0.183298 	 lr: 0.00017
[epoch 126: 280/307] 	 train loss: 0.171999 	 lr: 0.00017
[epoch 126: 300/307] 	 train loss: 0.128134 	 lr: 0.00017
[epoch 127:   0/307] 	 train loss: 0.142566 	 lr: 0.00012
[epoch 127:  20/307] 	 train loss: 0.125135 	 lr: 0.00012
[epoch 127:  40/307] 	 train loss: 0.090709 	 lr: 0.00012

val loss: 0.370838 	 acc: 0.903971

[epoch 127:  60/307] 	 train loss: 0.192702 	 lr: 0.00012
[epoch 127:  80/307] 	 train loss: 0.536395 	 lr: 0.00012
[epoch 127: 100/307] 	 train loss: 0.114079 	 lr: 0.00012
[epoch 127: 120/307] 	 train loss: 0.207534 	 lr: 0.00012
[epoch 127: 140/307] 	 train loss: 0.035741 	 lr: 0.00012
[epoch 127: 160/307] 	 train loss: 0.111485 	 lr: 0.00012
[epoch 127: 180/307] 	 train loss: 0.455285 	 lr: 0.00012
[epoch 127: 200/307] 	 train loss: 0.260839 	 lr: 0.00012

val loss: 0.356187 	 acc: 0.910454

[epoch 127: 220/307] 	 train loss: 0.069234 	 lr: 0.00012
[epoch 127: 240/307] 	 train loss: 0.210162 	 lr: 0.00012
[epoch 127: 260/307] 	 train loss: 0.071171 	 lr: 0.00012
[epoch 127: 280/307] 	 train loss: 0.246897 	 lr: 0.00012
[epoch 127: 300/307] 	 train loss: 0.068075 	 lr: 0.00012
[epoch 128:   0/307] 	 train loss: 0.057018 	 lr: 0.00012
[epoch 128:  20/307] 	 train loss: 0.079282 	 lr: 0.00012
[epoch 128:  40/307] 	 train loss: 0.175470 	 lr: 0.00012

val loss: 0.364152 	 acc: 0.909238

[epoch 128:  60/307] 	 train loss: 0.019981 	 lr: 0.00012
[epoch 128:  80/307] 	 train loss: 0.274654 	 lr: 0.00012
[epoch 128: 100/307] 	 train loss: 0.189018 	 lr: 0.00012
[epoch 128: 120/307] 	 train loss: 0.034179 	 lr: 0.00012
[epoch 128: 140/307] 	 train loss: 0.095260 	 lr: 0.00012
[epoch 128: 160/307] 	 train loss: 0.239393 	 lr: 0.00012
[epoch 128: 180/307] 	 train loss: 0.248592 	 lr: 0.00012
[epoch 128: 200/307] 	 train loss: 0.219580 	 lr: 0.00012

val loss: 0.352427 	 acc: 0.906402

[epoch 128: 220/307] 	 train loss: 0.018792 	 lr: 0.00012
[epoch 128: 240/307] 	 train loss: 0.335287 	 lr: 0.00012
[epoch 128: 260/307] 	 train loss: 0.055439 	 lr: 0.00012
[epoch 128: 280/307] 	 train loss: 0.127686 	 lr: 0.00012
[epoch 128: 300/307] 	 train loss: 0.070891 	 lr: 0.00012
[epoch 129:   0/307] 	 train loss: 0.108556 	 lr: 0.00012
[epoch 129:  20/307] 	 train loss: 0.203022 	 lr: 0.00012
[epoch 129:  40/307] 	 train loss: 0.174433 	 lr: 0.00012

val loss: 0.346365 	 acc: 0.915316

[epoch 129:  60/307] 	 train loss: 0.179247 	 lr: 0.00012
[epoch 129:  80/307] 	 train loss: 0.124034 	 lr: 0.00012
[epoch 129: 100/307] 	 train loss: 0.101376 	 lr: 0.00012
[epoch 129: 120/307] 	 train loss: 0.064514 	 lr: 0.00012
[epoch 129: 140/307] 	 train loss: 0.073823 	 lr: 0.00012
[epoch 129: 160/307] 	 train loss: 0.104407 	 lr: 0.00012
[epoch 129: 180/307] 	 train loss: 0.100425 	 lr: 0.00012
[epoch 129: 200/307] 	 train loss: 0.080519 	 lr: 0.00012

val loss: 0.348703 	 acc: 0.912885

[epoch 129: 220/307] 	 train loss: 0.274496 	 lr: 0.00012
[epoch 129: 240/307] 	 train loss: 0.182786 	 lr: 0.00012
[epoch 129: 260/307] 	 train loss: 0.197608 	 lr: 0.00012
[epoch 129: 280/307] 	 train loss: 0.193197 	 lr: 0.00012
[epoch 129: 300/307] 	 train loss: 0.133842 	 lr: 0.00012
[epoch 130:   0/307] 	 train loss: 0.107604 	 lr: 0.00012
[epoch 130:  20/307] 	 train loss: 0.146082 	 lr: 0.00012
[epoch 130:  40/307] 	 train loss: 0.418738 	 lr: 0.00012

val loss: 0.372211 	 acc: 0.906807

[epoch 130:  60/307] 	 train loss: 0.285489 	 lr: 0.00012
[epoch 130:  80/307] 	 train loss: 0.118153 	 lr: 0.00012
[epoch 130: 100/307] 	 train loss: 0.331766 	 lr: 0.00012
[epoch 130: 120/307] 	 train loss: 0.023457 	 lr: 0.00012
[epoch 130: 140/307] 	 train loss: 0.317918 	 lr: 0.00012
[epoch 130: 160/307] 	 train loss: 0.111433 	 lr: 0.00012
[epoch 130: 180/307] 	 train loss: 0.232486 	 lr: 0.00012
[epoch 130: 200/307] 	 train loss: 0.115730 	 lr: 0.00012

val loss: 0.337349 	 acc: 0.908428

[epoch 130: 220/307] 	 train loss: 0.061331 	 lr: 0.00012
[epoch 130: 240/307] 	 train loss: 0.049629 	 lr: 0.00012
[epoch 130: 260/307] 	 train loss: 0.205534 	 lr: 0.00012
[epoch 130: 280/307] 	 train loss: 0.401130 	 lr: 0.00012
[epoch 130: 300/307] 	 train loss: 0.100360 	 lr: 0.00012
[epoch 131:   0/307] 	 train loss: 0.240384 	 lr: 0.00012
[epoch 131:  20/307] 	 train loss: 0.131977 	 lr: 0.00012
[epoch 131:  40/307] 	 train loss: 0.110957 	 lr: 0.00012

val loss: 0.331100 	 acc: 0.909238

[epoch 131:  60/307] 	 train loss: 0.122640 	 lr: 0.00012
[epoch 131:  80/307] 	 train loss: 0.147187 	 lr: 0.00012
[epoch 131: 100/307] 	 train loss: 0.050974 	 lr: 0.00012
[epoch 131: 120/307] 	 train loss: 0.185976 	 lr: 0.00012
[epoch 131: 140/307] 	 train loss: 0.035599 	 lr: 0.00012
[epoch 131: 160/307] 	 train loss: 0.355193 	 lr: 0.00012
[epoch 131: 180/307] 	 train loss: 0.217780 	 lr: 0.00012

val loss: 0.355826 	 acc: 0.912885

[epoch 131: 200/307] 	 train loss: 0.134252 	 lr: 0.00012
[epoch 131: 220/307] 	 train loss: 0.256196 	 lr: 0.00012
[epoch 131: 240/307] 	 train loss: 0.115439 	 lr: 0.00012
[epoch 131: 260/307] 	 train loss: 0.083458 	 lr: 0.00012
[epoch 131: 280/307] 	 train loss: 0.179133 	 lr: 0.00012
[epoch 131: 300/307] 	 train loss: 0.107707 	 lr: 0.00012
[epoch 132:   0/307] 	 train loss: 0.079037 	 lr: 0.00012
[epoch 132:  20/307] 	 train loss: 0.133052 	 lr: 0.00012
[epoch 132:  40/307] 	 train loss: 0.282803 	 lr: 0.00012

val loss: 0.368075 	 acc: 0.908023

[epoch 132:  60/307] 	 train loss: 0.125743 	 lr: 0.00012
[epoch 132:  80/307] 	 train loss: 0.023963 	 lr: 0.00012
[epoch 132: 100/307] 	 train loss: 0.062134 	 lr: 0.00012
[epoch 132: 120/307] 	 train loss: 0.240704 	 lr: 0.00012
[epoch 132: 140/307] 	 train loss: 0.102808 	 lr: 0.00012
[epoch 132: 160/307] 	 train loss: 0.224732 	 lr: 0.00012
[epoch 132: 180/307] 	 train loss: 0.047123 	 lr: 0.00012

val loss: 0.367470 	 acc: 0.908833

[epoch 132: 200/307] 	 train loss: 0.234817 	 lr: 0.00012
[epoch 132: 220/307] 	 train loss: 0.086951 	 lr: 0.00012
[epoch 132: 240/307] 	 train loss: 0.112452 	 lr: 0.00012
[epoch 132: 260/307] 	 train loss: 0.095111 	 lr: 0.00012
[epoch 132: 280/307] 	 train loss: 0.216950 	 lr: 0.00012
[epoch 132: 300/307] 	 train loss: 0.110171 	 lr: 0.00012
[epoch 133:   0/307] 	 train loss: 0.175015 	 lr: 0.00012
[epoch 133:  20/307] 	 train loss: 0.216141 	 lr: 0.00012
[epoch 133:  40/307] 	 train loss: 0.088142 	 lr: 0.00012

val loss: 0.355096 	 acc: 0.910049

[epoch 133:  60/307] 	 train loss: 0.115029 	 lr: 0.00012
[epoch 133:  80/307] 	 train loss: 0.037001 	 lr: 0.00012
[epoch 133: 100/307] 	 train loss: 0.381458 	 lr: 0.00012
[epoch 133: 120/307] 	 train loss: 0.196059 	 lr: 0.00012
[epoch 133: 140/307] 	 train loss: 0.072381 	 lr: 0.00012
[epoch 133: 160/307] 	 train loss: 0.165810 	 lr: 0.00012
[epoch 133: 180/307] 	 train loss: 0.059772 	 lr: 0.00012

val loss: 0.360000 	 acc: 0.907212

[epoch 133: 200/307] 	 train loss: 0.167310 	 lr: 0.00012
[epoch 133: 220/307] 	 train loss: 0.195081 	 lr: 0.00012
[epoch 133: 240/307] 	 train loss: 0.080437 	 lr: 0.00012
[epoch 133: 260/307] 	 train loss: 0.051996 	 lr: 0.00012
[epoch 133: 280/307] 	 train loss: 0.096178 	 lr: 0.00012
[epoch 133: 300/307] 	 train loss: 0.131093 	 lr: 0.00012
[epoch 134:   0/307] 	 train loss: 0.231836 	 lr: 0.00012
[epoch 134:  20/307] 	 train loss: 0.157495 	 lr: 0.00012

val loss: 0.338528 	 acc: 0.912075

[epoch 134:  40/307] 	 train loss: 0.125595 	 lr: 0.00012
[epoch 134:  60/307] 	 train loss: 0.113101 	 lr: 0.00012
[epoch 134:  80/307] 	 train loss: 0.079995 	 lr: 0.00012
[epoch 134: 100/307] 	 train loss: 0.144250 	 lr: 0.00012
[epoch 134: 120/307] 	 train loss: 0.052380 	 lr: 0.00012
[epoch 134: 140/307] 	 train loss: 0.016248 	 lr: 0.00012
[epoch 134: 160/307] 	 train loss: 0.194051 	 lr: 0.00012
[epoch 134: 180/307] 	 train loss: 0.068858 	 lr: 0.00012

val loss: 0.347157 	 acc: 0.914506

[epoch 134: 200/307] 	 train loss: 0.254565 	 lr: 0.00012
[epoch 134: 220/307] 	 train loss: 0.052203 	 lr: 0.00012
[epoch 134: 240/307] 	 train loss: 0.156096 	 lr: 0.00012
[epoch 134: 260/307] 	 train loss: 0.034320 	 lr: 0.00012
[epoch 134: 280/307] 	 train loss: 0.081113 	 lr: 0.00012
[epoch 134: 300/307] 	 train loss: 0.169398 	 lr: 0.00012
[epoch 135:   0/307] 	 train loss: 0.206716 	 lr: 0.00012
[epoch 135:  20/307] 	 train loss: 0.071967 	 lr: 0.00012

val loss: 0.350086 	 acc: 0.907212

[epoch 135:  40/307] 	 train loss: 0.067888 	 lr: 0.00012
[epoch 135:  60/307] 	 train loss: 0.036617 	 lr: 0.00012
[epoch 135:  80/307] 	 train loss: 0.106748 	 lr: 0.00012
[epoch 135: 100/307] 	 train loss: 0.114042 	 lr: 0.00012
[epoch 135: 120/307] 	 train loss: 0.011538 	 lr: 0.00012
[epoch 135: 140/307] 	 train loss: 0.190999 	 lr: 0.00012
[epoch 135: 160/307] 	 train loss: 0.151022 	 lr: 0.00012
[epoch 135: 180/307] 	 train loss: 0.314129 	 lr: 0.00012

val loss: 0.344088 	 acc: 0.910454

[epoch 135: 200/307] 	 train loss: 0.232797 	 lr: 0.00012
[epoch 135: 220/307] 	 train loss: 0.093294 	 lr: 0.00012
[epoch 135: 240/307] 	 train loss: 0.272477 	 lr: 0.00012
[epoch 135: 260/307] 	 train loss: 0.182700 	 lr: 0.00012
[epoch 135: 280/307] 	 train loss: 0.115794 	 lr: 0.00012
[epoch 135: 300/307] 	 train loss: 0.133452 	 lr: 0.00012
[epoch 136:   0/307] 	 train loss: 0.067999 	 lr: 0.00012
[epoch 136:  20/307] 	 train loss: 0.271395 	 lr: 0.00012

val loss: 0.352251 	 acc: 0.906402

[epoch 136:  40/307] 	 train loss: 0.080099 	 lr: 0.00012
[epoch 136:  60/307] 	 train loss: 0.225938 	 lr: 0.00012
[epoch 136:  80/307] 	 train loss: 0.143459 	 lr: 0.00012
[epoch 136: 100/307] 	 train loss: 0.137146 	 lr: 0.00012
[epoch 136: 120/307] 	 train loss: 0.039914 	 lr: 0.00012
[epoch 136: 140/307] 	 train loss: 0.187702 	 lr: 0.00012
[epoch 136: 160/307] 	 train loss: 0.229098 	 lr: 0.00012
[epoch 136: 180/307] 	 train loss: 0.030556 	 lr: 0.00012

val loss: 0.340238 	 acc: 0.905186

[epoch 136: 200/307] 	 train loss: 0.032747 	 lr: 0.00012
[epoch 136: 220/307] 	 train loss: 0.033634 	 lr: 0.00012
[epoch 136: 240/307] 	 train loss: 0.072027 	 lr: 0.00012
[epoch 136: 260/307] 	 train loss: 0.152638 	 lr: 0.00012
[epoch 136: 280/307] 	 train loss: 0.250865 	 lr: 0.00012
[epoch 136: 300/307] 	 train loss: 0.190153 	 lr: 0.00012
[epoch 137:   0/307] 	 train loss: 0.062859 	 lr: 0.00012
[epoch 137:  20/307] 	 train loss: 0.065001 	 lr: 0.00012

val loss: 0.337356 	 acc: 0.914506

[epoch 137:  40/307] 	 train loss: 0.016791 	 lr: 0.00012
[epoch 137:  60/307] 	 train loss: 0.137721 	 lr: 0.00012
[epoch 137:  80/307] 	 train loss: 0.100357 	 lr: 0.00012
[epoch 137: 100/307] 	 train loss: 0.159863 	 lr: 0.00012
[epoch 137: 120/307] 	 train loss: 0.093761 	 lr: 0.00012
[epoch 137: 140/307] 	 train loss: 0.053587 	 lr: 0.00012
[epoch 137: 160/307] 	 train loss: 0.018020 	 lr: 0.00012
[epoch 137: 180/307] 	 train loss: 0.111376 	 lr: 0.00012

val loss: 0.333870 	 acc: 0.911264

[epoch 137: 200/307] 	 train loss: 0.250477 	 lr: 0.00012
[epoch 137: 220/307] 	 train loss: 0.107680 	 lr: 0.00012
[epoch 137: 240/307] 	 train loss: 0.026537 	 lr: 0.00012
[epoch 137: 260/307] 	 train loss: 0.149019 	 lr: 0.00012
[epoch 137: 280/307] 	 train loss: 0.117162 	 lr: 0.00012
[epoch 137: 300/307] 	 train loss: 0.077876 	 lr: 0.00012
[epoch 138:   0/307] 	 train loss: 0.186649 	 lr: 0.00012
[epoch 138:  20/307] 	 train loss: 0.204429 	 lr: 0.00012

val loss: 0.331786 	 acc: 0.914506

[epoch 138:  40/307] 	 train loss: 0.137412 	 lr: 0.00012
[epoch 138:  60/307] 	 train loss: 0.150986 	 lr: 0.00012
[epoch 138:  80/307] 	 train loss: 0.057880 	 lr: 0.00012
[epoch 138: 100/307] 	 train loss: 0.054337 	 lr: 0.00012
[epoch 138: 120/307] 	 train loss: 0.248238 	 lr: 0.00012
[epoch 138: 140/307] 	 train loss: 0.063448 	 lr: 0.00012
[epoch 138: 160/307] 	 train loss: 0.155267 	 lr: 0.00012
[epoch 138: 180/307] 	 train loss: 0.100480 	 lr: 0.00012

val loss: 0.344419 	 acc: 0.911669

[epoch 138: 200/307] 	 train loss: 0.218580 	 lr: 0.00012
[epoch 138: 220/307] 	 train loss: 0.332114 	 lr: 0.00012
[epoch 138: 240/307] 	 train loss: 0.025485 	 lr: 0.00012
[epoch 138: 260/307] 	 train loss: 0.335595 	 lr: 0.00012
[epoch 138: 280/307] 	 train loss: 0.024399 	 lr: 0.00012
[epoch 138: 300/307] 	 train loss: 0.184393 	 lr: 0.00012
[epoch 139:   0/307] 	 train loss: 0.163834 	 lr: 0.00012
[epoch 139:  20/307] 	 train loss: 0.013699 	 lr: 0.00012

val loss: 0.344823 	 acc: 0.911264

[epoch 139:  40/307] 	 train loss: 0.149396 	 lr: 0.00012
[epoch 139:  60/307] 	 train loss: 0.104309 	 lr: 0.00012
[epoch 139:  80/307] 	 train loss: 0.114130 	 lr: 0.00012
[epoch 139: 100/307] 	 train loss: 0.083735 	 lr: 0.00012
[epoch 139: 120/307] 	 train loss: 0.311919 	 lr: 0.00012
[epoch 139: 140/307] 	 train loss: 0.177407 	 lr: 0.00012
[epoch 139: 160/307] 	 train loss: 0.282322 	 lr: 0.00012
[epoch 139: 180/307] 	 train loss: 0.171225 	 lr: 0.00012

val loss: 0.358871 	 acc: 0.912480

[epoch 139: 200/307] 	 train loss: 0.146883 	 lr: 0.00012
[epoch 139: 220/307] 	 train loss: 0.207869 	 lr: 0.00012
[epoch 139: 240/307] 	 train loss: 0.086053 	 lr: 0.00012
[epoch 139: 260/307] 	 train loss: 0.367884 	 lr: 0.00012
[epoch 139: 280/307] 	 train loss: 0.362244 	 lr: 0.00012
[epoch 139: 300/307] 	 train loss: 0.227763 	 lr: 0.00012
[epoch 140:   0/307] 	 train loss: 0.052031 	 lr: 0.00012
[epoch 140:  20/307] 	 train loss: 0.100114 	 lr: 0.00012

val loss: 0.334010 	 acc: 0.908023

[epoch 140:  40/307] 	 train loss: 0.117828 	 lr: 0.00012
[epoch 140:  60/307] 	 train loss: 0.088586 	 lr: 0.00012
[epoch 140:  80/307] 	 train loss: 0.111209 	 lr: 0.00012
[epoch 140: 100/307] 	 train loss: 0.133112 	 lr: 0.00012
[epoch 140: 120/307] 	 train loss: 0.284166 	 lr: 0.00012
[epoch 140: 140/307] 	 train loss: 0.198654 	 lr: 0.00012
[epoch 140: 160/307] 	 train loss: 0.077087 	 lr: 0.00012
[epoch 140: 180/307] 	 train loss: 0.046852 	 lr: 0.00012

val loss: 0.357965 	 acc: 0.910859

[epoch 140: 200/307] 	 train loss: 0.045352 	 lr: 0.00012
[epoch 140: 220/307] 	 train loss: 0.174875 	 lr: 0.00012
[epoch 140: 240/307] 	 train loss: 0.334354 	 lr: 0.00012
[epoch 140: 260/307] 	 train loss: 0.077602 	 lr: 0.00012
[epoch 140: 280/307] 	 train loss: 0.111973 	 lr: 0.00012
[epoch 140: 300/307] 	 train loss: 0.050559 	 lr: 0.00012
[epoch 141:   0/307] 	 train loss: 0.225264 	 lr: 0.00012
[epoch 141:  20/307] 	 train loss: 0.272342 	 lr: 0.00012

val loss: 0.327704 	 acc: 0.914911

[epoch 141:  40/307] 	 train loss: 0.262716 	 lr: 0.00012
[epoch 141:  60/307] 	 train loss: 0.119299 	 lr: 0.00012
[epoch 141:  80/307] 	 train loss: 0.299393 	 lr: 0.00012
[epoch 141: 100/307] 	 train loss: 0.211527 	 lr: 0.00012
[epoch 141: 120/307] 	 train loss: 0.024793 	 lr: 0.00012
[epoch 141: 140/307] 	 train loss: 0.316880 	 lr: 0.00012
[epoch 141: 160/307] 	 train loss: 0.049838 	 lr: 0.00012

val loss: 0.351681 	 acc: 0.909238

[epoch 141: 180/307] 	 train loss: 0.116946 	 lr: 0.00012
[epoch 141: 200/307] 	 train loss: 0.235817 	 lr: 0.00012
[epoch 141: 220/307] 	 train loss: 0.120399 	 lr: 0.00012
[epoch 141: 240/307] 	 train loss: 0.066078 	 lr: 0.00012
[epoch 141: 260/307] 	 train loss: 0.221081 	 lr: 0.00012
[epoch 141: 280/307] 	 train loss: 0.198383 	 lr: 0.00012
[epoch 141: 300/307] 	 train loss: 0.076305 	 lr: 0.00012
[epoch 142:   0/307] 	 train loss: 0.066765 	 lr: 0.00012
[epoch 142:  20/307] 	 train loss: 0.062975 	 lr: 0.00012

val loss: 0.357954 	 acc: 0.910049

[epoch 142:  40/307] 	 train loss: 0.084322 	 lr: 0.00012
[epoch 142:  60/307] 	 train loss: 0.074108 	 lr: 0.00012
[epoch 142:  80/307] 	 train loss: 0.041283 	 lr: 0.00012
[epoch 142: 100/307] 	 train loss: 0.100587 	 lr: 0.00012
[epoch 142: 120/307] 	 train loss: 0.066958 	 lr: 0.00012
[epoch 142: 140/307] 	 train loss: 0.045259 	 lr: 0.00012
[epoch 142: 160/307] 	 train loss: 0.095625 	 lr: 0.00012

val loss: 0.348589 	 acc: 0.908023

[epoch 142: 180/307] 	 train loss: 0.135508 	 lr: 0.00012
[epoch 142: 200/307] 	 train loss: 0.075534 	 lr: 0.00012
[epoch 142: 220/307] 	 train loss: 0.068999 	 lr: 0.00012
[epoch 142: 240/307] 	 train loss: 0.159025 	 lr: 0.00012
[epoch 142: 260/307] 	 train loss: 0.128207 	 lr: 0.00012
[epoch 142: 280/307] 	 train loss: 0.106862 	 lr: 0.00012
[epoch 142: 300/307] 	 train loss: 0.142276 	 lr: 0.00012
[epoch 143:   0/307] 	 train loss: 0.068564 	 lr: 0.00012
[epoch 143:  20/307] 	 train loss: 0.116857 	 lr: 0.00012

val loss: 0.362252 	 acc: 0.908833

[epoch 143:  40/307] 	 train loss: 0.181816 	 lr: 0.00012
[epoch 143:  60/307] 	 train loss: 0.090751 	 lr: 0.00012
[epoch 143:  80/307] 	 train loss: 0.255132 	 lr: 0.00012
[epoch 143: 100/307] 	 train loss: 0.150891 	 lr: 0.00012
[epoch 143: 120/307] 	 train loss: 0.118799 	 lr: 0.00012
[epoch 143: 140/307] 	 train loss: 0.202379 	 lr: 0.00012
[epoch 143: 160/307] 	 train loss: 0.188648 	 lr: 0.00012

val loss: 0.344211 	 acc: 0.910454

[epoch 143: 180/307] 	 train loss: 0.174716 	 lr: 0.00012
[epoch 143: 200/307] 	 train loss: 0.096814 	 lr: 0.00012
[epoch 143: 220/307] 	 train loss: 0.076869 	 lr: 0.00012
[epoch 143: 240/307] 	 train loss: 0.121705 	 lr: 0.00012
[epoch 143: 260/307] 	 train loss: 0.194009 	 lr: 0.00012
[epoch 143: 280/307] 	 train loss: 0.150517 	 lr: 0.00012
[epoch 143: 300/307] 	 train loss: 0.269326 	 lr: 0.00012
[epoch 144:   0/307] 	 train loss: 0.052823 	 lr: 0.00012

val loss: 0.358381 	 acc: 0.909643

[epoch 144:  20/307] 	 train loss: 0.078728 	 lr: 0.00012
[epoch 144:  40/307] 	 train loss: 0.080367 	 lr: 0.00012
[epoch 144:  60/307] 	 train loss: 0.067525 	 lr: 0.00012
[epoch 144:  80/307] 	 train loss: 0.417808 	 lr: 0.00012
[epoch 144: 100/307] 	 train loss: 0.116813 	 lr: 0.00012
[epoch 144: 120/307] 	 train loss: 0.084021 	 lr: 0.00012
[epoch 144: 140/307] 	 train loss: 0.070093 	 lr: 0.00012
[epoch 144: 160/307] 	 train loss: 0.064292 	 lr: 0.00012

val loss: 0.351178 	 acc: 0.908428

[epoch 144: 180/307] 	 train loss: 0.069188 	 lr: 0.00012
[epoch 144: 200/307] 	 train loss: 0.144656 	 lr: 0.00012
[epoch 144: 220/307] 	 train loss: 0.183912 	 lr: 0.00012
[epoch 144: 240/307] 	 train loss: 0.126469 	 lr: 0.00012
[epoch 144: 260/307] 	 train loss: 0.109248 	 lr: 0.00012
[epoch 144: 280/307] 	 train loss: 0.195412 	 lr: 0.00012
[epoch 144: 300/307] 	 train loss: 0.342134 	 lr: 0.00012
[epoch 145:   0/307] 	 train loss: 0.218695 	 lr: 0.00012

val loss: 0.335331 	 acc: 0.912075

[epoch 145:  20/307] 	 train loss: 0.127880 	 lr: 0.00012
[epoch 145:  40/307] 	 train loss: 0.055726 	 lr: 0.00012
[epoch 145:  60/307] 	 train loss: 0.060774 	 lr: 0.00012
[epoch 145:  80/307] 	 train loss: 0.091768 	 lr: 0.00012
[epoch 145: 100/307] 	 train loss: 0.031499 	 lr: 0.00012
[epoch 145: 120/307] 	 train loss: 0.029238 	 lr: 0.00012
[epoch 145: 140/307] 	 train loss: 0.042318 	 lr: 0.00012
[epoch 145: 160/307] 	 train loss: 0.129068 	 lr: 0.00012

val loss: 0.336942 	 acc: 0.911669

[epoch 145: 180/307] 	 train loss: 0.371772 	 lr: 0.00012
[epoch 145: 200/307] 	 train loss: 0.104437 	 lr: 0.00012
[epoch 145: 220/307] 	 train loss: 0.403419 	 lr: 0.00012
[epoch 145: 240/307] 	 train loss: 0.101704 	 lr: 0.00012
[epoch 145: 260/307] 	 train loss: 0.290871 	 lr: 0.00012
[epoch 145: 280/307] 	 train loss: 0.051033 	 lr: 0.00012
[epoch 145: 300/307] 	 train loss: 0.140103 	 lr: 0.00012
[epoch 146:   0/307] 	 train loss: 0.219636 	 lr: 0.00012

val loss: 0.336673 	 acc: 0.912480

[epoch 146:  20/307] 	 train loss: 0.154611 	 lr: 0.00012
[epoch 146:  40/307] 	 train loss: 0.115981 	 lr: 0.00012
[epoch 146:  60/307] 	 train loss: 0.353774 	 lr: 0.00012
[epoch 146:  80/307] 	 train loss: 0.033006 	 lr: 0.00012
[epoch 146: 100/307] 	 train loss: 0.049814 	 lr: 0.00012
[epoch 146: 120/307] 	 train loss: 0.264272 	 lr: 0.00012
[epoch 146: 140/307] 	 train loss: 0.126869 	 lr: 0.00012
[epoch 146: 160/307] 	 train loss: 0.051318 	 lr: 0.00012

val loss: 0.359557 	 acc: 0.912075

[epoch 146: 180/307] 	 train loss: 0.130255 	 lr: 0.00012
[epoch 146: 200/307] 	 train loss: 0.136455 	 lr: 0.00012
[epoch 146: 220/307] 	 train loss: 0.097544 	 lr: 0.00012
[epoch 146: 240/307] 	 train loss: 0.030462 	 lr: 0.00012
[epoch 146: 260/307] 	 train loss: 0.127424 	 lr: 0.00012
[epoch 146: 280/307] 	 train loss: 0.062817 	 lr: 0.00012
[epoch 146: 300/307] 	 train loss: 0.176424 	 lr: 0.00012
[epoch 147:   0/307] 	 train loss: 0.058823 	 lr: 0.00012

val loss: 0.348260 	 acc: 0.915721

[epoch 147:  20/307] 	 train loss: 0.108345 	 lr: 0.00012
[epoch 147:  40/307] 	 train loss: 0.162885 	 lr: 0.00012
[epoch 147:  60/307] 	 train loss: 0.114082 	 lr: 0.00012
[epoch 147:  80/307] 	 train loss: 0.256521 	 lr: 0.00012
[epoch 147: 100/307] 	 train loss: 0.156018 	 lr: 0.00012
[epoch 147: 120/307] 	 train loss: 0.240162 	 lr: 0.00012
[epoch 147: 140/307] 	 train loss: 0.136782 	 lr: 0.00012
[epoch 147: 160/307] 	 train loss: 0.087712 	 lr: 0.00012

val loss: 0.345338 	 acc: 0.914100

[epoch 147: 180/307] 	 train loss: 0.116554 	 lr: 0.00012
[epoch 147: 200/307] 	 train loss: 0.102971 	 lr: 0.00012
[epoch 147: 220/307] 	 train loss: 0.196982 	 lr: 0.00012
[epoch 147: 240/307] 	 train loss: 0.113975 	 lr: 0.00012
[epoch 147: 260/307] 	 train loss: 0.133403 	 lr: 0.00012
[epoch 147: 280/307] 	 train loss: 0.082965 	 lr: 0.00012
[epoch 147: 300/307] 	 train loss: 0.093069 	 lr: 0.00012
[epoch 148:   0/307] 	 train loss: 0.070489 	 lr: 0.00008

val loss: 0.345506 	 acc: 0.912075

[epoch 148:  20/307] 	 train loss: 0.185246 	 lr: 0.00008
[epoch 148:  40/307] 	 train loss: 0.226291 	 lr: 0.00008
[epoch 148:  60/307] 	 train loss: 0.090042 	 lr: 0.00008
[epoch 148:  80/307] 	 train loss: 0.067212 	 lr: 0.00008
[epoch 148: 100/307] 	 train loss: 0.291203 	 lr: 0.00008
[epoch 148: 120/307] 	 train loss: 0.377207 	 lr: 0.00008
[epoch 148: 140/307] 	 train loss: 0.189676 	 lr: 0.00008
[epoch 148: 160/307] 	 train loss: 0.150812 	 lr: 0.00008

val loss: 0.346767 	 acc: 0.906807

[epoch 148: 180/307] 	 train loss: 0.332751 	 lr: 0.00008
[epoch 148: 200/307] 	 train loss: 0.286773 	 lr: 0.00008
[epoch 148: 220/307] 	 train loss: 0.116114 	 lr: 0.00008
[epoch 148: 240/307] 	 train loss: 0.271357 	 lr: 0.00008
[epoch 148: 260/307] 	 train loss: 0.104223 	 lr: 0.00008
[epoch 148: 280/307] 	 train loss: 0.194382 	 lr: 0.00008
[epoch 148: 300/307] 	 train loss: 0.032448 	 lr: 0.00008
[epoch 149:   0/307] 	 train loss: 0.170402 	 lr: 0.00008

val loss: 0.340804 	 acc: 0.913290

[epoch 149:  20/307] 	 train loss: 0.127487 	 lr: 0.00008
[epoch 149:  40/307] 	 train loss: 0.030835 	 lr: 0.00008
[epoch 149:  60/307] 	 train loss: 0.144252 	 lr: 0.00008
[epoch 149:  80/307] 	 train loss: 0.102918 	 lr: 0.00008
[epoch 149: 100/307] 	 train loss: 0.022607 	 lr: 0.00008
[epoch 149: 120/307] 	 train loss: 0.207813 	 lr: 0.00008
[epoch 149: 140/307] 	 train loss: 0.104519 	 lr: 0.00008
[epoch 149: 160/307] 	 train loss: 0.180492 	 lr: 0.00008

val loss: 0.347508 	 acc: 0.915316

[epoch 149: 180/307] 	 train loss: 0.068107 	 lr: 0.00008
[epoch 149: 200/307] 	 train loss: 0.099574 	 lr: 0.00008
[epoch 149: 220/307] 	 train loss: 0.137576 	 lr: 0.00008
[epoch 149: 240/307] 	 train loss: 0.038259 	 lr: 0.00008
[epoch 149: 260/307] 	 train loss: 0.072476 	 lr: 0.00008
[epoch 149: 280/307] 	 train loss: 0.176571 	 lr: 0.00008
[epoch 149: 300/307] 	 train loss: 0.044019 	 lr: 0.00008
[epoch 150:   0/307] 	 train loss: 0.068716 	 lr: 0.00008

val loss: 0.352481 	 acc: 0.912480

[epoch 150:  20/307] 	 train loss: 0.204510 	 lr: 0.00008
[epoch 150:  40/307] 	 train loss: 0.143608 	 lr: 0.00008
[epoch 150:  60/307] 	 train loss: 0.021016 	 lr: 0.00008
[epoch 150:  80/307] 	 train loss: 0.127940 	 lr: 0.00008
[epoch 150: 100/307] 	 train loss: 0.256284 	 lr: 0.00008
[epoch 150: 120/307] 	 train loss: 0.231202 	 lr: 0.00008
[epoch 150: 140/307] 	 train loss: 0.047225 	 lr: 0.00008
[epoch 150: 160/307] 	 train loss: 0.163165 	 lr: 0.00008

val loss: 0.341727 	 acc: 0.913695

[epoch 150: 180/307] 	 train loss: 0.196059 	 lr: 0.00008
[epoch 150: 200/307] 	 train loss: 0.212619 	 lr: 0.00008
[epoch 150: 220/307] 	 train loss: 0.060309 	 lr: 0.00008
[epoch 150: 240/307] 	 train loss: 0.011030 	 lr: 0.00008
[epoch 150: 260/307] 	 train loss: 0.042106 	 lr: 0.00008
[epoch 150: 280/307] 	 train loss: 0.091260 	 lr: 0.00008
[epoch 150: 300/307] 	 train loss: 0.080873 	 lr: 0.00008
[epoch 151:   0/307] 	 train loss: 0.059152 	 lr: 0.00008

val loss: 0.333105 	 acc: 0.914100

[epoch 151:  20/307] 	 train loss: 0.106829 	 lr: 0.00008
[epoch 151:  40/307] 	 train loss: 0.142168 	 lr: 0.00008
[epoch 151:  60/307] 	 train loss: 0.288749 	 lr: 0.00008
[epoch 151:  80/307] 	 train loss: 0.189896 	 lr: 0.00008
[epoch 151: 100/307] 	 train loss: 0.048204 	 lr: 0.00008
[epoch 151: 120/307] 	 train loss: 0.213967 	 lr: 0.00008
[epoch 151: 140/307] 	 train loss: 0.236040 	 lr: 0.00008

val loss: 0.347706 	 acc: 0.911264

[epoch 151: 160/307] 	 train loss: 0.062755 	 lr: 0.00008
[epoch 151: 180/307] 	 train loss: 0.286319 	 lr: 0.00008
[epoch 151: 200/307] 	 train loss: 0.286856 	 lr: 0.00008
[epoch 151: 220/307] 	 train loss: 0.041715 	 lr: 0.00008
[epoch 151: 240/307] 	 train loss: 0.192274 	 lr: 0.00008
[epoch 151: 260/307] 	 train loss: 0.138677 	 lr: 0.00008
[epoch 151: 280/307] 	 train loss: 0.422283 	 lr: 0.00008
[epoch 151: 300/307] 	 train loss: 0.259155 	 lr: 0.00008
[epoch 152:   0/307] 	 train loss: 0.088733 	 lr: 0.00008

val loss: 0.350456 	 acc: 0.910859

[epoch 152:  20/307] 	 train loss: 0.079318 	 lr: 0.00008
[epoch 152:  40/307] 	 train loss: 0.135636 	 lr: 0.00008
[epoch 152:  60/307] 	 train loss: 0.189403 	 lr: 0.00008
[epoch 152:  80/307] 	 train loss: 0.060719 	 lr: 0.00008
[epoch 152: 100/307] 	 train loss: 0.065254 	 lr: 0.00008
[epoch 152: 120/307] 	 train loss: 0.112762 	 lr: 0.00008
[epoch 152: 140/307] 	 train loss: 0.398475 	 lr: 0.00008

val loss: 0.348761 	 acc: 0.913290

[epoch 152: 160/307] 	 train loss: 0.092487 	 lr: 0.00008
[epoch 152: 180/307] 	 train loss: 0.434289 	 lr: 0.00008
[epoch 152: 200/307] 	 train loss: 0.131181 	 lr: 0.00008
[epoch 152: 220/307] 	 train loss: 0.055614 	 lr: 0.00008
[epoch 152: 240/307] 	 train loss: 0.095980 	 lr: 0.00008
[epoch 152: 260/307] 	 train loss: 0.070549 	 lr: 0.00008
[epoch 152: 280/307] 	 train loss: 0.115334 	 lr: 0.00008
[epoch 152: 300/307] 	 train loss: 0.200180 	 lr: 0.00008
[epoch 153:   0/307] 	 train loss: 0.099852 	 lr: 0.00008

val loss: 0.340917 	 acc: 0.912075

[epoch 153:  20/307] 	 train loss: 0.083815 	 lr: 0.00008
[epoch 153:  40/307] 	 train loss: 0.175521 	 lr: 0.00008
[epoch 153:  60/307] 	 train loss: 0.243216 	 lr: 0.00008
[epoch 153:  80/307] 	 train loss: 0.286036 	 lr: 0.00008
[epoch 153: 100/307] 	 train loss: 0.130307 	 lr: 0.00008
[epoch 153: 120/307] 	 train loss: 0.055242 	 lr: 0.00008
[epoch 153: 140/307] 	 train loss: 0.149531 	 lr: 0.00008

val loss: 0.346433 	 acc: 0.915721

[epoch 153: 160/307] 	 train loss: 0.103110 	 lr: 0.00008
[epoch 153: 180/307] 	 train loss: 0.223070 	 lr: 0.00008
[epoch 153: 200/307] 	 train loss: 0.072625 	 lr: 0.00008
[epoch 153: 220/307] 	 train loss: 0.158660 	 lr: 0.00008
[epoch 153: 240/307] 	 train loss: 0.052405 	 lr: 0.00008
[epoch 153: 260/307] 	 train loss: 0.267293 	 lr: 0.00008
[epoch 153: 280/307] 	 train loss: 0.095916 	 lr: 0.00008
[epoch 153: 300/307] 	 train loss: 0.229772 	 lr: 0.00008

val loss: 0.339145 	 acc: 0.909238

[epoch 154:   0/307] 	 train loss: 0.091994 	 lr: 0.00008
[epoch 154:  20/307] 	 train loss: 0.069563 	 lr: 0.00008
[epoch 154:  40/307] 	 train loss: 0.062849 	 lr: 0.00008
[epoch 154:  60/307] 	 train loss: 0.399600 	 lr: 0.00008
[epoch 154:  80/307] 	 train loss: 0.126916 	 lr: 0.00008
[epoch 154: 100/307] 	 train loss: 0.051600 	 lr: 0.00008
[epoch 154: 120/307] 	 train loss: 0.025780 	 lr: 0.00008
[epoch 154: 140/307] 	 train loss: 0.024244 	 lr: 0.00008

val loss: 0.342055 	 acc: 0.912480

[epoch 154: 160/307] 	 train loss: 0.131488 	 lr: 0.00008
[epoch 154: 180/307] 	 train loss: 0.163648 	 lr: 0.00008
[epoch 154: 200/307] 	 train loss: 0.033219 	 lr: 0.00008
[epoch 154: 220/307] 	 train loss: 0.117341 	 lr: 0.00008
[epoch 154: 240/307] 	 train loss: 0.121360 	 lr: 0.00008
[epoch 154: 260/307] 	 train loss: 0.120107 	 lr: 0.00008
[epoch 154: 280/307] 	 train loss: 0.244010 	 lr: 0.00008
[epoch 154: 300/307] 	 train loss: 0.066530 	 lr: 0.00008

val loss: 0.360226 	 acc: 0.913290

[epoch 155:   0/307] 	 train loss: 0.107553 	 lr: 0.00008
[epoch 155:  20/307] 	 train loss: 0.261629 	 lr: 0.00008
[epoch 155:  40/307] 	 train loss: 0.091177 	 lr: 0.00008
[epoch 155:  60/307] 	 train loss: 0.145312 	 lr: 0.00008
[epoch 155:  80/307] 	 train loss: 0.079244 	 lr: 0.00008
[epoch 155: 100/307] 	 train loss: 0.121090 	 lr: 0.00008
[epoch 155: 120/307] 	 train loss: 0.183149 	 lr: 0.00008
[epoch 155: 140/307] 	 train loss: 0.114602 	 lr: 0.00008

val loss: 0.362925 	 acc: 0.909643

[epoch 155: 160/307] 	 train loss: 0.186148 	 lr: 0.00008
[epoch 155: 180/307] 	 train loss: 0.127754 	 lr: 0.00008
[epoch 155: 200/307] 	 train loss: 0.217551 	 lr: 0.00008
[epoch 155: 220/307] 	 train loss: 0.208922 	 lr: 0.00008
[epoch 155: 240/307] 	 train loss: 0.064669 	 lr: 0.00008
[epoch 155: 260/307] 	 train loss: 0.064141 	 lr: 0.00008
[epoch 155: 280/307] 	 train loss: 0.158624 	 lr: 0.00008
[epoch 155: 300/307] 	 train loss: 0.103992 	 lr: 0.00008

val loss: 0.323665 	 acc: 0.916937

[epoch 156:   0/307] 	 train loss: 0.040661 	 lr: 0.00008
[epoch 156:  20/307] 	 train loss: 0.020354 	 lr: 0.00008
[epoch 156:  40/307] 	 train loss: 0.287313 	 lr: 0.00008
[epoch 156:  60/307] 	 train loss: 0.078382 	 lr: 0.00008
[epoch 156:  80/307] 	 train loss: 0.084045 	 lr: 0.00008
[epoch 156: 100/307] 	 train loss: 0.045565 	 lr: 0.00008
[epoch 156: 120/307] 	 train loss: 0.202252 	 lr: 0.00008
[epoch 156: 140/307] 	 train loss: 0.205053 	 lr: 0.00008

val loss: 0.343403 	 acc: 0.912480

[epoch 156: 160/307] 	 train loss: 0.138787 	 lr: 0.00008
[epoch 156: 180/307] 	 train loss: 0.170333 	 lr: 0.00008
[epoch 156: 200/307] 	 train loss: 0.094585 	 lr: 0.00008
[epoch 156: 220/307] 	 train loss: 0.202691 	 lr: 0.00008
[epoch 156: 240/307] 	 train loss: 0.075671 	 lr: 0.00008
[epoch 156: 260/307] 	 train loss: 0.151207 	 lr: 0.00008
[epoch 156: 280/307] 	 train loss: 0.386407 	 lr: 0.00008
[epoch 156: 300/307] 	 train loss: 0.286755 	 lr: 0.00008

val loss: 0.317468 	 acc: 0.921799

saved model with accuracy  0.9217990275526742
[epoch 157:   0/307] 	 train loss: 0.105376 	 lr: 0.00008
[epoch 157:  20/307] 	 train loss: 0.177413 	 lr: 0.00008
[epoch 157:  40/307] 	 train loss: 0.118256 	 lr: 0.00008
[epoch 157:  60/307] 	 train loss: 0.092169 	 lr: 0.00008
[epoch 157:  80/307] 	 train loss: 0.144179 	 lr: 0.00008
[epoch 157: 100/307] 	 train loss: 0.335966 	 lr: 0.00008
[epoch 157: 120/307] 	 train loss: 0.027416 	 lr: 0.00008
[epoch 157: 140/307] 	 train loss: 0.113536 	 lr: 0.00008

val loss: 0.333637 	 acc: 0.911264

[epoch 157: 160/307] 	 train loss: 0.142708 	 lr: 0.00008
[epoch 157: 180/307] 	 train loss: 0.055001 	 lr: 0.00008
[epoch 157: 200/307] 	 train loss: 0.091877 	 lr: 0.00008
[epoch 157: 220/307] 	 train loss: 0.107245 	 lr: 0.00008
[epoch 157: 240/307] 	 train loss: 0.112378 	 lr: 0.00008
[epoch 157: 260/307] 	 train loss: 0.169164 	 lr: 0.00008
[epoch 157: 280/307] 	 train loss: 0.339155 	 lr: 0.00008

val loss: 0.324437 	 acc: 0.919773

[epoch 157: 300/307] 	 train loss: 0.344059 	 lr: 0.00008
[epoch 158:   0/307] 	 train loss: 0.050995 	 lr: 0.00008
[epoch 158:  20/307] 	 train loss: 0.054538 	 lr: 0.00008
[epoch 158:  40/307] 	 train loss: 0.025459 	 lr: 0.00008
[epoch 158:  60/307] 	 train loss: 0.197701 	 lr: 0.00008
[epoch 158:  80/307] 	 train loss: 0.103015 	 lr: 0.00008
[epoch 158: 100/307] 	 train loss: 0.071104 	 lr: 0.00008
[epoch 158: 120/307] 	 train loss: 0.216963 	 lr: 0.00008
[epoch 158: 140/307] 	 train loss: 0.021984 	 lr: 0.00008

val loss: 0.328188 	 acc: 0.916532

[epoch 158: 160/307] 	 train loss: 0.062754 	 lr: 0.00008
[epoch 158: 180/307] 	 train loss: 0.063915 	 lr: 0.00008
[epoch 158: 200/307] 	 train loss: 0.284385 	 lr: 0.00008
[epoch 158: 220/307] 	 train loss: 0.089553 	 lr: 0.00008
[epoch 158: 240/307] 	 train loss: 0.207974 	 lr: 0.00008
[epoch 158: 260/307] 	 train loss: 0.122428 	 lr: 0.00008
[epoch 158: 280/307] 	 train loss: 0.283548 	 lr: 0.00008

val loss: 0.327249 	 acc: 0.910859

[epoch 158: 300/307] 	 train loss: 0.121033 	 lr: 0.00008
[epoch 159:   0/307] 	 train loss: 0.032202 	 lr: 0.00008
[epoch 159:  20/307] 	 train loss: 0.060581 	 lr: 0.00008
[epoch 159:  40/307] 	 train loss: 0.055586 	 lr: 0.00008
[epoch 159:  60/307] 	 train loss: 0.027708 	 lr: 0.00008
[epoch 159:  80/307] 	 train loss: 0.080184 	 lr: 0.00008
[epoch 159: 100/307] 	 train loss: 0.085631 	 lr: 0.00008
[epoch 159: 120/307] 	 train loss: 0.139693 	 lr: 0.00008
[epoch 159: 140/307] 	 train loss: 0.120183 	 lr: 0.00008

val loss: 0.341212 	 acc: 0.914911

[epoch 159: 160/307] 	 train loss: 0.126453 	 lr: 0.00008
[epoch 159: 180/307] 	 train loss: 0.272311 	 lr: 0.00008
[epoch 159: 200/307] 	 train loss: 0.228991 	 lr: 0.00008
[epoch 159: 220/307] 	 train loss: 0.079162 	 lr: 0.00008
[epoch 159: 240/307] 	 train loss: 0.202252 	 lr: 0.00008
[epoch 159: 260/307] 	 train loss: 0.103698 	 lr: 0.00008
[epoch 159: 280/307] 	 train loss: 0.101266 	 lr: 0.00008

val loss: 0.341835 	 acc: 0.916126

[epoch 159: 300/307] 	 train loss: 0.095854 	 lr: 0.00008
[epoch 160:   0/307] 	 train loss: 0.162221 	 lr: 0.00008
[epoch 160:  20/307] 	 train loss: 0.073721 	 lr: 0.00008
[epoch 160:  40/307] 	 train loss: 0.074714 	 lr: 0.00008
[epoch 160:  60/307] 	 train loss: 0.046216 	 lr: 0.00008
[epoch 160:  80/307] 	 train loss: 0.274534 	 lr: 0.00008
[epoch 160: 100/307] 	 train loss: 0.045901 	 lr: 0.00008
[epoch 160: 120/307] 	 train loss: 0.274946 	 lr: 0.00008
[epoch 160: 140/307] 	 train loss: 0.020245 	 lr: 0.00008

val loss: 0.341394 	 acc: 0.909238

[epoch 160: 160/307] 	 train loss: 0.095058 	 lr: 0.00008
[epoch 160: 180/307] 	 train loss: 0.162586 	 lr: 0.00008
[epoch 160: 200/307] 	 train loss: 0.071249 	 lr: 0.00008
[epoch 160: 220/307] 	 train loss: 0.297399 	 lr: 0.00008
[epoch 160: 240/307] 	 train loss: 0.118079 	 lr: 0.00008
[epoch 160: 260/307] 	 train loss: 0.134090 	 lr: 0.00008
[epoch 160: 280/307] 	 train loss: 0.086518 	 lr: 0.00008

val loss: 0.334264 	 acc: 0.909643

[epoch 160: 300/307] 	 train loss: 0.259230 	 lr: 0.00008
[epoch 161:   0/307] 	 train loss: 0.165531 	 lr: 0.00008
[epoch 161:  20/307] 	 train loss: 0.027033 	 lr: 0.00008
[epoch 161:  40/307] 	 train loss: 0.073852 	 lr: 0.00008
[epoch 161:  60/307] 	 train loss: 0.048865 	 lr: 0.00008
[epoch 161:  80/307] 	 train loss: 0.058235 	 lr: 0.00008
[epoch 161: 100/307] 	 train loss: 0.405902 	 lr: 0.00008
[epoch 161: 120/307] 	 train loss: 0.138464 	 lr: 0.00008

val loss: 0.342981 	 acc: 0.909643

[epoch 161: 140/307] 	 train loss: 0.126216 	 lr: 0.00008
[epoch 161: 160/307] 	 train loss: 0.133660 	 lr: 0.00008
[epoch 161: 180/307] 	 train loss: 0.180053 	 lr: 0.00008
[epoch 161: 200/307] 	 train loss: 0.326951 	 lr: 0.00008
[epoch 161: 220/307] 	 train loss: 0.109599 	 lr: 0.00008
[epoch 161: 240/307] 	 train loss: 0.142819 	 lr: 0.00008
[epoch 161: 260/307] 	 train loss: 0.055477 	 lr: 0.00008
[epoch 161: 280/307] 	 train loss: 0.087727 	 lr: 0.00008

val loss: 0.360964 	 acc: 0.910454

[epoch 161: 300/307] 	 train loss: 0.128536 	 lr: 0.00008
[epoch 162:   0/307] 	 train loss: 0.070168 	 lr: 0.00008
[epoch 162:  20/307] 	 train loss: 0.076010 	 lr: 0.00008
[epoch 162:  40/307] 	 train loss: 0.030678 	 lr: 0.00008
[epoch 162:  60/307] 	 train loss: 0.290978 	 lr: 0.00008
[epoch 162:  80/307] 	 train loss: 0.083528 	 lr: 0.00008
[epoch 162: 100/307] 	 train loss: 0.123664 	 lr: 0.00008
[epoch 162: 120/307] 	 train loss: 0.138764 	 lr: 0.00008

val loss: 0.344249 	 acc: 0.910049

[epoch 162: 140/307] 	 train loss: 0.146009 	 lr: 0.00008
[epoch 162: 160/307] 	 train loss: 0.219832 	 lr: 0.00008
[epoch 162: 180/307] 	 train loss: 0.049158 	 lr: 0.00008
[epoch 162: 200/307] 	 train loss: 0.085006 	 lr: 0.00008
[epoch 162: 220/307] 	 train loss: 0.146557 	 lr: 0.00008
[epoch 162: 240/307] 	 train loss: 0.275517 	 lr: 0.00008
[epoch 162: 260/307] 	 train loss: 0.197037 	 lr: 0.00008
[epoch 162: 280/307] 	 train loss: 0.176960 	 lr: 0.00008

val loss: 0.343025 	 acc: 0.910049

[epoch 162: 300/307] 	 train loss: 0.194492 	 lr: 0.00008
[epoch 163:   0/307] 	 train loss: 0.224667 	 lr: 0.00008
[epoch 163:  20/307] 	 train loss: 0.112314 	 lr: 0.00008
[epoch 163:  40/307] 	 train loss: 0.031597 	 lr: 0.00008
[epoch 163:  60/307] 	 train loss: 0.121617 	 lr: 0.00008
[epoch 163:  80/307] 	 train loss: 0.088922 	 lr: 0.00008
[epoch 163: 100/307] 	 train loss: 0.197943 	 lr: 0.00008
[epoch 163: 120/307] 	 train loss: 0.027302 	 lr: 0.00008

val loss: 0.355708 	 acc: 0.912075

[epoch 163: 140/307] 	 train loss: 0.006159 	 lr: 0.00008
[epoch 163: 160/307] 	 train loss: 0.140838 	 lr: 0.00008
[epoch 163: 180/307] 	 train loss: 0.154485 	 lr: 0.00008
[epoch 163: 200/307] 	 train loss: 0.154874 	 lr: 0.00008
[epoch 163: 220/307] 	 train loss: 0.070593 	 lr: 0.00008
[epoch 163: 240/307] 	 train loss: 0.099832 	 lr: 0.00008
[epoch 163: 260/307] 	 train loss: 0.235816 	 lr: 0.00008
[epoch 163: 280/307] 	 train loss: 0.081532 	 lr: 0.00008

val loss: 0.347766 	 acc: 0.912075

[epoch 163: 300/307] 	 train loss: 0.068371 	 lr: 0.00008
[epoch 164:   0/307] 	 train loss: 0.137392 	 lr: 0.00008
[epoch 164:  20/307] 	 train loss: 0.196788 	 lr: 0.00008
[epoch 164:  40/307] 	 train loss: 0.085897 	 lr: 0.00008
[epoch 164:  60/307] 	 train loss: 0.048359 	 lr: 0.00008
[epoch 164:  80/307] 	 train loss: 0.096293 	 lr: 0.00008
[epoch 164: 100/307] 	 train loss: 0.241881 	 lr: 0.00008
[epoch 164: 120/307] 	 train loss: 0.380271 	 lr: 0.00008

val loss: 0.359505 	 acc: 0.909643

[epoch 164: 140/307] 	 train loss: 0.051390 	 lr: 0.00008
[epoch 164: 160/307] 	 train loss: 0.048175 	 lr: 0.00008
[epoch 164: 180/307] 	 train loss: 0.208115 	 lr: 0.00008
[epoch 164: 200/307] 	 train loss: 0.209037 	 lr: 0.00008
[epoch 164: 220/307] 	 train loss: 0.106857 	 lr: 0.00008
[epoch 164: 240/307] 	 train loss: 0.187324 	 lr: 0.00008
[epoch 164: 260/307] 	 train loss: 0.037617 	 lr: 0.00008
[epoch 164: 280/307] 	 train loss: 0.088570 	 lr: 0.00008

val loss: 0.348577 	 acc: 0.911264

[epoch 164: 300/307] 	 train loss: 0.214397 	 lr: 0.00008
[epoch 165:   0/307] 	 train loss: 0.019868 	 lr: 0.00008
[epoch 165:  20/307] 	 train loss: 0.090930 	 lr: 0.00008
[epoch 165:  40/307] 	 train loss: 0.088382 	 lr: 0.00008
[epoch 165:  60/307] 	 train loss: 0.155428 	 lr: 0.00008
[epoch 165:  80/307] 	 train loss: 0.312526 	 lr: 0.00008
[epoch 165: 100/307] 	 train loss: 0.081421 	 lr: 0.00008
[epoch 165: 120/307] 	 train loss: 0.105393 	 lr: 0.00008

val loss: 0.337087 	 acc: 0.917342

[epoch 165: 140/307] 	 train loss: 0.225961 	 lr: 0.00008
[epoch 165: 160/307] 	 train loss: 0.333980 	 lr: 0.00008
[epoch 165: 180/307] 	 train loss: 0.099726 	 lr: 0.00008
[epoch 165: 200/307] 	 train loss: 0.123687 	 lr: 0.00008
[epoch 165: 220/307] 	 train loss: 0.178070 	 lr: 0.00008
[epoch 165: 240/307] 	 train loss: 0.160472 	 lr: 0.00008
[epoch 165: 260/307] 	 train loss: 0.303844 	 lr: 0.00008
[epoch 165: 280/307] 	 train loss: 0.096958 	 lr: 0.00008

val loss: 0.349522 	 acc: 0.910454

[epoch 165: 300/307] 	 train loss: 0.016400 	 lr: 0.00008
[epoch 166:   0/307] 	 train loss: 0.214451 	 lr: 0.00008
[epoch 166:  20/307] 	 train loss: 0.073722 	 lr: 0.00008
[epoch 166:  40/307] 	 train loss: 0.443102 	 lr: 0.00008
[epoch 166:  60/307] 	 train loss: 0.111716 	 lr: 0.00008
[epoch 166:  80/307] 	 train loss: 0.152446 	 lr: 0.00008
[epoch 166: 100/307] 	 train loss: 0.288730 	 lr: 0.00008
[epoch 166: 120/307] 	 train loss: 0.543588 	 lr: 0.00008

val loss: 0.343535 	 acc: 0.908428

[epoch 166: 140/307] 	 train loss: 0.113325 	 lr: 0.00008
[epoch 166: 160/307] 	 train loss: 0.178236 	 lr: 0.00008
[epoch 166: 180/307] 	 train loss: 0.216328 	 lr: 0.00008
[epoch 166: 200/307] 	 train loss: 0.060029 	 lr: 0.00008
[epoch 166: 220/307] 	 train loss: 0.019491 	 lr: 0.00008
[epoch 166: 240/307] 	 train loss: 0.178230 	 lr: 0.00008
[epoch 166: 260/307] 	 train loss: 0.173764 	 lr: 0.00008
[epoch 166: 280/307] 	 train loss: 0.110947 	 lr: 0.00008

val loss: 0.336712 	 acc: 0.909643

[epoch 166: 300/307] 	 train loss: 0.112245 	 lr: 0.00008
[epoch 167:   0/307] 	 train loss: 0.065880 	 lr: 0.00008
[epoch 167:  20/307] 	 train loss: 0.191022 	 lr: 0.00008
[epoch 167:  40/307] 	 train loss: 0.190817 	 lr: 0.00008
[epoch 167:  60/307] 	 train loss: 0.158989 	 lr: 0.00008
[epoch 167:  80/307] 	 train loss: 0.174499 	 lr: 0.00008
[epoch 167: 100/307] 	 train loss: 0.139198 	 lr: 0.00008
[epoch 167: 120/307] 	 train loss: 0.051596 	 lr: 0.00008

val loss: 0.347185 	 acc: 0.913695

[epoch 167: 140/307] 	 train loss: 0.110754 	 lr: 0.00008
[epoch 167: 160/307] 	 train loss: 0.134503 	 lr: 0.00008
[epoch 167: 180/307] 	 train loss: 0.206264 	 lr: 0.00008
[epoch 167: 200/307] 	 train loss: 0.119770 	 lr: 0.00008
[epoch 167: 220/307] 	 train loss: 0.293936 	 lr: 0.00008
[epoch 167: 240/307] 	 train loss: 0.035537 	 lr: 0.00008
[epoch 167: 260/307] 	 train loss: 0.043224 	 lr: 0.00008

val loss: 0.351037 	 acc: 0.908023

[epoch 167: 280/307] 	 train loss: 0.293423 	 lr: 0.00008
[epoch 167: 300/307] 	 train loss: 0.132306 	 lr: 0.00008
[epoch 168:   0/307] 	 train loss: 0.024335 	 lr: 0.00008
[epoch 168:  20/307] 	 train loss: 0.141323 	 lr: 0.00008
[epoch 168:  40/307] 	 train loss: 0.036265 	 lr: 0.00008
[epoch 168:  60/307] 	 train loss: 0.243143 	 lr: 0.00008
[epoch 168:  80/307] 	 train loss: 0.175624 	 lr: 0.00008
[epoch 168: 100/307] 	 train loss: 0.112648 	 lr: 0.00008
[epoch 168: 120/307] 	 train loss: 0.146814 	 lr: 0.00008

val loss: 0.337997 	 acc: 0.906402

[epoch 168: 140/307] 	 train loss: 0.168173 	 lr: 0.00008
[epoch 168: 160/307] 	 train loss: 0.156652 	 lr: 0.00008
[epoch 168: 180/307] 	 train loss: 0.072024 	 lr: 0.00008
[epoch 168: 200/307] 	 train loss: 0.192942 	 lr: 0.00008
[epoch 168: 220/307] 	 train loss: 0.023910 	 lr: 0.00008
[epoch 168: 240/307] 	 train loss: 0.105536 	 lr: 0.00008
[epoch 168: 260/307] 	 train loss: 0.072642 	 lr: 0.00008

val loss: 0.335313 	 acc: 0.913290

[epoch 168: 280/307] 	 train loss: 0.117134 	 lr: 0.00008
[epoch 168: 300/307] 	 train loss: 0.125077 	 lr: 0.00008
[epoch 169:   0/307] 	 train loss: 0.070389 	 lr: 0.00006
[epoch 169:  20/307] 	 train loss: 0.243368 	 lr: 0.00006
[epoch 169:  40/307] 	 train loss: 0.020500 	 lr: 0.00006
[epoch 169:  60/307] 	 train loss: 0.167408 	 lr: 0.00006
[epoch 169:  80/307] 	 train loss: 0.170941 	 lr: 0.00006
[epoch 169: 100/307] 	 train loss: 0.112704 	 lr: 0.00006
[epoch 169: 120/307] 	 train loss: 0.101146 	 lr: 0.00006

val loss: 0.344770 	 acc: 0.911264

[epoch 169: 140/307] 	 train loss: 0.100079 	 lr: 0.00006
[epoch 169: 160/307] 	 train loss: 0.043707 	 lr: 0.00006
[epoch 169: 180/307] 	 train loss: 0.480333 	 lr: 0.00006
[epoch 169: 200/307] 	 train loss: 0.172415 	 lr: 0.00006
[epoch 169: 220/307] 	 train loss: 0.097378 	 lr: 0.00006
[epoch 169: 240/307] 	 train loss: 0.360532 	 lr: 0.00006
[epoch 169: 260/307] 	 train loss: 0.219955 	 lr: 0.00006

val loss: 0.341220 	 acc: 0.914506

[epoch 169: 280/307] 	 train loss: 0.116215 	 lr: 0.00006
[epoch 169: 300/307] 	 train loss: 0.225996 	 lr: 0.00006
[epoch 170:   0/307] 	 train loss: 0.309291 	 lr: 0.00006
[epoch 170:  20/307] 	 train loss: 0.230606 	 lr: 0.00006
[epoch 170:  40/307] 	 train loss: 0.232549 	 lr: 0.00006
[epoch 170:  60/307] 	 train loss: 0.088115 	 lr: 0.00006
[epoch 170:  80/307] 	 train loss: 0.283817 	 lr: 0.00006
[epoch 170: 100/307] 	 train loss: 0.225676 	 lr: 0.00006
[epoch 170: 120/307] 	 train loss: 0.069986 	 lr: 0.00006

val loss: 0.349181 	 acc: 0.910454

[epoch 170: 140/307] 	 train loss: 0.288716 	 lr: 0.00006
[epoch 170: 160/307] 	 train loss: 0.154933 	 lr: 0.00006
[epoch 170: 180/307] 	 train loss: 0.039438 	 lr: 0.00006
[epoch 170: 200/307] 	 train loss: 0.304483 	 lr: 0.00006
[epoch 170: 220/307] 	 train loss: 0.181367 	 lr: 0.00006
[epoch 170: 240/307] 	 train loss: 0.222985 	 lr: 0.00006
[epoch 170: 260/307] 	 train loss: 0.154868 	 lr: 0.00006

val loss: 0.335626 	 acc: 0.912075

[epoch 170: 280/307] 	 train loss: 0.187647 	 lr: 0.00006
[epoch 170: 300/307] 	 train loss: 0.455483 	 lr: 0.00006
[epoch 171:   0/307] 	 train loss: 0.075357 	 lr: 0.00006
[epoch 171:  20/307] 	 train loss: 0.061400 	 lr: 0.00006
[epoch 171:  40/307] 	 train loss: 0.170368 	 lr: 0.00006
[epoch 171:  60/307] 	 train loss: 0.176594 	 lr: 0.00006
[epoch 171:  80/307] 	 train loss: 0.110394 	 lr: 0.00006
[epoch 171: 100/307] 	 train loss: 0.223642 	 lr: 0.00006

val loss: 0.331450 	 acc: 0.914100

[epoch 171: 120/307] 	 train loss: 0.288905 	 lr: 0.00006
[epoch 171: 140/307] 	 train loss: 0.188432 	 lr: 0.00006
[epoch 171: 160/307] 	 train loss: 0.055459 	 lr: 0.00006
[epoch 171: 180/307] 	 train loss: 0.116593 	 lr: 0.00006
[epoch 171: 200/307] 	 train loss: 0.124948 	 lr: 0.00006
[epoch 171: 220/307] 	 train loss: 0.259016 	 lr: 0.00006
[epoch 171: 240/307] 	 train loss: 0.413438 	 lr: 0.00006
[epoch 171: 260/307] 	 train loss: 0.137938 	 lr: 0.00006

val loss: 0.359863 	 acc: 0.912480

[epoch 171: 280/307] 	 train loss: 0.111496 	 lr: 0.00006
[epoch 171: 300/307] 	 train loss: 0.242414 	 lr: 0.00006
[epoch 172:   0/307] 	 train loss: 0.091087 	 lr: 0.00006
[epoch 172:  20/307] 	 train loss: 0.043161 	 lr: 0.00006
[epoch 172:  40/307] 	 train loss: 0.110836 	 lr: 0.00006
[epoch 172:  60/307] 	 train loss: 0.084453 	 lr: 0.00006
[epoch 172:  80/307] 	 train loss: 0.245256 	 lr: 0.00006
[epoch 172: 100/307] 	 train loss: 0.092837 	 lr: 0.00006

val loss: 0.349664 	 acc: 0.908833

[epoch 172: 120/307] 	 train loss: 0.220625 	 lr: 0.00006
[epoch 172: 140/307] 	 train loss: 0.148888 	 lr: 0.00006
[epoch 172: 160/307] 	 train loss: 0.267823 	 lr: 0.00006
[epoch 172: 180/307] 	 train loss: 0.205961 	 lr: 0.00006
[epoch 172: 200/307] 	 train loss: 0.190541 	 lr: 0.00006
[epoch 172: 220/307] 	 train loss: 0.188248 	 lr: 0.00006
[epoch 172: 240/307] 	 train loss: 0.101455 	 lr: 0.00006
[epoch 172: 260/307] 	 train loss: 0.133564 	 lr: 0.00006

val loss: 0.328537 	 acc: 0.915316

[epoch 172: 280/307] 	 train loss: 0.063280 	 lr: 0.00006
[epoch 172: 300/307] 	 train loss: 0.074581 	 lr: 0.00006
[epoch 173:   0/307] 	 train loss: 0.253371 	 lr: 0.00006
[epoch 173:  20/307] 	 train loss: 0.091694 	 lr: 0.00006
[epoch 173:  40/307] 	 train loss: 0.154948 	 lr: 0.00006
[epoch 173:  60/307] 	 train loss: 0.280050 	 lr: 0.00006
[epoch 173:  80/307] 	 train loss: 0.066306 	 lr: 0.00006
[epoch 173: 100/307] 	 train loss: 0.125896 	 lr: 0.00006

val loss: 0.338021 	 acc: 0.916532

[epoch 173: 120/307] 	 train loss: 0.108065 	 lr: 0.00006
[epoch 173: 140/307] 	 train loss: 0.169623 	 lr: 0.00006
[epoch 173: 160/307] 	 train loss: 0.317028 	 lr: 0.00006
[epoch 173: 180/307] 	 train loss: 0.195304 	 lr: 0.00006
[epoch 173: 200/307] 	 train loss: 0.087195 	 lr: 0.00006
[epoch 173: 220/307] 	 train loss: 0.155571 	 lr: 0.00006
[epoch 173: 240/307] 	 train loss: 0.021866 	 lr: 0.00006
[epoch 173: 260/307] 	 train loss: 0.179794 	 lr: 0.00006

val loss: 0.344383 	 acc: 0.916126

[epoch 173: 280/307] 	 train loss: 0.182021 	 lr: 0.00006
[epoch 173: 300/307] 	 train loss: 0.077068 	 lr: 0.00006
[epoch 174:   0/307] 	 train loss: 0.121502 	 lr: 0.00006
[epoch 174:  20/307] 	 train loss: 0.267120 	 lr: 0.00006
[epoch 174:  40/307] 	 train loss: 0.205508 	 lr: 0.00006
[epoch 174:  60/307] 	 train loss: 0.028531 	 lr: 0.00006
[epoch 174:  80/307] 	 train loss: 0.121741 	 lr: 0.00006
[epoch 174: 100/307] 	 train loss: 0.069206 	 lr: 0.00006

val loss: 0.342809 	 acc: 0.907618

[epoch 174: 120/307] 	 train loss: 0.179928 	 lr: 0.00006
[epoch 174: 140/307] 	 train loss: 0.136286 	 lr: 0.00006
[epoch 174: 160/307] 	 train loss: 0.086927 	 lr: 0.00006
[epoch 174: 180/307] 	 train loss: 0.036574 	 lr: 0.00006
[epoch 174: 200/307] 	 train loss: 0.079135 	 lr: 0.00006
[epoch 174: 220/307] 	 train loss: 0.120040 	 lr: 0.00006
[epoch 174: 240/307] 	 train loss: 0.157859 	 lr: 0.00006
[epoch 174: 260/307] 	 train loss: 0.134906 	 lr: 0.00006

val loss: 0.358042 	 acc: 0.910454

[epoch 174: 280/307] 	 train loss: 0.037790 	 lr: 0.00006
[epoch 174: 300/307] 	 train loss: 0.130257 	 lr: 0.00006
[epoch 175:   0/307] 	 train loss: 0.116908 	 lr: 0.00006
[epoch 175:  20/307] 	 train loss: 0.064207 	 lr: 0.00006
[epoch 175:  40/307] 	 train loss: 0.079651 	 lr: 0.00006
[epoch 175:  60/307] 	 train loss: 0.155756 	 lr: 0.00006
[epoch 175:  80/307] 	 train loss: 0.114169 	 lr: 0.00006
[epoch 175: 100/307] 	 train loss: 0.195784 	 lr: 0.00006

val loss: 0.350086 	 acc: 0.911264

[epoch 175: 120/307] 	 train loss: 0.190391 	 lr: 0.00006
[epoch 175: 140/307] 	 train loss: 0.326660 	 lr: 0.00006
[epoch 175: 160/307] 	 train loss: 0.213572 	 lr: 0.00006
[epoch 175: 180/307] 	 train loss: 0.124640 	 lr: 0.00006
[epoch 175: 200/307] 	 train loss: 0.018106 	 lr: 0.00006
[epoch 175: 220/307] 	 train loss: 0.168665 	 lr: 0.00006
[epoch 175: 240/307] 	 train loss: 0.106135 	 lr: 0.00006
[epoch 175: 260/307] 	 train loss: 0.095189 	 lr: 0.00006

val loss: 0.334216 	 acc: 0.913290

[epoch 175: 280/307] 	 train loss: 0.155743 	 lr: 0.00006
[epoch 175: 300/307] 	 train loss: 0.180187 	 lr: 0.00006
[epoch 176:   0/307] 	 train loss: 0.040866 	 lr: 0.00006
[epoch 176:  20/307] 	 train loss: 0.023116 	 lr: 0.00006
[epoch 176:  40/307] 	 train loss: 0.096890 	 lr: 0.00006
[epoch 176:  60/307] 	 train loss: 0.093462 	 lr: 0.00006
[epoch 176:  80/307] 	 train loss: 0.062529 	 lr: 0.00006
[epoch 176: 100/307] 	 train loss: 0.029823 	 lr: 0.00006

val loss: 0.336987 	 acc: 0.913290

[epoch 176: 120/307] 	 train loss: 0.079862 	 lr: 0.00006
[epoch 176: 140/307] 	 train loss: 0.366849 	 lr: 0.00006
[epoch 176: 160/307] 	 train loss: 0.043810 	 lr: 0.00006
[epoch 176: 180/307] 	 train loss: 0.110211 	 lr: 0.00006
[epoch 176: 200/307] 	 train loss: 0.072857 	 lr: 0.00006
[epoch 176: 220/307] 	 train loss: 0.096261 	 lr: 0.00006
[epoch 176: 240/307] 	 train loss: 0.098234 	 lr: 0.00006
[epoch 176: 260/307] 	 train loss: 0.095688 	 lr: 0.00006

val loss: 0.332363 	 acc: 0.917342

[epoch 176: 280/307] 	 train loss: 0.344447 	 lr: 0.00006
[epoch 176: 300/307] 	 train loss: 0.129896 	 lr: 0.00006
[epoch 177:   0/307] 	 train loss: 0.059278 	 lr: 0.00006
[epoch 177:  20/307] 	 train loss: 0.278904 	 lr: 0.00006
[epoch 177:  40/307] 	 train loss: 0.150312 	 lr: 0.00006
[epoch 177:  60/307] 	 train loss: 0.142964 	 lr: 0.00006
[epoch 177:  80/307] 	 train loss: 0.337577 	 lr: 0.00006
[epoch 177: 100/307] 	 train loss: 0.266412 	 lr: 0.00006

val loss: 0.358074 	 acc: 0.912480

[epoch 177: 120/307] 	 train loss: 0.182541 	 lr: 0.00006
[epoch 177: 140/307] 	 train loss: 0.126772 	 lr: 0.00006
[epoch 177: 160/307] 	 train loss: 0.105081 	 lr: 0.00006
[epoch 177: 180/307] 	 train loss: 0.356015 	 lr: 0.00006
[epoch 177: 200/307] 	 train loss: 0.052409 	 lr: 0.00006
[epoch 177: 220/307] 	 train loss: 0.126718 	 lr: 0.00006
[epoch 177: 240/307] 	 train loss: 0.123855 	 lr: 0.00006

val loss: 0.327693 	 acc: 0.915721

[epoch 177: 260/307] 	 train loss: 0.145218 	 lr: 0.00006
[epoch 177: 280/307] 	 train loss: 0.138405 	 lr: 0.00006
[epoch 177: 300/307] 	 train loss: 0.090803 	 lr: 0.00006
[epoch 178:   0/307] 	 train loss: 0.337511 	 lr: 0.00006
[epoch 178:  20/307] 	 train loss: 0.320476 	 lr: 0.00006
[epoch 178:  40/307] 	 train loss: 0.218613 	 lr: 0.00006
[epoch 178:  60/307] 	 train loss: 0.031152 	 lr: 0.00006
[epoch 178:  80/307] 	 train loss: 0.124366 	 lr: 0.00006
[epoch 178: 100/307] 	 train loss: 0.142232 	 lr: 0.00006

val loss: 0.353035 	 acc: 0.912075

[epoch 178: 120/307] 	 train loss: 0.075629 	 lr: 0.00006
[epoch 178: 140/307] 	 train loss: 0.042531 	 lr: 0.00006
[epoch 178: 160/307] 	 train loss: 0.143130 	 lr: 0.00006
[epoch 178: 180/307] 	 train loss: 0.063019 	 lr: 0.00006
[epoch 178: 200/307] 	 train loss: 0.347675 	 lr: 0.00006
[epoch 178: 220/307] 	 train loss: 0.237116 	 lr: 0.00006
[epoch 178: 240/307] 	 train loss: 0.098836 	 lr: 0.00006

val loss: 0.343869 	 acc: 0.914506

[epoch 178: 260/307] 	 train loss: 0.052846 	 lr: 0.00006
[epoch 178: 280/307] 	 train loss: 0.063522 	 lr: 0.00006
[epoch 178: 300/307] 	 train loss: 0.086481 	 lr: 0.00006
[epoch 179:   0/307] 	 train loss: 0.149682 	 lr: 0.00006
[epoch 179:  20/307] 	 train loss: 0.323236 	 lr: 0.00006
[epoch 179:  40/307] 	 train loss: 0.253122 	 lr: 0.00006
[epoch 179:  60/307] 	 train loss: 0.111604 	 lr: 0.00006
[epoch 179:  80/307] 	 train loss: 0.044343 	 lr: 0.00006
[epoch 179: 100/307] 	 train loss: 0.482569 	 lr: 0.00006

val loss: 0.348234 	 acc: 0.906402

[epoch 179: 120/307] 	 train loss: 0.527029 	 lr: 0.00006
[epoch 179: 140/307] 	 train loss: 0.226368 	 lr: 0.00006
[epoch 179: 160/307] 	 train loss: 0.142451 	 lr: 0.00006
[epoch 179: 180/307] 	 train loss: 0.044823 	 lr: 0.00006
[epoch 179: 200/307] 	 train loss: 0.109766 	 lr: 0.00006
[epoch 179: 220/307] 	 train loss: 0.102229 	 lr: 0.00006
[epoch 179: 240/307] 	 train loss: 0.183777 	 lr: 0.00006

val loss: 0.330741 	 acc: 0.910454

[epoch 179: 260/307] 	 train loss: 0.249914 	 lr: 0.00006
[epoch 179: 280/307] 	 train loss: 0.054115 	 lr: 0.00006
[epoch 179: 300/307] 	 train loss: 0.153418 	 lr: 0.00006
[epoch 180:   0/307] 	 train loss: 0.239327 	 lr: 0.00006
[epoch 180:  20/307] 	 train loss: 0.104068 	 lr: 0.00006
[epoch 180:  40/307] 	 train loss: 0.202252 	 lr: 0.00006
[epoch 180:  60/307] 	 train loss: 0.076527 	 lr: 0.00006
[epoch 180:  80/307] 	 train loss: 0.076260 	 lr: 0.00006
[epoch 180: 100/307] 	 train loss: 0.178603 	 lr: 0.00006

val loss: 0.330600 	 acc: 0.917342

[epoch 180: 120/307] 	 train loss: 0.016450 	 lr: 0.00006
[epoch 180: 140/307] 	 train loss: 0.132681 	 lr: 0.00006
[epoch 180: 160/307] 	 train loss: 0.470626 	 lr: 0.00006
[epoch 180: 180/307] 	 train loss: 0.148277 	 lr: 0.00006
[epoch 180: 200/307] 	 train loss: 0.036043 	 lr: 0.00006
[epoch 180: 220/307] 	 train loss: 0.132439 	 lr: 0.00006
[epoch 180: 240/307] 	 train loss: 0.103753 	 lr: 0.00006

val loss: 0.361789 	 acc: 0.908428

[epoch 180: 260/307] 	 train loss: 0.057152 	 lr: 0.00006
[epoch 180: 280/307] 	 train loss: 0.054244 	 lr: 0.00006
[epoch 180: 300/307] 	 train loss: 0.286521 	 lr: 0.00006
[epoch 181:   0/307] 	 train loss: 0.040552 	 lr: 0.00006
[epoch 181:  20/307] 	 train loss: 0.115818 	 lr: 0.00006
[epoch 181:  40/307] 	 train loss: 0.096923 	 lr: 0.00006
[epoch 181:  60/307] 	 train loss: 0.185616 	 lr: 0.00006
[epoch 181:  80/307] 	 train loss: 0.302357 	 lr: 0.00006

val loss: 0.349543 	 acc: 0.912885

[epoch 181: 100/307] 	 train loss: 0.180845 	 lr: 0.00006
[epoch 181: 120/307] 	 train loss: 0.175377 	 lr: 0.00006
[epoch 181: 140/307] 	 train loss: 0.144447 	 lr: 0.00006
[epoch 181: 160/307] 	 train loss: 0.195735 	 lr: 0.00006
[epoch 181: 180/307] 	 train loss: 0.101678 	 lr: 0.00006
[epoch 181: 200/307] 	 train loss: 0.048777 	 lr: 0.00006
[epoch 181: 220/307] 	 train loss: 0.196446 	 lr: 0.00006
[epoch 181: 240/307] 	 train loss: 0.048803 	 lr: 0.00006

val loss: 0.331859 	 acc: 0.910859

[epoch 181: 260/307] 	 train loss: 0.183708 	 lr: 0.00006
[epoch 181: 280/307] 	 train loss: 0.160768 	 lr: 0.00006
[epoch 181: 300/307] 	 train loss: 0.277128 	 lr: 0.00006
[epoch 182:   0/307] 	 train loss: 0.053029 	 lr: 0.00006
[epoch 182:  20/307] 	 train loss: 0.239149 	 lr: 0.00006
[epoch 182:  40/307] 	 train loss: 0.091678 	 lr: 0.00006
[epoch 182:  60/307] 	 train loss: 0.117432 	 lr: 0.00006
[epoch 182:  80/307] 	 train loss: 0.285764 	 lr: 0.00006

val loss: 0.339613 	 acc: 0.908833

[epoch 182: 100/307] 	 train loss: 0.119725 	 lr: 0.00006
[epoch 182: 120/307] 	 train loss: 0.034836 	 lr: 0.00006
[epoch 182: 140/307] 	 train loss: 0.038025 	 lr: 0.00006
[epoch 182: 160/307] 	 train loss: 0.241451 	 lr: 0.00006
[epoch 182: 180/307] 	 train loss: 0.091336 	 lr: 0.00006
[epoch 182: 200/307] 	 train loss: 0.107750 	 lr: 0.00006
[epoch 182: 220/307] 	 train loss: 0.112715 	 lr: 0.00006
[epoch 182: 240/307] 	 train loss: 0.041360 	 lr: 0.00006

val loss: 0.330930 	 acc: 0.911264

[epoch 182: 260/307] 	 train loss: 0.083486 	 lr: 0.00006
[epoch 182: 280/307] 	 train loss: 0.200363 	 lr: 0.00006
[epoch 182: 300/307] 	 train loss: 0.039201 	 lr: 0.00006
[epoch 183:   0/307] 	 train loss: 0.093940 	 lr: 0.00006
[epoch 183:  20/307] 	 train loss: 0.088619 	 lr: 0.00006
[epoch 183:  40/307] 	 train loss: 0.136536 	 lr: 0.00006
[epoch 183:  60/307] 	 train loss: 0.159734 	 lr: 0.00006
[epoch 183:  80/307] 	 train loss: 0.255519 	 lr: 0.00006

val loss: 0.335324 	 acc: 0.910859

[epoch 183: 100/307] 	 train loss: 0.528663 	 lr: 0.00006
[epoch 183: 120/307] 	 train loss: 0.364922 	 lr: 0.00006
[epoch 183: 140/307] 	 train loss: 0.130991 	 lr: 0.00006
[epoch 183: 160/307] 	 train loss: 0.153609 	 lr: 0.00006
[epoch 183: 180/307] 	 train loss: 0.124962 	 lr: 0.00006
[epoch 183: 200/307] 	 train loss: 0.259561 	 lr: 0.00006
[epoch 183: 220/307] 	 train loss: 0.057701 	 lr: 0.00006
[epoch 183: 240/307] 	 train loss: 0.133014 	 lr: 0.00006

val loss: 0.340841 	 acc: 0.915721

[epoch 183: 260/307] 	 train loss: 0.124944 	 lr: 0.00006
[epoch 183: 280/307] 	 train loss: 0.119024 	 lr: 0.00006
[epoch 183: 300/307] 	 train loss: 0.209459 	 lr: 0.00006
[epoch 184:   0/307] 	 train loss: 0.156972 	 lr: 0.00006
[epoch 184:  20/307] 	 train loss: 0.108193 	 lr: 0.00006
[epoch 184:  40/307] 	 train loss: 0.120122 	 lr: 0.00006
[epoch 184:  60/307] 	 train loss: 0.187183 	 lr: 0.00006
[epoch 184:  80/307] 	 train loss: 0.145209 	 lr: 0.00006

val loss: 0.351868 	 acc: 0.912480

[epoch 184: 100/307] 	 train loss: 0.130423 	 lr: 0.00006
[epoch 184: 120/307] 	 train loss: 0.188406 	 lr: 0.00006
[epoch 184: 140/307] 	 train loss: 0.111863 	 lr: 0.00006
[epoch 184: 160/307] 	 train loss: 0.051189 	 lr: 0.00006
[epoch 184: 180/307] 	 train loss: 0.064942 	 lr: 0.00006
[epoch 184: 200/307] 	 train loss: 0.058532 	 lr: 0.00006
[epoch 184: 220/307] 	 train loss: 0.133125 	 lr: 0.00006
[epoch 184: 240/307] 	 train loss: 0.297175 	 lr: 0.00006

val loss: 0.344695 	 acc: 0.917747

[epoch 184: 260/307] 	 train loss: 0.057486 	 lr: 0.00006
[epoch 184: 280/307] 	 train loss: 0.105921 	 lr: 0.00006
[epoch 184: 300/307] 	 train loss: 0.108952 	 lr: 0.00006
[epoch 185:   0/307] 	 train loss: 0.205629 	 lr: 0.00006
[epoch 185:  20/307] 	 train loss: 0.117335 	 lr: 0.00006
[epoch 185:  40/307] 	 train loss: 0.348172 	 lr: 0.00006
[epoch 185:  60/307] 	 train loss: 0.163445 	 lr: 0.00006
[epoch 185:  80/307] 	 train loss: 0.186430 	 lr: 0.00006

val loss: 0.322799 	 acc: 0.912480

[epoch 185: 100/307] 	 train loss: 0.177679 	 lr: 0.00006
[epoch 185: 120/307] 	 train loss: 0.236104 	 lr: 0.00006
[epoch 185: 140/307] 	 train loss: 0.054781 	 lr: 0.00006
[epoch 185: 160/307] 	 train loss: 0.045077 	 lr: 0.00006
[epoch 185: 180/307] 	 train loss: 0.085523 	 lr: 0.00006
[epoch 185: 200/307] 	 train loss: 0.062624 	 lr: 0.00006
[epoch 185: 220/307] 	 train loss: 0.217495 	 lr: 0.00006
[epoch 185: 240/307] 	 train loss: 0.133631 	 lr: 0.00006

val loss: 0.347554 	 acc: 0.916937

[epoch 185: 260/307] 	 train loss: 0.307193 	 lr: 0.00006
[epoch 185: 280/307] 	 train loss: 0.082427 	 lr: 0.00006
[epoch 185: 300/307] 	 train loss: 0.027374 	 lr: 0.00006
[epoch 186:   0/307] 	 train loss: 0.279405 	 lr: 0.00006
[epoch 186:  20/307] 	 train loss: 0.265025 	 lr: 0.00006
[epoch 186:  40/307] 	 train loss: 0.077442 	 lr: 0.00006
[epoch 186:  60/307] 	 train loss: 0.073506 	 lr: 0.00006
[epoch 186:  80/307] 	 train loss: 0.213827 	 lr: 0.00006

val loss: 0.346590 	 acc: 0.914100

[epoch 186: 100/307] 	 train loss: 0.235256 	 lr: 0.00006
[epoch 186: 120/307] 	 train loss: 0.087179 	 lr: 0.00006
[epoch 186: 140/307] 	 train loss: 0.147767 	 lr: 0.00006
[epoch 186: 160/307] 	 train loss: 0.075775 	 lr: 0.00006
[epoch 186: 180/307] 	 train loss: 0.105382 	 lr: 0.00006
[epoch 186: 200/307] 	 train loss: 0.378027 	 lr: 0.00006
[epoch 186: 220/307] 	 train loss: 0.036125 	 lr: 0.00006
[epoch 186: 240/307] 	 train loss: 0.060428 	 lr: 0.00006

val loss: 0.344952 	 acc: 0.910859

[epoch 186: 260/307] 	 train loss: 0.009740 	 lr: 0.00006
[epoch 186: 280/307] 	 train loss: 0.193365 	 lr: 0.00006
[epoch 186: 300/307] 	 train loss: 0.194632 	 lr: 0.00006
[epoch 187:   0/307] 	 train loss: 0.080540 	 lr: 0.00006
[epoch 187:  20/307] 	 train loss: 0.044897 	 lr: 0.00006
[epoch 187:  40/307] 	 train loss: 0.096711 	 lr: 0.00006
[epoch 187:  60/307] 	 train loss: 0.104272 	 lr: 0.00006
[epoch 187:  80/307] 	 train loss: 0.330717 	 lr: 0.00006

val loss: 0.361271 	 acc: 0.911264

[epoch 187: 100/307] 	 train loss: 0.063671 	 lr: 0.00006
[epoch 187: 120/307] 	 train loss: 0.129132 	 lr: 0.00006
[epoch 187: 140/307] 	 train loss: 0.084396 	 lr: 0.00006
[epoch 187: 160/307] 	 train loss: 0.114206 	 lr: 0.00006
[epoch 187: 180/307] 	 train loss: 0.100222 	 lr: 0.00006
[epoch 187: 200/307] 	 train loss: 0.117052 	 lr: 0.00006
[epoch 187: 220/307] 	 train loss: 0.234923 	 lr: 0.00006

val loss: 0.342406 	 acc: 0.913695

[epoch 187: 240/307] 	 train loss: 0.057437 	 lr: 0.00006
[epoch 187: 260/307] 	 train loss: 0.036621 	 lr: 0.00006
[epoch 187: 280/307] 	 train loss: 0.156088 	 lr: 0.00006
[epoch 187: 300/307] 	 train loss: 0.050975 	 lr: 0.00006
[epoch 188:   0/307] 	 train loss: 0.038008 	 lr: 0.00006
[epoch 188:  20/307] 	 train loss: 0.074115 	 lr: 0.00006
[epoch 188:  40/307] 	 train loss: 0.044205 	 lr: 0.00006
[epoch 188:  60/307] 	 train loss: 0.143298 	 lr: 0.00006
[epoch 188:  80/307] 	 train loss: 0.188188 	 lr: 0.00006

val loss: 0.340111 	 acc: 0.913290

[epoch 188: 100/307] 	 train loss: 0.299452 	 lr: 0.00006
[epoch 188: 120/307] 	 train loss: 0.214433 	 lr: 0.00006
[epoch 188: 140/307] 	 train loss: 0.238588 	 lr: 0.00006
[epoch 188: 160/307] 	 train loss: 0.251441 	 lr: 0.00006
[epoch 188: 180/307] 	 train loss: 0.098203 	 lr: 0.00006
[epoch 188: 200/307] 	 train loss: 0.062670 	 lr: 0.00006
[epoch 188: 220/307] 	 train loss: 0.222094 	 lr: 0.00006

val loss: 0.362263 	 acc: 0.909643

[epoch 188: 240/307] 	 train loss: 0.041798 	 lr: 0.00006
[epoch 188: 260/307] 	 train loss: 0.198977 	 lr: 0.00006
[epoch 188: 280/307] 	 train loss: 0.049101 	 lr: 0.00006
[epoch 188: 300/307] 	 train loss: 0.234002 	 lr: 0.00006
[epoch 189:   0/307] 	 train loss: 0.128660 	 lr: 0.00006
[epoch 189:  20/307] 	 train loss: 0.289225 	 lr: 0.00006
[epoch 189:  40/307] 	 train loss: 0.245251 	 lr: 0.00006
[epoch 189:  60/307] 	 train loss: 0.178933 	 lr: 0.00006
[epoch 189:  80/307] 	 train loss: 0.102052 	 lr: 0.00006

val loss: 0.340958 	 acc: 0.916937

[epoch 189: 100/307] 	 train loss: 0.221119 	 lr: 0.00006
[epoch 189: 120/307] 	 train loss: 0.135928 	 lr: 0.00006
[epoch 189: 140/307] 	 train loss: 0.094607 	 lr: 0.00006
[epoch 189: 160/307] 	 train loss: 0.055841 	 lr: 0.00006
[epoch 189: 180/307] 	 train loss: 0.070119 	 lr: 0.00006
[epoch 189: 200/307] 	 train loss: 0.099295 	 lr: 0.00006
[epoch 189: 220/307] 	 train loss: 0.140443 	 lr: 0.00006

val loss: 0.341324 	 acc: 0.913695

[epoch 189: 240/307] 	 train loss: 0.242425 	 lr: 0.00006
[epoch 189: 260/307] 	 train loss: 0.243509 	 lr: 0.00006
[epoch 189: 280/307] 	 train loss: 0.089609 	 lr: 0.00006
[epoch 189: 300/307] 	 train loss: 0.110056 	 lr: 0.00006
[epoch 190:   0/307] 	 train loss: 0.184952 	 lr: 0.00004
[epoch 190:  20/307] 	 train loss: 0.236191 	 lr: 0.00004
[epoch 190:  40/307] 	 train loss: 0.407624 	 lr: 0.00004
[epoch 190:  60/307] 	 train loss: 0.201078 	 lr: 0.00004
[epoch 190:  80/307] 	 train loss: 0.182966 	 lr: 0.00004

val loss: 0.343376 	 acc: 0.914911

[epoch 190: 100/307] 	 train loss: 0.205247 	 lr: 0.00004
[epoch 190: 120/307] 	 train loss: 0.110521 	 lr: 0.00004
[epoch 190: 140/307] 	 train loss: 0.350308 	 lr: 0.00004
[epoch 190: 160/307] 	 train loss: 0.058399 	 lr: 0.00004
[epoch 190: 180/307] 	 train loss: 0.058613 	 lr: 0.00004
[epoch 190: 200/307] 	 train loss: 0.022022 	 lr: 0.00004
[epoch 190: 220/307] 	 train loss: 0.202629 	 lr: 0.00004

val loss: 0.365624 	 acc: 0.911669

[epoch 190: 240/307] 	 train loss: 0.240571 	 lr: 0.00004
[epoch 190: 260/307] 	 train loss: 0.297373 	 lr: 0.00004
[epoch 190: 280/307] 	 train loss: 0.142165 	 lr: 0.00004
[epoch 190: 300/307] 	 train loss: 0.188543 	 lr: 0.00004
[epoch 191:   0/307] 	 train loss: 0.304655 	 lr: 0.00004
[epoch 191:  20/307] 	 train loss: 0.204100 	 lr: 0.00004
[epoch 191:  40/307] 	 train loss: 0.225002 	 lr: 0.00004
[epoch 191:  60/307] 	 train loss: 0.182583 	 lr: 0.00004

val loss: 0.347394 	 acc: 0.912480

[epoch 191:  80/307] 	 train loss: 0.198279 	 lr: 0.00004
[epoch 191: 100/307] 	 train loss: 0.017497 	 lr: 0.00004
[epoch 191: 120/307] 	 train loss: 0.244728 	 lr: 0.00004
[epoch 191: 140/307] 	 train loss: 0.037261 	 lr: 0.00004
[epoch 191: 160/307] 	 train loss: 0.160788 	 lr: 0.00004
[epoch 191: 180/307] 	 train loss: 0.116182 	 lr: 0.00004
[epoch 191: 200/307] 	 train loss: 0.075602 	 lr: 0.00004
[epoch 191: 220/307] 	 train loss: 0.059813 	 lr: 0.00004

val loss: 0.331358 	 acc: 0.912075

[epoch 191: 240/307] 	 train loss: 0.040140 	 lr: 0.00004
[epoch 191: 260/307] 	 train loss: 0.027352 	 lr: 0.00004
[epoch 191: 280/307] 	 train loss: 0.111663 	 lr: 0.00004
[epoch 191: 300/307] 	 train loss: 0.210531 	 lr: 0.00004
[epoch 192:   0/307] 	 train loss: 0.146779 	 lr: 0.00004
[epoch 192:  20/307] 	 train loss: 0.111918 	 lr: 0.00004
[epoch 192:  40/307] 	 train loss: 0.061996 	 lr: 0.00004
[epoch 192:  60/307] 	 train loss: 0.228757 	 lr: 0.00004

val loss: 0.346594 	 acc: 0.916532

[epoch 192:  80/307] 	 train loss: 0.021793 	 lr: 0.00004
[epoch 192: 100/307] 	 train loss: 0.114368 	 lr: 0.00004
[epoch 192: 120/307] 	 train loss: 0.327133 	 lr: 0.00004
[epoch 192: 140/307] 	 train loss: 0.104882 	 lr: 0.00004
[epoch 192: 160/307] 	 train loss: 0.161277 	 lr: 0.00004
[epoch 192: 180/307] 	 train loss: 0.175500 	 lr: 0.00004
[epoch 192: 200/307] 	 train loss: 0.259957 	 lr: 0.00004
[epoch 192: 220/307] 	 train loss: 0.398950 	 lr: 0.00004

val loss: 0.351174 	 acc: 0.909643

[epoch 192: 240/307] 	 train loss: 0.064070 	 lr: 0.00004
[epoch 192: 260/307] 	 train loss: 0.113852 	 lr: 0.00004
[epoch 192: 280/307] 	 train loss: 0.117056 	 lr: 0.00004
[epoch 192: 300/307] 	 train loss: 0.099720 	 lr: 0.00004
[epoch 193:   0/307] 	 train loss: 0.299436 	 lr: 0.00004
[epoch 193:  20/307] 	 train loss: 0.193746 	 lr: 0.00004
[epoch 193:  40/307] 	 train loss: 0.233059 	 lr: 0.00004
[epoch 193:  60/307] 	 train loss: 0.083327 	 lr: 0.00004

val loss: 0.353862 	 acc: 0.908833

[epoch 193:  80/307] 	 train loss: 0.076576 	 lr: 0.00004
[epoch 193: 100/307] 	 train loss: 0.233962 	 lr: 0.00004
[epoch 193: 120/307] 	 train loss: 0.173195 	 lr: 0.00004
[epoch 193: 140/307] 	 train loss: 0.198289 	 lr: 0.00004
[epoch 193: 160/307] 	 train loss: 0.082964 	 lr: 0.00004
[epoch 193: 180/307] 	 train loss: 0.155828 	 lr: 0.00004
[epoch 193: 200/307] 	 train loss: 0.099675 	 lr: 0.00004
[epoch 193: 220/307] 	 train loss: 0.376059 	 lr: 0.00004

val loss: 0.334624 	 acc: 0.908023

[epoch 193: 240/307] 	 train loss: 0.110228 	 lr: 0.00004
[epoch 193: 260/307] 	 train loss: 0.140421 	 lr: 0.00004
[epoch 193: 280/307] 	 train loss: 0.083184 	 lr: 0.00004
[epoch 193: 300/307] 	 train loss: 0.146508 	 lr: 0.00004
[epoch 194:   0/307] 	 train loss: 0.205887 	 lr: 0.00004
[epoch 194:  20/307] 	 train loss: 0.260964 	 lr: 0.00004
[epoch 194:  40/307] 	 train loss: 0.283475 	 lr: 0.00004
[epoch 194:  60/307] 	 train loss: 0.075295 	 lr: 0.00004

val loss: 0.345428 	 acc: 0.911264

[epoch 194:  80/307] 	 train loss: 0.043235 	 lr: 0.00004
[epoch 194: 100/307] 	 train loss: 0.108335 	 lr: 0.00004
[epoch 194: 120/307] 	 train loss: 0.151704 	 lr: 0.00004
[epoch 194: 140/307] 	 train loss: 0.063273 	 lr: 0.00004
[epoch 194: 160/307] 	 train loss: 0.091541 	 lr: 0.00004
[epoch 194: 180/307] 	 train loss: 0.193744 	 lr: 0.00004
[epoch 194: 200/307] 	 train loss: 0.150197 	 lr: 0.00004
[epoch 194: 220/307] 	 train loss: 0.048488 	 lr: 0.00004

val loss: 0.344724 	 acc: 0.913290

[epoch 194: 240/307] 	 train loss: 0.032352 	 lr: 0.00004
[epoch 194: 260/307] 	 train loss: 0.137910 	 lr: 0.00004
[epoch 194: 280/307] 	 train loss: 0.120686 	 lr: 0.00004
[epoch 194: 300/307] 	 train loss: 0.159494 	 lr: 0.00004
[epoch 195:   0/307] 	 train loss: 0.177349 	 lr: 0.00004
[epoch 195:  20/307] 	 train loss: 0.288173 	 lr: 0.00004
[epoch 195:  40/307] 	 train loss: 0.181892 	 lr: 0.00004
[epoch 195:  60/307] 	 train loss: 0.290452 	 lr: 0.00004

val loss: 0.341008 	 acc: 0.914911

[epoch 195:  80/307] 	 train loss: 0.187934 	 lr: 0.00004
[epoch 195: 100/307] 	 train loss: 0.162088 	 lr: 0.00004
[epoch 195: 120/307] 	 train loss: 0.166680 	 lr: 0.00004
[epoch 195: 140/307] 	 train loss: 0.010326 	 lr: 0.00004
[epoch 195: 160/307] 	 train loss: 0.025706 	 lr: 0.00004
[epoch 195: 180/307] 	 train loss: 0.075717 	 lr: 0.00004
[epoch 195: 200/307] 	 train loss: 0.060145 	 lr: 0.00004
[epoch 195: 220/307] 	 train loss: 0.243402 	 lr: 0.00004

val loss: 0.346731 	 acc: 0.912480

[epoch 195: 240/307] 	 train loss: 0.052760 	 lr: 0.00004
[epoch 195: 260/307] 	 train loss: 0.087870 	 lr: 0.00004
[epoch 195: 280/307] 	 train loss: 0.063470 	 lr: 0.00004
[epoch 195: 300/307] 	 train loss: 0.296693 	 lr: 0.00004
[epoch 196:   0/307] 	 train loss: 0.163802 	 lr: 0.00004
[epoch 196:  20/307] 	 train loss: 0.088317 	 lr: 0.00004
[epoch 196:  40/307] 	 train loss: 0.031885 	 lr: 0.00004
[epoch 196:  60/307] 	 train loss: 0.040572 	 lr: 0.00004

val loss: 0.347386 	 acc: 0.919368

[epoch 196:  80/307] 	 train loss: 0.283285 	 lr: 0.00004
[epoch 196: 100/307] 	 train loss: 0.215465 	 lr: 0.00004
[epoch 196: 120/307] 	 train loss: 0.065644 	 lr: 0.00004
[epoch 196: 140/307] 	 train loss: 0.034948 	 lr: 0.00004
[epoch 196: 160/307] 	 train loss: 0.043649 	 lr: 0.00004
[epoch 196: 180/307] 	 train loss: 0.152173 	 lr: 0.00004
[epoch 196: 200/307] 	 train loss: 0.133552 	 lr: 0.00004
[epoch 196: 220/307] 	 train loss: 0.208820 	 lr: 0.00004

val loss: 0.337554 	 acc: 0.911264

[epoch 196: 240/307] 	 train loss: 0.154863 	 lr: 0.00004
[epoch 196: 260/307] 	 train loss: 0.148293 	 lr: 0.00004
[epoch 196: 280/307] 	 train loss: 0.049935 	 lr: 0.00004
[epoch 196: 300/307] 	 train loss: 0.080325 	 lr: 0.00004
[epoch 197:   0/307] 	 train loss: 0.007999 	 lr: 0.00004
[epoch 197:  20/307] 	 train loss: 0.088442 	 lr: 0.00004
[epoch 197:  40/307] 	 train loss: 0.024305 	 lr: 0.00004
[epoch 197:  60/307] 	 train loss: 0.098946 	 lr: 0.00004

val loss: 0.342363 	 acc: 0.914911

[epoch 197:  80/307] 	 train loss: 0.022041 	 lr: 0.00004
[epoch 197: 100/307] 	 train loss: 0.160543 	 lr: 0.00004
[epoch 197: 120/307] 	 train loss: 0.051113 	 lr: 0.00004
[epoch 197: 140/307] 	 train loss: 0.217548 	 lr: 0.00004
[epoch 197: 160/307] 	 train loss: 0.208508 	 lr: 0.00004
[epoch 197: 180/307] 	 train loss: 0.173600 	 lr: 0.00004
[epoch 197: 200/307] 	 train loss: 0.089829 	 lr: 0.00004

val loss: 0.331695 	 acc: 0.915721

[epoch 197: 220/307] 	 train loss: 0.187979 	 lr: 0.00004
[epoch 197: 240/307] 	 train loss: 0.051050 	 lr: 0.00004
[epoch 197: 260/307] 	 train loss: 0.221995 	 lr: 0.00004
[epoch 197: 280/307] 	 train loss: 0.133825 	 lr: 0.00004
[epoch 197: 300/307] 	 train loss: 0.098897 	 lr: 0.00004
[epoch 198:   0/307] 	 train loss: 0.279980 	 lr: 0.00004
[epoch 198:  20/307] 	 train loss: 0.181337 	 lr: 0.00004
[epoch 198:  40/307] 	 train loss: 0.314254 	 lr: 0.00004
[epoch 198:  60/307] 	 train loss: 0.218988 	 lr: 0.00004

val loss: 0.344623 	 acc: 0.912885

[epoch 198:  80/307] 	 train loss: 0.316797 	 lr: 0.00004
[epoch 198: 100/307] 	 train loss: 0.130824 	 lr: 0.00004
[epoch 198: 120/307] 	 train loss: 0.112544 	 lr: 0.00004
[epoch 198: 140/307] 	 train loss: 0.066727 	 lr: 0.00004
[epoch 198: 160/307] 	 train loss: 0.032748 	 lr: 0.00004
[epoch 198: 180/307] 	 train loss: 0.150468 	 lr: 0.00004
[epoch 198: 200/307] 	 train loss: 0.185571 	 lr: 0.00004

val loss: 0.342569 	 acc: 0.910859

[epoch 198: 220/307] 	 train loss: 0.422483 	 lr: 0.00004
[epoch 198: 240/307] 	 train loss: 0.048016 	 lr: 0.00004
[epoch 198: 260/307] 	 train loss: 0.050039 	 lr: 0.00004
[epoch 198: 280/307] 	 train loss: 0.106034 	 lr: 0.00004
[epoch 198: 300/307] 	 train loss: 0.125362 	 lr: 0.00004
[epoch 199:   0/307] 	 train loss: 0.230871 	 lr: 0.00004
[epoch 199:  20/307] 	 train loss: 0.100771 	 lr: 0.00004
[epoch 199:  40/307] 	 train loss: 0.087409 	 lr: 0.00004
[epoch 199:  60/307] 	 train loss: 0.139843 	 lr: 0.00004

val loss: 0.353561 	 acc: 0.914100

[epoch 199:  80/307] 	 train loss: 0.179289 	 lr: 0.00004
[epoch 199: 100/307] 	 train loss: 0.085634 	 lr: 0.00004
[epoch 199: 120/307] 	 train loss: 0.051780 	 lr: 0.00004
[epoch 199: 140/307] 	 train loss: 0.066607 	 lr: 0.00004
[epoch 199: 160/307] 	 train loss: 0.125476 	 lr: 0.00004
[epoch 199: 180/307] 	 train loss: 0.183062 	 lr: 0.00004
[epoch 199: 200/307] 	 train loss: 0.094746 	 lr: 0.00004

val loss: 0.351474 	 acc: 0.911264

[epoch 199: 220/307] 	 train loss: 0.317709 	 lr: 0.00004
[epoch 199: 240/307] 	 train loss: 0.310858 	 lr: 0.00004
[epoch 199: 260/307] 	 train loss: 0.146365 	 lr: 0.00004
[epoch 199: 280/307] 	 train loss: 0.090520 	 lr: 0.00004
[epoch 199: 300/307] 	 train loss: 0.181769 	 lr: 0.00004
[epoch 200:   0/307] 	 train loss: 0.056691 	 lr: 0.00004
[epoch 200:  20/307] 	 train loss: 0.061950 	 lr: 0.00004
[epoch 200:  40/307] 	 train loss: 0.320292 	 lr: 0.00004
[epoch 200:  60/307] 	 train loss: 0.173194 	 lr: 0.00004

val loss: 0.342896 	 acc: 0.914911

[epoch 200:  80/307] 	 train loss: 0.166772 	 lr: 0.00004
[epoch 200: 100/307] 	 train loss: 0.158394 	 lr: 0.00004
[epoch 200: 120/307] 	 train loss: 0.056116 	 lr: 0.00004
[epoch 200: 140/307] 	 train loss: 0.359257 	 lr: 0.00004
[epoch 200: 160/307] 	 train loss: 0.042989 	 lr: 0.00004
[epoch 200: 180/307] 	 train loss: 0.289458 	 lr: 0.00004
[epoch 200: 200/307] 	 train loss: 0.085005 	 lr: 0.00004

val loss: 0.362505 	 acc: 0.911669

[epoch 200: 220/307] 	 train loss: 0.094402 	 lr: 0.00004
[epoch 200: 240/307] 	 train loss: 0.113346 	 lr: 0.00004
[epoch 200: 260/307] 	 train loss: 0.078016 	 lr: 0.00004
[epoch 200: 280/307] 	 train loss: 0.067672 	 lr: 0.00004
[epoch 200: 300/307] 	 train loss: 0.099250 	 lr: 0.00004
